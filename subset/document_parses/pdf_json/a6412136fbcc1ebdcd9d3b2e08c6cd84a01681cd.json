{
    "paper_id": "a6412136fbcc1ebdcd9d3b2e08c6cd84a01681cd",
    "metadata": {
        "title": "What is the suitability of clinical vignettes in benchmarking the performance of online symptom checkers? An audit study",
        "authors": []
    },
    "abstract": [
        {
            "text": "To assess the suitability of primary care vignettes in benchmarking the performance of online symptom checkers",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Observational study using publicly available, free online symptom checkers",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Three symptom checkers (Healthily, Ada and Babylon) that provided consultations in English. 139 standardized patient vignettes were compiled by RCGP. Three independent GPs interpreted the vignettes to arrive at a \"Gold Standard\" consisting of 3 dispositions and divided into one of three categories of triage urgency: (1) emergency care required, (2) primary care required and (3) self-care.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Six professional non-medical and lay inputters simulated 2774 standardized patient evaluations using 3 online symptom checkers (OSC). We recorded when OSC provided a triage recommendation and whether it correctly recommended the appropriate triage recommendation across three categories of triage urgency (emergency care, primary care or self-care). We collected data on whether the solution appeared within the first 3 dispositions in each of the standards across 2774 standardized patient evaluations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "When benchmarked against the Gold Standard, Healthily provided an appropriate triage recommendation 61.9% of the time compared to 45.3% and 42.4% of the time for Babylon and Ada respectively. There was poor agreement between OSC consultation outcome and Gold Standard dispositions. When compared to the Gold Standard, Healthily gave an unsafe \"under-triage\" recommendation 28.6% of the time overall across the three categories compared to 43.3% for Ada and 47.5% for Babylon (P<0.001).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "OSCs recommended 'very unsafe' triages only <4% of the time suggesting that the online consultation tools are generally working at a safe level of risk. Primary care vignettes are a helpful tool to support development of OSC, but not ideally suited to benchmark the performance of different OSC. Real-world evidence studies involving general practice are recommended to benchmark the performance of OSC in the community setting.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "I, the Submitting Author has the right to grant and does grant on behalf of all authors of the Work (as defined in the below author licence), an exclusive licence and/or a non-exclusive licence for contributions from authors who are: i) UK Crown employees; ii) where BMJ has agreed a CC-BY licence shall apply, and/or iii) in accordance with the terms applicable for US Federal Government officers or employees acting as part of their official duties; on a worldwide, perpetual, irrevocable, royalty-free basis to BMJ Publishing Group Ltd (\"BMJ\") its licensees and where the relevant Journal is co-owned by BMJ to the co-owners of the Journal, to publish the Work in this journal and any other BMJ products and to exploit all rights, as set out in our licence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The Submitting Author accepts and understands that any supply made under these terms is made by BMJ to the Submitting Author unless you are acting as an employee on behalf of your employer or a postgraduate student of an affiliated institution which is paying any applicable article publishing charge (\"APC\") for Open Access articles. Where the Submitting Author wishes to make the Work available on an Open Access basis (and intends to pay the relevant APC), the terms of reuse of such Open Access shall be governed by a Creative Commons licence -details of these licences and which Creative Commons licence will apply to this Work are set out in our licence referred to above.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Other than as permitted in any relevant BMJ Author's Self Archiving Policies, I confirm this Work has not been accepted for publication elsewhere, is not being considered for publication elsewhere and does not duplicate material already published. I confirm all authors consent to publication of this Work and authorise the granting of this licence. What is the suitability of clinical vignettes in benchmarking the performance of online symptom checkers? An audit study 1 Strengths and limitations of this study \uf0b7 139 independently created primary care vignettes covering 18 subcategories of primary care were used to benchmark the performance of three online symptom checkers using 2774 unique patient simulations \uf0b7 A gold standard for each primary care vignette was derived using GP roundtables and single blinded testing \uf0b7 We investigated the extent that different inputters using the same vignette and online symptom checker received differing consultation outcomes and triage recommendations \uf0b7 We developed an accuracy matrix to objectively monitor online symptom checker consultation outcome and the safety of the triage recommendation \uf0b7 Limitations included a different number of inputters to simulate patients across the three online symptom checkers tested ",
            "cite_spans": [
                {
                    "start": 471,
                    "end": 472,
                    "text": "1",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "In the USA, over a third of adults self-diagnose their conditions using the internet, including queries about urgent (i.e., chest pain) and non-urgent (i.e., headache) symptoms (1, 2) . The main issue with self-diagnosing using websites such as Google and Yahoo is that the users may get confused or receive inaccurate information, and in the case of urgent symptoms, the users may not appreciate the need to seek emergency care (3) . In recent years, various online symptom checkers (OSC) based on algorithms or artificial intelligence (AI) have emerged to fill this gap.",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 180,
                    "text": "(1,",
                    "ref_id": null
                },
                {
                    "start": 181,
                    "end": 183,
                    "text": "2)",
                    "ref_id": null
                },
                {
                    "start": 429,
                    "end": 432,
                    "text": "(3)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "OSCs are calculators that ask users to input details about their symptoms of sickness, along with personal information such as gender and age. Using algorithms or AI, the symptom checkers propose a range of conditions that fit the symptoms the user experiences. Developers promote these digital tools as a way of saving time for patients, reducing anxiety and giving patients the opportunity to take control of their own health (4) (5) (6) . The diagnostic function of OSC is aimed at educating users on the range of possible conditions that may fit their symptoms. Further to present a condition outcome and give the users a triage recommendation that prioritises their health needs. The triage function of OSC guides users on whether they should self-care for the condition they are describing or whether they should seek professional healthcare support (3) . This added functionality could vastly enhance the usefulness of OSC by alerting people about when they need to seek emergency support or seek non-emergency care for common or self-limiting conditions (7) .",
            "cite_spans": [
                {
                    "start": 428,
                    "end": 431,
                    "text": "(4)",
                    "ref_id": null
                },
                {
                    "start": 432,
                    "end": 435,
                    "text": "(5)",
                    "ref_id": null
                },
                {
                    "start": 436,
                    "end": 439,
                    "text": "(6)",
                    "ref_id": null
                },
                {
                    "start": 856,
                    "end": 859,
                    "text": "(3)",
                    "ref_id": null
                },
                {
                    "start": 1062,
                    "end": 1065,
                    "text": "(7)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Babylon has claimed that their OSC performed better than the average doctor on a subsection of the Royal College of General Practitioners (RCGP) exam (8) . This claim has been supported by an internal evaluation study (9) , but the findings were later considered uncertain due to methodological concerns (10, 11) . Misdiagnosis of patients with life-threatening conditions could worsen their health, especially if they are not told to seek care when they should, resulting in an increased risk of preventable morbidity and mortality. In spite of this, there has been little evidence in previous literature to suggest if OSC are harmful to patients (12, 13) . However, OSC that have high false-negative rates may run similar risks if used by patients with high-risk disease such as cardiac ischaemia, pulmonary embolism or meningitis (5) . With this in mind, it is extremely important that there are guidelines on robust evaluation of OSC regarding patient safety, efficacy, effectiveness and cost (5) .",
            "cite_spans": [
                {
                    "start": 150,
                    "end": 153,
                    "text": "(8)",
                    "ref_id": null
                },
                {
                    "start": 218,
                    "end": 221,
                    "text": "(9)",
                    "ref_id": null
                },
                {
                    "start": 304,
                    "end": 308,
                    "text": "(10,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 309,
                    "end": 312,
                    "text": "11)",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 648,
                    "end": 652,
                    "text": "(12,",
                    "ref_id": null
                },
                {
                    "start": 653,
                    "end": 656,
                    "text": "13)",
                    "ref_id": null
                },
                {
                    "start": 833,
                    "end": 836,
                    "text": "(5)",
                    "ref_id": null
                },
                {
                    "start": 997,
                    "end": 1000,
                    "text": "(5)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Very little research has been done on the performance of symptom checkers for actual patients (14) (15) (16) (17) (18) (19) . Equally, there is a limited number of studies that attempted to benchmark the performance of different OSC using clinical vignettes (20) (21) (22) (23) (24) (25) (26) . A recent study compared the breadth of condition coverage, accuracy of suggested conditions and appropriateness of urgency advice of eight popular OSC (24) , and showed that the best performing OSCs have a high level of urgency advice accuracy which is close to that of GPs and are close to GP performance in providing the correct condition in their top-3 condition suggestions OSC (24) . However, it remains uncertain if clinical vignettes are ideal to investigate the accuracy and safety of OSC generally. To address this gap in knowledge, we worked in collaboration with RCGP to develop a methodology to determine if clinical vignettes were a suitable tool that can be used to benchmark the performance of different OSC.",
            "cite_spans": [
                {
                    "start": 94,
                    "end": 98,
                    "text": "(14)",
                    "ref_id": null
                },
                {
                    "start": 99,
                    "end": 103,
                    "text": "(15)",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 104,
                    "end": 108,
                    "text": "(16)",
                    "ref_id": null
                },
                {
                    "start": 109,
                    "end": 113,
                    "text": "(17)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 114,
                    "end": 118,
                    "text": "(18)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 119,
                    "end": 123,
                    "text": "(19)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 258,
                    "end": 262,
                    "text": "(20)",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 263,
                    "end": 267,
                    "text": "(21)",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 268,
                    "end": 272,
                    "text": "(22)",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "(23)",
                    "ref_id": null
                },
                {
                    "start": 278,
                    "end": 282,
                    "text": "(24)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 283,
                    "end": 287,
                    "text": "(25)",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 288,
                    "end": 292,
                    "text": "(26)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 446,
                    "end": 450,
                    "text": "(24)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 677,
                    "end": 681,
                    "text": "(24)",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Our approach included the creation of an independent source of vignettes from RCGP to arrive at a \"Gold Standard\" of medical opinion that worked from the condition to the outcome and the vignette to the outcome -as non-currently exists. The Gold Standard was used to explore the issues we faced with variable interpretations of vignettes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The primary aim of this study was to assess the suitability of primary care vignettes in benchmarking the performance of online symptom checkers. The secondary aim was to benchmark the safety and efficacy of a three popular online symptom checkers (Healthily, Ada and Babylon) against current Gold Standard. Safety was defined as giving the appropriate triage recommendation (the primary outcome) relative to the current Gold Standard, whereas accuracy was defined as providing the correct outcome consultation (the secondary outcome) for each vignette. We also sought to investigate the extent that interpretations of the same vignette by different inputters could lead to different outputs using the same OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Study aim"
        },
        {
            "text": "139 primary care clinical vignettes representing 18 sub-categories of primary care (Table 1) were devised as illustrated in Figure 1 . This involved a series of roundtables discussions at the Royal College of General Practitioners (RCGP) and consolidation of additional deliberations by independent GP partners to arrive at the Gold Standard. Figure 2 shows the testing process of the online symptom checkers (OSC) by three lay and four professional non-doctor inputters using the Gold Standard vignettes. This allowed us to benchmark the performance of online symptom checkers and to determine if clinical vignettes are a suitable methodology to compare the performance of OSC.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 83,
                    "end": 92,
                    "text": "(Table 1)",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 124,
                    "end": 132,
                    "text": "Figure 1",
                    "ref_id": null
                },
                {
                    "start": 343,
                    "end": 351,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "METHODS"
        },
        {
            "text": "A roundtable of experienced General Practitioners (GP) affiliated to the RCGP supported the development of 139 primary care vignettes. The vignettes were designed to include both common and less-common conditions relevant to general practice, including clinical presentations and conditions representing 18 sub-categories of primary care ( Table 1) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 340,
                    "end": 348,
                    "text": "Table 1)",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Clinical vignette creation"
        },
        {
            "text": "Most of the clinical vignettes described new presentations by adults (18yr-65yr) but assumed that none of the patients were pregnant or had any prior or existing long-term conditions such as diabetes, hypertension, cardiovascular disease, terminal illness or other co-morbidity. Each vignette was created with a list of 3 reasonable condition outcomes, and an appropriate triage recommendation arrived at through the majority decision of the vignette creation RCGP Roundtable. 5   Oncology  0  1  2  3  0  1  7  Eye  1  0  0  3  1  0  5  Respiratory  3  1  5  2  0  2  13  Rheumatoid  0  2  3  0  1  0  6  Surgical  1  3  0  0  3  3  10  Women's health  0  0  1  2  1  0  4  Total  22  29  28  28  17  15  139 Vignette characteristics Each vignette (V) script was assigned with three dispositions (D1-D3) describing the most likely 'diagnosis' in D1, and the least likely in D3 (figure 1). Each vignette was also given a triage recommendation (T) which was based on the most likely outcome (D1), and could assigned to any one of three categories: (1) Self-Care (i.e., see pharmacist, self-limiting condition or self-care); (2) Primary Care (i.e., see GP/Doctor in 12hr, 48hr or 2 weeks), or (3) Emergency Care (i.e., seek emergency treatment, or call ambulance). The characteristics of each vignette can be summarised in a simple 5-item cellular configuration illustrating the arrangement of D1, D2 & D3 and the T for each V (figures1 & 2).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 477,
                    "end": 709,
                    "text": "5   Oncology  0  1  2  3  0  1  7  Eye  1  0  0  3  1  0  5  Respiratory  3  1  5  2  0  2  13  Rheumatoid  0  2  3  0  1  0  6  Surgical  1  3  0  0  3  3  10  Women's health  0  0  1  2  1  0  4  Total  22  29  28  28  17  15  139",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Clinical vignette creation"
        },
        {
            "text": "We provided the vignette scripts to 3 GPs affiliated to Imperial College London that had no connection with any of the OSC providers. The list of 139 vignettes were provided without the diagnosis or triage recommendations proposed by the RCGP roundtable. We asked the GPs to independently deliberate on each vignette and record up to three dispositions and one triage recommendation. The triage recommendation was again based on the most serious disposition for each vignette. This resulted in the genesis of an alternative standard to the one provided by the RCGP (figure 1). This so called 'External GP (Imperial) Standard' was then considered in light of the RCGP Standard and both were consolidated to arrive at the Current Gold Standard (figure 2). The Gold Standard was used to benchmark the performance of all three online symptom checkers. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "External review of vignette by independent GPs"
        },
        {
            "text": "Lay and professional non-doctor inputters (n=6) used the vignettes to independently record the consultation outcome and triage recommendation from Healthily, Ada and Babylon OSC. Only one professional non-doctor inputter recorded the consultation outcome and triage recommendation using Ada and Babylon OSC for all 139 vignettes. Interpretation of the vignette script was left to the individual inputters who did not have any additional information. The inputters were instructed to make the following blanket assumptions when answering the questions posed by the OSCs for each vignette: the simulated patient is a non-smoker, not pregnant, not obese, not taking medication, not diabetic, not hypertensive, has no history of heart disease asthma, cancer, cystic fibrosis or other concerning or significant medical history, with no recent (3 months) sexual activity. Inputters were instructed to not include more than three consecutive symptoms in a single answer to any questions posed by the OSCs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Patient simulation by lay and professional non-doctor inputters"
        },
        {
            "text": "Different OSCs may give up to 7 consultation outcomes (range= 0-3 for Healthily, 0-5 for Ada, and 0-7 for Babylon) and a triage recommendation may or may not be provided. Inputters independently simulated the patient described in each vignette and recorded the consultation outcome using an electronic OSC consultation record form. Data were collected on up to 3 keywords used during input, details of any inputted keyword recognised by OSC, the first 3 consultation outcomes (if any) provided by OSC, the triage recommendation (if any) and whether the inputter was signposted to relevant information at end.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recording output from online symptom checkers"
        },
        {
            "text": "To support with data management and analysis of output from OSC, we developed a simple framework. We assessed output parameters for each vignette using all three OSCs against the dispositions of the three standards (RCGP, Imperial and Gold standards). We assigned a three-digit numeric score to objectively characterise the level of agreement between the three dispositions (D1, D2, D3) in each standard and the consultation outcome for each vignette: \uf0b7 3: Full agreement; Correct consultation outcome in the exact same position as the disposition cell in the RCGP standard \uf0b7 2: Partial agreement; Correct consultation outcome, but 1 cell apart from the RCGP disposition (e.g., D1 placement is found in D2, or D2 placement found in either D1 or D3 juxtaposing cell) \uf0b7 1: Partial agreement; Correct consultation outcome, but 2 cells apart from the RCGP disposition (e.g., D1 placement is found in D3 or vice versa) \uf0b7 0: No agreement; Incorrect consultation outcome in any cell, and not relating to any RCGP disposition \uf0b7 9: Null, or no output provided",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Consultation outcome data coding"
        },
        {
            "text": "The resulting 3-digit score described an output pattern that could be objectively scored and weighted to benchmark the performance of different OSCs against each vignette standard. Of the 125 possible permutation of the 3-digit score, only 59 combinations (supplementary table 1 ). The same terminology was used to describe the level of agreement between the dispositions in each Standard and OSC main triage recommendation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 256,
                    "end": 278,
                    "text": "(supplementary table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Consultation outcome data coding"
        },
        {
            "text": "The consultation outcomes and triage recommendations from Healthily, Ada and Babylon OSC were compared to the RCGP, Imperial and the Gold standards for each vignette (figure 3). We investigated the extent that different interpretations of the same vignette by different inputters resulted in different consultation outcomes when using the same OSC (Healthily). Descriptive analysis was used to assess the accuracy and safety of Healthily (using 6 inputters), Ada (using 1 inputter) and Babylon (using 1 inputter) against all three standards (the original RCGP standard, the Imperial standard from three external GP partners, and the consolidated Gold standard). Data were expressed in frequencies, proportions and 95% Confidence intervals (CI). Pearson's Chi-square test and Fisher's exact test were used to determine whether there was a difference in signposting, the provision of a consultation outcome or a triage recommendation by different inputters using the same OSC and vignette. Significance was noted when p-value was <0.05. The statistical analysis was performed using StataCorp. 2019. Stata Statistical Software, Release 16.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Statistical analysis"
        },
        {
            "text": "Patient and public involvement (PPI) was embedded in this project. Two lay non-doctor inputters were involved in the collection of output data from Healthily OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Patient and Public involvement"
        },
        {
            "text": "We compared the consultation outcome from Healthily OSC of two lay inputters against the output recorded by four professional non-doctor inputters to determine the extent that individuals could interpret the same vignette differently (table 2; figure 4). A significant difference was observed for consultation outcomes in disposition cells one (p<0.001) and three (p=0.03) between both type of non-doctor inputters), but not for disposition cell two (p=0.30) or the single triage option (p=0.93). ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparing interpretation of the same vignette by different inputters"
        },
        {
            "text": "There was no significant difference in signposting between professional inputters when using Healthily OSC (p=0.23). However, there was a significant difference between the two lay inputters (p<0.001), and between the professional (n=4) and lay (n=2) inputters when compared as a group (p<0.001). There was significant variation between inputters with respect to whether the same OSC (Healthily) provided signposting at the end for the same vignette, regardless of whether the simulation resulted in a triage recommendation or not but when there was no triage recommendation (p<0.001; table 3). The difference disappeared when no triage recommendation was provided (p=0.21). There was a good level of agreement overall (74.6%) between the consolidated triage recommendations of the three external GPs (the Imperial Standard) and the RCGP Standard (table 6) . There was also a good level of agreement (72.2%) between the consolidated Imperial Standard when assessed against the RCGP Standard at disposition cell one (D1), 31.2% at D2 and 12.5% at D3 (table 6). . Healthily was significantly more likely to recommend safe triages for vignettes indicating primary care than Ada (p<0.001), but the difference did not reach the level of significance when compared to Babylon (p=0.07). Similarly, Healthily was significantly more likely to recommend safe triages for vignettes indicating emergent care than Ada (p<0.001), but the difference did not reach the level of significance when compared to Babylon (p=0.10), figure 6.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 847,
                    "end": 856,
                    "text": "(table 6)",
                    "ref_id": "TABREF8"
                }
            ],
            "section": "Signposting at end of consultation outcome"
        },
        {
            "text": "This is the first study which directly sought to assess the suitability of clinical vignettes in benchmarking the performance (accuracy and safety) of OSC. To facilitate this, an independent series of primary care vignettes provided by the RCGP describing patient scenarios and symptoms across 18 sub-categories of primary care was needed. This new set was used to compare baseline performance of OSC against two iteratively refined and consolidated standards arising from further deliberations by an additional roundtable of independent general practitioners.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Our study showed significant variability of medical opinion depending on which group of GPs considered the vignette script, whereas consolidating the output of two different GP roundtables (RCGP and Imperial) resulted in a more refined third iteration representing the Gold Standard which by definition most accurately describes the most appropriate 'diagnoses' conferred by the vignette script. The different qualities of each standard suggests that clinical vignettes are not an ideal tool for benchmarking the accuracy of OSC since performance will always be related to the nature and order of the dispositions which we have shown can differ significantly between each standard depending on the approach and levels of input form GP roundtables. By extension, the Gold Standard can always be improved by consolidating the deliberations of a wider range medical opinion until saturation is reached and a final consensus emerges.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Another key factor that may impact the benchmarking of OSC using clinical vignettes even on occasion that a refined Gold Standard is used is related to the inputter's inability to answer truthfully to all questions that could be asked during the online consultation process. This inherent methodological limitation necessitates the use of blanket assumptions (e.g., not pregnant, did not have any recent sexual activity etc.,) which could lead to a different consultation outcome to what would be presented if a real patient who was experiencing the symptoms was the inputter. For example, the significant difference in OSC output from different inputters suggests that the wording of some items needs to be revised to reduce the likelihood of divergent interpretations of the same vignette script. It is inevitable that different people will use different words to describe their conditions, necessitating the use of machine learning to render OSC capable of understanding multiple different descriptions of the same problem. Further, the vignette script is necessarily limited in the number of words, and even if the description and context were expanded it may still not capture all the information necessary to simulate how a real patient may engage with the same OSC. This inherent limitation was illustrated by the finding that different inputters arrived at different consultation outcomes even when using the same vignette script and the same OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "The primary outcome measure in our study was the triage recommendation of the vignette. From the perspective of the RCGP Roundtable, the triage recommendation was always based on the first (most likely) disposition (i.e., D1) for each vignette. This was contrasted in the Gold Standard which assigned a triage recommendation based on the most severe disposition for each vignette regardless of the most likely outcome.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Recommending a triage option that is based on the 'worst case scenario' (above a certain likelihood threshold) is usually recommended as it ensures patient safety. For example, if dispositions 1, 2 & 3 for a vignette were Indigestion, Costochondritis and Heart attack, the triage will be for ambulance based on D3. This is clearly the safer of the two options and the one adopted by Healthily, whereas Ada and Babylon provide a triage consultation based on the first disposition in the series. This may explain why the performance of Healthily, and to a lesser extent Babylon, in recommending safe triages improved when compared to Ada which routinely makes the triage recommendation based on the most likely diagnosis (i.e., D1) as opposed to the most serious disposition in the series.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Pertinently, the independent deliberations of external GPs only agreed with RCGP dispositions on average 72% of time and on triage 74% of the time, but this did not mean that any of the GPs were wrong. When GPs diagnose, they assess probable risk and then investigate implying that primary care assessment is not binary; there is often not a correct answer but rather a series of options that could be explored with the patient to help resolve the symptoms and treat the condition using evidence-based decision refined over time including the use of further tests. By contrast, the provenance of a clinical vignette starts from the condition and builds a story, whereas conversely GPs and OSCs start with the story and then work towards a probable condition. Often, as we saw following the independent deliberations of three independent GPs, there are many possible conditions in the \"area\" a vignette might point towards. We found that often the OSC and the independent GPs were in the right area but not precisely \"correct\". This demonstrates why any claims that an OSC can \"diagnose\" need to be challenged, since GPs do not diagnose and therefore OSCs cannot. Diagnosis can only come after testing and verification of the initial hypothesis, and accurate diagnosis usually includes other aspects such as imaging, pathology results involving the use of point-of-care and other near patient testing procedures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Our study showed that Healthily performance improved by 6% in accuracy and by 18.2% in making an appropriate triage recommendation when benchmarked against the Gold Standard in comparison to the original RCGP Standard. On the whole, OSC recommended 'very unsafe' triages <4% of the time and this suggests that the online consultation tool is generally working at a safe level of probable risk. The OSCs benchmarked appeared to be 'safe' overall as they more frequently made an appropriate triage recommendation or signposted the user to the more urgent triage category as opposed to the other way around. It is reasonable to expect OCs to be 'risk averse' since these decision support tools arrive to a conclusion with limited data and without human interaction (27) . Our audit study had a number of limitations, including that the original RCGP dispositions and appropriate triage recommendations for each vignette offered a baseline for assessment but could not be considered as the Gold Standard prior to further validation and input from an external roundtable of independent GP partners. We also demonstrated a significant variation in how each of the 6 non-doctor inputters interpreted each vignette-thus often arriving at different outcome consultations (and to a lesser extent) triage recommendations when using the same online tool. We addressed this limitation by consolidating the outputs from the four professional nonmedical inputters. In spite of some limitations, the framework and pragmatic methodology used to support the objective development of the Gold Standard consisting of 139 vignettes with congruent dispositions and triage recommendation were suitable to benchmark the performance of online consultation tools. We acknowledge also that the Gold Standard can be developed further by inviting input from a larger number of general practitioners. Further work is indicated to refine the wording of some vignettes since there is a large variation in how different inputters could interpret each item leading to different consultation outcomes and triage recommendation (the main output parameters) when using the same online symptom checkers.",
            "cite_spans": [
                {
                    "start": 762,
                    "end": 766,
                    "text": "(27)",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "There are a number of person-centred and policy implications for the use of OSC. For example, access to healthcare is a major issue and this has become more pronounced since the advent of the Covid-19 pandemic (28) . Improving access to primary care and/or pre-primary care health advice is expected to reduce pressure on urgent and secondary care services, and this is a main driver for the use of a safe and effective OSCs. The widespread diffusion and use of OSC with added functionality can help empower individuals, improve health literacy levels through microlearning (29) , and promote individual self-care capability and the rational use of products and services. This applies especially for OSC that signpost users to relevant information that could help them determine possible next steps regardless of whether or not the OSC provided a triage recommendation or not. At this stage in their development, OSC must be risk averse by avoiding under-triage where patients are directed to a less urgent service. This may have a negative impact on health service resources in that it may result in unnecessary use of urgent or emergency health providers, but may equally result in an earlier diagnosis and appropriate treatment of medical conditions which reduces morbidity, mortality and overall costs in the long term. The correct use of OSC may also decrease the high demand on primary care providers and this utility is especially welcome since the workload for GPs in the UK has increased by 62% from 1995 to 2008 (30) , whereas there has been very little or no increase in the number of GPs per 1,000 population (31) .",
            "cite_spans": [
                {
                    "start": 210,
                    "end": 214,
                    "text": "(28)",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 574,
                    "end": 578,
                    "text": "(29)",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 1522,
                    "end": 1526,
                    "text": "(30)",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 1621,
                    "end": 1625,
                    "text": "(31)",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Clinical vignettes are a helpful tool to benchmark the performance of OSC for research and development purposes, but inherent limitations render them largely unsuitable to compare performance between different OSCs against the Gold Standard. This study showed that online consultation tools are already working at a safe level of probable risk, but further work is recommended to cross-validate the performance of OSC against real-world test case scenarios using real patient stories and interactions with GPs as opposed to using artificial vignettes only which will always be the single most important limitation to any cross-validation study. It is also essential that these tools do not exacerbate the \"digital divide\" and increase health inequalities in groups such as the poor, ethnic minorities and the elderly (32).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "John Norton for PPI input and for testing the symptom checkers, and Drs Aisha Newth, Prakash Chatlani, David Mummery and Benedict Hayhoe for clinical support.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements: The authors thank Ms Noor Jawhar, Ms Christina Pillay and Mr"
        },
        {
            "text": "Author Contributors: All authors provided substantial contributions to the conception (AEO, IW, AA, EB, AM), design (AEO, EB, IW, AA), acquisition (IW, AA, ER), and interpretation (EB, IW, HM, MS) of study data and approved the final version of the paper. AEO took the lead in planning the study with support from co-authors. EB carried out the data analysis with support from AA and MS. AEO is the guarantor.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements: The authors thank Ms Noor Jawhar, Ms Christina Pillay and Mr"
        },
        {
            "text": "No additional data are available Funding: Unconditional funding for this work was provided by Healthily (Imperial Self-Care 2020/1 How missing data on the index test and reference standard were handled 7 & 8",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data sharing statement"
        },
        {
            "text": "Any analyses of variability in diagnostic accuracy, distinguishing pre-specified from exploratory 7 & 8 18",
            "cite_spans": [],
            "ref_spans": [],
            "section": "17"
        },
        {
            "text": "Intended sample size and how it was determined 4",
            "cite_spans": [],
            "ref_spans": [],
            "section": "17"
        },
        {
            "text": "Flow of participants, using a diagram 5 20",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Participants 19"
        },
        {
            "text": "Baseline demographic and clinical characteristics of participants 4 21a Distribution of severity of disease in those with the target condition 4",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Participants 19"
        },
        {
            "text": "21b Distribution of alternative diagnoses in those without the target condition 4 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Participants 19"
        },
        {
            "text": "A diagnostic accuracy study evaluates the ability of one or more medical tests to correctly classify study participants as having a target condition. This can be a disease, a disease stage, response or benefit from therapy, or an event or condition in the future. A medical test can be an imaging procedure, a laboratory test, elements from history and physical examination, a combination of these, or any other method for collecting information about the current health status of a patient.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "The test whose accuracy is evaluated is called index test. A study can evaluate the accuracy of one or more index tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "Evaluating the ability of a medical test to correctly classify patients is typically done by comparing the distribution of the index test results with those of the reference standard. The reference standard is the best available method for establishing the presence or absence of the target condition. An accuracy study can rely on one or more reference standards.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "If test results are categorized as either positive or negative, the cross tabulation of the index test results against those of the reference standard can be used to estimate the sensitivity of the index test (the proportion of participants with the target condition who have a positive index test), and its specificity (the proportion without the target condition who have a negative index test). From this cross tabulation (sometimes referred to as the contingency or \"2x2\" table), several other accuracy statistics can be estimated, such as the positive and negative predictive values of the test. Confidence intervals around estimates of accuracy can then be calculated to quantify the statistical precision of the measurements.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "If the index test results can take more than two values, categorization of test results as positive or negative requires a test positivity cut-off. When multiple such cut-offs can be defined, authors can report a receiver operating characteristic (ROC) curve which graphically represents the combination of sensitivity and specificity for each possible test positivity cut-off. The area under the ROC curve informs in a single numerical value about the overall diagnostic accuracy of the index test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "The intended use of a medical test can be diagnosis, screening, staging, monitoring, surveillance, prediction or prognosis. The clinical role of a test explains its position relative to existing tests in the clinical pathway. A replacement test, for example, replaces an existing test. A triage test is used before an existing test; an add-on test is used after an existing test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "Besides diagnostic accuracy, several other outcomes and statistics may be relevant in the evaluation of medical tests. Medical tests can also be used to classify patients for purposes other than diagnosis, such as staging or prognosis. The STARD list was not explicitly developed for these other outcomes, statistics, and study types, although most STARD items would still apply.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "This STARD list was released in 2015. The 30 items were identified by an international expert group of methodologists, researchers, and editors. The guiding principle in the development of STARD was to select items that, when reported, would help readers to judge the potential for bias in the study, to appraise the applicability of the study findings and the validity of conclusions and recommendations. The list represents an update of the first version, which was published in 2003.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEVELOPMENT"
        },
        {
            "text": "More information can be found on http://www.equator-network.org/reporting-guidelines/stard. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEVELOPMENT"
        },
        {
            "text": "Assess the suitability of clinical vignettes in benchmarking the performance of online symptom checkers (OSC).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ABSTRACT Objective"
        },
        {
            "text": "Observational study using a publicly available free OSC",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Design"
        },
        {
            "text": "Healthily OSC which provided consultations in English was used to record consultation outcomes from two lay and four expert inputters using a 139 standardized patient vignettes. Each vignette included 3 diagnostic solutions and a triage recommendation in one of three categories of triage urgency. A panel of 3 independent general practitioners (GPs) interpreted the vignettes to arrive at an alternative set of diagnostic and triage solutions. Both sets of diagnostic and triage solutions were consolidated to arrive at a final consolidated version for benchmarking.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Participants"
        },
        {
            "text": "Six inputters simulated 834 standardized patient evaluations using Healthily OSC and recorded outputs (tirage solution, signposting, and whether the correct diagnostic solution appeared first or within the first 3 differentials). We estimated Cohen's kappa to assess how interpretations by different inputters could lead to divergent OSC output even when using the same vignette or when compared to a separate panel of physicians.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Main outcome measures"
        },
        {
            "text": "There was moderate agreement on triage recommendation (kappa=0.48), and substantial agreement on consultation outcomes between all inputters (kappa=0.73). OSC performance improved significantly from baseline when compared against the final consolidated diagnostic and triage solution (p<0.001).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "Clinical vignettes are inherently limited in their utility to benchmark the diagnostic accuracy or triage safety of OSC. Real world evidence studies involving real patients are recommended to benchmark the performance of OSC against a panel of physicians. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "\uf0b7 A standardised set of 139 independently created vignettes covering 18 subcategories of clinical care was used to benchmark the performance of a popular online symptom checker using 834 unique patient simulations \uf0b7 An alternative and a final consolidated set of diagnostic accuracy and triage solutions for each vignette was derived using GP roundtables and single blinded testing \uf0b7 We developed an accuracy matrix to monitor OSC outputs following each unique consultation with the online tool \uf0b7 We used inter-rater reliability testing to investigate the agreement between different inputters and physicians when using the same vignette and/or OSC \uf0b7 Study limitations include the use of a small sample of vignettes, and only one OSC as opposed to a variety of popular online consultation tools",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Strengths and limitations of this study"
        },
        {
            "text": "In the USA, over a third of adults self-diagnose their conditions using the internet, including queries about urgent (i.e., chest pain) and non-urgent (i.e., headache) symptoms(1, 2). The main issue with self-diagnosing using websites such as Google and Yahoo is that user may get confusing or inaccurate information, and in the case of urgent symptoms, the user may not appreciate the need to seek emergency care (3) . In recent years, various online symptom checkers (OSC) based on algorithms or artificial intelligence (AI) have emerged to fill this gap (4).",
            "cite_spans": [
                {
                    "start": 414,
                    "end": 417,
                    "text": "(3)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "OSCs are calculators that ask users to input details about their symptoms of sickness, along with personal information such as gender and age. Using algorithms or AI, the symptom checkers propose a range of conditions that fit the symptoms the user experiences. Developers promote these digital tools as a way of saving time for patients, reducing anxiety and giving patients the opportunity to take control of their own health(5-7). The diagnostic function of OSC is aimed at educating users on the range of possible conditions that may fit their symptoms. Further to presenting a condition outcome and giving the users a triage recommendation that prioritises their health needs, the triage function of OSC guides users on whether they should self-care for the condition they are describing or whether they should seek professional healthcare support (3). This added functionality could vastly enhance the usefulness of OSC by alerting people about when they need to seek emergency support or seek non-emergency care for common or self-limiting conditions (8) .",
            "cite_spans": [
                {
                    "start": 1058,
                    "end": 1061,
                    "text": "(8)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Babylon has claimed that their OSC performed better than the average doctor on a subsection of the Royal College of General Practitioners (RCGP) exam (9) . This claim has been supported by an internal evaluation study (10) , but the findings were later considered uncertain due to methodological concerns (11, 12) . Misdiagnosis of patients with life-threatening conditions could worsen their health, especially if they are not told to seek care when they should, and this could result in an increased risk of preventable morbidity and mortality. Despite this, there has been little evidence in previous literature to suggest if OSC are harmful to patients (13, 14) . However, OSC that have high false-negative rates may run similar risks if used by patients with high-risk disease such as cardiac ischaemia, pulmonary embolism or meningitis (6) . With this in mind, it is extremely important that there are guidelines on robust evaluation of OSC regarding patient safety, efficacy, effectiveness and cost (15) .",
            "cite_spans": [
                {
                    "start": 150,
                    "end": 153,
                    "text": "(9)",
                    "ref_id": null
                },
                {
                    "start": 218,
                    "end": 222,
                    "text": "(10)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 305,
                    "end": 309,
                    "text": "(11,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 310,
                    "end": 313,
                    "text": "12)",
                    "ref_id": null
                },
                {
                    "start": 657,
                    "end": 661,
                    "text": "(13,",
                    "ref_id": null
                },
                {
                    "start": 662,
                    "end": 665,
                    "text": "14)",
                    "ref_id": null
                },
                {
                    "start": 842,
                    "end": 845,
                    "text": "(6)",
                    "ref_id": null
                },
                {
                    "start": 1006,
                    "end": 1010,
                    "text": "(15)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Very little research has been done on the performance of symptom checkers for actual patients (16) (17) (18) (19) (20) (21) . Equally, there is a limited number of studies that attempted to benchmark the performance of different OSC using clinical vignettes (22) (23) (24) (25) (26) (27) (28) . A recent study compared the breadth of condition coverage, accuracy of suggested conditions and appropriateness of urgency advice of eight popular OSC (26) , and showed that the best performing OSCs have a high level of urgency advice accuracy which is close to that of GPs and are close to GP performance in providing the correct condition in their top-3 condition suggestions OSC (26) . However, it remains uncertain if clinical vignettes are ideal to investigate the accuracy and safety of OSC generally. To address this gap in knowledge, we worked in collaboration with RCGP to develop a methodology to determine if clinical vignettes were a suitable tool that can be used to benchmark the performance of different OSC.",
            "cite_spans": [
                {
                    "start": 94,
                    "end": 98,
                    "text": "(16)",
                    "ref_id": null
                },
                {
                    "start": 99,
                    "end": 103,
                    "text": "(17)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 104,
                    "end": 108,
                    "text": "(18)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 109,
                    "end": 113,
                    "text": "(19)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 114,
                    "end": 118,
                    "text": "(20)",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 119,
                    "end": 123,
                    "text": "(21)",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 258,
                    "end": 262,
                    "text": "(22)",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 263,
                    "end": 267,
                    "text": "(23)",
                    "ref_id": null
                },
                {
                    "start": 268,
                    "end": 272,
                    "text": "(24)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "(25)",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 278,
                    "end": 282,
                    "text": "(26)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 283,
                    "end": 287,
                    "text": "(27)",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 288,
                    "end": 292,
                    "text": "(28)",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 446,
                    "end": 450,
                    "text": "(26)",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 677,
                    "end": 681,
                    "text": "(26)",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "The primary aim of this study was to assess the suitability of vignettes in benchmarking the performance of OSC. Our approach included providing the vignettes to an independent panel of single-blinded physicians to arrive at an alternative set of diagnostic and triage solutions. The secondary aim was to benchmark the safety of a popular OSC (Healthily) by measuring the extent that it provided the correct diagnosis and triage solutions to a standardised set of vignettes as defined by a panel of physicians.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Our approach included the creation of an independent series of vignettes from RCGP. Each vignette was provided with 3 diagnostic solutions (S1-S3) and a triage (T) recommendation. Because RCGP created the vignettes from 'the condition in mind', we sought to arrive at an alternative set of diagnostic and triage solutions by inviting an independent panel of single blinded GPs to propose their own solutions based on the vignette script alone (as no such resource currently exists). This resulted in the creation of two iterative 'standardized' sets of diagnostic and triage solutions that were used to benchmark the performance of Healthily OSC using a range of lay and expert inputters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "METHODS"
        },
        {
            "text": "A roundtable of experienced GPs affiliated to the RCGP supported the development of 139 clinical vignettes relevant to common self-limiting conditions, general practice and urgent care (table 1) . Most of the clinical vignettes described new presentations by adults (18yr-65yr) but assumed that none of the patients were pregnant or had any prior or existing long-term conditions such as diabetes, hypertension, cardiovascular disease, terminal illness, or other co-morbidity. Each vignette was created with a list of three reasonable condition outcomes (diagnostic solutions) and an appropriate triage. The 139 vignettes including their diagnostic and triage solutions whose provenance is the RCGP are referred to as the 'original' set. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 185,
                    "end": 194,
                    "text": "(table 1)",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Vignette creation"
        },
        {
            "text": "Each vignette (V) script was assigned three diagnostic solutions (S1-S3) describing the most likely 'diagnosis' in S1, and the least likely in S3 (figure 1). RCGP also assigned each vignette a single triage recommendation (T) which was based on the most likely diagnostic solution (in cell one, S1). Triage could be in any one of three categories: (1) Self-Care (i.e., see pharmacist, self-limiting condition or self-care); (2) Seek Primary Care (i.e., see GP/Doctor in 12hr, 48hr or 2 weeks), or (3) Seek Urgent Care (i.e., seek emergency treatment, or call ambulance). The characteristics of each vignette can be summarised in a simple 5-item cellular configuration illustrating the arrangement of S1, S2 & S3 and the T for each V (figures 1 & 2). ",
            "cite_spans": [
                {
                    "start": 424,
                    "end": 427,
                    "text": "(2)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Vignette characteristics"
        },
        {
            "text": "We provided the vignette scripts to 3 independent GPs that had no connection with the OSC provider. The vignettes were provided without the diagnostic or triage solutions proposed by the RCGP. We asked the physicians to independently deliberate on each vignette and record up to three diagnostic solutions and one triage recommendation. We asked that each GP base their triage recommendation on the most severe diagnostic solution for each vignette. This resulted in the genesis of an 'alternative' set of diagnostic and triage solution to the vignettes provided by the RCGP (figure 1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "External review of vignettes by independent GPs"
        },
        {
            "text": "A final refined set of triage and diagnostic solutions that took into account the perspectives of the RCGP and independent panel of GPs was synthesised by consolidating the diagnostic and triage solutions of both. The triage recommendation for each vignette in this final iteration was based on the most severe diagnostic solution in the series. The correct diagnosis (S1, S2 & S3) for each vignette were synthesised by consolidating the solutions proposed in the preceding original and alternative sets. The correct diagnosis solutions were ordered by their frequency of appearance in the series, such that the most frequent solutions appeared in S1, and subsequently in S2 & S3 (figure 2). There were occasions when only S1 & S2 had a frequency of 2 or above. On occasion that a cell had diagnostic solutions with a frequency of just 1 each, it was not possible to order them objectively without introducing bias. In these instances, we reverted to the original (RCGP) set to assign the diagnostic solution for S2 & S3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Synthesising the consolidated diagnostic and triage solutions"
        },
        {
            "text": "The 139 vignettes were used by a panel of lay and expert inputters to benchmark the performance of Healthily OSC against all three standardised solutions to each vignette. Two laypersons and four expert inputters recruited though personal contacts used the vignettes to independently record the consultation outcome and triage recommendation from Healthily OSC. One layperson was a 20-year-old female firstyear university student, and the other lay inputter was a 47-year-old female who completed a Bachelor of Arts degree. Neither layperson nor expert inputter had any previous or significant experience in utilizing OSC). The four expert inputters recruited (2 males and 2 females; age range = 21-34 years) were all research assistants in the host research organisation (Department of Primary Care & Public Health). None of the inputters had a medical background; one half had a social science background and the other two were careered in biomedical science. Interpretation of the vignette script was left to the individual inputters who did not have any additional information. The inputters were instructed to make the following blanket assumptions when answering the questions posed by OSCs: the simulated patient is a non-smoker, not pregnant, not obese, not taking medication, not diabetic, not hypertensive, has no history of heart disease asthma, cancer, cystic fibrosis or other concerning or significant medical history, with no recent (3 months) sexual activity. Inputters were instructed to not include more than three consecutive symptoms in a single answer to any questions posed by OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Patient simulation by lay and expert inputters"
        },
        {
            "text": "Healthily OSC may give up to three diagnostic solutions (S1, S2, and S3), whereas a single a triage recommendation (T) may or may not be provided at the end of the online consultation. Inputters independently simulated the patient described in each 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y   7 vignette and recorded the consultation outcome (the diagnostic solution) using a case record form. Data were collected on up to 3 keywords used during input, details of any inputted keyword recognised by OSC, the first 3 consultation outcomes (if any) provided, the triage recommendation (if any) and whether the inputter was signposted to relevant information at the end (including external websites). Triage accuracy was defined as giving the appropriate triage recommendation (the primary outcome) relative to the standardized set of triage solutions. A triage recommendation was deemed safe when it exactly matched the triage category of a standardized set, and 'safe but over-cautious' when it recommended the more urgent triage category (e.g., see doctor instead of self-care). A triage recommendation was deemed unsafe when it suggested a less urgent category (e.g., seek 'primary care' instead of 'urgent care', or self-care instead of recommending 'urgent care'). Diagnostic accuracy was defined as providing the correct consultation outcome (the secondary outcome) for each vignette. We also sought to investigate the extent that interpretations of the same vignette by different inputters could lead to different outputs using the same OSC by comparing the Cohen's kappa which is a measure of inter-rater reliability (IRR) between groups of lay and expert inputters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 249,
                    "end": 534,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y   7",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Recording output"
        },
        {
            "text": "To support with data management and objective analysis of output from OSC, we developed a simple framework to capture various output parameters. We assigned a three-digit numeric score to objectively characterise the level of agreement between the OSC consultation outcome and diagnostic solutions (S1, S2, S3) for each vignette: \uf0b7 3: Full agreement; Correct consultation outcome appears in the exact same position as per the curated diagnostic solution in a given set \uf0b7 2: Partial agreement; Correct consultation outcome, but is one cell apart from the correct diagnostic solution (e.g., S1 placement is found in S2, or S2 placement found in either juxtaposed cell) \uf0b7 1: Partial agreement; Correct consultation outcome, but two cells apart from the correct diagnostic solution (e.g., S1 placement is found in S3 or vice versa) \uf0b7 0: No agreement; Incorrect consultation outcome in any cell, and not relating to a correct diagnostic solutions in the set \uf0b7 9: Null, or no output provided",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Consultation outcome data coding"
        },
        {
            "text": "The resulting 3-digit score described an output pattern that could be objectively scored and weighted to benchmark the performance of Healthily OSCs against the solutions in each standardised set. Of the 125 possible permutations of the 3-digit score, only 59 combinations were considered logical in representing the levels of agreement between the diagnostic solutions from OSC and those in a standardized set (Supplementary table 1) . The same terminology was used to describe the level of agreement between the triage solution in each set and the triage recommendation of the OSC (or the lack thereof).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 411,
                    "end": 434,
                    "text": "(Supplementary table 1)",
                    "ref_id": null
                }
            ],
            "section": "Consultation outcome data coding"
        },
        {
            "text": "The consultation outcomes and triage recommendations from Healthily OSC were compared to the original, the alternative and the consolidated sets of solutions for each vignette (figures 1 & 2) . We estimated Cohen's kappa coefficient which is a measure of inter-rater reliability (IRR) to investigate the extent that different interpretations of the same vignette by different inputters resulted in different consultation outcomes when using the same OSC (29) . Kappa values <0.41 were rated as fair, between 0.41 and 0.60 as moderate, between 0.61 and 0.8 as good, and >0.81 as very good (30) . Descriptive analysis was used to assess the perceived accuracy and safety of Healthily OSC against all three standardised sets. Data were expressed in frequencies, proportions and 95% Confidence intervals (CI). Pearson's Chi-square test and Fisher's exact test were used to determine whether there was a difference in signposting (e.g., to links where the user can learn more about the same or similar conditions), the provision of a consultation outcome or a triage recommendation by different inputters using the same OSC and vignette. Significance was noted when pvalue was <0.05. The statistical analysis was performed using StataCorp. 2019. Stata Statistical Software, Release 16.",
            "cite_spans": [
                {
                    "start": 454,
                    "end": 458,
                    "text": "(29)",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 588,
                    "end": 592,
                    "text": "(30)",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [
                {
                    "start": 176,
                    "end": 191,
                    "text": "(figures 1 & 2)",
                    "ref_id": null
                }
            ],
            "section": "Statistical analysis"
        },
        {
            "text": "Patient and public involvement (PPI) was embedded in this project. Two lay inputters were involved in the collection of output data from Healthily OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Patient and Public involvement"
        },
        {
            "text": "Ethical approval was not sought for this study as it did not involve recruitment of participants or the use of patient-identifiable data. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ethics"
        },
        {
            "text": "Overall, there was substantial agreement (kappa=0.66 ; table 2; supplementary table  2 ) in 'self-care' triage recommendation between the original triage solutions proposed by the RCGP and the alternative standard proposed by the independent panel of physicians, (kappa=0.48; Table 2 ), whereas there as only fair (kappa=0.24) and moderate (kappa=0.44) agreement for 'primary care' and 'urgent care' triage recommendations in that same order (table 2). There was fair agreement (kappa=0.35) between the diagnostic solutions proposed by the independent panel of GPs and the RCGP when the correct solution appeared in the first cell (S1), and fair agreement (kappa=0.29) when the correct solution appeared in any cell (S1-S3); (table 2; supplementary table 3) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 53,
                    "end": 86,
                    "text": "; table 2; supplementary table  2",
                    "ref_id": "TABREF21"
                },
                {
                    "start": 276,
                    "end": 283,
                    "text": "Table 2",
                    "ref_id": "TABREF21"
                },
                {
                    "start": 725,
                    "end": 757,
                    "text": "(table 2; supplementary table 3)",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Inter-rater reliability testing Independent panel of physicians"
        },
        {
            "text": "Overall, there was moderate agreement on triage recommendation from Healthy OSC between all inputters (expert and lay) and the original RCGP solutions across all vignettes (kappa=0.48 , table 3; Supplementary table 4) . The agreement on triage recommendation between the expert inputters and the original RCGP solution was moderate (kappa=0.44) whereas it was fair (kappa=0.37) between lay inputters. The highest (almost perfect; kappa= 0.84) agreement on triage recommendations was between the expert inputters for the self-care category (table 3) . The lowest agreement between the expert inputters had a kappa of 0.29 for Urgent Care. 10 We compared the consultation outcome from Healthily OSC from two lay inputters against the output recorded by four expert inputters to determine the extent that individuals could arrive at different solutions even when using the same vignette and OSC tool (Supplementary table 4) . A significant difference was observed in consultation outcomes in position cell one (S1; (p<0.001) and S3 (p=0.03) between both type of expert inputters, but not for S2 (p=0.30) or the single triage option (p=0.93). Overall, there was substantial agreement on consultation outcomes between all inputters (expert and lay) and the original RCGP solutions across all vignettes, (kappa=0. 73; table 3) . The agreement across all vignettes on consultation outcomes between expert inputters was substantial (kappa=0.71), whereas it was almost perfect (kappa=0.84) among lay inputters.",
            "cite_spans": [
                {
                    "start": 638,
                    "end": 640,
                    "text": "10",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 184,
                    "end": 217,
                    "text": ", table 3; Supplementary table 4)",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 539,
                    "end": 548,
                    "text": "(table 3)",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 897,
                    "end": 920,
                    "text": "(Supplementary table 4)",
                    "ref_id": null
                },
                {
                    "start": 1308,
                    "end": 1320,
                    "text": "73; table 3)",
                    "ref_id": null
                }
            ],
            "section": "Lay and expert inputters"
        },
        {
            "text": "There was no significant difference in signposting between expert inputters when using Healthily OSC (p=0.23; Supplementary table 5). However, there was a significant difference between the two lay inputters (p<0.001), and between the expert (n=4) and lay (n=2) inputters when compared as a group (p<0.001). There was significant variation between inputters with respect to whether the OSC provided signposting at the end for the same vignette, regardless of whether or not the simulation resulted in a triage recommendation (p<0.001). The difference disappeared when no triage recommendation was provided (p=0.21). ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Signposting at end of online consultation"
        },
        {
            "text": "In this study, we used a new series of clinical vignettes describing patient scenarios and symptoms across 18 sub-categories of clinical care to determine if vignettes were a suitable tool that could be used to benchmark the performance of OSCs. Our approach included providing the vignettes to a panel of independent physicians to arrive at an alternative set of diagnostic and triage solutions as originally proposed by RCGP. We consolidated both iterations to arrive at a final refined standardised set of solutions and benchmarked the performance of a popular OSC using 834 unique patient simulations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "We showed significant variability of medical opinion depending on which group of GPs considered the vignette script, whereas consolidating the output of two different GP roundtables (RCGP and the independent panel of GPs) resulted in a more refined third iteration (the consolidated standard) which more accurately included the 'correct' diagnostic and triage solutions conferred by the vignette script. This was demonstrated by significant extent that the performance of Healthily OSC improved when benchmarked between the original and final consolidated standards (diagnostic accuracy improved from 37.4% to 41.2% for S1, whereas congruent triage recommendation improved from 43.3% to 61.9%; table 4). The different qualities of the diagnostic and triage solutions between iterative standards suggest that vignettes are not an ideal tool for benchmarking the accuracy of OSC since performance will always be related to the nature and order of the diagnostic and triage solutions which we have shown can differ significantly depending on the approach and levels of input from independent physicians. By extension, the final consolidated standard for any vignette can always be improved by including a wider range of medical opinion until saturation is reached and a final consensus emerges.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Another key factor that may impact the suitability of benchmarking OSC using clinical vignettes is related to the inputter's inability to answer truthfully at all the questions that may be asked during the online consultation process. This inherent methodological limitation necessitates the use of blanket assumptions (e.g., the inputter is instructed to always indicate that they are 'not pregnant', or that they 'did not have any recent sexual activity' etc.,). This could lead to a different consultation outcome (including a different diagnostic solution, and/or triage recommendation) to what would otherwise be presented if a real patient -the intended end user of the OSC tool)-who was experiencing the symptoms was the inputter. The moderate agreement (kappa=0.48) between different inputters overall, which reduced to only fair agreement (kappa=0.29) for case vignettes with an urgent triage recommendation suggests that the wording of some vignettes could be revised to reduce the likelihood of divergent interpretations of the same script. It is inevitable that different people will use different words to describe their conditions, necessitating the use of machine learning to render OSC capable of understanding multiple different descriptions of the same problem. Further, the vignette script is necessarily limited in the number of words, and even if the description and context were expanded it may still not capture all the information necessary to simulate how a real patient may engage with the same OSC. These inherent limitations were illustrated by how different inputters arrived at different diagnostic solutions when using the same vignette script and the same OSC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Another key outcome measure was the congruence of the triage recommendation made by the online tool or each vignette relative to the correct solutions proposed in the original and subsequent iterations following input from an independent panel of physicians. Whereas RCGP always made a triage recommendation that was based on the first (most likely) 'correct' solution (i.e., S1) of each vignette, the triage recommendation in the alternative and consolidated standards was always based on the most severe diagnostic solution regardless of whether it appeared first or within the top three placements in the series. Recommending a triage option that was based on the most severe disposition-or 'worst case scenario'-is appropriate for OSC because this enhances patient safety, even on occasion when the triage option is safe but over-cautious. For example, if 'Indigestion' (S1), 'Costochondritis' (S2) and 'Heart attack' (S3) appeared in that same order, the appropriate triage recommendation is 'seek urgent care' even if this potential diagnosis did not appear first by the online tool. This is clearly the 'safer' option, and the one adopted by Healthily, whereas other OSC (e.g., Ada and Babylon) provide a triage consultation based on the first proposed solution in the series.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "That Healthily recommended 'unsafe' triages 28.6% overall, and very unsafe triages only 3.7% of the time suggests that the online consultation tool is generally working at a safe level of probable risk, and more frequently made an appropriate triage recommendation or signposted the user to the more urgent triage category as opposed to the other way around. This was unsurprising as it is reasonable to expect OSCs to be 'risk averse' since these decision support tools arrive to a conclusion with limited data and without human interaction (31) .",
            "cite_spans": [
                {
                    "start": 542,
                    "end": 546,
                    "text": "(31)",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Although the diagnostic solutions proposed by an independent panel of physicians agreed with the RCGP solutions on average 72% of time, and on triage 74% of the time, this did not mean that any of the GPs were wrong. When GPs diagnose, they assess probable risk and then investigate. This implies that primary care assessment is not binary; there is often not a correct answer but rather a series of options that could be explored with the patient to help resolve the symptoms and treat the condition using evidence-based decision making refined over time including the use of further tests. By contrast, the provenance of a clinical vignette usually starts from the condition and builds a story, whereas conversely GPs and OSCs start with the story and then work towards a probable condition. Often, as we saw following the independent deliberations of a panel of physicians, there are many possible conditions in the \"area\" a vignette might point towards. We found that both the online consultation tool and the physicians were in the right area but not precisely \"correct\". This demonstrates why any claims that an OSC can \"diagnose\" need to be challenged, since GPs do not diagnose and therefore OSCs cannot. Diagnosis can only come after testing and verification of the initial hypothesis, and accurate diagnosis usually includes other aspects such as imaging, pathology results involving the use of point-of-care and other near patient testing procedures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Our audit study had a number of limitations, including that the original RCGP diagnostic and triage solutions for each vignette offered a baseline for assessment but could not be considered as the 'ideal' or' gold' standard even after additional input from an external roundtable of independent GPs. Other limitations included a small sample of vignettes and using only one OSC (4). Despite these limitations, the framework and pragmatic methodology used to support the objective development of the consolidated set consisting of 139 vignettes with congruent diagnostic and triage solutions were suitable to benchmark the performance of online consultation tools. We acknowledge also that the final consolidated set can be developed further by inviting input from a larger number of general practitioners. Further work is indicated to refine 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y   14 the wording of some vignettes since there is a large variation in how different inputters could interpret each item leading to different diagnostic solutions and triage recommendation (the main output parameters) even when using the same OSC tool.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 842,
                    "end": 1128,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y   14",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "DISCUSSION"
        },
        {
            "text": "There are a number of person-centred and policy implications for the use of OSC(4) (4). For example, access to healthcare is a major issue and this has become more pronounced since the advent of the Covid-19 pandemic (32) . Improving access to primary care and/or pre-primary care health advice is expected to reduce pressure on urgent and secondary care services, and this is a main driver for the use of a safe and effective OSCs. The widespread adoption and diffusion of OSC with added functionality can help empower individuals, improve health literacy levels through microlearning (33) , and may even promote individual self-care capability and the rational use of products and services. This applies especially for OSC that signpost users to relevant information that could help them determine possible next steps regardless of whether the OSC provided a triage recommendation or not. At this stage in their development, OSCs must be risk averse by avoiding under-triage where patients are directed to a less urgent service. This may have a negative impact on health service resources in that it may result in unnecessary use of urgent or emergency health providers but may equally result in an earlier diagnosis and appropriate treatment of medical conditions which reduces morbidity, mortality and overall costs in the long term. The rational use of OSC may in the future decrease the high demand on primary care providers and this utility is especially welcome since the workload for GPs in the UK has increased by 62% from 1995 to 2008 (34) , whereas there has been very little or no increase in the number of GPs per 1,000 population (35) .",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 221,
                    "text": "(32)",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 586,
                    "end": 590,
                    "text": "(33)",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 1546,
                    "end": 1550,
                    "text": "(34)",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 1645,
                    "end": 1649,
                    "text": "(35)",
                    "ref_id": "BIBREF49"
                }
            ],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "A recent paper highlighted a wide variation in performance between available symptom checkers and that overall performance is significantly below what would be accepted in any other medical field (4). The authors concluded that external validation is urgently required to ensure these public facing tools are safe. Our study shows that vignettes are not ideally suited to benchmark the performance of OSC as inter-rater agreement is not perfect between different inputters and because larger roundtables of independent physicians could lead to more refined iterations of the diagnostic and triage solutions for each vignette. Further work is recommended to cross-validate the performance of OSC against real-world test case scenarios using real patient stories and interactions with GPs as opposed to using case vignettes only.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DISCUSSION"
        },
        {
            "text": "Inherent limitations of clinical vignettes render them largely unsuitable for benchmarking the performance of popular OSCs because the diagnosis and triage solutions assigned to each vignette script are amenable to change pending the deliberations of an independent panel of physicians. Although OSCs are already working at a safe level of probable risk, further work is recommended to cross-validate the performance of OSC against real-world test case scenarios using real patient stories and interactions with GPs as opposed to using artificial vignettes only which will always be the single most important limitation to any cross-validation study. 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59 Study objectives and hypotheses 4",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 651,
                    "end": 1159,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60   F  o  r  p  e  e  r  r  e  v  i  e  w  o  n  l  y  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1160,
                    "end": 1385,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1386,
                    "end": 1611,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1612,
                    "end": 1837,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1838,
                    "end": 2063,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 2064,
                    "end": 2289,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Conclusion"
        },
        {
            "text": "Whether data collection was planned before the index test and reference standard were performed (prospective study) or after (retrospective study)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Study design 5"
        },
        {
            "text": "Participants 6 Eligibility criteria 5 7",
            "cite_spans": [],
            "ref_spans": [],
            "section": "& 6"
        },
        {
            "text": "On what basis potentially eligible participants were identified (such as symptoms, results from previous tests, inclusion in registry)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "& 6"
        },
        {
            "text": "Where and when potentially eligible participants were identified (setting, location and dates) 4 AIM STARD stands for \"Standards for Reporting Diagnostic accuracy studies\". This list of items was developed to contribute to the completeness and transparency of reporting of diagnostic accuracy studies. Authors can use the list to write informative study reports. Editors and peer-reviewers can use it to evaluate whether the information has been included in manuscripts submitted for publication.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "& 6"
        },
        {
            "text": "A diagnostic accuracy study evaluates the ability of one or more medical tests to correctly classify study participants as having a target condition. This can be a disease, a disease stage, response or benefit from therapy, or an event or condition in the future. A medical test can be an imaging procedure, a laboratory test, elements from history and physical examination, a combination of these, or any other method for collecting information about the current health status of a patient.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "The test whose accuracy is evaluated is called index test. A study can evaluate the accuracy of one or more index tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "Evaluating the ability of a medical test to correctly classify patients is typically done by comparing the distribution of the index test results with those of the reference standard. The reference standard is the best available method for establishing the presence or absence of the target condition. An accuracy study can rely on one or more reference standards.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "If test results are categorized as either positive or negative, the cross tabulation of the index test results against those of the reference standard can be used to estimate the sensitivity of the index test (the proportion of participants with the target condition who have a positive index test), and its specificity (the proportion without the target condition who have a negative index test). From this cross tabulation (sometimes referred to as the contingency or \"2x2\" table), several other accuracy statistics can be estimated, such as the positive and negative predictive values of the test. Confidence intervals around estimates of accuracy can then be calculated to quantify the statistical precision of the measurements.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "If the index test results can take more than two values, categorization of test results as positive or negative requires a test positivity cut-off. When multiple such cut-offs can be defined, authors can report a receiver operating characteristic (ROC) curve which graphically represents the combination of sensitivity and specificity for each possible test positivity cut-off. The area under the ROC curve informs in a single numerical value about the overall diagnostic accuracy of the index test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "The intended use of a medical test can be diagnosis, screening, staging, monitoring, surveillance, prediction or prognosis. The clinical role of a test explains its position relative to existing tests in the clinical pathway. A replacement test, for example, replaces an existing test. A triage test is used before an existing test; an add-on test is used after an existing test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "Besides diagnostic accuracy, several other outcomes and statistics may be relevant in the evaluation of medical tests. Medical tests can also be used to classify patients for purposes other than diagnosis, such as staging or prognosis. The STARD list was not explicitly developed for these other outcomes, statistics, and study types, although most STARD items would still apply.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EXPLANATION"
        },
        {
            "text": "This STARD list was released in 2015. The 30 items were identified by an international expert group of methodologists, researchers, and editors. The guiding principle in the development of STARD was to select items that, when reported, would help readers to judge the potential for bias in the study, to appraise the applicability of the study findings and the validity of conclusions and recommendations. The list represents an update of the first version, which was published in 2003.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEVELOPMENT"
        },
        {
            "text": "More information can be found on http://www.equator-network.org/reporting-guidelines/stard. 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 92,
                    "end": 321,
                    "text": "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "DEVELOPMENT"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Should you search the internet for information about your acute symptom? Telemedicine and e-Health",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "North",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Ward",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Varkey",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Tulledge-Scheitel",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "18",
            "issn": "",
            "pages": "213--221",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Internet and American life project",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Health Online",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "World Health Organization. Regional Office for South-East A. Self care for health. New Delhi: WHO Regional Office for South-East Asia",
            "authors": [],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "It's like having a physician in your pocket!'A critical analysis of self-diagnosis smartphone apps",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lupton",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jutel",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Social Science & Medicine",
            "volume": "133",
            "issn": "",
            "pages": "128--163",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Healthy living is the best revenge: findings from the European Prospective Investigation Into Cancer and Nutrition-Potsdam study",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "S"
                    ],
                    "last": "Ford",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Bergmann",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kr\u00f6ger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Schienkiewitz",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Weikert",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Boeing",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Arch Intern Med",
            "volume": "169",
            "issn": "15",
            "pages": "1355--62",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Diagnostic inaccuracy of smartphone applications for melanoma detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Wolf",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "F"
                    ],
                    "last": "Moreau",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Akilov",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Patton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "English",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ho",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "JAMA dermatology",
            "volume": "149",
            "issn": "4",
            "pages": "422--428",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Trends in prehospital delay in patients with acute myocardial infarction (from the Worcester Heart Attack Study). The American journal of cardiology",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Saczynski",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yarzebski",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lessard",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Spencer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Gurwitz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Gore",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "102",
            "issn": "",
            "pages": "1589--94",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Babylon claims its chatbot beats GPs at medical exam: BBC",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Copestake",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "A comparative study of artificial intelligence and human doctors for the purpose of triage and diagnosis",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Razzaki",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Baker",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Perov",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Middleton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Baxter",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mullarkey",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Lancet T. Is digital medicine different",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Paper Review: the Babylon Chatbot",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Coiera",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Digital and online symptom checkers and health assessment/triage services for urgent health problems: systematic review",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chambers",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Cantrell",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Preston",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Baxter",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Booth",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BMJ open",
            "volume": "9",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Delineation of self-care and associated concepts",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Richard",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shea",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J Nurs Scholarsh",
            "volume": "43",
            "issn": "3",
            "pages": "255--64",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Are online symptoms checkers useful for patients with inflammatory arthritis? BMC musculoskeletal disorders",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Powley",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Mcilroy",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Simons",
                    "suffix": ""
                },
                {
                    "first": "K ;",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Van Der Linden",
                    "suffix": ""
                },
                {
                    "first": "Le",
                    "middle": [],
                    "last": "Cessie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Van Der Woude",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Knevel",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Huizinga",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Arthritis & Rheumatism",
            "volume": "17",
            "issn": "1",
            "pages": "3537--3583",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Delay in presentation to primary care physicians is the main reason why patients with rheumatoid arthritis are seen late by rheumatologists",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Daley",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Carruthers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Situnayake",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gordon",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Grindulis",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Rheumatology",
            "volume": "46",
            "issn": "9",
            "pages": "1438--1478",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "I just thought it was normal aches and pains': a qualitative study of decision-making processes in patients with early rheumatoid arthritis",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sheppard",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Buckley",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "L"
                    ],
                    "last": "Shaw",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Rheumatology",
            "volume": "47",
            "issn": "10",
            "pages": "1577--82",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Should you search the internet for information about your acute symptom? Telemedicine and e-Health",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "North",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Ward",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Varkey",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Tulledge-Scheitel",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "18",
            "issn": "",
            "pages": "213--221",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Internet and American life project",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Health Online",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "World Health Organization. Regional Office for South-East A. Self care for health",
            "authors": [],
            "year": 2014,
            "venue": "WHO Regional Office for",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Accuracy of online symptom checkers and the potential impact on service utilisation",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ceney",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tolond",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Glowinski",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Marks",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Swift",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Palser",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "PLOS ONE",
            "volume": "16",
            "issn": "7",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "It's like having a physician in your pocket!'A critical analysis of self-diagnosis smartphone apps",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lupton",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jutel",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Social Science & Medicine",
            "volume": "133",
            "issn": "",
            "pages": "128--163",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Healthy living is the best revenge: findings from the European Prospective Investigation Into Cancer and Nutrition-Potsdam study",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "S"
                    ],
                    "last": "Ford",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Bergmann",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kr\u00f6ger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Schienkiewitz",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Weikert",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Boeing",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Arch Intern Med",
            "volume": "169",
            "issn": "15",
            "pages": "1355--62",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Diagnostic inaccuracy of smartphone applications for melanoma detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Wolf",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "F"
                    ],
                    "last": "Moreau",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Akilov",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Patton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "English",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ho",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "JAMA dermatology",
            "volume": "149",
            "issn": "4",
            "pages": "422--428",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Trends in prehospital delay in patients with acute myocardial infarction (from the Worcester Heart Attack Study). The American journal of cardiology",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Saczynski",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yarzebski",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lessard",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Spencer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Gurwitz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Gore",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "102",
            "issn": "",
            "pages": "1589--94",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Babylon claims its chatbot beats GPs at medical exam: BBC",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Copestake",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "A comparative study of artificial intelligence and human doctors for the purpose of triage and diagnosis",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Razzaki",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Baker",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Perov",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Middleton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Baxter",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mullarkey",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Lancet T. Is digital medicine different",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Paper Review: the Babylon Chatbot",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Coiera",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Digital and online symptom checkers and health assessment/triage services for urgent health problems: systematic review",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chambers",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Cantrell",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Preston",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Baxter",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Booth",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BMJ open",
            "volume": "9",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Delineation of self-care and associated concepts",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Richard",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shea",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J Nurs Scholarsh",
            "volume": "43",
            "issn": "3",
            "pages": "255--64",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Safety of patient-facing digital symptom checkers",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fraser",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Coiera",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "The Lancet",
            "volume": "392",
            "issn": "",
            "pages": "2263--2267",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Are online symptoms checkers useful for patients with inflammatory arthritis? BMC musculoskeletal disorders",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Powley",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Mcilroy",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Simons",
                    "suffix": ""
                },
                {
                    "first": "K ;",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Van Der Linden",
                    "suffix": ""
                },
                {
                    "first": "Le",
                    "middle": [],
                    "last": "Cessie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Van Der Woude",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Knevel",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Huizinga",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Arthritis & Rheumatism",
            "volume": "17",
            "issn": "1",
            "pages": "3537--3583",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Delay in presentation to primary care physicians is the main reason why patients with rheumatoid arthritis are seen late by rheumatologists",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Daley",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Carruthers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Situnayake",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gordon",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Grindulis",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Rheumatology",
            "volume": "46",
            "issn": "9",
            "pages": "1438--1478",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "I just thought it was normal aches and pains': a qualitative study of decision-making processes in patients with early rheumatoid arthritis",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sheppard",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Buckley",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "L"
                    ],
                    "last": "Shaw",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Rheumatology",
            "volume": "47",
            "issn": "10",
            "pages": "1577--82",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "The influence of ethnicity on the extent of, and reasons underlying, delay in general practitioner consultation in patients with RA",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Daley",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Khattak",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Buckley",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Rheumatology",
            "volume": "49",
            "issn": "5",
            "pages": "1005--1017",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Delays in help seeking at the onset of the symptoms of rheumatoid arthritis: a systematic synthesis of qualitative literature. Annals of the rheumatic diseases",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "J"
                    ],
                    "last": "Stack",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shaw",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Mallen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Herron-Marx",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Horne",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "71",
            "issn": "",
            "pages": "493--500",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Evaluation of symptom checkers for self diagnosis and triage: audit study",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "L"
                    ],
                    "last": "Semigran",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Linder",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gidengil",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mehrotra",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "bmj",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Vignette methodologies for studying clinicians' decision-making: Validity, utility, and application in ICD-11 field studies",
            "authors": [],
            "year": 2015,
            "venue": "Int J Clin Health Psychol",
            "volume": "15",
            "issn": "2",
            "pages": "160--70",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Clinical vignette-based surveys: a tool for assessing physician practice variation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Veloski",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tai",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Evans",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "B"
                    ],
                    "last": "Nash",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Am J Med Qual",
            "volume": "20",
            "issn": "3",
            "pages": "151--158",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Methods of Observing Variations in Physicians' Decisions: The Opportunities of Clinical Vignettes",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Converse",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Barrett",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Rich",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Reschovsky",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J Gen Intern Med",
            "volume": "30",
            "issn": "3",
            "pages": "586--94",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "How accurate are digital symptom assessment apps for suggesting conditions and urgency advice? A clinical vignettes comparison to GPs",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gilbert",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mehl",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Baluch",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Cawley",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Challiner",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fraser",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "BMJ Open",
            "volume": "10",
            "issn": "12",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Evaluation of symptom checkers for self diagnosis and triage: audit study",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "L"
                    ],
                    "last": "Semigran",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Linder",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gidengil",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mehrotra",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "BMJ",
            "volume": "351",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "The global burden of chronic diseases: overcoming impediments to prevention and control",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yach",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Hawkes",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L"
                    ],
                    "last": "Gould",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "J"
                    ],
                    "last": "Hofman",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Jama",
            "volume": "291",
            "issn": "21",
            "pages": "2616--2638",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Accuracy of a Chatbot (Ada) in the Diagnosis of Mental Disorders: Comparative Case Study With Lay and Expert Users",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Jungmann",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Klan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kuhn",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Jungmann",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "JMIR Form Res",
            "volume": "3",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "An Application of Hierarchical Kappa-type Statistics in the Assessment of Majority Agreement among Multiple Observers",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Landis",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "G"
                    ],
                    "last": "Koch",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "Biometrics",
            "volume": "33",
            "issn": "2",
            "pages": "363--74",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Diagnostic error in internal medicine",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Graber",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Franklin",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gordon",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Arch Intern Med",
            "volume": "165",
            "issn": "13",
            "pages": "1493--1502",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "The primary care response to COVID-19 in",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Majeed",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Maile",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Bindman",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "The efficacy of microlearning in improving self-care capability: a systematic review of the literature",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bakhet",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gnani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "El-Osta",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Public Health",
            "volume": "186",
            "issn": "",
            "pages": "286--96",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Telephone triage for management of same-day consultation requests in general practice (the ESTEEM trial): a cluster-randomised controlled trial and cost-consequence analysis",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Campbell",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Fletcher",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Britten",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Green",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Holt",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Lattimer",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "The Lancet",
            "volume": "384",
            "issn": "9957",
            "pages": "1859--68",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Securing a sustainable and fit-for-purpose UK health and care workforce. The Lancet",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Anderson",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "O&apos;neill",
                    "suffix": ""
                },
                {
                    "first": "Macleod",
                    "middle": [],
                    "last": "Clark",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Street",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Woods",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Johnston-Webber",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF4": {
            "text": "logical in representing the consultation outcome by the OSC",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Clinical vignette creation process Creating the consolidated set of diagnostic and triage solutions for each vignette",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Diagnostic accuracy On average, Healthily OSC provided a diagnostic solution 74.6% of the time (figure 3). When compared against the original (RCGP) set, Healthily OSC provided the correct diagnostic solution at any position 43.3% of the time (figure 4;",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Healthily OSC diagnostic accuracy benchmarked against three standards Healthily OSC triage recommendations benchmarked against three standardsSafety of triage recommendationWhen compared against the consolidated solutions, Healthily OSC made triage recommendations that were deemed unsafe 4.3% and 24.3% of the time (28.6% total) for vignettes describing a symptom that required primary care and emergent care respectively (P<0.001; table 5; figure 5).",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Imperial College London, Department of Primary Care & Public Health *Corresponding author: Dr Austen El-Osta, Self-Care Academic Research Unit (SCARU), Imperial College London Department of Primary Care & Public Health, 323 Reynolds Building, Charing Cross Hospital, St Dunstan's Road. London W6 8RP, Tel. 0207 594 7604; a.el-osta@imperial.ac.uk",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Triage recommendations for 139 vignettes across 18 subcategories of primary care",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The vignettes developed by the RCGP included a set of 3 dispositions and a triage recommendation as deemed suitable by the RCGP roundtable. Working on the assumption that the vignette script provided by the RCGP was immutable, the Gold Standard dispositions and triage recommendation for each vignette was synthesised by consolidating the deliberations of three additional GP Partners with the original RCGP Standard. The Gold Standard dispositions (D1, D2 & D3) for each vignette are therefore a synthesis from up to 12 dispositions; 9 dispositions in total from the 3 external GPs, and 3 dispositions form the original RCGP Standard (2). When producing the Gold Standard for each vignette, the dispositions were ranked by frequency of appearance in the series; the dispositions that were most frequent appeared in D1, and subsequently inD2 & D3 (figure 2). There were occasions when only D1 & D2 had a frequency of 2 or above. On occasion that D2 & D3 had frequencies of just 1 each, it was not possible to order them objectively without introducing bias. In these instances, we reverted to the original RCGP Standard to assign D2 & D3. The triage recommendation for each vignette in the Gold Standard was set to the most severe disposition in the series.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Level of agreement for triage recommendation between RCGP and Imperial standards",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Levels of agreement between consolidated Imperial Standard & RCGP Standard",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "). The Funder did not have a role in study design or analysis. Austen El-Osta and Azeem Majeed are supported by the National Institute for Health Research (NIHR) Applied Research Collaboration (ARC) North West London. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health and Social Care For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml Daley E, Khattak F, Buckley CD, Raza K. The influence of ethnicity on the extent of, and reasons underlying, delay in general practitioner consultation in patients with RA. Rheumatology. 2010;49(5):1005-12. 19. Stack RJ, Shaw K, Mallen C, Herron-Marx S, Horne R, Raza K. Delays in help seeking at the onset of the symptoms of rheumatoid arthritis: a systematic synthesis of qualitative literature. Annals of the rheumatic diseases. 2012;71(4):493-7. 20. Semigran HL, Linder JA, Gidengil C, Mehrotra A. Evaluation of symptom checkers for self diagnosis and triage: audit study. bmj. 2015;351. 21. Evans SC, Roberts MC, Keeley JW, Blossom JB, Amaro CM, Garcia AM, et al. Vignette methodologies for studying clinicians' decision-making: Validity, utility, and application in ICD-11 field studies. Int J Clin Health Psychol. 2015;15(2):160-70. 22. Veloski J, Tai S, Evans AS, Nash DB. Clinical vignette-based surveys: a tool for assessing physician practice variation. Am J Med Qual. 2005;20(3):151-7. 23. Converse L, Barrett K, Rich E, Reschovsky J. Methods of Observing Variations in Physicians' Decisions: The Opportunities of Clinical Vignettes. J Gen Intern Med. 2015;30 Suppl 3(Suppl 3):S586-94. 24. Gilbert S, Mehl A, Baluch A, Cawley C, Challiner J, Fraser H, et al. How accurate are digital symptom assessment apps for suggesting conditions and urgency advice? A clinical vignettes comparison to GPs. BMJ Open. 2020;10(12):e040269. 25. Semigran HL, Linder JA, Gidengil C, Mehrotra A. Evaluation of symptom checkers for self diagnosis and triage: audit study. BMJ. 2015;351:h3480. 26. Yach D, Hawkes C, Gould CL, Hofman KJ. The global burden of chronic diseases: overcoming impediments to prevention and control. Jama. 2004;291(21):2616-22. 27. Graber ML, Franklin N, Gordon R. Diagnostic error in internal medicine. Arch Intern Med. 2005;165(13):1493-9. 28. Majeed A, Maile EJ, Bindman AB. The primary care response to COVID-19 in England's National Health Service. Journal of the Royal Society of Medicine. 2020;113(6):208-10. 29. Wang C, Bakhet M, Roberts D, Gnani S, El-Osta A. The efficacy of microlearning in improving self-care capability: a systematic review of the literature. Public Health. 2020;186:286-96. 30. Campbell JL, Fletcher E, Britten N, Green C, Holt TA, Lattimer V, et al. Telephone triage for management of same-day consultation requests in general practice (the ESTEEM trial): a cluster-randomised controlled trial and costconsequence analysis. The Lancet. 2014;384(9957):1859-68. 31. Anderson M, O'Neill C, Macleod Clark J, Street A, Woods M, Johnston-Webber C, et al. Securing a sustainable and fit-for-purpose UK health and care workforce. The Lancet. 2021. 32. thebmjopinion. Covid-19 is magnifying the digital divide 2020 [Available from: https://blogs.bmj.com/bmj/2020/09/01/covid-19-is-magnifying-the-digital-divide/. For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml Supplementary table 1: List of the 59 combinations that were considered logical in representing the consultation outcome by the OSC",
            "latex": null,
            "type": "table"
        },
        "TABREF15": {
            "text": "STARD stands for \"Standards for Reporting Diagnostic accuracy studies\". This list of items was developed to contribute to the completeness and transparency of reporting of diagnostic accuracy studies. Authors can use the list to write informative study reports. Editors and peer-reviewers can use it to evaluate whether the information has been included in manuscripts submitted for publication.",
            "latex": null,
            "type": "table"
        },
        "TABREF21": {
            "text": "Cohen's kappa of agreement between the panel of physicians and RCGP split by triage and diagnostic solution",
            "latex": null,
            "type": "table"
        },
        "TABREF22": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF24": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF25": {
            "text": "Safety of Healthily OSC triage recommendations of against the final Consolidated Standard",
            "latex": null,
            "type": "table"
        },
        "TABREF27": {
            "text": "Page 14 of 27For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF28": {
            "text": "For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF29": {
            "text": "For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF30": {
            "text": "For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF31": {
            "text": "For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF32": {
            "text": "For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF33": {
            "text": "List of the 59 combinations that were considered logical in representing the consultation outcome by the OSCFor peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtmlSUPPLEMENTARY TABLE 2 Levels agreement of diagnostic and triage between the original and alternative solutionsFor peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtmlLevel of agreement between for signpostingFor peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml Identification as a study of diagnostic accuracy using at least one measure of accuracy (such as sensitivity, specificity, predictive values, or AUC) Structured summary of study design, methods, results, and conclusions (for specific guidance, see STARD for Abstracts) Scientific and clinical background, including the intended use and clinical role of the index test 3 & 4 4",
            "latex": null,
            "type": "table"
        },
        "TABREF34": {
            "text": "12a Definition of and rationale for test positivity cut-offs or result categories of the index test, distinguishing pre-specified from exploratoryFor peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        },
        "TABREF35": {
            "text": "Page 28 of 27For peer review only -http://bmjopen.bmj.com/site/about/guidelines.xhtml",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors thank Ms Noor Jawhar, Ms Christina Pillay and Mr John Norton for PPI input and for testing the symptom checkers, and Drs Aisha Newth, Prakash Chatlani, David Mummery and Benedict Hayhoe for clinical support.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements:"
        },
        {
            "text": "Author Contributors: All authors provided substantial contributions to the conception (AEO, IW, AA, EB, AM), design (AEO, EB, IW, AA), acquisition (IW, AA, ER), and interpretation (EB, IW, HM, MS) of study data and approved the final version of the paper. AEO took the lead in planning the study with support from co-authors. EB carried out the data analysis with support from AA and MS. AEO is the guarantor.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "No additional data are available Funding: Unconditional funding for this work was provided by Healthily (IC Self-Care 2020/1 How missing data on the index test and reference standard were handled 7 & 8",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data sharing statement"
        },
        {
            "text": "Any analyses of variability in diagnostic accuracy, distinguishing pre-specified from exploratory 7 & 8 18Intended sample size and how it was determined 4",
            "cite_spans": [],
            "ref_spans": [],
            "section": "17"
        },
        {
            "text": "Flow of participants, using a diagram 5 20Baseline demographic and clinical characteristics of participants 4 21a Distribution of severity of disease in those with the target condition 421b Distribution of alternative diagnoses in those without the target condition 4 Where the full study protocol can be accessed NA",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Participants 19"
        },
        {
            "text": "Sources of funding and other support; role of funders 20",
            "cite_spans": [],
            "ref_spans": [],
            "section": "30"
        }
    ]
}