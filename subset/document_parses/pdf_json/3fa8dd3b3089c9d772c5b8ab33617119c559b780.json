{
    "paper_id": "3fa8dd3b3089c9d772c5b8ab33617119c559b780",
    "metadata": {
        "title": "A Deep Learning-Based Method for Forecasting Gold Price with Respect to Pandemics",
        "authors": [
            {
                "first": "Mahtab",
                "middle": [
                    "Mohtasham"
                ],
                "last": "Khani",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [],
                "last": "Sahand Vahidnia",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Alireza",
                "middle": [],
                "last": "Abbasi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The spread of COVID-19 has had a devastating impact on the world economy, international trade relations, and globalization. As this pandemic advances and new potential pandemics are on the horizon, a precise analysis of recent fluctuations of trade becomes necessary for international decisions and controlling the world in a similar crisis. The COVID-19 pandemic made a new pattern of trade in the world and affected how businesses work and trade with each other. It means that every potential pandemic or any unprecedented event in the world can change the market rules. This research develops a novel model to have a proper estimation of the stock market values with respect to the COVID-19 dataset using long short-term memory networks (LSTM). The goal of this study is to establish a model that can predict near future regarding the variable set of features. The nature of the features in each pandemic is completely different; therefore, prediction results for a pandemic by a specific model cannot be applied to other pandemics. Hence, recognizing and extracting the features which affect the pandemic is pivotal. In this study, we develop a framework that provides a better understanding of the features and feature selection process. Although the global impacts of COVID-19 are complicated, we are trying to show how additional features like COVID-19 cases can help to forecast in a real-world scenario, rather than relying solely on the history of tickers, which is used conventionally for prediction. This study is based on a preliminary analysis of features such as COVID-19 cases and other market tickers for enhancing forecasting models' performance against fluctuations in the market. Our predictors are based on the market value data and COVID-19 pandemic daily time-series data (i.e. the number of new cases). In this study, we selected Gold price as a base for our forecasting task which can be replaced by any other markets. We have applied Convolutional Neural Networks (CNN) LSTM, vector sequence output LSTM, Bidirectional LSTM, and encoder-decoder LSTM on the dataset. The results of the vector sequence output LSTM achieved an MSE of 6.0e \u2212 4 , 8.0e \u2212 4 , and 2.0e \u2212 3 on the validation set respectfully for 1 day, 2 days, and 30 days predictions in advance which are outperforming other proposed method in the literature.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The novel Coronavirus (SARS-CoV-2) disease identified as COVID-19 has been initiated in Wuhan, China, and had a quick global spread. This disease first led to big human health problems in all countries and many cascading financial problems resulted from social distancing and travel restrictions. Governments proceeded with specific procedures to control the speed of spreading the disease such as canceling flights, locking down their national and state borders, preventing most exports and imports, and shutting down some businesses which lead to a huge economic shock to the world. In this situation, trading (including business travel) which is essential and crucial part of today's life can Mahtab Mohtasham Khani and Sahand Vahidnia contributed equally to this work. facilitate spreading the virus in many ways [39] . On the other hand, without trading economy will collapse and the effects of such economic devastation will remain for a long time. The pandemic has damaged the global economy by creating problems in the world supply chain [4] . For example, equity markets in the EU and US dropped by as much as 30% [19] . Generally, there was a dramatic shock to global trading activities during the COVID-19 pandemic such as increasing the demand for essential goods such as medical products and food, as well as a sharp decrease in the prices of some products like oil, or the collapse of some airlines declaring bankruptcy with hopes to resume operations after the end of the outbreak [34] . According to a recent review, [5] trade implications of the COVID-19 pandemic that China and the rest of the world follow a new pattern which leads some economies to win and some to lose.",
            "cite_spans": [
                {
                    "start": 817,
                    "end": 821,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1046,
                    "end": 1049,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1123,
                    "end": 1127,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1496,
                    "end": 1500,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1533,
                    "end": 1536,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Understanding the economic implications and impact of the pandemic on the economy is a way to minimize the impact and support the economic decision-makers on their trade choices. Conventional methods such as tacking economic factors of companies and the markets, like the statement of cash flow and balance sheet, or technical analysis to understand the market trend based on the volume and price, have been in place for many years and predictions have been made for decades using these methods. With the emergence and advancements in machine learning and deep learning, new methods have emerged to better understand the patterns and make more accurate predictions. These data-driven methods require access to large datasets, which have been available during recent years, and has paved the ground for the research in this direction [29] . The nature of the features of each pandemic is different, hence, one result cannot be applied to other cases. Hence, in this study, we develop a framework facilitating the overall procedure of time series analysis and predictive robust models in various cases.",
            "cite_spans": [
                {
                    "start": 833,
                    "end": 837,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this work, we use LSTM for time series analysis in order to better understand the patterns in the sequences and improve the prediction performance. LSTMs are basically artificial recurrent neural networks (RNNs) that can process the entire sequence of data. LSTM was first investigated by Hochreiter [22] to deal with the problem of vanishing or exploding the gradients of RNNs. LSTM Networks are a solution for extracting the pattern of the input data-set which spans over a sequence of time which can be responsible for COVID-19 as a nonlinear feature over a sequence of time.",
            "cite_spans": [
                {
                    "start": 303,
                    "end": 307,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The main objective of this research is to analyze and explore the implications of COVID-19 on the economy considering short-term implications and patterns of pandemics on the world trade and market sector, by studying the case of Gold price on the stock market, based on the COVID-19 time series and 11 sectors of the market during the recent years and months. We study the correlation between different sectors and COVID-19 new cases for distinguishing the effective features in market prediction. This paper contributes to market prediction accuracy by developing an accurate forecasting model on the stock market values with respect to the COVID-19 dataset, using LSTM. Our forecasts are based on the market value data extracted from Yahoo! Finance and COVID-19 pandemic daily time-series data (i.e. the number of new cases). We applied our method for 1, 2, and 30 days in advance predictions, concerning COVID-19 data. The performance of our proposed method has been examined and validated using Mean Square Error (MSE) on the validation dataset, by comparing it to the most recent developments in the field.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Human beings have faced many pandemics throughout the history such as SARS Epidemic [6] , Middle East respiratory syndrome (MERS) [11] , West African Ebola epidemic [24] , and H1N1 Swine Flu pandemic [17] . The pandemics are known to have significant effects on the economy, some of which may persist for decades after the pandemic [23] . There are many studies trying to understand the pandemic and its effects on trade. Some of these studies are purely economic and are not relying on machine learning for predictions. Machine learning is a branch of analytic predictions in which has a lower reliance on human expert supervision for understanding and analyzing the reasons and causes [31] . Machine learning algorithms do not count out the need for human expert analyzes, meanwhile they are one of the best solutions for extracting the underlying patterns [33] . The studies in this section analyze the economical, social, and even political aspects of the markets to understand and explain the market. These studies provide insights into the economic point of view of the pandemics and help to better understand the variables. In a review paper by Barua [5] , likely trade implications of the COVID-19 pandemic have been found to provide a better understanding of the impacts of COVID-19 on coming days. This study investigates a standard trade framework and then proposes a theoretical mapping that depicts the progress of trade implications. The study then reviews some real-life evidence for testing his map and concluded with clues for controlling pandemic situations. The study divides the effects of a pandemic into different short and long-term stages, and it suggests reducing reliance on specific countries to reduce the economic impact. In another survey about macroeconomic implications of COVID-19, the effects of negative supply shocks on the shortage of demands are discussed [21] . They argue the future of economic shocks of COVID-19 as well as presenting the theory of Keynesian supply shock, which is about larger changes in aggregate demand than the shocks, in comparison to standard supply shocks which concluded in a good understanding about availability or lack of some goods in the pandemic situation. The Center of Economic Policy Research (CERF), which is a network of economists mostly from European universities, has asserted that \"The virus is likely to be as 'contagious' economically as it is medically\" [3] . In the past recessions, global trade has slowed faster than global growth. This study [3] also discussed the demand shock on trade as well as the supply-sides of this virus. This study is an analysis across the COVID-19 and trade which emphasized the danger of permanent collapse of the trading system. Also, the optimal lock-down policies for minimizing the output costs of the lock-down was researched by Alvarez et al. [1] . The study uses a linear economy model to formalize the planner's dynamic control problem and identifies the features to measure the optimal intensity, shape, and time that this lockdown will last. Gormsen et al. [19] study the impacts of Coronavirus on stock prices and the growth expectation. They show how effective are news, events, and the data on dividend futures on forecasting and analyzing the drop and growth of the economy over time. They have studied the expected growth in the US and EU S&P 500 and Euro Stoxx 50 and estimated that Expected growth over the next year is down by 2.6% both in the US and the EU.",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 87,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 130,
                    "end": 134,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 165,
                    "end": 169,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 200,
                    "end": 204,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 332,
                    "end": 336,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 687,
                    "end": 691,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 859,
                    "end": 863,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1152,
                    "end": 1161,
                    "text": "Barua [5]",
                    "ref_id": null
                },
                {
                    "start": 1894,
                    "end": 1898,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 2438,
                    "end": 2441,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 2530,
                    "end": 2533,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 2866,
                    "end": 2869,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 3084,
                    "end": 3088,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Economy and Pandemics"
        },
        {
            "text": "The studies on market prediction and the surrounding literature can be generally divided into two categories: (1) the studies which predict the market using social networks analysis; and (2) the studies of time series analysis. The former category comprises methods like the diffusion models which are useful for minding lots of latent information and market predicting. Li et al. [26] investigate the research methods and techniques on diffusion models that could facilitate the prediction of social network influences or predicting the trade future leads. In another study, [2] proposed a system for detecting influenza epidemics using Twitter data. They extracted the tweets that mention actual influenza patients using the support vector machine (SVM)-based classifier for separating the negative and positive tweets.",
            "cite_spans": [
                {
                    "start": 381,
                    "end": 385,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 576,
                    "end": 579,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Stock Market Prediction"
        },
        {
            "text": "The second category, which is more in terms of quantity, mainly focus on methodologies to predict various financial time series. LSTM networks are always one of the best solutions for a sequence of data and single data points [16] . Hence, Fischer and Krauss propose and use the use of LSTMs in financial time series. The feature space in their study is the standardized daily stock market return of specific markets and days. They provide a comparison of LSTM, random forest, a standard deep net, and logistic regression and conclude that LSTM outperforms all other methods. In a more recent study, Livieris et al. [27] implement a CNN-LSTM model to predict gold price time-series and its fluctuations. The paper asserts that the combination of LSTM layers with some other convolutional layers increases the forecasting performance. They do not consider other variables and the pandemic, which could be a limitation of this study.",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 230,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 616,
                    "end": 620,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Stock Market Prediction"
        },
        {
            "text": "In a review paper on time series classification [15] , it has been emphasized that LSTM networks are the most efficient way for time series classification. Among the usages of LSTMs, time series forecasting problems are considered to reduce the complication of study in comparison to the other traditional ones [18] . This study [18] suggest using traditional methods in non-complicated tasks and to use LSTMs as substitute methodology. They conclude that LSTM has a great promise and opportunity for applying to the problem of time series forecasting. In another study [7] , LSTM is used in order to predict China's stock market return and has reported the power of LSTM in stock market prediction. Besides, Persio and Honchar [12] investigated a similar problem by applying artificial neural network architectures to predict trend movement on the stock market based on past returns. According to their results, in a comparison of multi-layer perceptron (MLP), convolutional neural networks, LSTMs for feature extractions, and the combination of wavelet transform and CNN, the latter one has achieved the best results.",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 52,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 311,
                    "end": 315,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 329,
                    "end": 333,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 570,
                    "end": 573,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 728,
                    "end": 732,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Stock Market Prediction"
        },
        {
            "text": "In a study surveying time series forecasting of the transmission of COVID-19 in Canada [8] , LSTMs are used to predict the possible stopping time of COVID-19 in Canada and around the world. They propose a multi-step LSTM method and predicted 2, 4, 6, 8, 10, 12, and 14th day for two successive days. The study proposes the use of bidirectional LSTM for the forecasting model. LSTM is also used as a data-driven estimation method in India for predicting the spread of COVID-19 and the effects of preventing protocols [36] . In this study, they predicted the number of COVID-19 cases in India 30 days ahead.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 90,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 516,
                    "end": 520,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "Stock Market Prediction"
        },
        {
            "text": "The prediction of the number of cases in a pandemic has been demonstrated to be somehow predictable based on the historical data. However, the same is not true for market data, as it has far more fluctuations. Additionally, as the studies suggest, the world pandemic situations would make the market movements more chaotic and unpredictable. As a result, we aim to adopt LSTM, as one of the best forecasting methods, to develop a predictive model for stock market prediction using LSTM-series by considering the COVID-19 data-set for market prediction for the first time. This will establish a guideline for future works of this category.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Stock Market Prediction"
        },
        {
            "text": "Our method comprises four steps. First, our data in which the overall market sectors and tickers are analyzed, compiled, and extracted. Then the relevant features are processed and extracted. Later, LSTM models are trained and tuned on the aforementioned features to create forecasting models with a range of hyperparameters, steps, and historical periods. Finally, the method and the results are evaluated and validated to be used for future forecasting tasks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "Originally, LSTM was investigated in 1991 by Hochreiter [22] to deal with the problem of vanishing or exploding gradients, which are very common in RNNs. Generally, RNNs are good at handling the sequence dependencies. LSTMs are a type of RNNs which are better suited for larger architectures and more capable of extracting patterns from large sequences of datasets. LSTMs are also known to have a better response for non-linearity [28] . The COVID-19 and market time-series data show a non-linear behavior that motivates the application of LSTM in this research.",
            "cite_spans": [
                {
                    "start": 56,
                    "end": 60,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 431,
                    "end": 435,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "LSTM Models"
        },
        {
            "text": "As illustrated in Fig. 1 , each LSTM unit consists of three gates: a forget gate which remembers the values over arbitrary time intervals, and two other gates to regulate information into and out of the cell, which is called input and output gates. Each LSTM cell maintains a cell state vector and at each time step, the next LSTM can choose to read from it, write to it or reset the cell. These gates give the ability to control the process of memorizing to LSTM, and therefore, it can avoid long-term dependency [25] which is a key factor of solving problems related to COVID-19 with a short historical dataset. The parameters of the gates are expressed in Eq. 1, where expresses the sigmoid function, w x expresses the weights for the neurons of gate x, h t\u22121 expresses the output from last LSTM unit, x t expresses current input, and b x expresses the biases for the gate x.",
            "cite_spans": [
                {
                    "start": 514,
                    "end": 518,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 18,
                    "end": 24,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "LSTM Models"
        },
        {
            "text": "In this study, we conduct both single-step and multi-step analysis, predict gold prices at least a day ahead. To have a better sensitivity analysis, we also employ both multi-variate and uni-variate approaches to demonstrate the effectiveness of other variables. There are numerous methods and approaches involving LSTMs to tackle time series forecasting analysis which depends on the dataset and the task. In the following sections, these approaches will be discussed and established to pave the ground for comparison and model selection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "LSTM Models"
        },
        {
            "text": "To predict the gold price a day in advance, single-step feedforward stacked LSTM networks are used. As mentioned earlier, a series of hyper-parameters and input variables are tested to better understand the effect of feature space on the prediction error. The overall structure of the LSTM networks employed in this section is depicted in Fig. 2 . Generally, the higher number of LSTM cells within a layer would allow us to have a longer memory. This means that for longer historic days, we can grow the width of the LSTM network and vice versa to have an optimal fit. The activation layers in all architectures are Rectified Linear Unit (ReLU) (Eq. 2) and the optimizer of choice for LSTM networks are usually ADAM, as opposed to Stochastic Gradient Descent (SGD) which are usually known for robust optimization. After tuning",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 339,
                    "end": 345,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Single-Step LSTM"
        },
        {
            "text": "for input gate Table 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 15,
                    "end": 22,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Single-Step LSTM"
        },
        {
            "text": "Forecasting for more than one day or step makes it a multi-step forecasting problem. The methods for addressing the multi-step forecasting problem can be categorized under the vector-output sequence prediction approach and encoder-decoder approach. The encoder-decoder approach in addition to the vector output sequence prediction methods is the main focus of this study. To validate the results and have a comparison to other suggested methods in the literature, the results will also be compared to Bidirectional LSTM and CNN-LSTM.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-step LSTM"
        },
        {
            "text": "The output for a multi-step forecasting LSTM can be a vector sequence. This can be achieved by simply adding n-output neurons to a simple vanilla LSTM network. Hence, the overall architecture of the multi-step vector output approach is almost identical to Fig. 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 256,
                    "end": 262,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Multi-step LSTM"
        },
        {
            "text": "Encoder-decoder as it is explained by its name, predicts by encoding the inputs and then decoding the output. This approach is used for multi-step time series forecasting [10] . The model was designed to solve sequence to sequence problems like natural language processing [35] , text translation, and answering textual questions. Encoder-decoder is also known to yield good results for image classification, image to text, movement classification, and describing images by text tasks [38] . The encoder-decoder approach in LSTM can have many different implementations, suiting different workloads. In general, the overall architecture of the experimented encoder-decoder models in this study can be illustrated as Fig. 3 . As illustrated, the model takes and encodes the inputs, then repeats the final state of the encoding layer for all time steps. The decoder comprises at least an LSTM layer and time distributed dense layer to provide the output of the desired shape and structure.",
            "cite_spans": [
                {
                    "start": 171,
                    "end": 175,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 485,
                    "end": 489,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [
                {
                    "start": 715,
                    "end": 721,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Multi-step LSTM"
        },
        {
            "text": "CNN-LSTMs are the combination of CNNs and LSTMs [29] that are common to be utilized in computer vision problems [13] . CNN-LSTMs are also encoder-decoder-based approaches, where the encoding happens in the CNN section. They have been utilized in various tasks in the literature like caption generation [38] and prediction of gold prices [27] . Thus, CNN-LSTM models have also been experimented in this study, and the results are discussed in the following section.",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 52,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 112,
                    "end": 116,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 302,
                    "end": 306,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 337,
                    "end": 341,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Multi-step LSTM"
        },
        {
            "text": "Bidirectional LSTM is inspired by Bidirectional Recurrent Neural Networks [32] . The network learns the sequences both from forward and backward and then concatenates all",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 78,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Multi-step LSTM"
        },
        {
            "text": "the data for prediction. Bidirectional LSTM networks can be more beneficial than unidirectional ones in terms of results [20] .",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 125,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Multi-step LSTM"
        },
        {
            "text": "Similar to the single-step LSTM approaches, ReLU activation and ADAM optimizer have been used in all architectures. In the following section, we discuss the evaluation metrics, the data required for this analysis and forecasting models, and the result of the analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi-step LSTM"
        },
        {
            "text": "For validation purposes, we separate a 90 recent days period of our dataset as a validation set and validated the model on the aforementioned period. In order to accommodate the randomness factor, the tests have been repeated a number of times and only the top-performing seeds and training instances have been referred to.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Validation and Evaluation"
        },
        {
            "text": "There are various metrics to calculate the loss in regression and prediction tasks. Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error(MAE), Mean Squared Logarithmic Error (MSLE) are all techniques to find the difference between the predicted value and the actual value. However, in this study the models are optimized on the MSE values. Hence, the comparison results will favor this metric. This affects both best-model and training checkpoint selection, and the comparison of different LSTM methodologies and models based on validation Fig. 3 Encoder-decoder LSTM network architecture. X is input, Y is output, and h is hidden state of the LSTM cells errors. However, to better understand the results, we take advantage of all of them which are respectfully defined by Eq. 3, where n is for the number of predictions and y i is the ground truth of i instance and the \u0177 i is the predicted results of them.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 563,
                    "end": 569,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Validation and Evaluation"
        },
        {
            "text": "There are thousands of publicly traded stocks around the world and every one of them can be categorized as a member of the 11 major market sectors [14], including Financial, Utilities, Consumer Discretionary, Consumer Staples, Energy, Healthcare, Industrial, Technology, Telecom, Materials, and Real Estate. These 11 sectors are responding to the key areas of the economy and all the companies in each sector share the same broad focus. The list of corresponding tickers of the 11 market sectors has been collected from ETFdb. 1 As the list of the market sectors is long and the market values and volume of the tickers vary drastically, only the top 10 tickers with the highest values for each sector have been selected. The market data in this study is gathered for this selected top 10 sector tickers for the past five years from 07/2015 to 07/2020 from Yahoo! Finance, which also covers the recent global COVID-19 pandemic period. On the other hand, we also need COVID-19 pandemic data (including newly infected and total infections) to incorporate in our model and it has been collected from the \"'JHU CSSE COVID-19 Data\" daily time series. As the market data has been collected from 30-07-2015 to 30-07-2020 and COVID-19 data starts from 22-01-2020, the COVID-19 values prior to 22-01-2020 have been set to zero to match the dimensionality of market dates.",
            "cite_spans": [
                {
                    "start": 527,
                    "end": 528,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "The Data"
        },
        {
            "text": "The COVID-19 time-series data comprises both the world and USA data separately. To best utilize this data,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Understanding the Feature Space"
        },
        {
            "text": "an aggregation of these cases have also been recorded and added to the feature space. Then the new cases have been calculated as the difference of the daily cases, yielding six features as follows: US-new, US-all, World-wide-new (except the US), World-wide-all (except the US), Totalnew, Total-all. Finally, the case numbers are normalized before feeding to the neural networks, making the feature space even better suited for the task. The stock market data has many missing rows as a result of market closures for holidays and weekends. Hence, data was padded to interpolate the missing data. The reason to prefer padding to other interpolation techniques is that it's intuitive to refer to the final exchange rates and values as the current one. To obtain sector data, the selected ticker data for market close rate, volume, and daily average rates are acquired and calculated. Later, the mean of the corresponding values is taken as the overall sector values and then normalized to better fit the neural networks. To better understand the feature space and the relationships among the features, Fig. 4 illustrates the technology sector symbol average vs. the COVID-19 cases, which hints at a correlation in the data. Hence, a correlation analysis is carried out to better understand these relationships among COVID-19 and the market. This analysis provides further insights into the strength of relationships among the variables and parameters to be used in our model, helping us to confidently include important variables in the feature space and eliminate less important ones.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1099,
                    "end": 1105,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Understanding the Feature Space"
        },
        {
            "text": "To prepare the data for analysis, the volume, and the average of daily sector values are calculated. Later, the results are normalized and then the logistic regression model of the values is calculated. As the prediction goal and case of this study are to forecast gold price, the feature space should be prepared. To better understand the feature space, the correlation coefficients are calculated against the daily gold price (as the possible dependent variable) within the last 300 days period. A strong correlation can be subjective and vary from one study to other [37] , but in this study, r = \u00b10.4 has been selected as the correlation coefficient threshold to eliminate weak correlations. As shown in Table 1 , only some sectors including total new COVID-19 cases in the world, Consumer-staples (closing price), and Technology (closing price) have statistically significant correlations (significance of over 95% and r > 0.4 or r < \u22120.4 ) with gold price. Hence, all the remaining sectors values with non-significant correlations are eliminated to finalize the feature space. Table 1 shows the correlation coefficients across the sectors. In Table 1 the correlations for both 'Close-gold' and 'Averagegold' are presented to illustrate the difference between the correlations of the closing price of the market and the daily average prices. Overall, we can see similar results on both.",
            "cite_spans": [
                {
                    "start": 570,
                    "end": 574,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [
                {
                    "start": 708,
                    "end": 715,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1083,
                    "end": 1090,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1149,
                    "end": 1156,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Understanding the Feature Space"
        },
        {
            "text": "As shown in Table 1 , new COVID-19 cases have stronger correlation (r value) with the market data. On the other hand, it is also observable that the daily market average value (normalized) has a stronger correlation with the COVID-19 pandemic than the market volume (normalized). It should also be reminded that correlation does not necessarily result in causation, yet the strong correlations can bear latent underlying connections, relationships, or meanings. For instance, the energy sector has the strongest (negative) correlation coefficient to the new cases. As the cases rise, the energy sector market value falls. This is very sensible, as can be observed from the recent drop in fuel prices, which hints at causality. The same also applies to the industrial sector, which comes second after the energy sector. The financial sector also has a very strong correlation coefficient, with -0.954, which comes third in this table. This indicates that the financial sector has also been hit hard by the pandemic at similar levels.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 19,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Understanding the Feature Space"
        },
        {
            "text": "The experiments in this study have been implemented in Python 3.8. Keras [9] has been used for deep learning implementations and Scikit-learn [30] has been used for some loss evaluations.",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 76,
                    "text": "[9]",
                    "ref_id": null
                },
                {
                    "start": 142,
                    "end": 146,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "Time series analysis has 1, 2 and 30 days of future data (single and multi-step) predictions. The history and the range of the data to infer from has also been a variable tuned in this study for both single and multi-step predictions. The number of historical days to tune is 5, 9, 15, 22 , and 30 for the 1 and 2-day predictions, and 45 and 60 historical days for 30 days prediction models. All models have been trained for 400 epochs, with the best model checkpoints.",
            "cite_spans": [
                {
                    "start": 276,
                    "end": 278,
                    "text": "5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 279,
                    "end": 281,
                    "text": "9,",
                    "ref_id": null
                },
                {
                    "start": 282,
                    "end": 285,
                    "text": "15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 286,
                    "end": 288,
                    "text": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "An objective of this study is to see the effect of COVID-19 pandemic data in the market future prediction error. Hence, the models are trained with varying features to see the influence of COVID-19. In this study as presented in the results Table 3 , the inclusion of COVID-19 data in feature space would increase the model's performance for 1 and 2 days in advance predictions. Taking into account that the variation in feature space might require architectural modifications and tuning, the tests and tuning were carried out on three different feature spaces of uni-variate gold data, multi-variate data with COVID-19, and multivariate data without COVID-19. We also notice that as opposed to many other studies that implement uni-variate methods, implementation of the multi-variate approach and taking advantage of related variables in the market has improved the performance of the models by reducing their errors. As discussed in Understanding the Feature Space section, the features have been selected based on their correlation coefficients with the target market value.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 241,
                    "end": 248,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "The Feature Space"
        },
        {
            "text": "The features in this study can only capture so much of the real-world influence of variables on the stock market. Many other variables, including the sentiment of the news related to the pandemic does influence the markets. The use of COVID-19 case data in addition to the historic market data for the models in this study has been proposed to demonstrate this effect and its influence on the market data. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Feature Space"
        },
        {
            "text": "The best results were achieved with 30 days of historical data as sequence inputs for the 1-day predictions, and the LSTM network with the architecture of the winner model is mentioned in Table 3 . It is worth mentioning that the output of the stacked LSTM layers was taken and the hidden states were ignored, as it was noticed that having the hidden states does not improve the performance. A sample of this experiment has been recorded in Table 3 . The statement regarding the improved predictions using COVID-19 data stands true in single-step models as illustrated in Fig. 5 . We can see that the predictions can follow the trend much faster when we incorporate and enrich the market data features with COVID-19 data, visible in Fig. 5b . Error values are also self explanatory in this comparison, where the model on Fig. 5b has MSE of 0.00053 and the model on Fig. 5a stops at 0.00197.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 188,
                    "end": 195,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 441,
                    "end": 448,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 572,
                    "end": 578,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 733,
                    "end": 740,
                    "text": "Fig. 5b",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 821,
                    "end": 828,
                    "text": "Fig. 5b",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 865,
                    "end": 872,
                    "text": "Fig. 5a",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Single Step"
        },
        {
            "text": "As discussed previously in Multi-Step LSTM section, various multi-step models are tested in this study, including vector-output sequence prediction and encoder-decoder. According to our experiments and after many different runs due to the stochastic and random behavior, we determined that the winner method is vector output sequence prediction with 22 days of history, predicting two days in advance. The MSE of the model on validation data has been recorded as 0.00080. The encoder-decoder approach also performed very well in comparison to the rest of the approaches. Using the encoder-decoder approach, the MSE of 0.00091 was hit on the validation set. We noticed that simple stacked LSTM networks would outperform other methods for 1 and 2 days of prediction in advance, as probably it requires a less complicated approach for this kind of prediction task, and over-complicating the approach does not necessarily increase the performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multiple Steps"
        },
        {
            "text": "As it can be seen in Table 3 , COVID-19 data have a noticeable effect on the results. Generally, the results of the experiments without COVID-19 as demonstrated in Table 3 do not show any improvement. Besides, to calculate the effects of uni-variate data-sets, we predict some of the experiments with only the Gold-close data-set and our winner architecture and the results did not show any improvement in the performance. As it can be seen in Table 3 the error rate with uni-variate data-set is increasing totally.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 21,
                    "end": 28,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 164,
                    "end": 171,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 444,
                    "end": 451,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Multiple Steps"
        },
        {
            "text": "Finally, 30 days prediction of the stock market value sequence is carried out, which is presented in Table 2 . The historical periods of 45 days and 60 days are compared as the best resulted in experiments in this category. The MSE of the best model is 0.0021 which indicates the model has converged and reached a low error value. As illustrated, the vector output model has achieved the be best results in comparison to encoder-decoder, bidirectional, and CNN-LSTM models. These results are in line with 2-day prediction models, hinting at the capability of the vector output model, given correct architecture and hyper-parameters. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 101,
                    "end": 108,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Multiple Steps"
        },
        {
            "text": "Here we discuss and compare our proposed methods' results with two other proposed models. The first study proposes a time-series forecasting prediction for the price of gold, by a CNN-LSTM model [27] that using uni-variate data and single-step prediction (single-day forecast) which is shown in Table 3 (marked by * on row 26). Changing the uni-variate to multivariate model using the same overall architecture improves the results (specifically MSE), as illustrated in the next row. Also, comparing these results with our best architectures (i.e. vector-output sequence) with the same features, we notice that regarding the prediction of Gold price with this much fluctuations, our models yield better results in terms of prediction error (lower MSE) (Fig. 6) . The second study [8] surveyed the prediction of COVID-19 in Canada Using LSTM Networks for 14 days in advance and used uni-variate dataset and Bidirectional LSTM (model '28, td14' in Table 3 ). It was noticed that the method could not be fitted to this problem efficiently and the errors are higher than other methods. For a more accurate comparison, we also predicted 14 days with encoder-decoder architecture and uni-variate dataset (model 'L200-r-L200-td100-td1'), and as the results reflect, our proposed model outperforms the approach. Besides, we further modified their model by changing the dataset from uni-variate to multi-variate ('BDL28, td1' on rows 30 and 31), and as it can be seen the results improved with reducing the errors (considering all four errors). Changing the architecture, yet preserving the bidirectional LSTM approach improves the errors, but fails to outperform the rest of the approaches. We can see in Table 3 on rows 23-25 that using the encoder-decoder approach reduces the errors drastically. Hence, we can conclude that tuning and adapting bidirectional and CNN-LSTM approaches for this task would be much harder and even impossible. Finally, we can assert that the multivariate dataset affects the final results positively in almost every architecture, yielding lower errors. ",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 199,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 780,
                    "end": 783,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 932,
                    "end": 945,
                    "text": "'28, td14' in",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 295,
                    "end": 302,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 752,
                    "end": 760,
                    "text": "(Fig. 6)",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 946,
                    "end": 953,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 1697,
                    "end": 1704,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Comparison of the Proposed Method"
        },
        {
            "text": "In this study, we developed a set of prediction models for financial markets based on various features (including COVID-19 and different analyses of the market). We further investigated the effects of these features, specifically the COVID-19 pandemic, on the predictive models. The paper focuses on three aspects: (1) days to predict, (2) machine learning approaches, and (3) the feature space.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        },
        {
            "text": "The results and experiments show that although vanilla stacked LSTMs might seem simple, yet they are very powerful at prediction compared to encoder-decoder, Bidirectional, and CNN-LSTM approaches in time series prediction problems. In this study, we achieve the MSE of 5e \u2212 4 for single-step and 8e \u2212 4 for multi-step forecasting for two days of prediction in advance as illustrated in Table 3 . These results can be achieved using at least 5 days of historic data for single-step predictions, 22 days of historic data for twostep prediction, and 45 days of historic data for 30 days prediction in advance. The models expect normalized data, and should be trained on a sufficient amount of historic time series data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 387,
                    "end": 394,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Conclusion and Future Work"
        },
        {
            "text": "We also show the power of other financial indicators (i.e. market data like oil, technology symbols, etc.) and non-financial parameters (e.g. COVID-19 new cases), in the prediction of a specific market. Correlation analyses are utilized in this study to establish the connection among markets and the features in general. According to the results, we can assert that having a dataset of other pandemics and the variations of the economy in that situation in history can boost the results. Although the models can achieve very low errors, it should also be acknowledged that markets rely on many variables like geopolitical decisions, global news, and escalations that can result in sudden movements. This is a limitation of machine learning at market forecasting, as designing an AI to comprehend every variable is not easily achievable. A reliable predictive model for real-world use may rely on numerous data points and features. It should be acknowledged that this study is a simplified proof of concept showing the effectiveness of non-economic features for short term predictions. As a future work, understanding the semantics and context of social networks can also be considered as a potential feature in predictive models. Further economic and market calculations as pre-processing stages of the features may also be explored in future works to increase the accuracy and making the real-world implementations more reliable.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A simple planning problem for covid-19 lockdown",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "E"
                    ],
                    "last": "Alvarez",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Argente",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Lippi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "National Bureau of Economic Research",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3386/w26981"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Twitter catches the flu: detecting influenza epidemics using twitter",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Aramaki",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Maskawa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Morita",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the conference on empirical methods in natural language processing",
            "volume": "",
            "issn": "",
            "pages": "1568--76",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Economics in the time of COVID-19: a new E-book. VOX CEPR Policy Portal",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Baldwin",
                    "suffix": ""
                },
                {
                    "first": "Di",
                    "middle": [],
                    "last": "Mauro",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "W"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "The greater trade collapse of 2020: learnings from the 2008-2009 great trade collapse",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Baldwin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Covid-19 pandemic and world trade: some analytical notes",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Barua",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Available at SSRN",
            "volume": "3577627",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "A chronicle on the sars epidemic",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Chin Law Government",
            "volume": "36",
            "issn": "4",
            "pages": "12--17",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A LSTM-based method for stock returns prediction: a case study of china stock market",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 IEEE International Conference on Big Data",
            "volume": "",
            "issn": "",
            "pages": "2823--2827",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Time series forecasting of COVID-19 transmission in Canada using LSTM networks",
            "authors": [
                {
                    "first": "Vkr",
                    "middle": [],
                    "last": "Chimmula",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "135",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Cho",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Van Merri\u00ebnboer",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gulcehre",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bahdanau",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Bougares",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Schwenk",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1406.1078"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Commentary: middle east respiratory syndrome coronavirus (mers-cov): announcement of the coronavirus study group",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "J"
                    ],
                    "last": "De Groot",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "C"
                    ],
                    "last": "Baker",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Baric",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "S"
                    ],
                    "last": "Brown",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Drosten",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Enjuanes",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Fouchier",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Galiano",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Gorbalenya",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Memish",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "J Virol",
            "volume": "87",
            "issn": "14",
            "pages": "7790--7792",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Artificial neural networks approach to the forecast of stock market price movements",
            "authors": [
                {
                    "first": "Di",
                    "middle": [],
                    "last": "Persio",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Honchar",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International Journal of Economics and Management Systems",
            "volume": "1",
            "issn": "",
            "pages": "158--62",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Long-term recurrent convolutional networks for visual recognition and description",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Donahue",
                    "suffix": ""
                },
                {
                    "first": "Anne",
                    "middle": [],
                    "last": "Hendricks",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Guadarrama",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rohrbach",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Venugopalan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Saenko",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Darrell",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "2625--2659",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "The 11 sectors of the stock market",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "4--2020",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Deep learning for time series classification: a review",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "I"
                    ],
                    "last": "Fawaz",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Forestier",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Weber",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Idoumghar",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Muller",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Data Min Knowl Disc",
            "volume": "33",
            "issn": "4",
            "pages": "917--63",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Deep learning with long short-term memory networks for financial market predictions",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Krauss",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Eur J Oper Res",
            "volume": "270",
            "issn": "2",
            "pages": "654--69",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "The 2009 h1n1 pandemic: summary highlights",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "For Disease Control",
                    "suffix": ""
                },
                {
                    "first": "Prevention",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Official Online Article Published by the Centers for Disease Control",
            "volume": "4",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Applying lstm to time series predictable through time-window approaches",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Gers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Eck",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Neural Nets WIRN Vietri-01",
            "volume": "",
            "issn": "",
            "pages": "193--200",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Coronavirus: impact on stock prices and growth expectations",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "J"
                    ],
                    "last": "Gormsen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Koijen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Rev Asset Pric Stud",
            "volume": "10",
            "issn": "4",
            "pages": "574--97",
            "other_ids": {
                "DOI": [
                    "10.1093/rapstu/raaa013"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures. Neural Netw",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Graves",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "",
            "volume": "18",
            "issn": "",
            "pages": "602--612",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Macroeconomic implications of COVID-19: Can negative supply shocks cause demand shortages?",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Guerrieri",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lorenzoni",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Straub",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Werning",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "National Bureau of Economic Research: Tech. rep",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Long short-term memory",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural Comput",
            "volume": "9",
            "issn": "8",
            "pages": "1735--80",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Longer-run economic consequences of pandemics",
            "authors": [
                {
                    "first": "\u00d2",
                    "middle": [],
                    "last": "Jord\u00e0",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Taylor",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "National Bureau of Economic Research: Tech",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Understanding ebola: the 2014 epidemic. Glob Health",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kaner",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Schaack",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "12",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Application of long short-term memory (LSTM) neural network for flood forecasting. Water (Switzerland)",
            "authors": [
                {
                    "first": "X",
                    "middle": [
                        "H"
                    ],
                    "last": "Le",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "V"
                    ],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jung",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/w11071387"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A survey on information diffusion in online social networks: models and methods. Information (Switzerland)",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/info8040118"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A CNN-LSTM model for gold price time-series forecasting",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "E"
                    ],
                    "last": "Livieris",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Pintelas",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Pintelas",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Neural Comput Appl",
            "volume": "32",
            "issn": "23",
            "pages": "1--10",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Non-linear prediction with LSTM recurrent neural networks for acoustic novelty detection",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Marchi",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Vesperini",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Weninger",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Eyben",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Squartini",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schuller",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 International Joint Conference on Neural Networks (IJCNN)",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Deep-learning-based crack detection with applications for the structural health monitoring of gas turbines",
            "authors": [
                {
                    "first": "Mohtasham",
                    "middle": [],
                    "last": "Khani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Vahidnia",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ghasemzadeh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "E"
                    ],
                    "last": "Yuvalaklioglu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Akin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ure",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "K"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Struct Health Monit",
            "volume": "19",
            "issn": "5",
            "pages": "1440--52",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Scikit-learn: machine learning in Python",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pedregosa",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Varoquaux",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gramfort",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Michel",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Thirion",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Grisel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Blondel",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Prettenhofer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Weiss",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Dubourg",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Vanderplas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Passos",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cournapeau",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Brucher",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Perrot",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Duchesnay",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J Mach Learn Res",
            "volume": "12",
            "issn": "",
            "pages": "2825--2855",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Modeling syndromic surveillance and outbreaks in subpopulations",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Pettie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Bidirectional recurrent neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schuster",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "K"
                    ],
                    "last": "Paliwal",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "IEEE Trans Signal Process",
            "volume": "45",
            "issn": "11",
            "pages": "2673--81",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Application of machine learning algorithms for clinical predictive modeling: a data-mining approach in sct",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Shouval",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Bondi",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mishan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shimoni",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Unger",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Nagler",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Bone Marrow Transplant",
            "volume": "49",
            "issn": "3",
            "pages": "332--339",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Many of the world's airlines could be bankrupt by may because of the COVID-19 crisis",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Slotnick",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Sequence to sequence learning with neural networks. In: Advances in neural information processing systems",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Vinyals",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "3104--3116",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Prediction for the spread of COVID-19 in India and effectiveness of preventive measures",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tomar",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sci Total Environ",
            "volume": "728",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "An early phase software project risk assessment support method for emergent software organizations",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Vahidnia",
                    "suffix": ""
                },
                {
                    "first": "\u00d6",
                    "middle": [
                        "\u00d6"
                    ],
                    "last": "Tanr\u0131\u00f6ver",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Askerzade",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Int J Advan Comp Sci Appl",
            "volume": "8",
            "issn": "5",
            "pages": "105--123",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Show and tell: a neural image caption generator",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Vinyals",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Toshev",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erhan",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "3156--64",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Travel and the emergence of infectious diseases",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Wilson",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Emerg Infect Dis",
            "volume": "1",
            "issn": "2",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "LSTM internal architecture which consist of: h t\u22121 for the output from last LSTM unit, c t\u22121 for memory of the last LSTM unit and c \u2032 t for candidates of cell state at time t Two s to represent non-linearity as a sigmoid layers, tan h : represent tan h layer Vector operations: X expresses scaling the information, and + expresses adding informationFig. 2LSTM network architecture. X is input, Y is output, with stacked LSTM cells numerous hyper-parameters, the selection of top models has been presented at",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Technology symbols and COVID-19 time series in 300 days until 03 Jul 2020 Page 8 of 12 SN Computer Science",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Single-step time series prediction. Figure on the left a has been trained on the market data without COVID-19 time series. Figure on the right b has been trained on all features including COVID-19 time series data. Red markings are ground truth validation points and green marking are the predictions. The model makes prediction based on 30 days of historical data. The architecture is: LSTM(300)-LSTM(300)-Dense(100)-Dense(1)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Multi-step time series prediction. Figure on the left a has been trained on the market data without COVID-19 time series. Figure on the right b has been trained on all features including COVID-19 time series data. Red markings are ground truth validation points and green marking are the predictions. The model makes prediction based on 22 days of historical data. The architecture is: LSTM(200)-LSTM(200)-Dropout-Dense(2)",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Correlation analysis of all sectors vs. gold The p values for the corresponding correlations in this table, which already have been filtered, are below 1.59e \u2212 7 ww notion in COVID-19 cases indicates world-wide cases except the United States, US indicates the United States cases, norm indicates normalized data, all denotes the aggregated cases of the United States and the rest of the world, Close indicates the mean closing price of sector symbols, Avg. indicates the mean daily-average price of sector symbols",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "MSE error rates for 30 days prediction in advance with some of the best architectures History column shows the number of days that predictions are based on. L denotes LSTM layers, d denotes Dense layers, C denotes Convolution layers, BDL denotes bidirectional LSTM layers, pool denotes Max-pooling layers, E-D denotes encoder-decoder model, BD denotes bidirectional model, CNN denotes CNN-LSTM model, SE denotes vector output sequence prediction model",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Table of resultsThe column \"Step\" indicates the number of steps ahead (days) predicted that are 1, 2, and 14 days in this table.The column \"Variable\" shows different variables used in feature space (i.e Uni indicates the dataset which only includes Gold, Multi includes all the dataset, and COVID less includes all the financial, variables without COVID-19 data) History column shows the number of days that predictions are based on L denotes LSTM layers, d denotes Dense layers, C denotes Convolution layers, BDL denotes bidirectional LSTM layers, pool denotes Max-pooling layers, td denotes time distributed dense, pool denotes Max-pooling layers, E-D denotes encoder-decoder model, BD denotes bidirectional model, CNN denotes CNN-LSTM model, SE denotes vector sequence output prediction model * Based on[27] * * Based on[8]",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors declare that they have no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}