{"paper_id": "4450f32b838a66ea4087d284d3f43fb666f1b166", "metadata": {"title": "An Unsupervised Learning Approach to Discontinuity-Preserving Image Registration", "authors": [{"first": "Eric", "middle": [], "last": "Ng", "suffix": "", "affiliation": {"laboratory": "Imaging Lab", "institution": "Ontario Tech University", "location": {"addrLine": "2000 Simcoe Street North", "postCode": "L1H 7K4", "settlement": "Oshawa", "region": "ON", "country": "Canada"}}, "email": "eric.ng@ontariotechu.ca"}, {"first": "Mehran", "middle": [], "last": "Ebrahimi", "suffix": "", "affiliation": {"laboratory": "Imaging Lab", "institution": "Ontario Tech University", "location": {"addrLine": "2000 Simcoe Street North", "postCode": "L1H 7K4", "settlement": "Oshawa", "region": "ON", "country": "Canada"}}, "email": "mehran.ebrahimi@ontariotechu.ca"}]}, "abstract": [{"text": "Most traditional image registration algorithms aimed at aligning a pair of images impose well-established regularizers to guarantee smoothness of unknown deformation fields. Since these methods assume global smoothness within the image domain, they pose issues for scenarios where local discontinuities are expected, such as the sliding motion between the lungs and the chest wall during the respiratory cycle. Furthermore, an objective function must be optimized for each given pair of images, thus registering multiple sets of images become very time-consuming and scale poorly to higher resolution image volumes.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}, {"text": "Using recent advances in deep learning, we propose an unsupervised learning-based image registration model. The model is trained over a loss function with a custom regularizer that preserves local discontinuities, while simultaneously respecting the smoothness assumption in homogeneous regions of image volumes. Qualitative and quantitative validations on 3D pairs of lung CT datasets will be presented.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Image registration is an invaluable tool for medical image analysis and has received vast attention in imaging research for the past several decades. Image registration is used as a tool to find meaningful temporal transformations to align images taken at different time frames. Traditionally, registration algorithms assume smooth transformations. This assumption quickly falls apart for many cases, since different organs move, to a certain degree, independently from one another. Image misalignment becomes inevitable if smoothness is assumed at regions where discontinuities are expected, such as organ boundaries [4] . In this paper, we introduce an unsupervised learning model that learns the relationship between image pairs and a corresponding displacement field. We propose a regularizer that accounts for local image discontinuities while simultaneously respecting local homogeneity. This approach drastically decreases registration time, as the registration task is no longer an optimization task, but becomes a simple function evaluation.", "cite_spans": [{"start": 618, "end": 621, "text": "[4]", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "Introduction"}, {"text": "In traditional image registration, the most common approach is to solve an optimization problem, where the objective function is comprised of two terms, an image dissimilarity term and a regularization term to restrict the solution space. Common methods include elastic and diffusion models [16] , free-form deformations using b-splines [3] , and more recently, kernel methods [11] [12] [13] . Because all of these methods optimize an energy function for every image pair, large-scale or successive registration tasks becomes very time consuming. Specialized algorithms such as Thirion's Demons [5, 17, 22] allow significant reduction in computational time by estimating force vectors that acts to drive the deformation followed by Gaussian smoothing during the optimization process. Unfortunately, this algorithm restricts models to be diffusion-based models only.", "cite_spans": [{"start": 291, "end": 295, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 337, "end": 340, "text": "[3]", "ref_id": "BIBREF2"}, {"start": 377, "end": 381, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 382, "end": 386, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 387, "end": 391, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 595, "end": 598, "text": "[5,", "ref_id": "BIBREF4"}, {"start": 599, "end": 602, "text": "17,", "ref_id": "BIBREF16"}, {"start": 603, "end": 606, "text": "22]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "Related Work"}, {"text": "With the rise of deep learning over the past decade, learning-based approaches have become extremely popular. Several models are trained in a supervised manner which required ground truth transformations to be available [6, 15, 18] . Although these methods showed promising results, the task of obtaining ground truth transformation fields is cumbersome and highly prone to error. Thus, recent methods have shifted to an unsupervised approach instead, where models are trained based on how transformation fields act on images, rather than strictly on the transformations [1, 9, 25] . For a survey of learning-based image registration methods, refer to the article by Haskins et al. [10] .", "cite_spans": [{"start": 220, "end": 223, "text": "[6,", "ref_id": "BIBREF5"}, {"start": 224, "end": 227, "text": "15,", "ref_id": "BIBREF14"}, {"start": 228, "end": 231, "text": "18]", "ref_id": "BIBREF17"}, {"start": 571, "end": 574, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 575, "end": 577, "text": "9,", "ref_id": "BIBREF8"}, {"start": 578, "end": 581, "text": "25]", "ref_id": "BIBREF24"}, {"start": 682, "end": 686, "text": "[10]", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Related Work"}, {"text": "Our model follows a framework popularized by Voxelmorph [2] . Let I F and I M denote fixed and moving images. We find a function g \u03b8 (I F , I M ) that produces the displacement field u, i.e. u = g \u03b8 (I F , I M ). The deformation \u03c6 can then expressed as the mapping \u03c6 = Id + u where Id is the identity mapping. The deformation field is applied to I M to produce the warped image", "cite_spans": [{"start": 56, "end": 59, "text": "[2]", "ref_id": "BIBREF1"}], "ref_spans": [], "section": "Method"}, {"text": "Since \u03c6 may map the original coordinate system to non-integer valued voxel locations, interpolation is required to warp I M under \u03c6. For our experiments, we use trilinear interpolation due to its simplicity. An overview of the model is shown in Fig. 1 .", "cite_spans": [], "ref_spans": [{"start": 245, "end": 251, "text": "Fig. 1", "ref_id": "FIGREF0"}], "section": "Method"}, {"text": "The function g \u03b8 is modeled using a convolutional neural network where \u03b8 denotes the network parameters. The neural network follows a modified version of U-Net [19] , which contains an encoder and a decoder structure that mirror each other and are connected by skip connections at each layer (Fig. 2) . The encoder/decoder architecture is motivated by image pyramid techniques in many computer vision algorithms, where each encoding and decoding layer operate from coarse to fine representations of the input. The encoder consists of three convolution layers by applying 3 \u00d7 3 \u00d7 3 convolutions with stride 2 for downsampling, followed by LeakyReLU with slope of 0.2 at each layer. Each convolution layer has 32 output channels except the first layer which contains 16 output channels.", "cite_spans": [{"start": 160, "end": 164, "text": "[19]", "ref_id": "BIBREF18"}], "ref_spans": [{"start": 292, "end": 300, "text": "(Fig. 2)", "ref_id": "FIGREF1"}], "section": "Network Architecture"}, {"text": "The decoder follows a similar structure as the encoder but in reverse order. In the first decoding layer, we simply use the output of the final encoding layer as the input. In subsequent decoding layers, we first upsample the output of the previous decoding layer. Skip connections are constructed by concatenating layer outputs with that of the mirroring encoding layer. This effectively uses representations of the encoding layers to enforce more precise outputs in the decoding layers. Similar to the encoder, each decoding layer applies 3 \u00d7 3 \u00d7 3 convolutions followed by LeakyReLU of slope 0.2, but with stride 1 to preserve resolution at each layer. The output of the final decoding layer is passed into an additional convolution layer with 3 output channels, where each output channel contains the coordinate components of the displacement field u.", "cite_spans": [], "ref_spans": [], "section": "Network Architecture"}, {"text": "We train our model using a loss function in the form", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "where L sim measures image dissimilarity, L disc is a discontinuity preserving regularizer, and L mag is a second loss term that manages the (ir)regularities in the magnitude of the displacement fields. \u03bb sim , \u03bb disc , and \u03bb mag are corresponding regularization constants.", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "Similarity Loss. To measure image similarity/dissimilarity, we use a local normalized cross correlation which is defined as ", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "(2) where x is any voxel in the image domain \u03a9, and y \u2208 N (x) are the neighborhood points around voxel x, and \u03bc M (x) and \u03bc F (x) are the average local intensities around x in the moving and fixed images, respectively. LNCC is maximized when I F = I M which measures similarity, thus we define the dissimilarity measure as L sim = 1 \u2212 LNCC.", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "Discontinuous Loss. In designing the discontinuous loss, we first assume that there are no topological changes, i.e. no new tissue is introduced nor destroyed. We then consider the requirements based on these physical scenarios: 1. Homogeneous movement, 2. Movement along rigid structures, and 3. Sliding organs.", "cite_spans": [], "ref_spans": [], "section": "Loss Function"}, {"text": "These scenarios help us define the requirements for our regularizer. Firstly, the regularizer must preserve smooth local deformations that occur locally within organ interiors. Secondly, the regularizer must not penalize large local changes in deformation magnitude as long as the movement is in a similar direction. This is to mimic the movement of soft tissues or organs against rigid structures such as the rib cage or the spinal column. Finally, the regularizer must be able to account for movements in the opposite directions along organ boundary. This final requirement is perhaps the most significant as there are many scenarios where sliding organs exist. Common examples include the sliding of the lungs against the chest wall during the respiratory cycle, and the movement of organs against one another in the abdominal region. Figure 3 visually summarizes possible desired behaviors of a discontinuous displacement field. Figure 4 (a) demonstrates local homogeneity which is expected within organs. Figure 4 (b) allows displacement vectors of different magnitudes as long as they are in a similar direction, which represents soft tissue moving against rigid structures. (c) depicts sliding boundary conditions as displacement vectors on opposite sides of the boundary travel in opposite directions.", "cite_spans": [], "ref_spans": [{"start": 838, "end": 846, "text": "Figure 3", "ref_id": "FIGREF2"}, {"start": 933, "end": 941, "text": "Figure 4", "ref_id": "FIGREF3"}, {"start": 1010, "end": 1018, "text": "Figure 4", "ref_id": "FIGREF3"}], "section": "Loss Function"}, {"text": "where N is the number of voxels in the image. Now consider two arbitrary vectors u i and u j , respectively corresponding to locations x i and x j in the image domain. The area of the parallelogram spanned by u i and u j is maximized when u i and u j is orthogonal to one another, and minimized when they are parallel. Thus the three conditions are encouraged for any regularizer in the form", "cite_spans": [], "ref_spans": [], "section": "Let u be represented by a collection of displacement vectors {u"}, {"text": "where P the unsigned area of the parallelogram spanned by u i and u j , and g : R \u2192 R is a strictly increasing function satisfying g(0) = 0. P is computed as", "cite_spans": [], "ref_spans": [], "section": "Let u be represented by a collection of displacement vectors {u"}, {"text": "where \u00d7 denotes the cross product. We propose the regularizer", "cite_spans": [], "ref_spans": [], "section": "Let u be represented by a collection of displacement vectors {u"}, {"text": "where k(x i , x j ) is a decreasing weight function that depends on the proximity between the locations x i and x j . For our experiments, we choose the C 4 Wendland kernel [26] for k(x i , x j ).", "cite_spans": [{"start": 173, "end": 177, "text": "[26]", "ref_id": "BIBREF25"}], "ref_spans": [], "section": "Let u be represented by a collection of displacement vectors {u"}, {"text": "During preliminary stages of our experiments, we noticed that deformations in large dark image regions (background of CT image, for instance) behave erratically. We found that imposing an additional magnitudebased regularizer is needed to suppress this unpredictable behavior. Thus we add the following term to our loss function", "cite_spans": [], "ref_spans": [], "section": "Magnitude Loss."}, {"text": "This effectively discourages large magnitudes of u. Evidently, this additional term may become problematic for coarse registration where large-scale movement may be expected. However, since this is aimed towards addressing local discontinuities, it is safe to assume that deformations remain relatively small.", "cite_spans": [], "ref_spans": [], "section": "Magnitude Loss."}, {"text": "Our model is implemented using PyTorch 1.3.0 and trained using an NVIDIA GeForce GTX 1080Ti with 11 GB of graphics memory. CPU tests are performed on an Intel Xeon E5-1620 at 3.7 GHz. We trained our model using Adam optimizer [14] with \u03bb sim = 100, \u03bb disc = \u03bb mag = 1, and learning rate 10 \u22124 . The model is evaluated over 4DCT datasets provided by DIR-Lab [7, 8] and the POPI-model [23] . The DIR-Lab Reference 4DCT datasets contain ten sets of image volumes of sizes 256\u00d7256 and 512\u00d7512 with various number of axial slices (average of 100 and 128 for the two respective resolutions). To account for these variations, we only keep the middle 96 axial slices of the 256 \u00d7 256 volume, and the middle 112 axial slices of the 512 \u00d7 512 volumes. Each set of image volumes are taken over 10 time steps over the period of a single respiratory cycle. Since the input is a pair of image volumes, I F is chosen as the image volume with a randomly chosen case number and time step, and I M is selected based on the same case number with a different time step. By choosing eight cases as training data, this allows 8 \u00d7 10 \u00d7 9 = 720 training samples and 2 \u00d7 10 \u00d7 9 = 180 test samples, despite only having ten available cases. The POPI-Model contains six image volumes of sizes 512 \u00d7 512 with 140 to 190 axial slices. For consistency, we only keep the middle 136 axial slices and use five of the six cases as training data. We follow the same approach as DIR-Lab in choosing I F and I M .", "cite_spans": [{"start": 226, "end": 230, "text": "[14]", "ref_id": "BIBREF13"}, {"start": 357, "end": 360, "text": "[7,", "ref_id": "BIBREF6"}, {"start": 361, "end": 363, "text": "8]", "ref_id": "BIBREF7"}, {"start": 383, "end": 387, "text": "[23]", "ref_id": "BIBREF22"}], "ref_spans": [], "section": "Setup"}, {"text": "We first compare our discontinuity-preserving model with one that assumes global smoothness. As a baseline, we trained a second model using the DIR-lab dataset with an identical configuration, with the exception where the discontinuous loss L disc is replaced with a total variation loss L TV defined as", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "where the summation is over all voxels indexed by i. Figure 4 shows a comparison between our model trained using L TV and L disc . One can quickly identify sudden changes in the displacement field near the lung's boundaries especially near the lung/vertebrae interface. Additional registration results are shown in Fig. 5 . We compare our results (Table 1) quantitatively to the following methods: Free-Form Deformations (FFD) [20] , isotropic parametric Total Variation (pTV) [24] , and Sparse Kernel Machines (SKM) [12] . For comparison, we fixed frame [20] , pTV [24] , and SKM [12] on the DIR-Lab and POPI 4DCT Model. Baseline model is the same configuration but trained with LTV in place of L disc . 1 as the fixed image, and register all remaining frames to the reference. Finally, we compare the time required to register a pair of images using our approach versus a classical registration algorithm using minimization (Table 2) . Classical registration is applied using the AIRLab framework [21] via diffusion regularizer.", "cite_spans": [{"start": 427, "end": 431, "text": "[20]", "ref_id": "BIBREF19"}, {"start": 477, "end": 481, "text": "[24]", "ref_id": "BIBREF23"}, {"start": 517, "end": 521, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 555, "end": 559, "text": "[20]", "ref_id": "BIBREF19"}, {"start": 566, "end": 570, "text": "[24]", "ref_id": "BIBREF23"}, {"start": 581, "end": 585, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 999, "end": 1003, "text": "[21]", "ref_id": "BIBREF20"}], "ref_spans": [{"start": 53, "end": 61, "text": "Figure 4", "ref_id": "FIGREF3"}, {"start": 315, "end": 321, "text": "Fig. 5", "ref_id": "FIGREF4"}, {"start": 347, "end": 356, "text": "(Table 1)", "ref_id": "TABREF0"}, {"start": 926, "end": 935, "text": "(Table 2)", "ref_id": null}], "section": "Results"}, {"text": "We presented an unsupervised learning-based model for discontinuity preserving image registration. Although the training set was relatively small, our model performed on par with existing methods while begin able to handle locations where discontinuities may occur. Furthermore, our model significantly reduced computation by several orders of magnitude, allowing successive registration to be performed within a relatively short time frame. A drawback of the model is its sensitivity to noise. In particular, since L disc is computed by comparing local displacement vectors with neighboring displacement vectors individually, there are no mechanisms to discourage local chaotic behaviors in the displacement field. A possible remedy is to extend the current model to incorporate additional information, such as segmentation masks and edge information. This allows image discontinuities to be defined rather than relying on only image intensities to predict boundary regions.", "cite_spans": [], "ref_spans": [], "section": "Conclusion and Future Work"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "An unsupervised learning model for deformable medical image registration", "authors": [{"first": "G", "middle": [], "last": "Balakrishnan", "suffix": ""}, {"first": "A", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "M", "middle": ["R"], "last": "Sabuncu", "suffix": ""}, {"first": "J", "middle": [], "last": "Guttag", "suffix": ""}, {"first": "A", "middle": ["V"], "last": "Dalca", "suffix": ""}], "year": 2018, "venue": "Proceedings of the IEEE Conference on CVPR", "volume": "", "issn": "", "pages": "9252--9260", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "VoxelMorph: a learning framework for deformable medical image registration", "authors": [{"first": "G", "middle": [], "last": "Balakrishnan", "suffix": ""}, {"first": "A", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "M", "middle": ["R"], "last": "Sabuncu", "suffix": ""}, {"first": "J", "middle": [], "last": "Guttag", "suffix": ""}, {"first": "A", "middle": ["V"], "last": "Dalca", "suffix": ""}], "year": 2019, "venue": "IEEE Trans. Med. Imaging", "volume": "38", "issn": "", "pages": "1788--1800", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Free-form B-spline deformation model for groupwise registration", "authors": [{"first": "S", "middle": ["K"], "last": "Balci", "suffix": ""}, {"first": "P", "middle": [], "last": "Golland", "suffix": ""}, {"first": "M", "middle": ["E"], "last": "Shenton", "suffix": ""}, {"first": "W", "middle": ["M"], "last": "Wells", "suffix": ""}], "year": 2007, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Registration of organs with sliding interfaces and changing topologies", "authors": [{"first": "F", "middle": ["F"], "last": "Berendsen", "suffix": ""}, {"first": "A", "middle": ["N"], "last": "Kotte", "suffix": ""}, {"first": "M", "middle": ["A"], "last": "Viergever", "suffix": ""}, {"first": "J", "middle": ["P"], "last": "Pluim", "suffix": ""}], "year": 2014, "venue": "", "volume": "9034", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "A demons algorithm for image registration with locally adaptive regularization", "authors": [{"first": "N", "middle": ["D"], "last": "Cahill", "suffix": ""}, {"first": "J", "middle": ["A"], "last": "Noble", "suffix": ""}, {"first": "D", "middle": ["J"], "last": "Hawkes", "suffix": ""}], "year": 2009, "venue": "MICCAI 2009", "volume": "5761", "issn": "", "pages": "574--581", "other_ids": {"DOI": ["10.1007/978-3-642-04268-3_71"]}}, "BIBREF5": {"ref_id": "b5", "title": "Deformable image registration based on similarity-steered CNN regression", "authors": [{"first": "X", "middle": [], "last": "Cao", "suffix": ""}], "year": 2017, "venue": "MICCAI 2017", "volume": "10433", "issn": "", "pages": "300--308", "other_ids": {"DOI": ["10.1007/978-3-319-66182-7_35"]}}, "BIBREF6": {"ref_id": "b6", "title": "Four-dimensional deformable image registration using trajectory modeling", "authors": [{"first": "E", "middle": [], "last": "Castillo", "suffix": ""}, {"first": "R", "middle": [], "last": "Castillo", "suffix": ""}, {"first": "J", "middle": [], "last": "Martinez", "suffix": ""}, {"first": "M", "middle": [], "last": "Shenoy", "suffix": ""}, {"first": "T", "middle": [], "last": "Guerrero", "suffix": ""}], "year": 2009, "venue": "Phys. Med. & Biol", "volume": "55", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "A framework for evaluation of deformable image registration spatial accuracy using large landmark point sets", "authors": [{"first": "R", "middle": [], "last": "Castillo", "suffix": ""}], "year": 2009, "venue": "Phys. Med. Biol", "volume": "54", "issn": "7", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Unsupervised learning for fast probabilistic diffeomorphic registration", "authors": [{"first": "A", "middle": ["V"], "last": "Dalca", "suffix": ""}, {"first": "G", "middle": [], "last": "Balakrishnan", "suffix": ""}, {"first": "J", "middle": [], "last": "Guttag", "suffix": ""}, {"first": "M", "middle": ["R"], "last": "Sabuncu", "suffix": ""}], "year": 2018, "venue": "MICCAI 2018", "volume": "11070", "issn": "", "pages": "729--738", "other_ids": {"DOI": ["10.1007/978-3-030-00928-1_82"]}}, "BIBREF9": {"ref_id": "b9", "title": "Deep learning in medical image registration: a survey", "authors": [{"first": "G", "middle": [], "last": "Haskins", "suffix": ""}, {"first": "U", "middle": [], "last": "Kruger", "suffix": ""}, {"first": "P", "middle": [], "last": "Yan", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1903.02026"]}}, "BIBREF10": {"ref_id": "b10", "title": "Bilateral regularization in reproducing kernel hilbert spaces for discontinuity preserving image registration", "authors": [{"first": "C", "middle": [], "last": "Jud", "suffix": ""}, {"first": "N", "middle": [], "last": "M\u00f6ri", "suffix": ""}, {"first": "B", "middle": [], "last": "Bitterli", "suffix": ""}, {"first": "P", "middle": ["C"], "last": "Cattin", "suffix": ""}, {"first": "L", "middle": [], "last": "Wang", "suffix": ""}, {"first": "E", "middle": [], "last": "Adeli", "suffix": ""}, {"first": "Q", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Shi", "suffix": ""}], "year": 2016, "venue": "MLMI 2016", "volume": "10019", "issn": "", "pages": "10--17", "other_ids": {"DOI": ["10.1007/978-3-319-47157-0_2"]}}, "BIBREF11": {"ref_id": "b11", "title": "Sparse kernel machines for discontinuous registration and nonstationary regularization", "authors": [{"first": "C", "middle": [], "last": "Jud", "suffix": ""}, {"first": "N", "middle": [], "last": "Mori", "suffix": ""}, {"first": "P", "middle": ["C"], "last": "Cattin", "suffix": ""}], "year": 2016, "venue": "Proceedings of the IEEE Conference on CVPR Workshops", "volume": "", "issn": "", "pages": "9--16", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Directional averages for motion segmentation in discontinuity preserving image registration", "authors": [{"first": "C", "middle": [], "last": "Jud", "suffix": ""}, {"first": "R", "middle": [], "last": "Sandk\u00fchler", "suffix": ""}, {"first": "N", "middle": [], "last": "M\u00f6ri", "suffix": ""}, {"first": "P", "middle": ["C"], "last": "Cattin", "suffix": ""}, {"first": "M", "middle": [], "last": "Descoteaux", "suffix": ""}, {"first": "L", "middle": [], "last": "Maier-Hein", "suffix": ""}, {"first": "A", "middle": [], "last": "Franz", "suffix": ""}, {"first": "P", "middle": [], "last": "Jannin", "suffix": ""}, {"first": "D", "middle": ["L"], "last": "Collins", "suffix": ""}], "year": 2017, "venue": "MICCAI 2017", "volume": "10433", "issn": "", "pages": "249--256", "other_ids": {"DOI": ["10.1007/978-3-319-66182-7_29"]}}, "BIBREF13": {"ref_id": "b13", "title": "Adam: a method for stochastic optimization", "authors": [{"first": "D", "middle": ["P"], "last": "Kingma", "suffix": ""}, {"first": "J", "middle": [], "last": "Ba", "suffix": ""}], "year": 2015, "venue": "International Conference on Learning Representations (ICLR", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Robust non-rigid registration through agent-based action learning", "authors": [{"first": "J", "middle": [], "last": "Krebs", "suffix": ""}], "year": 2017, "venue": "MICCAI 2017", "volume": "10433", "issn": "", "pages": "344--352", "other_ids": {"DOI": ["10.1007/978-3-319-66182-7_40"]}}, "BIBREF15": {"ref_id": "b15", "title": "FAIR: flexible algorithms for image registration", "authors": [{"first": "J", "middle": [], "last": "Modersitzki", "suffix": ""}], "year": 2009, "venue": "", "volume": "6", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Understanding the \"Demon's Algorithm\": 3D non-rigid registration by gradient descent", "authors": [{"first": "X", "middle": [], "last": "Pennec", "suffix": ""}, {"first": "P", "middle": [], "last": "Cachier", "suffix": ""}, {"first": "N", "middle": [], "last": "Ayache", "suffix": ""}], "year": 1999, "venue": "MICCAI 1999", "volume": "1679", "issn": "", "pages": "597--605", "other_ids": {"DOI": ["10.1007/10704282_64"]}}, "BIBREF17": {"ref_id": "b17", "title": "SVF-Net: learning deformable image registration using shape matching", "authors": [{"first": "M.-M", "middle": [], "last": "Roh\u00e9", "suffix": ""}, {"first": "M", "middle": [], "last": "Datar", "suffix": ""}, {"first": "T", "middle": [], "last": "Heimann", "suffix": ""}, {"first": "M", "middle": [], "last": "Sermesant", "suffix": ""}, {"first": "X", "middle": [], "last": "Pennec", "suffix": ""}, {"first": "M", "middle": [], "last": "Descoteaux", "suffix": ""}, {"first": "L", "middle": [], "last": "Maier-Hein", "suffix": ""}, {"first": "A", "middle": [], "last": "Franz", "suffix": ""}, {"first": "P", "middle": [], "last": "Jannin", "suffix": ""}, {"first": "D", "middle": ["L"], "last": "Collins", "suffix": ""}], "year": 2017, "venue": "MICCAI 2017", "volume": "10433", "issn": "", "pages": "266--274", "other_ids": {"DOI": ["10.1007/978-3-319-66182-7_31"]}}, "BIBREF18": {"ref_id": "b18", "title": "U-Net: convolutional networks for biomedical image segmentation", "authors": [{"first": "O", "middle": [], "last": "Ronneberger", "suffix": ""}, {"first": "P", "middle": [], "last": "Fischer", "suffix": ""}, {"first": "T", "middle": [], "last": "Brox", "suffix": ""}], "year": 2015, "venue": "MICCAI 2015", "volume": "9351", "issn": "", "pages": "234--241", "other_ids": {"DOI": ["10.1007/978-3-319-24574-4_28"]}}, "BIBREF19": {"ref_id": "b19", "title": "Nonrigid registration using free-form deformations: application to breast MR images", "authors": [{"first": "D", "middle": [], "last": "Rueckert", "suffix": ""}, {"first": "L", "middle": ["I"], "last": "Sonoda", "suffix": ""}, {"first": "C", "middle": [], "last": "Hayes", "suffix": ""}, {"first": "D", "middle": ["L"], "last": "Hill", "suffix": ""}, {"first": "M", "middle": ["O"], "last": "Leach", "suffix": ""}, {"first": "D", "middle": ["J"], "last": "Hawkes", "suffix": ""}], "year": 1999, "venue": "IEEE Trans. Med. Imaging", "volume": "18", "issn": "8", "pages": "712--721", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "AirLab: autograd image registration laboratory", "authors": [{"first": "R", "middle": [], "last": "Sandk\u00fchler", "suffix": ""}, {"first": "C", "middle": [], "last": "Jud", "suffix": ""}, {"first": "S", "middle": [], "last": "Andermatt", "suffix": ""}, {"first": "P", "middle": ["C"], "last": "Cattin", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1806.09907"]}}, "BIBREF21": {"ref_id": "b21", "title": "Image matching as a diffusion process: an analogy with Maxwell's demons", "authors": [{"first": "J", "middle": ["P"], "last": "Thirion", "suffix": ""}], "year": 1998, "venue": "Med. Image Anal", "volume": "2", "issn": "3", "pages": "243--260", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Spatiotemporal motion estimation for respiratory-correlated imaging of the lungs", "authors": [{"first": "J", "middle": [], "last": "Vandemeulebroucke", "suffix": ""}, {"first": "S", "middle": [], "last": "Rit", "suffix": ""}, {"first": "J", "middle": [], "last": "Kybic", "suffix": ""}, {"first": "P", "middle": [], "last": "Clarysse", "suffix": ""}, {"first": "D", "middle": [], "last": "Sarrut", "suffix": ""}], "year": 2011, "venue": "Med. Phys", "volume": "38", "issn": "1", "pages": "166--178", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Isotropic total variation regularization of displacements in parametric image registration", "authors": [{"first": "V", "middle": [], "last": "Vishnevskiy", "suffix": ""}, {"first": "T", "middle": [], "last": "Gass", "suffix": ""}, {"first": "G", "middle": [], "last": "Szekely", "suffix": ""}, {"first": "C", "middle": [], "last": "Tanner", "suffix": ""}, {"first": "O", "middle": [], "last": "Goksel", "suffix": ""}], "year": 2016, "venue": "IEEE Trans. Med. Imaging", "volume": "36", "issn": "2", "pages": "385--395", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "End-to-end unsupervised deformable image registration with a convolutional neural network", "authors": [{"first": "B", "middle": ["D"], "last": "De Vos", "suffix": ""}, {"first": "F", "middle": ["F"], "last": "Berendsen", "suffix": ""}, {"first": "M", "middle": ["A"], "last": "Viergever", "suffix": ""}, {"first": "M", "middle": [], "last": "Staring", "suffix": ""}, {"first": "I", "middle": [], "last": "I\u0161gum", "suffix": ""}], "year": 2017, "venue": "DLMIA/ML-CDS -2017", "volume": "10553", "issn": "", "pages": "204--212", "other_ids": {"DOI": ["10.1007/978-3-319-67558-9_24"]}}, "BIBREF25": {"ref_id": "b25", "title": "Piecewise polynomial, positive definite and compactly supported radial functions of minimal degree", "authors": [{"first": "H", "middle": [], "last": "Wendland", "suffix": ""}], "year": 1995, "venue": "Adv. Comput. Math", "volume": "4", "issn": "1", "pages": "389--396", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Overview of the model. Fixed and moving images IF , IM are passed into a convolutional neural network which produces the displacement field u(x). The spatial transformer morphs IM based on the displacement field. The loss is measured over the dissimilarity between the fixed and morphed moving images, as well as additional penalty functions defined over u.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Network architecture of g \u03b8 based on a modified version of U-Net. The network receives IM and IF to produce the displacement field u. The input and output of the network are of dimensions D \u00d7 H \u00d7 W \u00d7 2 and D \u00d7 H \u00d7 W \u00d7 3 respectively. The architecture consists of a contractive path (encoder) and a mirroring expansive path (decoder) connected by skip connections at each layer.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "Desired behaviors of the discontinuous displacement field.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Results obtained using LTV (a) and L disc (b). Columns 1 and 4 show an overlay of u over IM . Columns 2 and 5 show a magnified local region where transformation discontinuities are expected. Columns 3 and 6 are heatmaps of the displacement field's local magnitudes.", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Qualitative results of proposed model. From left to right: fixed image IF , moving image IM , registered image IM \u2022\u03c6, absolute error before registration |IF \u2212IM |, absolute error after registration |IF \u2212 IM \u2022 \u03c6|, heatmap of displacement field u.", "latex": null, "type": "figure"}, "TABREF0": {"text": "Target Registration Error (TRE) in millimeters (mm) against FFD", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Frame </td><td>DIR-Lab 256 </td><td>\u00a0</td><td>\u00a0</td><td>DIR-Lab 512 </td><td>\u00a0</td><td>\u00a0</td><td>POPI\n</td><td>\u00a0</td><td>\u00a0</td><td>\u00a0</td></tr><tr><td>FFD </td><td>pTV </td><td>SKM </td><td>Base </td><td>Ours </td><td>FFD </td><td>pTV </td><td>SKM </td><td>Base </td><td>Ours </td><td>FFD </td><td>pTV </td><td>SKM </td><td>Base </td><td>Ours\n</td></tr><tr><td>0 </td><td>1.01 </td><td>0.92 </td><td>1.06 </td><td>1.10 </td><td>1.04 </td><td>0.79 </td><td>0.62 </td><td>0.59 </td><td>0.77 </td><td>0.65 </td><td>0.79 </td><td>0.72 </td><td>0.66 </td><td>0.77 </td><td>0.76\n</td></tr><tr><td>2 </td><td>0.99 </td><td>0.89 </td><td>0.85 </td><td>0.94 </td><td>0.91 </td><td>0.81 </td><td>0.63 </td><td>0.57 </td><td>0.73 </td><td>0.64 </td><td>0.81 </td><td>0.71 </td><td>0.65 </td><td>0.73 </td><td>0.74\n</td></tr><tr><td>3 </td><td>1.29 </td><td>1.34 </td><td>1.32 </td><td>1.26 </td><td>1.24 </td><td>1.14 </td><td>0.99 </td><td>1.01 </td><td>0.97 </td><td>1.00 </td><td>1.14 </td><td>1.12 </td><td>1.17 </td><td>1.08 </td><td>1.11\n</td></tr><tr><td>4 </td><td>1.26 </td><td>1.27 </td><td>1.25 </td><td>1.23 </td><td>1.26 </td><td>1.11 </td><td>0.92 </td><td>0.93 </td><td>0.96 </td><td>0.95 </td><td>1.11 </td><td>1.01 </td><td>1.07 </td><td>1.04 </td><td>1.07\n</td></tr><tr><td>5 </td><td>1.27 </td><td>1.29 </td><td>1.35 </td><td>1.29 </td><td>1.31 </td><td>1.11 </td><td>1.00 </td><td>1.01 </td><td>0.99 </td><td>1.02 </td><td>1.11 </td><td>1.11 </td><td>1.13 </td><td>1.10 </td><td>1.16\n</td></tr><tr><td>6 </td><td>1.31 </td><td>1.17 </td><td>1.18 </td><td>1.27 </td><td>1.25 </td><td>1.20 </td><td>0.90 </td><td>0.89 </td><td>1.02 </td><td>0.92 </td><td>1.20 </td><td>1.03 </td><td>1.00 </td><td>1.11 </td><td>1.06\n</td></tr><tr><td>7 </td><td>1.36 </td><td>1.19 </td><td>1.22 </td><td>1.25 </td><td>1.30 </td><td>1.20 </td><td>0.95 </td><td>0.93 </td><td>1.00 </td><td>1.01 </td><td>1.20 </td><td>1.06 </td><td>1.05 </td><td>1.09 </td><td>1.13\n</td></tr><tr><td>8 </td><td>1.10 </td><td>1.05 </td><td>0.94 </td><td>1.04 </td><td>1.07 </td><td>0.88 </td><td>0.73 </td><td>0.67 </td><td>0.78 </td><td>0.79 </td><td>0.88 </td><td>0.84 </td><td>0.75 </td><td>0.88 </td><td>0.90\n</td></tr><tr><td>9 </td><td>1.09 </td><td>0.97 </td><td>0.99 </td><td>1.07 </td><td>1.09 </td><td>0.92 </td><td>0.70 </td><td>0.75 </td><td>0.78 </td><td>0.80 </td><td>0.92 </td><td>0.81 </td><td>0.83 </td><td>0.86 </td><td>0.89\n</td></tr></table></body></html>"}, "TABREF1": {"text": "FFD pTV SKM Base Ours FFD pTV SKM Base Ours FFD pTV SKM Base OursTable 2. Comparison of registration time between learning-based model and inverse model. For the learning-based model, we used our proposed model for evaluation. For the inverse model, we perform pairwise registration with diffusion regularizer over 1,000 iterations. The inverse model is evaluated using the AIRLab framework[21]. The CPU time for the classical model over DIR-Lab 512 and POPI Model is not computed, as they were much higher than the corresponding GPU time. Time is measured in seconds.", "latex": null, "type": "table"}, "TABREF2": {"text": "Table 2. Comparison of registration time between learning-based model and inverse model. For the learning-based model, we used our proposed model for evaluation. For the inverse model, we perform pairwise registration with diffusion regularizer over 1,000 iterations. The inverse model is evaluated using the AIRLab framework [ 21 ]. The CPU time for the classical model over DIR-Lab 512 and POPI Model is not computed, as they were much higher than the corresponding GPU time. Time is measured in seconds.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Learning-based </td><td>Inverse Model\n</td></tr><tr><td>\u00a0</td><td>GPU </td><td>CPU </td><td>GPU </td><td>CPU\n</td></tr><tr><td>DIR-lab 256 </td><td>0.33 </td><td>15.70 </td><td>82.57 </td><td>5724.36\n</td></tr><tr><td>DIR-lab 512 </td><td>1.38 </td><td>63.14 </td><td>532.41 </td><td>-\n</td></tr><tr><td>POPI Model </td><td>1.67 </td><td>76.45 </td><td>702.86 </td><td>-\n</td></tr></table></body></html>"}}, "back_matter": [{"text": "Acknowledgments. This research was supported by an NSERC Discovery Grant for M. Ebrahimi. We acknowledge the support of NVIDIA Corporation for the donation of GPUs used in this research.", "cite_spans": [], "ref_spans": [], "section": "acknowledgement"}]}