{
    "paper_id": "585e1b0e6bf463fbee8e23ee632533e7510cc50e",
    "metadata": {
        "title": "NSGA-II as feature selection technique and AdaBoost classifier for COVID-19 prediction using patient's symptoms",
        "authors": [
            {
                "first": "Makram",
                "middle": [],
                "last": "Soui",
                "suffix": "",
                "affiliation": {},
                "email": "m.soui@seu.edu.sa"
            },
            {
                "first": "Nesrine",
                "middle": [],
                "last": "Mansouri",
                "suffix": "",
                "affiliation": {},
                "email": "nesrine.mansouri@isimg.tn"
            },
            {
                "first": "Raed",
                "middle": [],
                "last": "Alhamad",
                "suffix": "",
                "affiliation": {},
                "email": "ralhamad@seu.edu.sa"
            },
            {
                "first": "Marouane",
                "middle": [],
                "last": "Kessentini",
                "suffix": "",
                "affiliation": {},
                "email": "marouane@umich.edu"
            },
            {
                "first": "Khaled",
                "middle": [],
                "last": "Ghedira",
                "suffix": "",
                "affiliation": {},
                "email": "khaledghedira3@gmail.com"
            },
            {
                "first": "M",
                "middle": [],
                "last": "Soui",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "R"
                ],
                "last": "Alhamad",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "R",
                "middle": [],
                "last": "Alhamad",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "N",
                "middle": [],
                "last": "Mansouri",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "M",
                "middle": [],
                "last": "Kessentini",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "K",
                "middle": [],
                "last": "Ghedira",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Nowadays, humanity is facing one of the most dangerous pandemics known as COVID-19. Due to its high inter-person contagiousness, COVID-19 is rapidly spreading across the world. Positive patients are often suffering from different symptoms that can vary from mild to severe including cough, fever, sore throat, and body aches. In more dire cases, infected patients can experience severe symptoms that can cause breathing difficulties which lead to stern organ failure and die. The medical corps all over the world are overloaded because of the exponentially myriad number of contagions. Therefore, screening for the disease becomes overwrought with the limited tools of test. Additionally, test results may take a long time to acquire, leaving behind a higher potential for the prevalence of the virus among other individuals by the patients. To reduce the",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "chances of infection, we suggest a prediction model that distinguishes the infected COVID-19 cases based on clinical symptoms and features. This model can be helpful for citizens to catch their infection without the need for visiting the hospital. Also, it helps the medical staff in triaging patients in case of a deficiency of medical amenities. In this paper, we use the non-dominated sorting genetic algorithm (NSGA-II) to select the interesting features by finding the best trade-offs between two conflicting objectives: minimizing the number of features and maximizing the weights of selected features. Then, a classification phase is conducted using an AdaBoost classifier. The proposed model is evaluated using two different datasets. To maximize results, we performed a natural selection of hyper-parameters of the classifier using the genetic algorithm. The obtained results prove the efficiency of NSGA-II as a feature selection algorithm combined with AdaBoost classifier. It exhibits higher classification results that outperformed the existing methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Keywords COVID-19 prediction \u00b7 Machine learning \u00b7 Feature selection \u00b7 AdaBoost \u00b7 NSGA-II \u00b7 Hyperparameters optimization",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "In December 2019, an atypical pneumonia case was discovered in the Hubei province of Wuhan, China. Immediately after this revelation, thousands of other cases have been detected worldwide and soon the situation evolved exponentially to become a global pandemic. On 11th February 2020 [1] , the World Health Organization (W.H.O) named this unfamiliar pneumonia as COVID-19. It has created immense chaos erupting worldwide, leading to affect people's lives and cause a huge number of deaths. As of April 12, 2021, the global epidemiological situation determines that confirmed COVID-19 cases have reached 135,646,617 and 2,930,732 confirmed deaths since the first case was detected. As shown in Fig. 1 , the number of COVID-19 cases has increased to reach over 4 million new cases in the past week. A sharp increase of 11% in the number of new deaths compared to the previous week to reach over 71,000 deaths.",
            "cite_spans": [
                {
                    "start": 284,
                    "end": 287,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [
                {
                    "start": 693,
                    "end": 699,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "The WHO reported that, in the case of mild to moderate contamination, the symptoms are dry cough, fatigue, and fever. While, in some dangerous cases, dyspnea, fever, and tiredness can occur [2] . Furthermore, hospitalized patients with COVID-19 suffered from other symptoms like shortness of breath or difficulty breathing, muscle aches, chills, sore throat, runny nose, headache, chest pain, and pink eye. Diabetics, asthmatics, and heart disease patients are more susceptible to the virus [3] . Unlike the other viruses, COVID-19 has a long incubation period varying from 3 to 13 days, while on average, the time between the exposure and the appearance of the symptoms is about 5-6 days. This duration makes COVID-19 more infectious, as positive people continue to communicate with others without knowing about their contamination, which will lead to more infections. Moreover, several infected individuals are asymptomatic and can get the virus without show-ing any symptom which making the detection, tracking, and containing this disease more challenging. The two aforementioned characteristics of COVID-19 have been contributing to its rapid spread. Phenotypes of this viral infection are distinct in terms of observable characteristics. It can range from no or fairly milder symptoms and quiet recovery without any health issues. Additionally, it drives in certain cases to swift deterioration and failure in the multi-organ system and death.",
            "cite_spans": [
                {
                    "start": 190,
                    "end": 193,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 491,
                    "end": 494,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This epidemic has not only engrossed the scientific community in the search for drug treatment and vaccine but also, in the struggles to examine statistics and meteorological variables to investigate the foremost factors that might contribute to its rapid spread. According to [4] , one of the main factors of the sharp rise in transmission of this deadly virus is the weather. In this context, Li et al. [5] aims to investigate the relationship between temperature and sunshine duration with the COVID-19 cases for the country of China. It explored that the temperature has an important yet negative correlation, unlike the sunshine duration which has an inverse association. A recent study showed that episodes of fine particle (PM) pollution play a key role in the rise of the number of contaminated cases [6] . Gupta et al. [7] studied the impact of the most important parameters of weather (maximum, minimum and mean temperature, temperature range, average humidity, humidity range, and wind speed) on the prevalence of the COVID-19 cases in more populated countries, such as India. Moreover, temperature, rainfall, and humidity are explored to be reliable signs to anticipate the number of COVID-19 cases in the coming days [6] [7] [8] .",
            "cite_spans": [
                {
                    "start": 277,
                    "end": 280,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 405,
                    "end": 408,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 809,
                    "end": 812,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 828,
                    "end": 831,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1230,
                    "end": 1233,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1234,
                    "end": 1237,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1238,
                    "end": 1241,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The relation between geography and the COVID-19 phenomena has attracted diverse global health specialists because the prevalence of this type of dangerous virus, in particular, is inevitably spatial. They try to identify the infection movement using local or global transmissions based on the contact trajectories within the population network. To this end, experts toward to use Geographical Information System (GIS) and spatial statistics to capture and analyze spatial and geographic data. Different studies have been implemented based on a geographical and geo-spatial analysis in order to understand the locations and the distribution patterns of COVID-19. Some of these studies have focused on specific countries, such as Oman [9] , China [10] , Indonesia [11] , South Korea [12] , India [13] , United States [14] , etc, while others focused at the globe scale [15, 16] .",
            "cite_spans": [
                {
                    "start": 733,
                    "end": 736,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 745,
                    "end": 749,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 762,
                    "end": 766,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 781,
                    "end": 785,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 794,
                    "end": 798,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 815,
                    "end": 819,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 867,
                    "end": 871,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 872,
                    "end": 875,
                    "text": "16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As this virus is a new and fatal strain that has never infected people before, it continues to overload the medical corps because of the exponentially myriad number of infections all over the world and challenge them in many aspects. These challenges including the sharp increases in demands for hospital beds and the overwhelming need for medical resources while many medical staffs have themselves been infected. Currently, reverse transcription-polymerase chain reaction (RT-PCR) has been used as the most validated diagnostic test for COVID-19 infection. Nevertheless, it has long been in shortage in many countries around the world particularly the developing ones. Additionally, test results may take a long time to acquire, leaving behind a higher potential for the prevalence of the virus among other individuals by the patients. Therefore, the development of an automatic diagnosis system became paramount to assist clinicians in triaging infected patients and thus help reduce the infection spread rate. The most common performed methods to detect the virus are based on blood tests [17, 18] that may take a long turnaround time to generate results approximately 3-4 h or imaging modalities including X-ray images and CT scans [19, 20] that could be unavailable in certain hospitals and laboratories. This highlights the critical need to a simple, accurate, and fast Artificial Intelligence (AI) model that can be very useful in these tough times in hopes of early detect the contaminated patients and control the epidemic infestation.",
            "cite_spans": [
                {
                    "start": 1093,
                    "end": 1097,
                    "text": "[17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1098,
                    "end": 1101,
                    "text": "18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1237,
                    "end": 1241,
                    "text": "[19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1242,
                    "end": 1245,
                    "text": "20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The use of AI in medicine has recently demonstrated prodigious popularity by becoming an adjunct tool for clinicians [21] . Machine learning (ML), which is a well-known research field of AI, enables creating models that reach promised outcomes for the automatic diagnosis of several diseases. ML is often applied for the classification task which tends to categorize data on a basis of a certain number of features. Making use of a small training set can increase the risk of facing the overfitting problem, and therefore, negatively affects the model's generalizability. Additionally, these samples can be probably non-gaussian noise-contaminated [22, 23] . The number of features also can reflect some issues. It is known that the dataset may contain irrelevant and noisy features that may have an impact on the results [22] and the uncertainties of the model [24] . Thus, the selection of a really important set of features can be an optimal solution to overcome these issues. Moreover, it improves the performance of the classification model and makes it faster in terms of execution time.",
            "cite_spans": [
                {
                    "start": 117,
                    "end": 121,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 648,
                    "end": 652,
                    "text": "[22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 653,
                    "end": 656,
                    "text": "23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 822,
                    "end": 826,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 862,
                    "end": 866,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In order to develop an optimal classification model, some components must be taken into considerations. Among these components, the configuration of hyperparameters which is considered a fundamental key to build an effective model [25] . However, the search space of potential combinations of parameter values is probably infinite, and thereby tuning manually becomes impractical, ineffective, time-consuming, and often needs deep knowledge of models. To this end, automatic hyper-parameter optimization is a critical need. Several techniques are existing in this context in which each technique has its strengths and drawbacks [26] . Recently, meta-heuristic algorithms have shown a great outstanding in solving hyper-parameter problems. Genetic algorithm (GA) and particle swarm optimization (PSO) are the most widely used algorithms [26] . To this end, GA is used to select the optimal combination of hyper-parameters. In fact, this technique has been commonly used in different areas [27] [28] [29] which provide outstanding results in maximizing the results. It also has revealed to be more efficient compared to other techniques in searching parameters [26] . The main objective of the present paper is to develop a machine learning model for COVID-19 prediction based on clinical symptoms and features. This model can be vastly and rapidly applied as needed during the pandemic. In summary, our main contributions are as following: The rest of this paper is organized as follows. Section 2 reviews state of the art techniques employed for COVID-19 diagnosis. Section 3 presents the machinelearning and feature selection algorithms. Section 4 introduces the proposed model, Sect. 5 reports our evaluation results. Finally, in Sect. 7, we summarize our contribution and we present our future work.",
            "cite_spans": [
                {
                    "start": 231,
                    "end": 235,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 628,
                    "end": 632,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 836,
                    "end": 840,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 988,
                    "end": 992,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 993,
                    "end": 997,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 998,
                    "end": 1002,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1159,
                    "end": 1163,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Depending on the features and symptoms used to perform COVID-19 prediction, the related studies can be divided into two major categories: symptoms-based for COVID-19 prediction and blood-based test for COVID-19 diagnosis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related works"
        },
        {
            "text": "Zoabi et al. [30] aims to determine the number of infectious cases based on symptoms and other demographic features. The idea is to develop a machine learning model based on gradient boosting intends to classify the cases. This study focused on eight features: gender, whether age is above 60, known contact with an infected individual, and five initial clinical symptoms; cough, fever, sore throat, shortness of breath, headache. They mentioned a flaw in the used data that has shortcomings and biases. The AUC of the proposed model decreased to 0.862 if this bias is eliminated [31] .",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 17,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 580,
                    "end": 584,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Symptoms-based for COVID-19 prediction"
        },
        {
            "text": "Khandy et al. [3] aims to classify clinical reports retrieved from doctor's notes into four categories of disease: COVID, SARS, ARDS, and both (COVID, ARDS). The data used in this study is accessed from the metadata of these X-ray images of John Hopkins University. It contains 24 attributes namely patient id, offset, sex, age, finding, survival, intubated, wenticu, neededsupplementalO2, extubated, temperature, pO2 saturation, leukocytecount, neutrophil count, lymphocyte count, view, modality, date, location, folder, filename, DOI, URL, License, Clinical notes, and other notes. A feature engineering step is conducted to extract 40 features from the textual attribute \"Clinical notes\". The proposed model is based on Logistic Regression (LR) and Multinomial Na\u00efve Bayes (MNB). This model is assessed using a small dataset that holds 212 patients. It can help analyze the clinical reports and make suitable recommendations for battling this epidemic.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 17,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Symptoms-based for COVID-19 prediction"
        },
        {
            "text": "Banik et al. [32] aims to estimate the probability of person infection by the COVID-19 virus. To this end, several machine learning algorithms are studied such as LR, MNB, Linear SVM, and DT to build an accurate model to predict the probability that a patient is infected based on clinical symptoms of patients. This model considered many features that have the same importance. However, there are the set of characteristics having more importance to identify COVID-19 cases.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 17,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Symptoms-based for COVID-19 prediction"
        },
        {
            "text": "Batista et al. [33] conducted a prediction model to diagnose COVID-19 using features of blood test based on the SVM algorithm. The used data derived from emergency care admission exams in Brazil. The outcome of this work is to detect the risk of positive COVID-19 diagnosis. A total of 15 predictors are used to train this model such as age, sex, haemoglobin, platelets, red blood cells, Mean Corpuscular Haemoglobin Concentration (MCHC), Mean Corpuscular Haemoglobin (MCH), Red Cell Distribution width (RDW), Mean Corpuscular Volume (MCV), leukocytes, lymphocytes, monocytes, basophils, eosinophils, C-Reactive Protein (CRP). The advantage is that would be very beneficial in assigning testing priorities in case of a shortage of equipment.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "Mondal et al. [34] developed a classification model to recognize positive cases from all suspected patients based on the dataset collected from hospital Albert Einstein, Brazil. To this end, various machine learning algorithms are used. MLP, LR, and XGBoost that showed promising results over the remaining algorithms. The best accuracy rate is provided by MLP. This work outperforms the work of [33] in terms of performance due to using more data and features (61 attributes against 15 used by [33] ).",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 18,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 396,
                    "end": 400,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 495,
                    "end": 499,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "Brinati et al. [17] built a diagnosis tool for SARS-CoV-2 detection. It allows distinguishing infected persons based on hematochemical values from routine blood exams. The designed tool is based on a random forest algorithm. Multiple features are used to carry out this work such as C-reactive protein (CRP), Aspartate Aminotransferase (AST), Alanine Amino Transferase (ALT), Gamma Glutamil Transferasi (GGT), Lactate Dehydrogenase (LDH), Leukocyte Count (WBC), Plate-lets, Neutrophils, Lymphocytes, Monocytes, Eosinophils, and Basophils. The proposed model can be a good alternative to rRT-PCR test for recognizing COVID-19 infected patients. Particularly, it can be very useful for developing countries that are facing problems with medical resources and specialized laboratories. Nevertheless, this study suffers from some shortcomings. The training process is based on a reduced number of samples. According to [35] , the precision of this analysis test may be highly influenced by problems like inadequate methods for collection, transport, handling, sample contamination, and existence of interfering substances, etc.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 915,
                    "end": 919,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "Wu el al. [18] developed a diagnostic tool to determine COVID-19 confirmed cases from a variety of suspected patients. This work focused on 11 top-ranking clinical blood indices and built using a random forest algorithm. Although more clinical research is required to validate the tool, it can offer some new insights to ensure the rapid diagnosis of COVID-19 infection in order to deal with serious situations caused by the dangerous characteristics of human-to-human transmission.",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 14,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "Kukar et al. [36] established a diagnostic tool to analyze blood exams and find the suspect cases of COVID-19. It used XGBoost as a machine learning classifier. It employs five blood parameters as features, which are Mean Corpuscular Hemoglobin Concentration (MCHC), eosinophil count, albummin, International Normalized Ratio (INR), and prothrombin activ-ity percentage. This study holds some limitations. First, the analysis was conducted in a single center from which the data collected. While this can restrict generalizability, they expect similar laboratory blood test findings in other centers by using incorporated and advisable reagents, procedures, and technology. Second, a limited number of positive cases was involved in this work.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 17,
                    "text": "[36]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "The main limitation of these studies is that patients should move to the hospital to carry out the test, which may take a long time to acquire, leaving behind a higher potential for the prevalence of the virus among other individuals by the patients.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Blood-based test for COVID-19 diagnosis"
        },
        {
            "text": "Artificial intelligence is the ability of machine to mimic cognitive functions associated with human capacity such as, learning, perceiving, solving the problem. In this section, we review some algorithms and techniques that are prerequisites for our work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "Machine learning is a research area evolving several induction algorithms that training machines to analyze data and acquire information from it. This section includes the background details of supervised machine learning algorithms.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Machine learning algorithms"
        },
        {
            "text": "A LR model is a supervised learning algorithm that is used to predict the class membership probability of a given variable based on its relationship with the label [37] . One of the properties of this model is that the final probability prediction may be excessively influenced by a small shift in the input value. In addition, the dimension of the input vector (number of predictors) should be low, as this can affect the cost of the model training and may lead to overfitting. Besides, It can be resulting in the poor generalizability of the model. In fact, LR can be a valuable model to be chosen when there are various data sources that have to be incorporated into a binary classification task, and low complexity is needed.",
            "cite_spans": [
                {
                    "start": 164,
                    "end": 168,
                    "text": "[37]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Classical machine learning algorithms (a) Logistic Regression (LR)"
        },
        {
            "text": "SVM is a supervised machine learning algorithm designed for classification and regression. The aim of SVM is to find the optimal linear or nonlinear boundary that separating data into two or more classes [38] . Before applying SVM, it is necessary to select the function responsible for data separation, called Kernel. The linear function or the Gaussian function is the most frequently used kernel. The remaining parameters are empirically selected by training a variety of models and preserving the model settings providing the lowest error rate. The most commonly used SVM classifier is a linear one. It attempts to predict the class of the test sample between two possible classifications. It works as follows; take a specified number of features with the class label and trying to search for the optimal linear separating hyper-plane in an N-dimensional space, where N defines the number of features. The best hyper-plane is selected using the support vectors and margins. It is based on the distance between the two classes. One of SVM's main drawbacks is its need for high computational cost when dealing with a large number of data.",
            "cite_spans": [
                {
                    "start": 204,
                    "end": 208,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "Classical machine learning algorithms (a) Logistic Regression (LR)"
        },
        {
            "text": "A DT is a predictive model, capable of giving coherent classification rules. It repeatedly divides the data depending on particular criteria that maximize the separation of the data, producing a tree-structured like [38] . The main idea behind the decision tree algorithm is to select the most important attributes using Attribute Selection Measures (ASM) to split the records. Make that attribute a decision node and breaks the dataset into smaller subsets. The tree starts to build through repeating this process recursively for each leaf until one of the conditions satisfies the termination criteria and all the tuples belong to the same attribute value and no more remaining attributes or instances. To predict a class label, starting from the root and compare the test sample with the values of the root attribute. The comparison consists of following the branch corresponding to the value and jump to the next node. This process repeats until reaches the leaf node with predicted class value.",
            "cite_spans": [
                {
                    "start": 216,
                    "end": 220,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "(c) Decision Tree (DT)"
        },
        {
            "text": "MLP is a model of Neural Networks (NN), inspired from the structure and function of the brain that learns from data and specializes in pattern recognition. MLP is based on a feed-forward algorithm. The input feature vector is entered into the neurons for training. A backpropagation algorithm is applied to train the neurons, with the flow in the forward direction. Next, the generated output is compared to the desired output using a cost function such as the Mean Squared Error (MSE) function. If the outputs do not match, an error is produced. This error propagates in the backward direction. In this case, the weights are adjusted in order to reduce the error. This processing is repeated until the error becomes zero [39] . There is a layered structure in the NNs with the number of interconnected nodes. Among each one of these nodes, there is an activation function which can be a tangent hyperbolic function, sigmoid function, piece-wise linear function, and threshold function. In the case of binary classification, the neural network is built with a single output node.",
            "cite_spans": [
                {
                    "start": 722,
                    "end": 726,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "(d) Multi-Layer Perceptron (MLP)"
        },
        {
            "text": "Ensemble learning method refers to combine a set of weak classifiers to produce a single strong classifier in order to improve the overall performance [37] .",
            "cite_spans": [
                {
                    "start": 151,
                    "end": 155,
                    "text": "[37]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Ensemble learning methods"
        },
        {
            "text": "Bagging also known as, Bootstrap aggregating, is a broadly useful ensemble machine learning paradigm. It allows improving the performance of machine learning models and helps also avoid overfitting. The main idea behind bagging is to combine the results-producing by multiple models to get a generalized result. One of the well-versed techniques that following bagging technique is Random Forest (RF).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(a) Bagging techniques"
        },
        {
            "text": "Random forest is one of the most commonly used supervised machine learning due to its simplicity and diversity as it can be used in both classification and regression tasks. RF aggregates a set of DT that produces a forest [40] . Better prediction results are often obtained often when incorporating more trees in the forest. Each DT is a set of rules that are based on the values retrieved from the input features and optimized to be reliable for classify all the examples of the training set. If the DT built in a deep manner, it can lead to encounter some problems such as over-fitting due to irregularities in the training set. This issue can be solved using Random Forest whereby apply the training phase on multiple train samples. Accordingly, as the number of DT increased as the variance is reduced, therefore minimize the generalization error and turning a strong classifier. Prior to application RF, there are two parameters to be tuning such as the number of trees and the depth level for each tree. Nevertheless, it should be borne in mind that if the discriminatory power over the training dataset increases as DT increases in depth. It often comes at the expense of the loss of generalization performance. The RF is chosen to transform the problem into a collection of hierarchical requests represented as DT. However, RF is not very immune to noisy data.",
            "cite_spans": [
                {
                    "start": 223,
                    "end": 227,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "(a) Bagging techniques"
        },
        {
            "text": "Boosting is an ensemble method designed for enhancing the prediction rate of a machine learning algorithm. The main idea is to train weak learners in a sequential way, where each trying to correct the previous model [41] .",
            "cite_spans": [
                {
                    "start": 216,
                    "end": 220,
                    "text": "[41]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "(b) Boosting techniques"
        },
        {
            "text": "One of the most popular ensembles boosting classifier is Adaptive Boosting known as AdaBoost. It aims to combine multiple weak learners into a strong learner to enhance the performance of the prediction model [42] . Basically, the concept of AdaBoost consists of setting the weights of poorly performing classifiers and training the samples in each iteration. The process of generating a weak learner consists of taking equal weights for each sample and trains the weak learner using the weighted data. A coefficient \u03b1 should be chosen based on the performance of this weak learning classifier. In the case of misclassified points, the weights are increased and the weights of correctly classified points are reduced. Then, the weak learning algorithms are run again to obtain a weak classifier for the new weighted data. Repeating this process until all the data points have been correctly classified, or the maximum iteration level has been reached.",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 213,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "(b) Boosting techniques"
        },
        {
            "text": "Gradient Boosting is another well-known algorithm that belongs to the boosting family. It is an ensemble machine learning method that combines a set of weak learners sequentially with some shrinkage on them [43] . It identifies the weakness of each poor learner using gradients in the loss function. GB conducts variables selection to improve the predictors of the tree as its based-on decision tree-like AdaBoost. Therefore, the model is a combination of two trees. Then, it calculates the difference between these two trees and produces a third tree in order to predict the revised residuals. A number of iterations should be specified to repeat the process. The subsequent trees help to classify the observations which are not well classified by the pre-ceding trees. The predictions of the final model are therefore the weighted sum of the predictions derived by the previous tree model.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 211,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": "(b) Boosting techniques"
        },
        {
            "text": "A well-known computational speed and model performance is XGBoost, short of eXtreme Gradient Boosting. It is a scalable machine learning algorithm for tree boosting that is commonly used in different fields. It is based on the idea of \"Boosting\", which consists of integrating multiple predictors of an ensemble of \"weak learners\" to build a powerful learner [44] . This process can be done through additive learning strategies during the training phase. The process consists initially of fitted the first learner with the entire input data, and the second model with the residuals to fix the shortcomings of the weak learner. This fitting method is repeated several times until satisfies the stopping criterion. The final prediction of the model is achieved by the sum of the predictions of each learner. In this way, XGBoost helps to reduce overfitting and optimize the computational resources thanks to supporting a variety of regularization techniques.",
            "cite_spans": [
                {
                    "start": 359,
                    "end": 363,
                    "text": "[44]",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "(b) Boosting techniques"
        },
        {
            "text": "Selecting the most relevant features that are used for the training phase is deemed to be an essential step for many pattern recognition problems. Accordingly, the key issue resides in how to find the most adequate set of features that match with data classes and can provide an enhancement in the model performance. To deal with this challenging task, many feature selection algorithms have been reported. The main idea resides in removing the irrelevant and repetitive features from the original dataset and keep only the important ones. In this way, feature selection can be a beneficial step in terms of enhancing the performance of the model, reducing the dimension of the dataset in case of handling a large number of features, and avoiding the overfitting problem. In our work, we aim to apply feature selection algorithms to better discriminate the symptoms of patients infected with COVID-19 virus and thereby improve the efficiency of the model. In this work, we investigate four feature selection algorithms that are considered the most widely used: Sequential Forward Selection (SFS), Sequential Forward Floating Selection (SFFS), Sequential Backward Selection (SBS), and Non-dominated Sorting Genetic Algorithm II (NSGA-II) to choose the optimal subset of features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Features selection algorithms"
        },
        {
            "text": "SFS is a wrapper-based algorithm based on a bottomup search procedure that allows generating an optimal subset of features [45] . Initially, it is empty and gradually adds features, that are selected upon an evaluation criterion function, one by one until reaching the best subset. Due to its simplicity and speed, SFS is a widely used sequential algorithm. Also, it is very suitable with smaller datasets [46] . Algorithm 1 is the pseudo-code for the SFS algorithm.",
            "cite_spans": [
                {
                    "start": 123,
                    "end": 127,
                    "text": "[45]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 406,
                    "end": 410,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Sequential forward selection (SFS)"
        },
        {
            "text": "Input:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 1: Sequential Forward Selection (SFS) algorithm"
        },
        {
            "text": "Go to Step1 6. Termination: k=p",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 1: Sequential Forward Selection (SFS) algorithm"
        },
        {
            "text": "As illustrated in Algorithm 1, the SFS algorithm takes the whole d-dimensional feature set of the COVID-19 symptoms dataset Y as input. It initializes with two empty variables, X 0 denotes the set of features to be generated, and a variable k (line 1). At each inclusion step, the algorithm selects the feature x that maximizes the criterion function based on the evaluation of a classification algorithm and adding it to the subset X k (line 3). This feature is relevant to boost the efficiency of the model. In this way, each feature incorporated into the subset X k , the variable K will be incremented (line 4). This process is repeated until k equal to p where all desired features are added (lines 5 and 6). The ultimate output of the SFS algorithm is a subset containing the most significant features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 1: Sequential Forward Selection (SFS) algorithm"
        },
        {
            "text": "From SFS algorithm, we can toggle to SBS algorithm as it is works in the backward direction. It starts by initializes the algorithm with the whole set of features and starts to remove irrelevant features greedily until getting the desired number of features to generate the optimal subset. Algorithm 2 describes how the SBS process works.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential backward selection (SBS)"
        },
        {
            "text": "Input: The set of all features of the COVID-19 symptoms Y Output: A correlated subset of features",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 2: Sequential Backward Selection (SBS) algorithm"
        },
        {
            "text": "As illustrated in Algorithm 2, the SBS algorithm takes the COVID-19 symptoms dataset Y as input. It initializes the variable X 0 with the entire feature set and the size K equal to d. At each step of exclusion, it omits the feature whose dropping yields the maximal performance improvement on the basis of criterion function J (lines 1 and 2). Then, the variable k is decremented (line 4). This process continues sequentially until obtaining the desired number of features (lines 5 and 6). The SBS algorithm generates the interesting features as output.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 2: Sequential Backward Selection (SBS) algorithm"
        },
        {
            "text": "SFFS algorithm is based on forward and backward steps [47] . It aims to adjust the trade-off between these two steps. SFFS allows a \"self-controlled backtracking\" that can eventually find better solutions.",
            "cite_spans": [
                {
                    "start": 54,
                    "end": 58,
                    "text": "[47]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": "As illustrated in algorithm 3, the SFFS takes the entire feature set as input. The process starts with initializing X 0 with an empty set and it is composed of two steps, inclusion and conditional exclusion. At each inclusion step, the feature x that maximizes the criterion is appended to the current feature subset X 0 (lines 2, 3 and 4) based on the evaluation of a classification algorithm. After the addition of a feature, a conditional exclusion is examined (lines 5 and 6). At this step, the feature that maximizes the criterion function on the new subset of feature is sought. If the removes of this feature resulting in a gain rise in the performance, it is Output: A subset of features",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": "Step 1 (Inclusion):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": "5. Go to Step 2 6.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": "Step 2 (Conditional Exclusion):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": ". Go to Step 1 12. Termination: k = p removed completely from the feature subset (lines 8, 9 and 10). Otherwise, go back to step 1 (line 11). The whole process stops when k equals the number of features (line 12). In the end, the SFFS algorithm yields a subset of the most important features that are beneficial for improving the classification performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential forward floating selection (SFFS)"
        },
        {
            "text": "In this section, we introduce our proposed machine learning model which is based on a feature selection phase and a classification phase to predict COVID-19 patient infection. An overview of the proposed approach is illustrated in the Fig. 2 . The first phase uses NSGA-II algorithm to select the optimal subset of features that satisfies the conflicting objectives for the training. While, the second phase is to train the model based on the AdaBoost classifier to predict each target class. Finally, a testing phase is conducted to assess the efficiency of the model using the test data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 235,
                    "end": 241,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Proposed approach"
        },
        {
            "text": "This part aims to identify the optimal set of features needed for COVID-19 prediction. It is expected that the selected features improve the performance of the model and speeding up the training process. To this end, we employed NSGA-II to extract the relevant features. It is a multi-objective search algorithm that has been Fig. 2 Overview of proposed approach used to solve several real-world optimization problems [48] . It is considered as one of the most widely used and successful algorithms to find non-dominated solutions. NSGA-II aims to find the trade-off between objectives that are often conflicting and generates a set of optimal solutions called Pareto front or non-dominated solutions. A high-level view of NSGA-II is depicted in Algorithm 4. We define the feature selection phase as a problem that includes two conflicting objectives functions that aim to find the optimal subset of features. The two conflicting objectives are outlined in the following Eq. 1. The solution is represented as a simple coding scheme where a binary chromosome representation is used. Each feature is represented as zero or one based on the objective functions.",
            "cite_spans": [
                {
                    "start": 418,
                    "end": 422,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [
                {
                    "start": 326,
                    "end": 332,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Feature selection phase"
        },
        {
            "text": "The first objective f 1 (x) consists of minimizing the number of features in the generated subset S i . The optimization process aims to reduce the complexity of the input variables by minimizing the number of features for the classifier. The second objective f 2 (x) aims to maximize the weight of the selected features. To this end, we use the Information Value (IV) which is one of the most useful techniques that intends to select the essential features. It helps to rank the features based on their importance in the dataset and their relationship with the class label which can be achieved using the weight. Therefore, each feature takes a weight \"w\" which is ranged between \u22121 and 1. The goal of IV is to distinguish between the features that have a strong relationship and the ones not. IV measures the difference between the percentage of COVID-19 infected persons (C) and the percentage of NON COVID-19 infected persons (NC) multiplied by the WOE for each respective features. The IV is measured as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection phase"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection phase"
        },
        {
            "text": "IV i , the weight of each feature in the obtained subset and \"n\" denotes the subset size. C, the total number of COVID-19 instances. NC, the total number of NON COVID-19 instances. c i , the number of COVID-19 within the feature i. nc i the number of NON COVID-19 within the feature i.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection phase"
        },
        {
            "text": "Algorithm (NSGA-II) 1 . Create an initial population P 0 2. Create an offspring population Q 0 3. t = 0 4. while stopping criteria not reached do 5. R t = P t \u222a Q t 6. F = fast-non-dominated-sort (R t ) 7. P t+1 = \u2205 and i = 1 8. while |P t+1 | + |F i | \u2264 N do 9. Apply crowding-distance-assignment (F i )",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 21,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 4: Non-dominated Sorting Genetic"
        },
        {
            "text": "As illustrated in Algorithm 4, it starts by creating an initial population P 0 of individuals (line 1). Then, based on crossover and mutation, a child population Q 0 is generated using the parent population previously created (line 2). The two created populations (P 0 and Q 0 ) are merged to construct an initial population R 0 of size N (line 5). A fast-non-dominated sort is applied which is the main technique used by NSGA-II to classify the solutions into different dominance levels (line 6). In fact, this technique consists of comparing the solutions (individuals) of the population. In this way, all the evaluated solutions based on the objective functions are sorted into different fronts (line 6). Accordingly, solutions that are found in the first Pareto-front F0 were assigned a dominance level of 0 and the fast non-dominated-sort continue to calculate the remaining population. Solutions that are found in this second front were assigned dominance level of 1, and so on. Then, the next population is generated using the dominance level of solutions (F i ). NSGA-II relies basically on the crowding distance when making a selection of a subset of solutions that are belong to the same dominance level (line 8). Crowding distance is used to raise variety in the population. To split the front F i , the solutions should be sorted in descending order (line 12), and the first (N \u2212 |Pt + 1|) elements of F i are chosen (line 13). Finally, selection, crossover, and mutation are applied to create a new population Q t+1 (line 14). This procedure continue until satisfies the termination criteria.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 4: Non-dominated Sorting Genetic"
        },
        {
            "text": "This phase is designed to classify the suspected infected patients into two classes. Before starting the training process, we split the used datasets into two subsets: training and testing data by applying the hold-out method. We recall that dataset 1 contains 1495 samples, 70% of them are devoted to train (1046 samples) while the remaining 30% (449 samples) are dedicated to test the model. The second dataset includes 99,232 samples that are divided as follows: 69,463 samples for the training and 29,769 samples for the testing. Our goal is to classify the patients into two classes: COVID-19 or NON-COVID-19. To this end, we use the AdaBoost classifier that aims to reduce the misclassification rate of a weak learner and create a strong classifier by combining a set of weak learners.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification phase"
        },
        {
            "text": "As illustrated in algorithm 5, AdaBoost takes as input the set of training instances m which contains (x n , y n ), where each x n denotes the example and y n is a binary value label referring to whether x n is a positive or negative sample. The principle of AdaBoost consists of assigning weights for each sample to increase or decrease this weight later to lessen the classification error. To this end, it initializes the weights of data points set",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification phase"
        },
        {
            "text": ") (Z is a normalization factor) according to the function D t (i), where m defines the number of samples. It assigns the same weights to all samples. In each iteration t, the weak classifier is trained and used to predict the samples to calculates the error rate e t (lines 2 and 3) of the misclassified samples. The higher the error, the more the corresponding learner will be weighted when assigning weights to samples (line 4). If the error greater than 0.5, it adjusting the value of \u03b1 and the distribution D t (x) by putting more weights on the incorrectly classified training samples and fewer weights on the correctly classified (lines 5, 6, and 7) to better classified in the next iteration. This reweighing step allows increasing the importance of examples that were wrongly classified by the previous weak classifier. This process repeats until reaches the desired number of iterations T . Finally, the algorithm yields a strong classifier derived from a weighted combination of weak learners. Typically, the outcome of AdaBoost can negatively affected due to the use of noisy data because each learner is too dependent on the output of its predecessors. In this case, the learner will not capable of correcting the misclassified instances which are noisy data. To this end, we give importance to the verification step which consists of checking the quality of used datasets. In our work, since the dataset 2 is imbalanced, the sampling technique (SMOTE) is used to balance the class distribution before starting the training process.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification phase"
        },
        {
            "text": "After training the model with the relevant features, it is crucial to check the efficiency of the obtained model. Basically, this phase is considered as a fundamental step that permits the assessment of the built model against data that has never been used in the training phase. It is examined based on the test data (30% of the original dataset) that provided using the hold-out method for both datasets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation phase"
        },
        {
            "text": "In our experimentation, two datasets were considered. These datasets have several symptoms and different sizes. The first dataset (Dataset 1) was obtained from the Wolfram Data Research Repository (2020). 1 It contains 1495 patients cases of whom 757 patients are infected with the COVID-19 virus. A total of 12 clinical symptoms covered in the used dataset along with the three other demographic features. The second dataset (Dataset 2) 2 was obtained from the study of [30] . It includes a total of 99,232 samples in which 8393 COVID-19 cases. This dataset contains eight features of whom five initial clinical symptoms. Customarily, data preprocessing is a fundamental step before training the model in case the data is inconsistent or incomplete. Indeed, this is not the case with the dataset 1, as we skip this step due to the well-structured binary values. Nevertheless, with the dataset 2, we fall into the problem of imbalanced data where the class NON-COVID-19 outnumber the class COVID-19. To address this problem, we apply one of the most widely used techniques to synthesizing new examples which is the Synthetic Minority Oversampling TEchnique (SMOTE) [49] . This technique of oversampling consists of generating new synthetic samples for the minority class. In this way, the total number of samples in the training set for the two classes is equals [50] . Tables 1 and 2 give a comprehensive description of the features held in the used datasets. [51] . Generally, the most commonly used performance evaluation indicator is the accuracy of the model [52] . However, this metric is not enough to truly judge the model. This highlights the critical need for other assessment parameters to select the well-performing model. To this end, we considered five evaluation metrics as well the accuracy: precision, sensitivity, specificity, f1-score, and AUC. These metrics can be derived from the following confusion matrix outlined in Table 3 .",
            "cite_spans": [
                {
                    "start": 471,
                    "end": 475,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1165,
                    "end": 1169,
                    "text": "[49]",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 1363,
                    "end": 1367,
                    "text": "[50]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 1461,
                    "end": 1465,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 1564,
                    "end": 1568,
                    "text": "[52]",
                    "ref_id": "BIBREF52"
                }
            ],
            "ref_spans": [
                {
                    "start": 1370,
                    "end": 1384,
                    "text": "Tables 1 and 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1941,
                    "end": 1948,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Description of the experimental datasets"
        },
        {
            "text": "-Accuracy: represents the percentage of correctly predicted cases relative to the whole dataset. It is calculated as follows: To answer RQ2, we sought to compare the obtained results of our proposed model to different existing work based on three performance criteria: Accuracy, Precision and Recall.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Description of the experimental datasets"
        },
        {
            "text": "6 Results and discussions",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Description of the experimental datasets"
        },
        {
            "text": "Our research study used two COVID-19 symptoms data-sets. Three experiments are conducted in which the SFS, SFFS, SBS and NSGA-II algorithms are used to select the optimal subset of features for COVID-19 prediction. We respectively present the results of the studied machine learning algorithms.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results for research question 1"
        },
        {
            "text": "In this part, we introduce an empirical evaluation of the studied classifiers that are trained using the full features of the used datasets. As reports in Table 4 , for ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 155,
                    "end": 162,
                    "text": "Table 4",
                    "ref_id": "TABREF5"
                }
            ],
            "section": "Experimental results with full dataset"
        },
        {
            "text": "In this part, we present the experimental results of the studied classifiers that are trained based on the attributes extracted using the feature selection algorithms. As reported in Tables 5 and 6 , the performance of the majority of classifiers for both datasets is experienced a considerable enhancement due to the feature selection algorithms application.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 183,
                    "end": 197,
                    "text": "Tables 5 and 6",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Experimental results with filtered dataset"
        },
        {
            "text": "(a) First experiment In the first conducted experiment, features are selected using the SFS algorithm as described in Algorithm 1. As depicted in Table 5 , the MLP classifier achieved the best classification rate with an average 82.39% of AUC, accuracy of 82.41%, pre-cision of 84.32%, sensitivity of 82.57%, specificity of 83.44%, and F1-score of 83.44%. In fact, the SFS confirmed its efficiency with MLP regarding the result of the full dataset whereas the accuracy rate is increased by 2.45%. Additionally, Random forest, Decision Tree, and XGBoost yielded a slight increase in their accuracy rate that reaches, 81.96%, 80.4%, and 80.85% respectively. For the AdaBoost classifier, the classification accuracy is improved to achieve 81.07% with SFS selection algorithm instead of 79.96% when using all the features. Besides, the Gradient Boosting classifier generates a slight rise. It provides an accuracy rate of 81.07% instead of 80.4% with the full dataset. As illustrated in Table 6 , Logistic regression attains the highest performance results with the dataset 2. It provided an AUC value of 94.32%, accuracy of 93.75%, precision of 93.75%, Sensitivity of 93.75%, Specificity of 94.9%, and f1-score of 93.75%. Moreover, Random forest achieved a significant increase compared to its results without feature selection application. It provided 92.62% instead of 89.36% as accuracy. XGBoost, Gradient boosting, and MLP achieved a slight improvement in their classification performance compared to their results without feature selection. These classifiers yielded an accu- Bold value indicates the highest result racy rate of 92.51%, 92.51%, and 92.62%, respectively. To conclude, the best subset of features is extracted using MLP classifier for the first dataset 1. It contains the following features: Age, Gender, Fever, Pains, Nasal congestion, Chills, and Vomiting. While, Logistic regression achieved the highest results for the dataset 2 with the following subset: Cough, Sore Throat, Fever, and Known with confirmed.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 146,
                    "end": 153,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 983,
                    "end": 990,
                    "text": "Table 6",
                    "ref_id": "TABREF7"
                }
            ],
            "section": "Experimental results with filtered dataset"
        },
        {
            "text": "(b) Second experiment In the second experiment, the SFFS is used for feature selection as described in Algorithm 3. As shown in Table 5 , XGBoost has proved its mettle in terms of performance regarding the remaining classifiers. It generates the best AUC value of 82.84%, accuracy of 82.85%, precision of 84.75%, sensitivity of 82.99%, specificity 82.69%, and f1score of 83.86%. A slight increase is achieved Table 6 shows that AdaBoost provides the highest classi- In this experiment, feature selection is performed using NSGA-II algorithm. Table 5 shows that the highest classification rate is provided by the AdaBoost classifier for dataset 1. It yielded an AUC value of 87.16%, accuracy of 85%, precision of 90%, sensitivity 89.32%, specificity of 85%, and f1-score of 86.01%. Additionally, decision tree and gradient boosting performing well with the subset generated by NSGA-II. It provided as accuracy Bold values highlight the best results for the two studied datasets",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 128,
                    "end": 135,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 409,
                    "end": 416,
                    "text": "Table 6",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 542,
                    "end": 549,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Experimental results with filtered dataset"
        },
        {
            "text": "The process of hyper-parameters tuning for machine learning models has a significant impact on the performance of the model. It is anticipated that the optimal model is obtained after this process. In our proposed model, we choose the natural selection of parameters based on one of the most widely known techniques known as Genetic Algorithms (GA).In this way, we configured the parameters of the NSGA-II for the feature selection algorithm, and also, we adjusted the parameters of the AdaBoost classifier using the technique of hyper-parameters optimization using GA with an objective function: maximizing the accuracy rate. NSGA-II and GA have several parameters which have different effects on their performance. Among these parameters, the population size, the number of generations, and the three basic operations: selection, mutation, and crossover. Additionally, we highlight the major parameters to be tuned in AdaBoost which are max_depth of the base classifier, learning rate (lr), and the number of estimators. The max_depth is the most important parameter in the DT, which controls the maximum depth of the tree. The learning rate refers to how each tree contributes to the outcomes while the number of estimators indicates the number of learners.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Parameter tuning and statistical tests"
        },
        {
            "text": "The whole parameters used in this study are described in Table 7 . We defined a search space for each parameter and the optimal combination of parameters that gives the best accuracy rate is represented in the Table 7 for the two datasets. For NSGA-II and GA, we used the same values of parameters for both datasets.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 57,
                    "end": 64,
                    "text": "Table 7",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 210,
                    "end": 217,
                    "text": "Table 7",
                    "ref_id": "TABREF9"
                }
            ],
            "section": "Parameter tuning and statistical tests"
        },
        {
            "text": "For both datasets, the NSGA-II with AdaBoost classifier is significantly better than the other models. To statistically confirm the hypothesis, a paired t-test is used to evaluate the importance of the obtained results. The null hypothesis H 0 deems that there is no statistically significant difference between the two models means \"The accuracy of model A = accuracy of model B\". H 0 is complimented by the alternate hypothesis H 1 which deems that there is a statistically significant difference between the two models means \"accuracy of model A = accuracy of model B\". From Tables 8  and 9 , it is observed that the p-value is less than 0.05 for all the cases. Therefore, the null hypothesis is rejected, and it is wrapped up that there is a statistically significant improvement in predicting the COVID-19 infected patients by using NSGA-II for feature selection with the AdaBoost classifier. Thus, it is drawn to conclude that NSGA-II + AdaBoost has outstanding performance than the other studied models.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 578,
                    "end": 593,
                    "text": "Tables 8  and 9",
                    "ref_id": "TABREF10"
                }
            ],
            "section": "Parameter tuning and statistical tests"
        },
        {
            "text": "The performance of the proposed model compared to other existing models is presented in this part. From Table 10 , it is clearly seen that our proposed model: NSGA-II with AdaBoost classifier achieved promising results compared to existing models proposed by Banik et al. [32] and Zoabi et al. [30] for both dataset 1 and dataset 2. For dataset 1, NSGA-II+AdaBoost provides 85% as accuracy rate, 90% of precision, and 84% of sensitivity, 85% of specificity, 86.01% of f1-score, and 87.16% of AUC, followed by the logistic regression model proposed by [32] which provided 81.2% as accuracy, 79.7% of precision, and 79.7% of sensitivity, and 79.7% of f1-score. For dataset 2, NSGA-II+AdaBoost yielded an accuracy of 95.56%, precision of 95.56%, sensitivity of 95.56%, specificity of 98.1%, and AUC rate of 96.87% followed by Gradient boosting model proposed by [30] that achieved a sensitivity rate of 87.3%, specificity of 71.98% and AUC value of 90%. The strength of AdaBoost resides in combining weak learners into a powerful learner based on the adjustments of weights. These weights are mainly related to samples that are used by the learner in the training phase. This phase can generate a set of misclassified samples by the learners. In this case, AdaBoost tries to address the wrongly classified samples by empowering them with suitable weights. The large weight is assigned to samples that are misclassified and the small weight is assigned to samples that are already handled well. This ability to identify the misclassify samples and attempt to correct them to be feed to the next learner until an accurate predictor model is built makes AdaBoost considered as one of the most powerful models in binary classification. Additionally to the strength of AdaBoost in our proposed model, the NSGA-II algorithm has also shown a significant performance in solving multi-objective problems. It successfully found the trade-off between two objectives: maximizing the weights of selected features and minimizing the number of features that yielded an optimal subset of features. These features have positively influenced the performance of the predictive model.",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 276,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 294,
                    "end": 298,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 551,
                    "end": 555,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 859,
                    "end": 863,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 104,
                    "end": 112,
                    "text": "Table 10",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Results for research question 2"
        },
        {
            "text": "At present, the emergence of COVID-19 pandemic is a dangerous menace to global health. Lack of care facilities and rapid spread of the virus has reduced the possibility of corralling this outbreak. Given the severity of these circumstances and the exponential growth of confirmed cases, an automatic detection tool is a pressing need that can bring new helpful avenues for healthcare systems. Application of Machine learning (ML) and Artificial Intelligence (AI) methods gives an assuring solution to assist medical staff in clinical decision making. This perspective highlights the benefits of these tools observed in a diversity of clinical environments and shows the importance of ML and AI algorithms in building these models. The focus of this study is to develop a machine-learning model to diagnose COVID-19 infection based on clinical symptoms and features. Our work is based on three main steps: The first step is feature selection which aims to select the optimal set of features using the NSGA-II algorithm. While the second step is the classification which consists of training the model using the AdaBoost classifier. Finally, an evaluation step is carried out to assess the efficiency of the proposed model based on the test data. We conducted a set of experiments that prove the significant role of NSGA-II in selecting the most important features which improve the classification performance. The proposed model (NSGA-II+AdaBoost) can potentially be useful for early virus prediction. In fact, the use of automatic diagnosis models in clinical decisions could include some issues. These issues reside on that the model could fail to generalize to different patient populations and might provide incorrect decisions which adverse effects on several patient outcomes. Due to the severity of this disease, the diagnosis should be precise and reliable as much as possible. Currently, several positive COVID-19 patients are experiencing two new symptoms including loss of smell and taste, and the possibility of being contaminated without carrying the most common symptoms such as fever and cough, is highly anticipated. Additionally, the daily increase of asymptomatic individuals' rate makes the diagnosis of COVID-19 infection becoming laborious. This set of circumstances can be possible limitations of our model. In addition, the size of the used datasets was not extensive enough which does not include the two aforementioned symptoms. Hence, these symptoms are hard to skip to obtain a good prediction. Meanwhile, it can lead to model uncertainty. To overcome some of these issues, we suggest incorporating more robust data that is highly recommended to be collected from different countries. Meanwhile, integrate more symptoms and gathering equal quantities of samples for each class as much as a possible. Providing the model with more robust data can be very helpful in reducing uncertainty. Besides, we highlight the need for more performant model results to be more accurate in prediction. This can be achieved by using advanced techniques such as deep learning algorithms. Moreover, we intend to validate the model externally before undergo any clinical usage. This step is invaluable as it is correctly evaluating the model. The results of external validation will determine whether the model performs to a satisfactory degree. We plan also to extend our study by developing a publicly available online tool and to use the Xray images for COVID-19 detection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A new coronavirus associated with human respiratory disease in China",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "G"
                    ],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "W"
                    ],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "Y"
                    ],
                    "last": "Pei",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "L"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "H"
                    ],
                    "last": "Dai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "M"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "C"
                    ],
                    "last": "Holmes",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "Z"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Nature",
            "volume": "44",
            "issn": "59",
            "pages": "265--269",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: a descriptive study",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Qu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Gong",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "",
            "pages": "507--513",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Machine learning based approaches for detecting COVID-19 using clinical text data",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "M U D"
                    ],
                    "last": "Khanday",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "T"
                    ],
                    "last": "Rabani",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "R"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Rouf",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "U M"
                    ],
                    "last": "Din",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Int. J. Inf. Technol",
            "volume": "12",
            "issn": "3",
            "pages": "731--739",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Impact of weather parameters and population density on the COVID-19 transmission: evidence from 81 provinces of Turkey",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Selcuk",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gormus",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Guven",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Earth Syst. Environ",
            "volume": "",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Investigating the significance of aerosols in determining the coronavirus fatality rate among three European Countries",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "El-Askary",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Piechota",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Struppa",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "A A"
                    ],
                    "last": "Ghaffar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Earth Syst. Environ",
            "volume": "4",
            "issn": "3",
            "pages": "513--522",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Peaks of fine particulate matter may modulate the spreading and virulence of COVID-19",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rohrer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Flahault",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Stoffel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Earth Syst. Environ",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Estimating the impact of daily weather on the temporal pattern of COVID-19 outbreak in India",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Pradhan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "N A"
                    ],
                    "last": "Maulud",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Earth Syst. Environ",
            "volume": "4",
            "issn": "3",
            "pages": "523--534",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Effects of temperature and humidity on the daily new cases and new deaths of COVID-19 in 166 countries",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Jing",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "729",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Spatiotemporal assessment of COVID-19 spread over Oman using GIS techniques",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Al-Kindi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Alkharusi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Alshukaili",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Al Nasiri",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Al-Awadhi",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Charabi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "El Kenawy",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Earth Syst. Environ",
            "volume": "4",
            "issn": "4",
            "pages": "797--811",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "COVID-19: challenges to GIS with big data",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pei",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Geogr. Sustain",
            "volume": "1",
            "issn": "1",
            "pages": "77--87",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "COVID-19 challenges to Pakistan: Is GIS analysis useful to draw solutions?",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarwar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Waheed",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarwar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sci. Total Environ",
            "volume": "730",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Application of geographic information system in monitoring and detecting the COVID-19 outbreak",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rezaei",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Nouri",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "S"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Iran. J. Public Health",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Distribution and trend analysis of COVID-19 in India: geospatial approach",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Murugesan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Karuppannan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "T"
                    ],
                    "last": "Mengistie",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ranganathan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gopalakrishnan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Geogr. Stud",
            "volume": "4",
            "issn": "1",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Rapid surveillance of COVID-19 in the United States using a prospective space-time scan statistic: detecting and evaluating emerging clusters",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Desjardins",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hohl",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "M"
                    ],
                    "last": "Delmelle",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Appl. Geogr",
            "volume": "118",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Monitoring and epidemiological trends of coronavirus disease (COVID-19) around the world",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saha",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Patil",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Matrix Sci. Med",
            "volume": "4",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Assessment of the outbreak risk, mapping and infestation behavior of COVID-19: application of the autoregressive and moving average (ARMA) and polynomial models",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "Pourghasemi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pouyan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Farajzadeh",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sadhasivam",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Heidari",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Babaei",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Tiefenbacher",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Detection of COVID-19 infection from routine blood exams with machine learning: a feasibility study",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Brinati",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Campagner",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ferrari",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Locatelli",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Banfi",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Cabitza",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Med. Syst",
            "volume": "44",
            "issn": "8",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Rapid and accurate identification of COVID-19 infection through machine learning based on clinical available blood test results",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "New machine learning method for imagebased diagnosis of COVID-19",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Elaziz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Hosny",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Salah",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Darwish",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "T"
                    ],
                    "last": "Sahlol",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "PLoS ONE",
            "volume": "15",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Deep learning system to screen coronavirus disease",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Butt",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gill",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "A"
                    ],
                    "last": "Babu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Survey of machine learning techniques in medical imaging",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Arasi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Babu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Int. J. Adv. Trends Comput. Sci. Eng",
            "volume": "8",
            "issn": "5",
            "pages": "210--2116",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Robust identification for fault detection in the presence of non-Gaussian noises: application to hydraulic servo drives",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Stojanovic",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Prsic",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Nonlinear Dyn",
            "volume": "100",
            "issn": "3",
            "pages": "2299--2313",
            "other_ids": {
                "DOI": [
                    "10.1007/s11071-020-05616-4"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "State and parameter joint estimation of linear stochastic systems in presence of faults and non-Gaussian noises",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Stojanovic",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Int. J. Robust Nonlinear Control",
            "volume": "30",
            "issn": "16",
            "pages": "6683--6700",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Robust fault detection filter design for a class of discrete-time conic-type non-linear Markov jump systems with jump fault signals",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Stojanovic",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IET Control Theory Appl",
            "volume": "14",
            "issn": "14",
            "pages": "1912--1919",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Automated machine learning: state-of-the-art and open challenges",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Elshawi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Maher",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sakr",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "ArXiv",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "On hyperparameter optimization of machine learning algorithms: theory and practice",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shami",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Neurocomputing",
            "volume": "415",
            "issn": "",
            "pages": "295--316",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neucom.2020.07.061"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A nature inspired optimal control of pneumatic-driven parallel robot platform",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Pr\u0161i\u0107",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Nedi\u0107",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Stojanovi\u0107",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. Inst. Mech. Eng. Part C J. Mech. Eng. Sci",
            "volume": "231",
            "issn": "1",
            "pages": "59--71",
            "other_ids": {
                "DOI": [
                    "10.1177/0954406216662367"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "An optimized brain-based algorithm for classifying Parkinson's disease",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Olivares",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Munoz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Soto",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Crawford",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "C\u00e1rdenas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ponce",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Taramasco",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Appl. Sci. Switzerland",
            "volume": "10",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/app10051827"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Using black hole algorithm to improve EEG-based emotion recognition",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Munoz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Olivares",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Taramasco",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Villarroel",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Soto",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Barcelos",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Merino",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "F"
                    ],
                    "last": "Alonso-S\u00e1nchez",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Intell. Neurosci",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1155/2018/3050214"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Machine learningbased prediction of COVID-19 diagnosis based on symptoms. npj Digit",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zoabi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Deri-Rozov",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shomron",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "4",
            "issn": "",
            "pages": "1--5",
            "other_ids": {
                "DOI": [
                    "10.1038/s41746-020-00372-6"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Applications of artificial intelligence in combating Covid-19: a systematic review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Enughwure",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Febaide",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Open Access Library J",
            "volume": "7",
            "issn": "",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Probabilistic estimation of COVID-19 using patient's symptoms",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Banik",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Banik",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "P"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tomar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Choudhury",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Perumal",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mahdi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Data Driven Approach Towards Disruptive Technologies Studies in Autonomic, Data-Driven and Industrial Computing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/978-981-15-9873-9_29"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "COVID-19 diagnosis prediction in emergency care patients: a machine learning approach",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "F M"
                    ],
                    "last": "De Batista",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Miraglia",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "H R"
                    ],
                    "last": "Donato",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "D P"
                    ],
                    "last": "Chiavegatto Filho",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Data analytics for novel coronavirus disease",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R H"
                    ],
                    "last": "Mondal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bharati",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Podder",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Podder",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Inform. Med. Unlock",
            "volume": "20",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Potential preanalytical and analytical vulnerabilities in the laboratory diagnosis of coronavirus disease 2019 (covid-19)",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lippi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Simundic",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Plebani",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Clin. Chem. Lab. Med. CCLM",
            "volume": "58",
            "issn": "",
            "pages": "1070--1076",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "COVID-19 diagnosis by routine blood tests using machine learning",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--11",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Logistic regression and artificial neural network classification models: a methodology review",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dreiseitl",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ohno-Machado",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "J. Biomed. Inform",
            "volume": "35",
            "issn": "5-6",
            "pages": "352--359",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Data mining: data mining concepts and techniques",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings-2013 International Conference on Machine Intelligence Research and Advancement",
            "volume": "2013",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Neural Networks and Artificial Intelligence",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "MATLAB Deep Learning: With Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "The linear random forest algorithm and its advantages in machine learning assisted logging regression modeling",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Petrol. Sci. Eng",
            "volume": "174",
            "issn": "",
            "pages": "776--789",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Visual diagnosis of tree boosting methods",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Vis. Comput. Graph",
            "volume": "24",
            "issn": "1",
            "pages": "163--173",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Ordinal decision-tree-based ensemble approaches: the case of controlling the daily local growth rate of the COVID-19 epidemic",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Singer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Marudi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Entropy",
            "volume": "22",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Stochastic gradient boosting",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Friedman",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Comput. Stat. Data Anal",
            "volume": "38",
            "issn": "4",
            "pages": "367--378",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "XGBoost: A scalable tree boosting system",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Guestrin",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
            "volume": "",
            "issn": "",
            "pages": "785--794",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Feature selection methods and their combinations in high-dimensional classification of speaker likability, intelligibility and personality traits",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pohjalainen",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "R\u00e4s\u00e4nen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kadioglu",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Comput. Speech Lang",
            "volume": "29",
            "issn": "1",
            "pages": "145--171",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Comparison of support vector machine and extreme gradient boosting for predicting daily global solar radiation using temperature and precipitation in humid subtropical climates: a case study in China",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xiang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Energy Convers. Manage",
            "volume": "164",
            "issn": "",
            "pages": "102--111",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "A survey on feature selection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Niu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Procedia Comput. Sci",
            "volume": "91",
            "issn": "",
            "pages": "919--926",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "A fast and elitist multiobjective genetic algorithm: NSGA-II",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Deb",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pratap",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Meyarivan",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IEEE Trans. Evol. Comput",
            "volume": "6",
            "issn": "2",
            "pages": "182--197",
            "other_ids": {
                "DOI": [
                    "10.1109/4235.996017"
                ]
            }
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "An empirical comparison and evaluation of minority oversampling techniques on a large number of imbalanced datasets",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kov\u00e1cs",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Appl. Soft Comput. J",
            "volume": "83",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.asoc.2019.105662"
                ]
            }
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "SMOTE for high-dimensional classimbalanced data",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Blagus",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lusa",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "BMC Bioinform",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/1471-2105-14-106"
                ]
            }
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Classification assessment methods",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tharwat",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Appl. Comput. Inform",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.aci.2018.08.003"
                ]
            }
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "An experimental comparison of performance measures for classification",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ferri",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hern\u00e1ndez-Orallo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Modroiu",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Pattern Recogn. Lett",
            "volume": "30",
            "issn": "1",
            "pages": "27--38",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patrec.2008.08.010"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Fig. 1 Number of COVID-19 confirmed cases and total deaths for the period (30 December 2019-12 April 2021) reported weekly by WHO (https://www.who.int/ publications/m/item/ weekly-epidemiological-update-on-covid-19---6-april-2021 (Accessed 12 April 2021))",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Input: The set of all feature of the COVID-19 symptoms dataset Y where Y = {y1, y2, . . . , yd}.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Input: A sequence of m instances S = {(x 1 , y 1 ) \u00b7 \u00b7 \u00b7 (x m , y m )} where x i \u2208 X k with labels y i \u2208 Y = {0, 1} from COVID-19 symptoms dataset -Weak learner: Decision Tree -T (number of iterations) Result: The final classifier with hypothesis H (x) = sign( T t=1 \u03b1 t h t (x)) Initialization: D1(i) = 1/m for all i = 1, . . . , m 1. For t = 1 to T 2. Call Weak learner using distribution D t 3. Get Weak classifier and obtain hypothesis h t : X \u2192 \u22121, +1 4. Calculate the error rate e t m i=1 D t (i)[h t (x i ) = y i ]of h t 5. If e t > 0.5 then T = t \u2212 1 and abort loop 6.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "We conducted various experiments to compare the obtained results after running eight machine learn-",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Dataset 1 description",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Dataset 2 description",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Confusion matrix",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Classification results with full datasets",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Significant test results of paired t-test (\u03b1 = 0.05) for Dataset 1 rate of 84.51% and 84.41% respectively. Besides, the results derived by MLP is improved compared to its results without feature selection. It achieved 83.52% as accuracy rate instead of 79.96%. SVM also generates a noticeable increase. It yielded as accuracy 79.51% instead of 75.72% with all the features. The results described inTable 6prove the efficiency of AdaBoost with NSGA-II as it achieved the best classification performance for the dataset 2. It generated 96.87% as AUC value, 95.56% of accuracy, 95.56% of precision, sensitivity of 95.56%, specificity of 98.19%, and 95.56% of f1-score. Furthermore, gradient boosting and SVM achieved a high classification accuracy of 95.34% and 95.1% respectively. To conclude, the optimal subset of features for dataset 1 that satisfies the two conflicting objectives included the following features: Fever, Cough, Fatigue, Nasal congestion, Diarrhea, Headache, and Lives in affected area. While the optimal subset of features for dataset 2 contained: Cough, Fever, Sore Throat, Shortness of breath, headache, and Known with confirmed.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Significant test results of paired t-test (\u03b1=0.05) for Dataset 2",
            "latex": null,
            "type": "table"
        },
        "TABREF12": {
            "text": "Comparison of our model with similar works for COVID-19 prediction",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Acknowledgements The authors extend their appreciation to the Deputyship for Research and Innovation, Ministry of Education in Saudi Arabia for funding this research work through the project number 7848.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        },
        {
            "text": "The authors declare that they have no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}