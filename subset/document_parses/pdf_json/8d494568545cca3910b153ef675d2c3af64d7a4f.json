{
    "paper_id": "8d494568545cca3910b153ef675d2c3af64d7a4f",
    "metadata": {
        "title": "MithraDetective: A System for Cherry-picked Trendlines Detection",
        "authors": [
            {
                "first": "Yoko",
                "middle": [],
                "last": "Nagafuchi",
                "suffix": "",
                "affiliation": {},
                "email": "yokon@umich.edu"
            },
            {
                "first": "Yin",
                "middle": [],
                "last": "Lin",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Kaushal",
                "middle": [],
                "last": "Mamgain",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Abolfazl",
                "middle": [],
                "last": "Asudeh",
                "suffix": "",
                "affiliation": {},
                "email": "asudeh@uic.edu"
            },
            {
                "first": "H",
                "middle": [
                    "V"
                ],
                "last": "Jagadish",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Wu",
                "middle": [
                    "\u2225"
                ],
                "last": "",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Cong",
                "middle": [],
                "last": "Yu",
                "suffix": "",
                "affiliation": {},
                "email": "congyu@google.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "Given a data set, misleading conclusions can be drawn from it by cherry picking selected samples. One important class of conclusions is a trend derived from a data set of values over time. Our goal is to evaluate whether the 'trends' described by the extracted samples are representative of the true situation represented in the data. We demonstrate MithraDetective, a system to compute a support score to indicate how cherry-picked a statement is; that is, whether the reported trend is well-supported by the data. The system can also be used to discover more supported alternatives. MithraDetective provides an interactive visual interface for both tasks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Fake news has attracted much attention recently. While some fake news is just plain false, quite often we see impressive statements made on the basis of cherry-picked data points, with a particular agenda in mind. Although this type of statement is not a complete fabrication, it is misleading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "One type of statement often made on cherry-picked data is a trendline statement. By carefully selecting the start and the end point of the trendline, it is often possible to show misleading 'trends' that are not representative of the real situation. These statements are prevalent in various fields, and particularly in political contexts. Climate change, in particular, has seen a great deal of this because intra-day and seasonal variations in temperature are so much greater than the global warming trend. Let us look at several examples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Example 1 (Northern Hemisphere's Temperature). In [7] , John Mason exhibits an example of using cherry-picked data points in the monthly temperature trendline dataset to distort the reality of climate change. By selecting a shorter time frame and cherry-picking specific locations, one can come out with the fantasy-like statement that: The northern hemisphere summers are colder than winters. For example, a cherry-picked summer day of Ann Arbor (MI, USA) on Aug. 18 had an average temperature of 58\u00b0, which is 8 degrees lower than its average temperature on Mar. 15 (a winter day). In fact, both of the seasonal aggregation results and the validation [3] indicate that such cherry-picked trendline statements are not a fair representation of the truth.",
            "cite_spans": [
                {
                    "start": 50,
                    "end": 53,
                    "text": "[7]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 653,
                    "end": 656,
                    "text": "[3]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Cherry-picked claims can aggravate public panic and lead to potentially dangerous outcomes in policy-making, as shown in the next example.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Example 2 (President Trump's COVID-19 statement (from politifact.com)). On May 24, as the number of deaths of COVID-19 reached 100,000, President Donald Trump tweeted \"Cases, numbers and deaths are going down all over the Country!\" to build an optimistic attitude towards the pandemic. If we look at a short time window, it was true that in some states, the pandemic was easing; so the statement was not totally false, rather it was cherry-picked. The opposite conclusion would have been reached considering most other time periods, and particularly, longer periods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "In practice, common fact-checking methods include crowdsourced or expert-based manual fact-checking (i.e., Politi-Fact [2], FactCheck [1]), and automatic fact-checking relying on techniques like information retrieval [5] , natural language processing [6] , and graph theory [4] . See [9] for a comprehensive review. In the context of data management, [8] use query perturbation to evaluate the sensibility of the statements. [3] focus on the trendline statements, and proposes efficient exact and approximate algorithms works for both unconstrained and constrained trendline statements.",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 220,
                    "text": "[5]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 251,
                    "end": 254,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 274,
                    "end": 277,
                    "text": "[4]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 284,
                    "end": 287,
                    "text": "[9]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 351,
                    "end": 354,
                    "text": "[8]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 425,
                    "end": 428,
                    "text": "[3]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "In this demonstration, we present MithraDetective, a system for detection of cherry-picked trendlines. MithraDetective adopts the definitions and algorithms developed in [3] for statement validation and alternative statement discovery. We provide users an interactive UI, where they can set up the statement parameters to validate how cherry-picked a statement is and find alternatives. The pre-loaded datasets cover various controversial topics, including COVID-19, employment, and climate change.",
            "cite_spans": [
                {
                    "start": 170,
                    "end": 173,
                    "text": "[3]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "In the rest of this demo description, we first provide our system details, including what the system does, the system implementation, user interface, and back-end algorithm in Section 2. In Section 3, we overview our demonstration plan.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "MithraDetective is a cherry-picked trendline statement factchecking web application. Our focus is restricted to trendline statements based on selected endpoints. We perform both statement validation and alternative discovery. Trendline Statement. A trendline statement describes the relationship of a pair of trend points (beginning) and (end) and their target values, ( ) and ( ) respectively. A trendline statement provides a numerical upper bound and lower bound where ( ) \u2212 ( ) falls within. For instance, in Example 1, the beginning point of the trendline is <Aug. 18, Ann Arbor> and the end point is <March 15, Ann Arbor>, the bound condition of the statement is (0, inf), which means that ( ) \u2212 ( ) = 66 \u2212 58 > 0. Statement Validation. Given the region of all possible beginning points ( ) and end points ( ), the support of a statement is the proportion of ( , ) pairs whose ( ) \u2212 ( ) falls within the bounds of the statement. Alternative Statement Discovery. Given a threshold for the statement support score, for a statement whose score is lower than the given threshold, find an alternative statement that has (1) the highest support score and (2) the tightest statement boundary (see Section 2.1 for details).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SYSTEM DETAILS"
        },
        {
            "text": "MithraDetective is built using the Flask framework (v1.1.1). The front-end is implemented using AngularJS (v1.8.0), Bootstrap (v4.0.0), HTML, and CSS. The back-end is written in Python 3.7.4. We describe the front-end user interface in Section 2.1 and demonstrate the backend validation and alternative discovery algorithms in Section 2.2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SYSTEM DETAILS"
        },
        {
            "text": "MithraDetective's user interface has two input sections and one output section. Input: Dataset and Task Selection. As shown in Figure  1 (a), in the first input section, the user first selects a preloaded dataset related to the trendline of their interest. Then, they select one of the three tasks, or all, to perform:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 127,
                    "end": 136,
                    "text": "Figure  1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "User Interface"
        },
        {
            "text": "\u2022 Support value: evaluates if a statement is cherry-picked by returning a value between 0 and 1. The higher the support value, the less cherry-picked the trendline is. In the table, the values in bold were the outputs of the algorithms, and those not in bold were conditions specified by the user as in Figure 1 (b). The conditions that were not needed to complete the task are marked with \"--\". If the user has specified the task as support value or all, the user sees the support values calculated using three algorithms: exact baseline, exact, and random. In Figure 1 (c), the statement \"Detroit summers are colder than winters\" has been evaluated to have a support value of 0.001 for the exact baseline and exact algorithms. This means that the statement is barely supported by the points in the support region, and it is very likely cherry-picked. In addition, the statement has a support value of 0.001 for the random algorithm. If the user does not specify a budget, the system uses five large budgets shown in Figure 1(c) , and calculates the support respectively.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 303,
                    "end": 311,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 562,
                    "end": 570,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1018,
                    "end": 1029,
                    "text": "Figure 1(c)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "User Interface"
        },
        {
            "text": "If the task is most supported statement or all, the user sees the upper and lower bounds of the statement range as well as the highest support value achieved. Using our Detroit example, we can state that the least cherry-picked statement with the statement range 40 has bounds (1.550, 41.551) and support value 0.995. In other words, \"Detroit winters are colder than summers by 1.550 to 41.551 degrees\" has the If the task is tightest statement or all, the user sees as the output the upper and lower bounds of the statement range which results in the specified support value. Again using our Detroit example, we can state that the statement that has the tightest statement range with support value 0.9 has bounds (12.520, 50.920) and range 38.400. \"Detroit winters are colder than summers by 12.520 to 50.920 degrees\" has at least 0.9 as its support value. The statement has the tightest range of 38.400, out of all statements with at least 0.9 support.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "User Interface"
        },
        {
            "text": "For evaluating the support value, the system uses three algorithms. The exact baseline algorithm uses the brute force algorithm. It first counts the total number of all possible pairs of the points in the beginning and end support regions. After counting the pairs that fulfill the support bounds, it divides the counts by the total number. To improve efficiency, the exact algorithm uses binary search. If the dataset contains a very large number of records, the exact algorithm becomes inefficient. To tackle this problem, we use the random algorithm, which uses the point sampling method. For evaluating the most supported statement and tightest statement, we also use efficient algorithms instead of brute force. The efficiency is improved by sorting the list of every ( ) \u2212 ( ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Statement Validation and Discovery"
        },
        {
            "text": "MithraDetective is part of the Mithra system 1 . We will demontrate it with three real-world datasets. They are focusing on controversial topics including COVID-19, employment, immigration policy, and climate change.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEMONSTRATION PLAN"
        },
        {
            "text": "(1) COVID- The user selects a dataset from the preloaded datasets. We use the Weather Dataset (WD) to demonstrate how a user could interact with MithraDetective 6 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEMONSTRATION PLAN"
        },
        {
            "text": "(1) For the first section, select \"temperature.csv\" from the drop-down menu, then click \"Select.\" For the second section, select \"All Tasks\" from the drop-down menu, then click \"Continue. \" (2) Choose \"Detroit\" for the target attribute and click \"Select. \" Choose \"datetime\" for the trend attribute, check \"dates,\" and click \"Add.\" For the Statement Bounds, specify the upper bound as 0 and leave the lower bound blank. The lower bound is set to \u2212\u221e by default. Next, choose \"datetime\" for the Support Region. Specify the beginning from 2012-12-01 00:00:00 to 2013-03-01 01:00:00 and the end from 2013-06-01 00:00:00 to 2013-09-01 01:00:00, then click \"Add.\" Leave blank Constraints (length of the window) in Support Region, Number of Data Points, and Budget for Random Sampling. For the Width of the Statement Range, enter 40. Lastly, for the Support Value of the Tightest Statement, enter 0.9. Click \"Evaluate!. \" (3) The results are displayed. Depending on the task completed, the user will see one or all of the support values, tightest statement, and most supported statement. (4) If the user wishes to evaluate a constrained trendline, they should enter some value in Constraints under Support Region. If they wish to use the first rows of the dataset for evaluation, they should enter the number in Number of Data Points. must be a positive number less than the total number of rows, which is shown on the page. If they wish to specify the number of sampled points used in the Support Random algorithm, they should enter a positive number in the Budget for Random Sampling.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DEMONSTRATION PLAN"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "On detecting cherry-picked trendlines",
            "authors": [
                {
                    "first": "Abolfazl",
                    "middle": [],
                    "last": "Asudeh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "V"
                    ],
                    "last": "Jagadish",
                    "suffix": ""
                },
                {
                    "first": "You",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Cong",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "PVLDB",
            "volume": "13",
            "issn": "",
            "pages": "939--952",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Computational journalism",
            "authors": [
                {
                    "first": "Sarah",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "James",
                    "suffix": ""
                },
                {
                    "first": "Fred",
                    "middle": [],
                    "last": "Hamilton",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Turner",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Commun. ACM",
            "volume": "54",
            "issn": "",
            "pages": "66--71",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Principles of data integration",
            "authors": [
                {
                    "first": "Anhai",
                    "middle": [],
                    "last": "Doan",
                    "suffix": ""
                },
                {
                    "first": "Alon",
                    "middle": [],
                    "last": "Halevy",
                    "suffix": ""
                },
                {
                    "first": "Zachary",
                    "middle": [],
                    "last": "Ives",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Danalix: a domain-adaptive natural language interface for querying xml",
            "authors": [
                {
                    "first": "Yunyao",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Ishan",
                    "middle": [],
                    "last": "Chaudhuri",
                    "suffix": ""
                },
                {
                    "first": "Huahai",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Satinder",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "V"
                    ],
                    "last": "Jagadish",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "SIGMOD",
            "volume": "",
            "issn": "",
            "pages": "1165--1168",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "How to use short timeframes to distort reality: a guide to cherrypicking",
            "authors": [
                {
                    "first": "John",
                    "middle": [],
                    "last": "Mason",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Computational fact checking through query perturbations",
            "authors": [
                {
                    "first": "You",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Pankaj",
                    "suffix": ""
                },
                {
                    "first": "Chengkai",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                },
                {
                    "first": "Jun",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Cong",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "TODS",
            "volume": "42",
            "issn": "",
            "pages": "1--41",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Fake news: A survey of research, detection methods, and opportunities",
            "authors": [
                {
                    "first": "Xinyi",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Reza",
                    "middle": [],
                    "last": "Zafarani",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1812.00315"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Most supported statement (MSS): The user specifies a bound condition, which is the range of the upper and lower bounds. Given the condition, MSS returns the upper and lower bounds of a trendline with the highest support value. If your statement is cherry-picked, the most supported statement can be a better alternative. \u2022 Tightest statement: returns the tightest bounds of a trendline statement with at least the given support value threshold. Input: Statement Parameters Configuration. As in Figure 1(b), in the second input section, the user specifies seven conditions for the evaluation of the trendline. (1) The user specifies the target and trend attributes, which define the trend points and their target values of the trendline. They should specify if an attribute represents dates. (2) Statement Bounds: the upper and lower bounds of a statement, within which ( ) \u2212 ( ) would fall if the trendline supports the statement. (3) Support Region: A pair of disjoint regions, ( ) and ( ), to which every and belong respectively. Trendlines created from and are considered when computing the support value of the trendline statement of interest. The user should specify Constraints (Length of the window) if their trendline statement is constrained. (4) Budget for Random Sampling: The system improves the efficiency of the evaluation by using the random algorithm. The user specifies the number of points to sample from the Support Region. (5) Width of the Statement Range (for the MSS task): The user specifies a number greater than 0 for the range of the MSS. (6) Support Value of the Tightest Statement: The user specifies a number within (0, 1). Output: Evaluation Results. The output section, as shown in Figure 1(c), displays the results of the evaluation as a table.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "MithraDetective: User Interface highest support value with 0.995, satisfying the condition that the statement range equals 40.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "BorderCrossing dataset contains data related to the number of border crossings in the U.S.-Canada and U.S.-Mexico borders. There are five attributes describing the method of crossing, port name, and state. The data is published by the Bureau of Transportation Statistics. (4) Weather Dataset (WD) 5 : WD contains 45,253 records of hourly temperatures for 35 cities in the United States, Canada, and Israel. For each city, the dataset contains temperatures in Kelvin from October 1, 2012 to November 30, 2017. We will demonstrate our system using Example 1.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}