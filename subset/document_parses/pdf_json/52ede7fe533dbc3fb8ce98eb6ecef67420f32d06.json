{
    "paper_id": "52ede7fe533dbc3fb8ce98eb6ecef67420f32d06",
    "metadata": {
        "title": "A COVID-19 Multipurpose Platform",
        "authors": [
            {
                "first": "Nikos",
                "middle": [],
                "last": "Petrellis",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Peloponnese",
                    "location": {
                        "settlement": "Patras",
                        "country": "Greece"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Background: Contactless symptom tracking is essential for the diagnosis of COVID-19 cases that need hospitalization. Indications from sensors and user descriptions have to be combined in order to make the right decisions. Methods: The proposed multipurpose platform Coronario combines sensory information from different sources for a valid diagnosis following a dynamically adaptable protocol. The information exchanged can also be exploited for the advancement of research on COVID-19. The platform consists of mobile and desktop applications, sensor infrastructure, and cloud services. It may be used by patients in pre-and post-hospitalization stages, vulnerable populations, medical practitioners, and researchers. Results: The supported audio processing is used to demonstrate how the Coronario platform can assist research on the nature of COVID-19. Cough sounds are classified as a case study, with 90% accuracy. Discussion/Conclusions: The dynamic adaptation to new medical protocols is one of the main advantages of the developed platform, making it particularly useful for several target groups of patients that require different screening methods. A medical protocol determines the structure of the questionnaires, the medical sensor sampling strategy and, the alert rules.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The subjective judgement of the primary health care call center operator, critical information that may be missing, and unimportant details that have been overstressed by the caller explain why the decisions made about whether a patient needs hospitalization are not always correct. Patients in the rehabilitation stage of COVID-19 should also be closely monitored. A recent incident in Greece, where a patient with kidney failure spread the COVID-19 virus to many other patients and the personnel of a hemodialysis center [1] , showed that on-site screening is crucial to ensure other patients' safety.",
            "cite_spans": [
                {
                    "start": 523,
                    "end": 526,
                    "text": "[1]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The nucleic acid amplification test, immunoassays, and sequencing are reliable molecular tests for COVID-19 diagnosis and they are currently applied to a fraction of the potential patients selected based on symptom assessment. Image processing techniques applied to coaxial tomography or x-ray scans have been investigated, e.g., for pneumonia detection [2] . Lung ultrasonography images can also reveal signs of COVID-19 [3] . Sound processing (respiratory [4] or cough [5] [6] [7] [8] [9] [10] ) can also support the valid diagnosis of this virus. Speech modeling can track COVID-19 in asymptomatic/ symptomatic stages [11] . Machine learning techniques can effectively diagnose COVID-19. Deep learning methods have been employed in [12] in a user-friendly platform for physicians and researchers. Social distancing can be assisted by smart phones and social networks [13] .",
            "cite_spans": [
                {
                    "start": 354,
                    "end": 357,
                    "text": "[2]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 422,
                    "end": 425,
                    "text": "[3]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 458,
                    "end": 461,
                    "text": "[4]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 471,
                    "end": 474,
                    "text": "[5]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 475,
                    "end": 478,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 479,
                    "end": 482,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 483,
                    "end": 486,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 487,
                    "end": 490,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 491,
                    "end": 495,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 621,
                    "end": 625,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 735,
                    "end": 739,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 870,
                    "end": 874,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Additional sensor indications need to be taken into consideration for a more valid diagnosis. In a study by Ding et al. [14] , wearable devices, unobtrusive sensing systems, and telehealth technologies were studied. An Internet of Medical Things-enabled wearable device is presented by Tripathy et al. [15] for contact tracing and social distancing.",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 124,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 302,
                    "end": 306,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The developed Coronario platform consists of several modules implemented as mobile or desktop applications and sensor and cloud infrastructure. It has multiple objectives, i.e., (1) to assist the call centers of primary healthcare units in making a reliable COVID-19 diagnosis based on a plurality of medical data, (2) to support a dynamic adoption of new medical protocols (MP) appropriate for different target groups of patients (pre-or posthospitalized patients with a weak immune system) that require different screening methods, and (3) to exploit the exchanged anonymous medical data for research purposes with privacy respected.",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 318,
                    "text": "(2)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Dynamic MP updating means that the questionnaires as well as the sensor sampling strategy and the alert rules are reconfigured in real time. Coronario consists of various modules targeted to different users (i.e., patients, supervising doctors, health institutes, and researchers). The developed platform allows advanced medical data processing such as sound analysis for the classification of cough or respiratory sounds. Additionally, user localization can support social distancing and tracing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The Coronario platform consists of the following modules: (1) the User App, which is a mobile phone application for the patient; (2) the Supervisor App, which is a desktop application that allows the supervisor to access the medical data; (3) the eHealth IoT sensor infrastructure, (4) the cloud, which is used to securely store medical data, protocols, etc.; and (5) the Scientific App, which enables researchers to access, experiment with, and process statistically the anonymous medical data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The User App was developed using Microsoft Visual Studio 2019 with Xamarin. It can be deployed as either an android or an iOS application. This application authenticates the user, and dynamically structured questionnaires defined in the MP appear. The current position of the user is detected and displayed on the map through the global positioning system (GPS) and the coordinates found are used to locate the country or region. The number of COVID-19 cases diagnosed so far in this region are displayed. This information can also be used to trace the user contacts. Recorded cough or respiratory sound files can be processed and the extracted features can be uploaded to the cloud. Several messages can be displayed in the User App, including diagnosis results and instructions about how and when to use the medical sensors. Actions triggered by the alert rules that have been defined can also generate their own notifications for the user.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The Supervisor App is used by authorized medical practitioners to access patient medical data and exchange messages. A supervising doctor accesses the sensor values in readable form and selects or creates MP files where the conditions that generate alerts are defined. The sensor sampling scheme that has to be followed and instructions about how the user will perform the necessary tests on his or her own are also determined in the MP file. Finally, the questions that should be included in the questionnaires are selected. Visualization of the data stored in the cloud can be performed by the Supervisor App.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The sensor infrastructure can be employed to monitor additional parameters concerning the condition of the patient and his or her environment. The employed sensors should not require medical expertise as is the case with electrocardiogram (ECG) or electromyogram (EMG), although these sensors have been used in experimental eHealth platforms. Different sensors may be needed for each medical case. Sensors that are often used by patients at home include: blood pressure sensors, glucose meters, thermometers, SPO 2 , and body position. Sensors may be connected to a controller responsible for uploading their values to the cloud as in the study of Petrellis et al. [16] , where low-power, precision, and flexibility issues are discussed. In this case, the sensor values can be filtered locally and only the useful information can be uploaded to the cloud, making the system more secure in terms of data privacy. However, uploading of the medical data to the cloud with user permission can be exploited for the benefit of research on COVID-19. The voice or image of a patient does not need to be heard or seen, respectively, by anybody since it may be directly transformed in other domains (like the frequency domain). The necessary classification features are the only information that has to be anonymously exchanged.",
            "cite_spans": [
                {
                    "start": 665,
                    "end": 669,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The Coronario platform is connected to Microsoft Azure using only its storage facilities for higher portability and less dependence on specific cloud services. Other cloud platforms such as Google Cloud, AWS, or simpler ones (Ubidots and Thingspeak) can easily be used in place of Microsoft Azure. The following information is stored in the cloud: (1) sensor values stored along with time stamps and the identity of the user and the sensor, (2) MP files, and (3) text messages exchanged between the supervisor and the monitored patient.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The Scientific App is a variation of the User App preferably compiled as a desktop application. The sound processor page of the Scientific App is shown in Figure 1a . In this page the researcher can select a sound file, play it (this option can be inactivated for higher data privacy), determine if it is the sound of cough or respiratory sounds and whether a training process is going on. The classification of the sound is performed by comparing the spectrum features extracted from the tested sound file with the reference ones using a similarity metric (e.g., Pearson) determined by the researcher. Fast Fourier transform (FFT) is applied to the potentially subsampled input sound file with a configurable size. The \"signature\" of the analyzed sound is visualized in the Scientific App as shown in Figure 1b .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 155,
                    "end": 164,
                    "text": "Figure 1a",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 802,
                    "end": 811,
                    "text": "Figure 1b",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Materials and Methods"
        },
        {
            "text": "The dynamic MP configuration is facilitated by employing an appropriate JavaScript Object Notation (JSON) format with the following 3 sections: questionnaire, sensor sampling and alert. The User App is reconfigured according to the updated MP file without recompilation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The questionnaire section of the MP file determines the questions (taken from a pool) that should appear in the User App. Each entry in the questionnaire section consists of an identifier, the sensor identity, the question, and the answer type (Fig. 2) . The questionnaire answers and additional information such as the coordinates of the user position are uploaded to the cloud along with the question/user identity and a time stamp.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 244,
                    "end": 252,
                    "text": "(Fig. 2)",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Materials and Methods"
        },
        {
            "text": "The second section in the MP file defines the sensor sampling scenario. In each section entry the sensor name is declared followed by these 4 fields: type, date, period, and repeat. The type can be: once, repeat, or interval. If type = \"once\" then the medical test should be performed once at the specific date. If type = \"repeat\" then a routine medical test must start at the date indicated by the corresponding field. A time interval equal to the number in the period field should intervene between successive tests. The field repeat indicates a maximum number of tests that should be performed. If type = \"interval\" then the medical test should be performed in a period starting at date, repeat times. The sampling scenarios determined in this MP file section should generate notifications to the patient in order to schedule his medical tests (Fig. 3) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 847,
                    "end": 855,
                    "text": "(Fig. 3)",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Materials and Methods"
        },
        {
            "text": "This following scenario concerns sensor sampling for patients with type 2 diabetes. The patient has to be monitored for 1 week in order to obtain the average of his or her glucose levels before visiting his or her doctor. The glucose has to be tested twice a day, i.e., before breakfast and 2 h after lunch. It is also assumed that glucose will be measured day by day. Moreover, the blood pressure will also be monitored twice every day in this specific week. Other COVID-19 indications are also examined the day before the patient visits his or her doctor; the questionnaire is filled and respiratory sounds along with body temperature are also measured (Fig. 4) . The \"sampling\" section of the MP file could be in this case the one shown in Figure 5a .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 655,
                    "end": 663,
                    "text": "(Fig. 4)",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 743,
                    "end": 752,
                    "text": "Figure 5a",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Materials and Methods"
        },
        {
            "text": "As can be seen from this sampling section, glucose has been declared twice since the sampling of this sensor is not regular, as is the case with blood pressure (every 12 h). The systolic (BPressH) and diastolic (BPressL) blood pressures are declared separately but a single sensor could have been used, returning a string with 2 values. The body temperature (BTemp), the questionnaire (Quest), and the respiratory (Resp) tests are scheduled once at the end of the screening week. Although different medical tests could have been requested by a specialist on diabetes, the scenario described above demonstrates how irregular sensor sampling can be achieved with the specific format selected for the corresponding MP section; practically any sensor sampling scheme can be supported.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The \"alert\" section in the MP file defines rules, that are checked locally in the User App. Whenever the rule condition is true, an action (e.g., a notification) is taken. The supported conditions check whether a sensor value is within the limits. All of the conditions in a rule { { \"Ques\ufffdonnaire\":{ \"q1\":{ \"SensorId\":\"QFever\", \"Ques\ufffdon\":\"Fever?\"}, \"q2\":{ \"SensorId\":\"QFa\ufffdge\", \"Ques\ufffdon\":\"Fa\ufffdge?\"}, \"q3\":{ \"SensorId\":\"QCough\", \"Ques\ufffdon\":\"Cough?\"}}, \"Sampling\":{ \"BPos\":{\"Type\":\"Repeat\", \"Date\":\"2020 04 19 08:00\", \u2026 must be true to perform the defined action (logical AND). The OR operator can be implemented by defining twice the rule (with the same action). To understand how a complex condition can be supported, we assume that action A has to be taken if the sensor S 0 is within (S 0,min , S 0,max ) OR sensor S 1 is outside the range (S 1,min , S 1,max ). In both cases, S 3 has to be true. The alert section of the MP file could in this case be the one in Figure 5b (\"Inf\" denotes \u221e).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 963,
                    "end": 972,
                    "text": "Figure 5b",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Materials and Methods"
        },
        {
            "text": "Several medical cases can be supported since the sensors that need to be sampled are dynamically determined along with alert rules and questionnaires. Different conditions have to be monitored in COVID-19 patients in the pre-and posthospitalization phase or in patients \"Sampling\":{ \"BPos\":{\"Type\":\"Repeat\", \"Date\":\"2020 04 19 08:00\", \"Period\":\"30m\", \"Repeat\":\"10\"}, \"BPressH\":{\"Type\":\"Once\", \"Date\":\"2020 04 19 08:00\", \"Period\":\"0\", \"Repeat\":\"0\"}, \"BPressL\":{\"Type\":\"Once\", \"Date\":\"2020 04 19 08:00\", \"Period\":\"0\", \"Repeat\":\"0\"}, \u2026 with different health problems who are vulnerable to COVID-19. The dynamic nature of the employed MP protocols makes the developed platform appropriate for a large target group of patients. The implemented sound processor of the Scientific App can be used to classify cough or respiratory sounds related to the infection. The following 5 cough categories have been tested according to the availability of the corresponding sound files: child cough, dry cough of an adult male or female, and productive (wet) cough of an adult male or female. This categorization may not be the most useful in medical terms; a distinction between wet and dry cough is often all that is needed [10] . However, additional categories were employed in order to test [{\"Questionnaire\":{\u2026 \"Sampling\":{\u2026 \"Alerts\":{ \"m1\":{\"A\", \"Conditions\":{ \"c1a\": {\"SensId\":\"s0\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"s0_min\", \"Maximum\":\"s0_max\"} \"c1b\": {\"SensId\":\"s3\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"TRUE\", \"Maximum\":\"TRUE\"} } \"m2\":{\"A\", \"Conditions\":{ \"c2a\": {\"SensId\":\"s1\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"-Inf\", \"Maximum\":\"s1_min\"} \"c2b\": {\"SensId\":\"s3\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"TRUE\", \"Maximum\":\"TRUE\"} } \"m3\":{\"A\", \"Conditions\":{ \"c3a\": {\"SensId\":\"s1\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"s1_max\", \"Maximum\":\"+Inf\"} \"c3b\": {\"SensId\":\"s3\", \"Date\":\"2020 04 19 08:00\", \"Minimum\":\"TRUE\", \"Maximum\":\"TRUE\"} } .. the developed classification methods in more complicated situations. The experiments were carried out using 300 sound files, and the number of sound files in each category ranged between 30 and 120 according to the availability. The number of sound files used for training was one sixth of the available files from each category. The FFT outputs of the training files were averaged in order to extract the reference values compared with the FFT output of the sound being tested. All the sound files are publically available and were retrieved from soundsnap.com.",
            "cite_spans": [
                {
                    "start": 1208,
                    "end": 1212,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "The classification results concerning the 5 cough categories mentioned above are shown in Figure 6 . Figure 6 shows the alternative methods used for sound processing. The use of 1024-point FFT, 1/4 subsampling, and unfiltered data is denoted as \"1024-s4.\" The use of 256-point FFT (\"256-s1\") without subsampling had a poor performance due to the fact that the FFT segments cover shorter time intervals and thus they are less representative. For this reason, 1024-s4 was adopted in the rest of the examined methods, i.e., principal component analysis (PCA128) with 2 or 5 components (pca128-2 and pca128-5, respectively) and moving average window with a window of 7 or 15 samples (maw-7 and maw-15, respectively). Variations of 1024-s4, pca128-2, and maw-7, where the dominant (max) power of a frequency bin is used instead of the average between the training samples, were also tested (max1024-s4, maxpca128-2, and maxmaw-7, respectively). Observing the experimental results presented in Figure 6 we can understand that maxmaw-7 shows the highest accuracy among the tested methods. Moreover, it is also obvious that oversmoothing the FFT outputs (e.g., with maw-15 or pca128-2) does not improve the accuracy because the detail lost seems to be important.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 90,
                    "end": 98,
                    "text": "Figure 6",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 101,
                    "end": 109,
                    "text": "Figure 6",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 988,
                    "end": 996,
                    "text": "Figure 6",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Results"
        },
        {
            "text": "Male dry",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Child"
        },
        {
            "text": "Female dry",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Child"
        },
        {
            "text": "Female productive ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Male productive"
        },
        {
            "text": "The aim of the conducted cough sound classification experiments is to demonstrate the environment offered by the Coronario platform for statistical research. More specifically, the results listed in Figure 6 show how different filtering, signal processing, and classification methods can be applied to the available medical sound data. Although it was not intended to implement and compare all the popular classification methods on the Coronario platform, the experimental results show that the accuracy achieved by some of the tested methods is quite high. For example, maxmaw-7 achieved an accuracy higher than 90% in 3 of the 5 categories and only in 1 category (male-productive) was its accuracy less than 80%. The accuracy in the study of Pramono et al. [6] was 92% and it was over 90% in the study of Parker et al. [8] . The average (sensitivity, specificity) of maxmaw-7 is 67% and 91%, while the corresponding metrics were 94% and 88% in the study of Kosasih et al. [9] and less than 88% and 84% in the study of Swarnkar et al. [10] . Concerning the participating patients, 38, 91 (815 samples), and 98 (536 samples) were used in the studies of Pramono et al. [6] , Kosasih et al. [9] , and Swarnkar et al. [10] , respectively.",
            "cite_spans": [
                {
                    "start": 759,
                    "end": 762,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 821,
                    "end": 824,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 974,
                    "end": 977,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1036,
                    "end": 1040,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1168,
                    "end": 1171,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1189,
                    "end": 1192,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1215,
                    "end": 1219,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 199,
                    "end": 207,
                    "text": "Figure 6",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Image processing will be employed in future versions to monitor example skin disorders caused by an infection [17] . In the current version, the supervising doctor is responsible for the diagnosis. However, artificial intelligence deep learning tools such as Google Tensor Flow and Caffe can be plugged at various points of the system to assist the automation and reliability of the diagnosis.",
            "cite_spans": [
                {
                    "start": 110,
                    "end": 114,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Privacy and security were respected during the conducted experiments and are guaranteed for the real-time system operation. All of the cough sound files used were publically available. In the Scientific App, the researcher does not need to listen to the cough sound file. Even if he or she had to access these data in this way, they would be anonymous and given after permission. Statistical results can be extracted to help learn the behavior of COVID-19 without examining the details of an individual person's voice. Encryption and authentication are employed in all levels of data entry, access, and storage. Data is accessed only by the authorized personnel and they are deleted as soon as possible; medical sensor indications can be deleted from the cloud after they are received by the supervising doctor while the coordinates of the locations visited can be deleted after a safe time interval (e.g., 14 days, when tracing is no longer necessary). Local processing minimizes the risk of data exposure. The supported alerts defined in the MP can check various parameters locally and perform certain actions without having to move sensitive data outside the User App. Cloud facilities are exploited; different access privileges are assigned to the users, alerts can warn when an attempt is made to access the data by unauthorized personnel, etc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "The limitations of the developed platform that will be improved in future versions are: (1) Coronario has to be tested in a real healthcare environment, (2) the user Interface can be made more user friendly, (3) automatic generation of MP files must be supported, and (4) image processing can be supported.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Ethics approval is not required since this study did not involve animals or humans, except from cough sound files that are publically available on the internet. Please see https:// soundsnap.zendesk.com/hc/en-us/articles/115003916431 for the permissions for the sound files used in this study. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Statement of Ethics"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Covid-19 toll reaches 138 following Athens death",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A Noise-Robust Framework for Automatic Segmentation of COVID-19 Pneumonia Lesions From CT Images",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ruan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans Med Imaging",
            "volume": "39",
            "issn": "8",
            "pages": "2653--63",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Deep learning for classification and localization of COVID-19 markers in point-of-care lung ultrasound",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roy",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Menapace",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Oei",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Luijten",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Fini",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Saltori",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans Med Imaging",
            "volume": "39",
            "issn": "8",
            "pages": "2676--87",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Portable health screening device of respiratory infections",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 IEEE International Conference on Multimedia and Expo Workshops",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Continuous Sound Collection Using Smartphones and Machine Learning to Measure Cough",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kvapilova",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Boza",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Dubec",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Majernik",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bogar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jamison",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Digit Biomark",
            "volume": "3",
            "issn": "3",
            "pages": "166--75",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A Cough-Based Algorithm for Automatic Diagnosis of Pertussis",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "X"
                    ],
                    "last": "Pramono",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Imtiaz",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Rodriguez-Villegas",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "PLoS One",
            "volume": "11",
            "issn": "9",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A signal processing approach for the diagnosis of asthma from cough sounds",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Khassaweneh",
                    "suffix": ""
                },
                {
                    "first": "Bani",
                    "middle": [],
                    "last": "Abdelrahman",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "J Med Eng Technol",
            "volume": "37",
            "issn": "3",
            "pages": "165--71",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Detecting paroxysmal coughing from pertussis cases using voice recognition technology",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parker",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Picone",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Harati",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H"
                    ],
                    "last": "Jenkyns",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "M"
                    ],
                    "last": "Polgreen",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "PLoS One",
            "volume": "8",
            "issn": "12",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Wavelet augmented cough analysis for rapid childhood pneumonia diagnosis",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kosasih",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Abeyratne",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Swarnkar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Triasih",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Trans Biomed Eng",
            "volume": "62",
            "issn": "4",
            "pages": "1185--94",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Automatic identification of wet and dry cough in pediatric patients with respiratory diseases",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Swarnkar",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Abeyratne",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "A"
                    ],
                    "last": "Amrulloh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Setyati",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Triasih",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Ann Biomed Eng",
            "volume": "41",
            "issn": "5",
            "pages": "1016--1044",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A framework for biomarkers of COVID-19 based on coordination of speechproduction subsystems",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Quatieri",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Talkar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Palmer",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Open J Eng Med Biol",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/OJEMB.2020.2998051"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Artificial intelligence and COVID-19: deep learning approaches for diagnosis and treatment",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "B"
                    ],
                    "last": "Jamshidi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lalbakhsh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Talla",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Peroutka",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Hadjilooei",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Lalbakhsh",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Modelling strong control measures for epidemic propagation with networks: a COVID-19 case study",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Small",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cavanagh",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.3001298"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Wearable sensing and telehealth technology with potential applications in the coronavirus pandemic",
            "authors": [
                {
                    "first": "X",
                    "middle": [
                        "R"
                    ],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Clifton",
                    "suffix": ""
                },
                {
                    "first": "Ji",
                    "middle": [
                        "N"
                    ],
                    "last": "Lovell",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "H"
                    ],
                    "last": "Bonato",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Rev Biomed Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "EasyBand: a wearable for safety-aware mobility during pandemic outbreak",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Tripathy",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Mohapatra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Mohanty",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kougianos",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Joshi",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Consum Electron Mag",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/MCE.2020.2992034"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "On the design of low-cost IoT sensor node for e-Health environments",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Petrellis",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Birbas",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Gioulekas",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/electronics8020178"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Using color signatures for the classification of skin disorders",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Petrellis",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Proceedings of the 7th International Conference on Modern Circuits and Systems Technologies",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF1": {
            "text": "Scientific App sound editor (a) and visualization of the sound spectrum (b).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Customization of the questionnaire in User App.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Sampling scenario for a diabetic patient.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Converting the sampling section of the MP file to instructions for the user.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "The sampling section of the MP file for the scenario of type 2 diabetes (a) and the example alert section (b).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Accuracy",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Petrellis: A COVID-19 Multipurpose Platform www.karger.com/dib",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors have no conflict of interests to declare.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of Interest Statement"
        },
        {
            "text": "No funding was received for this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Funding Sources"
        },
        {
            "text": "Nikos Petrellis: concept, development, experiments, and preparation of this paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Author Contributions"
        }
    ]
}