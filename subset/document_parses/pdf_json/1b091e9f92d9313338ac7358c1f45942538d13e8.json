{
    "paper_id": "1b091e9f92d9313338ac7358c1f45942538d13e8",
    "metadata": {
        "title": "Transfer Learning U-Net Deep Learning for Lung Ultrasound Segmentation",
        "authors": [
            {
                "first": "Dorothy",
                "middle": [],
                "last": "Cheng",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Imperial College London. Correspondence",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Edmund",
                "middle": [
                    "Y"
                ],
                "last": "Lam",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "The University of Hong",
                    "location": {
                        "settlement": "Kong"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Transfer learning (TL) for medical image segmentation helps deep learning models achieve more accurate performances when there are scarce medical images. This study focuses on completing segmentation of the ribs from lung ultrasound images (LUS) and finding the best TL technique with U-Net, a convolutional neural network (CNN) for precise and fast image segmentation. Two approaches of TL were used, using a pretrained VGG16 model to build the U-Net (V-Unet) and pre-training U-Net network with grayscale natural salient object dataset (X-Unet). Visual results and dice coefficients (DICE) of the models were compared. X-Unet showed more accurate and artifact-free visual performances on the actual mask prediction, despite its lower DICE than V-Unet. A partial-frozen network fine-tuning (FT) technique was also applied to X-Unet to compare results between different FT strategies, which FT all layers slightly outperformed freezing part of the network. The effect of dataset sizes was also evaluated, showing the importance of the combination between TL and data augmentation (DA).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The emerging development in computer vision technology using deep CNN for medical image segmentation has been considered a great contribution to medical care recently. Image segmentation is a process of dividing an input image into multiple sets of pixels with the same nature to extract the targeted area people are interested in, transforming the medical image into a meaningful subject for diagnostic processes. [1] [2] [3] In this paper, we aimed to complete segmentation for LUS using U-Net network structure and find out the best transfer learning technique.",
            "cite_spans": [
                {
                    "start": 415,
                    "end": 418,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 419,
                    "end": 422,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 423,
                    "end": 426,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Lung ultrasound has become an important non-invasive assessment tool especially from the 2019 novel coronavirus disease (COVID-19) for lung condition detection and diagnosis such as consolidations, pneumothorax, pleural effusion, etc. [4] The rib in LUS is our targeted region in this study, which is the pivotal landmark exhibiting pronounced acoustic features. The rib appears hyperechoic with acoustic shadows posterior to them. [23] This study also covers the basic implementation of homomorphic wavelet transform to remove speckle noise (SN) in raw LUS which causes resolution degradation.",
            "cite_spans": [
                {
                    "start": 235,
                    "end": 238,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 432,
                    "end": 436,
                    "text": "[23]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We chose U-Net as the network architecture framework. It has a CNN structure that is first designed and outperformed in medical image segmentation tasks. [6] It is an end-to-end, pixel-to-pixel fully convolutional network, allowing efficient whole-image-at-a-time learning and dense prediction for per-pixel semantic segmentation. [7] Figure 1 shows its encoder-decoder structure with a series of skip connections. The encoder down-samples and gradually reduces the spatial dimension through merging the layers for feature extraction, and the decoder restores the image details and spatial dimension through up-sampling, giving U-Net the power to seamlessly segment arbitrarily large images with an overlap-tile strategy. [8] Transfer learning is another noteworthy technique implemented in this study. It is based on implementing previously learnt knowledge to solve new similar problems in a more effective and efficient manner. TL allows the model to be trained on a smaller amount of data, making it particularly useful in medical image segmentation. [9] One common application of TL in classification and segmentation problems is the use of CNN models pre-trained on ImageNet, such as VGGNet, ResNet, AlexNet and Inception etc. [10] We took this idea and implemented it on U-Net. ImageNet contains 100,000 RGB natural images for solving a range of tasks. Recent research suggested the idea of pretraining U-Net with a grayscale salient object dataset which is more specific for segmentations in general. [13] [14] We combined the idea of TL into U-Net with two approaches mentioned above in our LUS segmentation and evaluated their performances.",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 157,
                    "text": "[6]",
                    "ref_id": null
                },
                {
                    "start": 331,
                    "end": 334,
                    "text": "[7]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 722,
                    "end": 725,
                    "text": "[8]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1055,
                    "end": 1058,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1233,
                    "end": 1237,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1509,
                    "end": 1513,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1514,
                    "end": 1518,
                    "text": "[14]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 335,
                    "end": 343,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "U-Net has been widely used in medical image segmentation nowadays, which was first developed in 2015 for microscopy image segmentation of cells, aiming for fast and precise segmentation using a scarce amount of training images. [6] In 2020, U-Net-related papers covered a variety of medical image modalities, with magnetic resonance imaging (MRI) and computed tomography (CT) being the most common forms, and the brain and pathology being the most common application areas. [15] [16] U-Net also varies in different forms, such as applying 3D convolutional (conv) layers and inception modules to accommodate specific image modalities and applications. [3, 12, 15, [17] [18] Our 2D LUS require only 2D U-Net, with our research focusing mainly on TL techniques. Therefore, the basic 2D U-Net was used. There were a few research implementing basic U-Net particularly on US segmentation, such as article [19] for segmenting the fetal lung and heart and the Ultrasound Nerve Segmentation Kaggle Challenge in 2016. [20] It provided the dataset and U-Net coding examples of segmenting the Brachial Plexus, a collection of nerves, in US images.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 231,
                    "text": "[6]",
                    "ref_id": null
                },
                {
                    "start": 474,
                    "end": 478,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 479,
                    "end": 483,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 651,
                    "end": 654,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 655,
                    "end": 658,
                    "text": "12,",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 659,
                    "end": 662,
                    "text": "15,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 663,
                    "end": 667,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 668,
                    "end": 672,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 899,
                    "end": 903,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1008,
                    "end": 1012,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "U-Net for Medical Image Segmentation"
        },
        {
            "text": "The above research only focuses on the structural variants of U-Net. To optimize the model performance on a limited number of medical images, TL helps address the issue. TL is categorized into cross-domain and crossmodal, depending on the domains of the target and source data. Cross-domain TL was used in this study, which is a popular approach to pre-train the model in large non-US datasets such as ImageNet. It is efficient to learn about detections of edges, shapes, and textures from natural images, then modify and fine-tune the model with US images. [10] Using pre-trained models for TL is a common practice. According to the overview research on TL in breast ultrasound imaging (BUS) for breast cancer diagnosis, the most two common pre-trained models used on BUS were VGGNet followed by AlexNet, especially in classification problems. [10, 21] VGGNet (VGG16 and VGG19) outperformed the latter by superseding large kernel-sized filters with various small kernel-sized filers. VGG16 was chosen as our U-Net encoder due to its fewer conv layers between max-pooling layers, which matches better with the original U-Net structure. This idea was applied to US and MRI images before [11, 22] , in which article [22] is a similar work to our study. It used VGG16 as the encoder of U-Net for intravascular ultrasound (IVUS) segmentation of the lumen and media. It compared three training model approaches, simple U-Net, VGG16-UNet without DA, and VGG16-UNet with DA. Its DICE and visual performances are shown in Figure 8 , showing the significant improvements from using VGG16 for TL.",
            "cite_spans": [
                {
                    "start": 558,
                    "end": 562,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 845,
                    "end": 849,
                    "text": "[10,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 850,
                    "end": 853,
                    "text": "21]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1186,
                    "end": 1190,
                    "text": "[11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1191,
                    "end": 1194,
                    "text": "22]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1214,
                    "end": 1218,
                    "text": "[22]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 1514,
                    "end": 1522,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Transfer Learning Techniques"
        },
        {
            "text": "Besides the above TL method, recent research on U-Net US segmentation demonstrated the idea of implementing TL by pre-training the U-Net model ourselves. [13] It pre-trained the U-Net with a large image dataset of grayscale natural salient objects to better mimic US images, further on FT the model with simulated US (SUS), BUS, Fetal head US (FUS), and chest X-ray with different layer-freezing approaches and dataset sizes. Results showed that the best two FT strategies were training the whole network and whole network except the bottleneck block (BB) at the bottom. The best DICEs varied from 0.785 in BUS and 0.834 in SUS, also shown in Figure 8 , to 0.972 in FUS and 0.98 in chest X-ray. A similar approach was implemented to our LUS segmentation, with tests on different dataset sizes and FT strategies.",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 158,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 643,
                    "end": 651,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Transfer Learning Techniques"
        },
        {
            "text": "We adopted the basic U-Net architecture framework similar to the one from the original article [6] . TL with FT strategies was applied in two training models, the V-Unet and the X-Unet.",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 98,
                    "text": "[6]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Network Architecture"
        },
        {
            "text": "In V-Unet, as shown in Figure 2 , VGG16 was chosen to replace the contracting path of U-Net as a hybrid between these structures, due to its similarity to U-Net's contracting path with a smaller number of parameters. [23] Also, the VGG16 already has weights pre-trained by ImageNet that can be easily accessed and applied to our model, which shortens the training time. [6, 24] To resemble the VGG16 into a symmetrical U-Net structure, the last three fully connected layers were excluded and new layers for the expanding path were added. The expanding path worked reversely to the VGG16, with up-sampling through deconvolution by transposed conv layers. Concatenated skip connections were used to connect blocks of the same filter size from the contracting path to expanding path to reuse the features and retain more information from previous layers. A 1\u00d71 conv layer with sigmoid activation was used as the last layer to map the feature vector from 0 to 1. Due to the binary nature of the feature masks, a threshold value of 0.5 was used to convert all pixels with values above 0.5 to 1, and pixels with values below 0.5 to 0. The whole network had 28,804,545 parameters in total. ",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 221,
                    "text": "[23]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 370,
                    "end": 373,
                    "text": "[6,",
                    "ref_id": null
                },
                {
                    "start": 374,
                    "end": 377,
                    "text": "24]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 23,
                    "end": 31,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "(V-Unet) U-Net with VGG16 as the encoder and further trained on LUS"
        },
        {
            "text": "In X-Unet, as shown in Figure 3 , we took the idea of pre-training our own U-Net with grayscale salient object images instead of the publicly available pre-trained models. The network consisted of two 3\u00d73 conv layers followed by ReLU activation in each block. In the contracting path, the number of filters in each block was increased by a factor of 2, starting from 64 filters in the first block to 1024 filters in the fifth block, with 2\u00d72 pixel-window max-pooling layers between blocks. The expanding path, concatenation, and the last 1\u00d71 conv layer were the same as V-Unet's. The whole network had 31,031,745 parameters in total. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 23,
                    "end": 31,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "(X-Unet) U-Net pre-trained on salient object dataset and fine-tuned on LUS"
        },
        {
            "text": "The difference in network architectures of the two approaches required slightly different TL processes. For V-Unet, the contracting path (VGG16) was frozen in TL, to avoid modifying the ImageNet-pre-trained weights and destroying them in pre-training, as well as to decrease the computation time. [25] LUS were fed into the model for TL. For X-Unet, since no weights were pre-trained before, all layers were not frozen in TL. XPIE dataset was used to pre-train the model. [26] Upon TL, two models were fine-tuned separately using LUS. We first fine-tuned the whole network, with all layers being trainable (unfrozen), in both V-Unet and X-Unet. An additional FT scheme, training the whole network except the bottleneck block, was implemented on X-Unet and compared its performance to other training models. The BB contains 14,157,824 parameters, which is about half of the parameters of the whole network. Freezing this block has already frozen nearly half of the network, aiming to reduce the training time and maintain accuracy at the same time.",
            "cite_spans": [
                {
                    "start": 297,
                    "end": 301,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 472,
                    "end": 476,
                    "text": "[26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Design"
        },
        {
            "text": "For all the FT processes, five-fold cross-validation was used to assess model performances and provide a range of evaluation scores across different shuffles. 80% of the dataset was used for training, with the remaining 20% for validation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Design"
        },
        {
            "text": "To also investigate the effects of dataset sizes on the models, experiments on the two U-Net structures with different dataset sizes (200 and 600) were performed. It was aimed to find out the optimal dataset size that can enhance model performance under a relatively small dataset condition since medical images are in general very scarce in availability.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Design"
        },
        {
            "text": "Our LUS dataset consists of raw B-mode images collected from a healthy volunteer (a 26-year-old male). A Verasonics Vantage 256 system was used with a linear array probe operating at 5.2 MHz. Raw LUS were obtained with 960\u00d7128 in size stored in MAT format. 200 frames were randomly selected for building our LUS dataset and were annotated manually on MATLAB. Raw US images exhibit speckle noise due to the interference between coherent constructive and destructive energies of scattered echoes, resulting in resolution degradation and making the information extraction process complicated. At the pre-processing stage, homomorphic wavelet transform was applied to LUS for SN reduction. As SN in US images is a type of multiplicative noise, applying logarithmic transform using the following equality can convert SN into addictive noise and be removed by wavelet transform. [27] [28] [29] ( , ) = ( , ) + ! ( , )",
            "cite_spans": [
                {
                    "start": 873,
                    "end": 877,
                    "text": "[27]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 878,
                    "end": 882,
                    "text": "[28]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 883,
                    "end": 887,
                    "text": "[29]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "LUS Pre-processing"
        },
        {
            "text": "In which ( , ) represents the real noisy image, ( , ) represents the unknown noise-free image and ! ( , ) represents the multiplicative noise function. Denoised images were converted into TIFF format. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "LUS Pre-processing"
        },
        {
            "text": "DA techniques were implemented to create more data samples from our small LUS dataset and improve network performance. The dataset size was first doubled to 400 images by saving a copy of their horizontally flipped version. Real-time batch-wise DA was then implemented during the training process to ensure the model receives new variations at each epoch. [30] Variations include small-degree random deformation like rotation, width and height shift, shearing, zooming and horizontal flipping. [31] All LUS were resized to 256\u00d7256 pixels and normalized to between 0 and 1 to allow faster convergence during training.",
            "cite_spans": [
                {
                    "start": 356,
                    "end": 360,
                    "text": "[30]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 494,
                    "end": 498,
                    "text": "[31]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Data Augmentation"
        },
        {
            "text": "XPIE dataset was used to pre-train the X-Unet for TL purposes. It contains 10,000 segmented natural images originally for salient object detection. [26] The images were originally in RGB structure and 375\u00d7500 pixels in size. Article [32] suggested that pre-training on grayscale natural images better mimics the grayscale structure of our single-channeled LUS, leading to higher training accuracy and speed of inference. XPIE images were all converted into grayscale and resized into 256\u00d7256 pixels. Same DA strategies were performed in pre-training.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 152,
                    "text": "[26]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 233,
                    "end": 237,
                    "text": "[32]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "XPIE dataset"
        },
        {
            "text": "The Dice coefficient was chosen as the evaluation metrics. It is a spatial overlap index ranging from 0 to 1, indicating from no spatial overlap to complete overlap between the binary predicted mask and the ground truth. [33] It is a statistical tool that can represent the similarity between two sets of data clearly. [34] The equation is as follows:",
            "cite_spans": [
                {
                    "start": 221,
                    "end": 225,
                    "text": "[33]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 319,
                    "end": 323,
                    "text": "[34]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Performance Metrics"
        },
        {
            "text": "In which is the input image, is the actual ground truth and ( ) is the prediction output from the model. is a small number added to avoid division by zero. [35] ",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 160,
                    "text": "[35]",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "Performance Metrics"
        },
        {
            "text": "All experimental models were trained with GPU implementations. NVIDIA Tesla T4 provided by Google Colaboratory and NVIDIA GeForce GTX 1080 Ti were used to accelerate the forward propagation and backpropagation routines. [36] [37] All the proposed models were implemented with TensorFlow v2.6.0, with the use of Keras library. [38] Both TL and FT were performed using the Adaptive Moment Estimation (ADAM) optimizer. Different learning rates (LR) were tested initially and an LR of 10 -5 in TL and 5 -6 in FT were used in our experiments that gave the following results. Using a smaller LR for FT allows smaller changes made to the weights in each update for detailing the training. Table 1 shows all the DICEs from both V-Unet and X-Unet with different training conditions and strategies. For TL in both models, five-fold cross-validation was not implemented so only one (highest) DICE was shown, while the highest and average DICE were shown for the FT models.",
            "cite_spans": [
                {
                    "start": 220,
                    "end": 224,
                    "text": "[36]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 225,
                    "end": 229,
                    "text": "[37]",
                    "ref_id": null
                },
                {
                    "start": 326,
                    "end": 330,
                    "text": "[38]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [
                {
                    "start": 682,
                    "end": 689,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Results"
        },
        {
            "text": "By comparing the DICEs, V-Unet has the highest of 0.8632, which is 0.034 and 0.053 higher than X-Unet FT with all layers (0.8297) and FT with BB frozen (0.8107) respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparing V-Unet and X-Unet trained with 400 LUS"
        },
        {
            "text": "However, the visual results are surprisingly different from their DICE performances. Figure 5 shows the comparison of five visual examples between the original mask and four of our models with different training conditions. All the models were able to predict the general shape and location of the rib from LUS accurately. However, both V-Unet TL and FT models were obviously susceptible to artifacts and outliers, despite there were significant improvements in outlier elimination and refinement after FT. Predictions from V-Unet particularly had rough edges and sharp corners (figures 5d-e) that didn't exist in the ground truth. On the contrary, even though both X-Unet models had significantly lower DICEs, their predictions had an overall better performance in shaping and edge smoothing, as well as greater resistance to outliers than V-Unet.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 85,
                    "end": 93,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Comparing V-Unet and X-Unet trained with 400 LUS"
        },
        {
            "text": "To compare the two different FT techniques in X-Unet, although FT with all layers performed slightly better in both DICE and visual results than FT with BB frozen, the visual differences were insignificant. However, FT with BB frozen did not eventually cause a huge reduction in training time. FT with all layers would be a preferred strategy in this investigation. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparing V-Unet and X-Unet trained with 400 LUS"
        },
        {
            "text": "Firstly, in the V-Unet, we trained with the same strategy with 200 LUS (without the horizontally flipped copies) and compared its FT model with the performance of that trained with 400 LUS. Results in Table 1 show that training with 200 LUS had a DICE 0.082 lower than that trained with doubled LUS, which is also consistent with the visual results in Figure 6 . To justify whether a larger dataset size can significantly improve the model accuracy, extra 100 random frames of LUS with their horizontally flipped copies were added to the dataset to create a total of 600 images for FT all layers in X-Unet. The DICE and visualized results are also shown in Table 1 and Figure 7 . It shows that there is less than 0.01 increase in DICE when the dataset is 1.5 times larger. Both models produced similar masks except for (7c) and (7e) which there was a slight improvement in the length at the right end. All in all, increasing the dataset size indeed gives a higher DICE but the visual improvements are insignificant in this case. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 201,
                    "end": 208,
                    "text": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 352,
                    "end": 360,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 657,
                    "end": 664,
                    "text": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 669,
                    "end": 677,
                    "text": "Figure 7",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Comparing V-Unet and X-Unet trained with different dataset sizes"
        },
        {
            "text": "Both V-Unet and X-Unet exhibited the importance of TL and FT by having significant improvements in DICEs after FT which can also be visualized from TL and FT model prediction comparison of V-Unet. However, V-Unet models are generally very vulnerable to artifacts and outliers that cannot be reflected from its high DICE. It may be due to the fact that an LR of 10 -5 for TL is too large in V-Unet, causing the model to converge too quickly without fully learning and adapting to the edge details of LUS. Future investigation can implement adaptive LR through callbacks during training, which the model can monitor and reduce LR when DICE has stopped improving for a certain amount of epoch, aiming to fine-tune better on model weights and obtain a fit learning schedule. [39] [40] The approach suggested in [13] to pre-train the model with the grayscale XPIE dataset was also demonstrated.",
            "cite_spans": [
                {
                    "start": 771,
                    "end": 775,
                    "text": "[39]",
                    "ref_id": null
                },
                {
                    "start": 776,
                    "end": 780,
                    "text": "[40]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 807,
                    "end": 811,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Predictions from X-Unet were the closest to the ground truth among all models, despite its lower DICE to V-Unet. The XPIE dataset targets salient objects, which have more attentive edges and regions. Despite the resource-and time-consuming pre-training procedure, X-Unet models perform surprisingly better in edge smoothing, region shaping, and resisting artifacts and outliers especially at the two ends of the segmented rib.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Regarding the additional FT technique of freezing the BB in X-Unet, although the DICE wasn't as high as expected without a reduction in training time, the visual outcome was still comparable and considered successful. The reason behind the reduced DICE is because there is still a huge dissimilarity between the XPIE dataset and LUS. Freezing the deeper layers like the BB would make the network not specific enough in extracting special features in LUS, hence lowering the training accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "DICE, our evaluation metric, was achieved on a satisfactory level numerically greater than 0.8. However, it cannot achieve greater than 0.9 due to the fluctuation in the ability to resist outliers and artifacts, as shown from our model predictions. It may be due to the subjectivity and inconsistency from the manual annotation of the ground truth from a non-medical professional. There is subjective boundary uncertainty due to individual skills and image qualities. [41] Further investigation on this should consult medical professionals for annotation.",
            "cite_spans": [
                {
                    "start": 468,
                    "end": 472,
                    "text": "[41]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "To evaluate whether DICE is a suitable evaluation metric, there was consistency on visual results within V-Unet or X-Unet model itself. The increase in DICE from TL to FT within the same model matches with the improved visual accuracy, which may not always be the case. Figure 8 shows the visual results and DICEs from articles [22] and [13] that have model structures similar to our V-Unet and X-Unet respectively. For media segmentation indicated by the red box, DICE achieved 0.9771 while the mask was obviously smaller than the ground truth, which was a worse prediction than that with DICE of 0.9257. We were able to produce consistently improving predictions with increasing DICEs within the model itself.",
            "cite_spans": [
                {
                    "start": 328,
                    "end": 332,
                    "text": "[22]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 337,
                    "end": 341,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 270,
                    "end": 278,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "However, DICE is not a suitable indicator to directly compare performances between different models. As shown in section 4, DICEs of V-Unet FT model were considerably higher than that of X-Unet, while visual results from X-Unet significantly outperformed the former in terms of accuracy, shapes and edges. This inconsistency between models is also demonstrated in Figure 8 , where both lumen segmentation from [22] and SUS segmentation from [13] produced visual predictions very close to their ground truths, while they have a difference of 0. 13 [22] , SUS and BUS segmentation from [13] In terms of the effects of dataset sizes, there is a huge deterioration in results with 200 LUS on V-Unet model. This shows the strong need of DA for such a scarce number of images. Additionally, we expanded the dataset to 1.5 times larger particularly for testing whether it would give a significant improvement. X-Unet model just showed a slight increase of accuracy in both visual results and DICE. It is consistent with the fact that a larger dataset leads to better model performance from creating larger variance, but the level of improvement is not proportional. To aim at better results, further investigation on network structures or parameters is emphasized to compromise with the limited amount of data available.",
            "cite_spans": [
                {
                    "start": 410,
                    "end": 414,
                    "text": "[22]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 441,
                    "end": 445,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 544,
                    "end": 546,
                    "text": "13",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 547,
                    "end": 551,
                    "text": "[22]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 584,
                    "end": 588,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 364,
                    "end": 372,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "There are also other suggested improvements that could be done in the future, such as exploring other freezing techniques in the FT process. In this study, the main FT strategy used is training the whole network without freezing any layer. It is one of the easiest strategies to yield optimal results, but it is time-consuming for all the parameters to be updated. More of the FT strategies such as those suggested in [13] could be tried out in the future.",
            "cite_spans": [
                {
                    "start": 418,
                    "end": 422,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "It is also noteworthy to investigate on network regularization. Our network structures were based on the architecture suggested in [6] without regularization layers. One of the potential drawbacks of our models is that they may be over-fitting to US images only. Regarding this, batch normalization (BN) layers were implemented after conv layers into our V-Unet during the experimental period as a trial. However, training did not converge and the model failed to make predictions. It was because our batch size used (20) was small and our LUS were all similar without large fluctuation. They weren't in a need of normalization within batches and adding BN might, in turn, give a noisy approximation. [42] Further investigation on implementing other regularizations in the network for improving the model performance and preventing over-fitting is suggested.",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 134,
                    "text": "[6]",
                    "ref_id": null
                },
                {
                    "start": 517,
                    "end": 521,
                    "text": "(20)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 701,
                    "end": 705,
                    "text": "[42]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "This study presented the V-Unet and the X-Unet with the implementation of TL into U-Net for completing the LUS segmentation of ribs. V-Unet used VGG16 as the encoder of the U-Net, while X-Unet was pre-trained with grayscale natural salient object images. Although V-Unet achieved higher DICE than X-Unet, X-Unet outperformed the V-Unet in visual predictions with a significant refinement in shaping and edge smoothing. The evaluation must be done with both DICE and visual interpretations since direct comparison of DICE between different models is unreliable. We also performed a brief investigation on using different FT strategies and dataset sizes on model predictions. It is suggested that future investigation on monitoring the LR, modifying the network structure details and FT techniques are essential to achieve more accurate predictions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "We acknowledge Dr. Wei-Ning Lee and Xiao Fei Sun from the Department of Electrical and Electronic Engineering, The University of Hong Kong, for providing the lung ultrasound images and guidance on ultrasound image interpretations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgement"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Image Segmentation Algorithms Overview",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yuheng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Classification of Myocardial Ischemia in Delayed Contrast Enhancement Using Machine Learning. Intelligent Data Analysis for Biomedical Applications",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Merjulah",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chandra",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "209--244",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "A deep learning-based algorithm for 2-D cell segmentation in microscopy images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Al-Kofahi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zaltsman",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Graves",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Marshall",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rusu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "BMC Bioinformatics",
            "volume": "19",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Lung ultrasound: an additional tool in COVID-19. Radiologia Brasileira",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Oliveira Rr De",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "P"
                    ],
                    "last": "Rodrigues",
                    "suffix": ""
                },
                {
                    "first": "Psd",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Da",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Gomes",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Chammas",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "53",
            "issn": "",
            "pages": "241--51",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Fully Convolutional Networks for Semantic Segmentation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Shelhamer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Darrell",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A review of the application of deep learning in medical image classification and segmentation",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Annals of Translational Medicine",
            "volume": "8",
            "issn": "11",
            "pages": "713--716",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A Gentle Introduction To Transfer Learning | High On Techs",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Patle",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Transfer Learning in Breast Cancer Diagnoses via Ultrasound Imaging. Cancers",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ayana",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Dese",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Choe",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "13",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "PDF) UNet-VGG16 with transfer learning for MRI-based brain tumor segmentation",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Pravitasari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Iriawan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Almuhayar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Azmi",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Irhamah",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Fithriasari",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "KUnet: Microscopy Image Segmentation With Deep Unet Based Convolutional Networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "W"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "W"
                    ],
                    "last": "Liao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Fine-Tuning U-Net for Ultrasound Image Segmentation: Different Layers, Different Outcomes",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Amiri",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Brooks",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rivaz",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "U-Net and Its Variants for Medical Image Segmentation: A Review of Theory and Applications",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Siddique",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Paheding",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "P"
                    ],
                    "last": "Elkin",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Devabhaktuni",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "82031--57",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep Learning for Cardiac Image Segmentation: A Review. Frontiers in Cardiovascular Medicine",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Tarroni",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "7",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Modified U-Net block network for lung nodule detection",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Xplore",
            "volume": "",
            "issn": "",
            "pages": "599--605",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Neural Architecture Search for Medical Image Segmentation",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Weng",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nas-Unet",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "44247--57",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Ultrasonographic Segmentation of Fetal Lung with Deep Learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Journal of Biosciences and Medicines",
            "volume": "9",
            "issn": "1",
            "pages": "146--53",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Ultrasound Nerve Segmentation",
            "authors": [],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Breast Cancer Classification in Ultrasound Images using Transfer Learning",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hijab",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Rushdi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Gomaa",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Eldeib",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Automatic detection of lumen and media in the IVUS images using U-Net with VGG16 Encoder",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Balakrishna",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dadashzadeh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Soltaninejad",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Internet]",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "An overview of VGG16 and NiN models",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Keras documentation: Transfer learning & fine-tuning",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Team",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "What is and What is not a Salient Object? Learning Salient Object Detector by Ensembling Linear Exemplar Regressors",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Speckle Noise Reduction in Ultrasound Images for Improving the Metrological Evaluation of Biomedical Applications: An Overview. IEEE Access",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Duarte-Salazar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Castro-Ospina",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Becerra",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Delgado-Trejos",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "15983--99",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Despeckling Algorithm for Removing Speckle Noise from Ultrasound Images. Symmetry",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jeong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "12",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Speckle Noise Reduction in Ultrasound Images [Internet]. uk.mathworks.com",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Meshram",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Keras ImageDataGenerator for Image Augmentation | Python Use Case",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bhandari",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Keras documentation: Image data preprocessing [Internet]. keras.io",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Team",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Pre-training on Grayscale ImageNet Improves Medical Image Classification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Richmond",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Internet]",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Statistical Validation of Image Segmentation Quality Based on a Spatial Overlap Index. Academic radiology",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Zou",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Warfield",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bharatha",
                    "suffix": ""
                },
                {
                    "first": "Cmc",
                    "middle": [],
                    "last": "Tempany",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Kaus",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Haker",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "11",
            "issn": "",
            "pages": "178--89",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Dice similarity coefficient | Radiology Reference Article | Radiopaedia.org",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "M"
                    ],
                    "last": "Moore",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "AI for Medical Diagnosis",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Uyumazturk",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kiani",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Shyu",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Python Environment Setup for Deep Learning on Windows 10",
            "authors": [
                {
                    "first": "Tamim",
                    "middle": [],
                    "last": "Mirza",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Internet]. Medium. Towards Data Science",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Home -Keras Documentation",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Keras",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Understand the Impact of Learning Rate on Neural Network Performance",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Keras",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Io",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Machine Learning Mastery",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Keras documentation: ReduceLROnPlateau [Internet]. keras.io",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Team",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Comparison of metrics for the evaluation of medical segmentations using prostate MRI dataset",
            "authors": [
                {
                    "first": "Y-H",
                    "middle": [],
                    "last": "Nai",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "W"
                    ],
                    "last": "Teo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "L"
                    ],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "O&apos;doherty",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Stephenson",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "L"
                    ],
                    "last": "Thian",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Computers in Biology and Medicine",
            "volume": "134",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Batch Normalization -Why It's Important And Why It Is Not?",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Original U-Net structure for biomedical image segmentation",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The architecture of V-Unet model",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The architecture of X-Unet model",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Example of an LUS, binary mask, and the overlapping view",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Comparison of five examples (a-e) from the LUS data between the original mask, predicted masks from V-Unet TL, V-Unet FT, X-Unet FT (All layers), and X-Unet FT (BBFrozen). All of them were trained with 400 LUS. Yellow boxes indicate the defects from V-Unet. Green boxes indicate the defects from X-Unet.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The one trained with 400 LUS showed much fewer artifacts than that with 200 LUS especially on the two ends of the rib. Training with 200 LUS made the results prone to outliers. Comparison of 5 examples (a-e) from the LUS data between the original mask, predicted masks from V-Unet TL model trained with 400 LUS and 200 LUS. Yellow boxes indicate the defects of V-Unet (400). Orange boxes indicate the defects of V-Unet (200).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Comparison of 5 examples (a-e) from the LUS data between the original mask, predicted masks from X-Unet FT model trained with 400 LUS and 600 LUS. Green boxes indicate the defects of X-Unet (400).",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "DICEs of all the V-Unet and X-Unet models with different training conditions and dataset sizes. X-Unet TL was trained with natural images without LUS, which cannot be used directly to predict actual LUS.DICE is listed as a reference without direct comparing value.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "in DICE. DICE cannot be used alone as an evaluation indicator for different model comparisons without the interpretation of visual results. Other metrics can also be explored in the future as an extra reference to model evaluation.Figure 8: Visual results and DICEs of IVUS segmentation from",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}