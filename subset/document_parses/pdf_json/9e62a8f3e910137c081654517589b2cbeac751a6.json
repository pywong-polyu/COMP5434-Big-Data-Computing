{
    "paper_id": "9e62a8f3e910137c081654517589b2cbeac751a6",
    "metadata": {
        "title": "COVID-19 Classification of X-ray Images Using Deep Neural Networks",
        "authors": [
            {
                "first": "Elisha",
                "middle": [],
                "last": "Goldstein",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Weizmann Institute of Science",
                    "location": {
                        "settlement": "Rehovot",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Daphna",
                "middle": [],
                "last": "Keidar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "ETH Z\u00fcrich",
                    "location": {
                        "addrLine": "D-infk",
                        "postCode": "101, 8092",
                        "settlement": "R\u00e4mistrasse, Z\u00fcrich"
                    }
                },
                "email": ""
            },
            {
                "first": "Daniel",
                "middle": [],
                "last": "Yaron",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Weizmann Institute of Science",
                    "location": {
                        "settlement": "Rehovot",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Yair",
                "middle": [],
                "last": "Shachar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Eyeway Vision Ltd",
                    "location": {
                        "addrLine": "Yoni Netanyahu St 3",
                        "settlement": "Or Yehuda"
                    }
                },
                "email": ""
            },
            {
                "first": "Ayelet",
                "middle": [],
                "last": "Blass",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Leonid",
                "middle": [],
                "last": "Charbinsky",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Israel",
                "middle": [],
                "last": "Aharony",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Liza",
                "middle": [],
                "last": "Lifshitz",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Dimitri",
                "middle": [],
                "last": "Lumelsky",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Ziv",
                "middle": [],
                "last": "Neeman",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Matti",
                "middle": [],
                "last": "Mizrachi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bar-Ilan University",
                    "location": {
                        "settlement": "Nahariya, Safed",
                        "country": "Israel, Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Majd",
                "middle": [],
                "last": "Hajouj",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bar-Ilan University",
                    "location": {
                        "settlement": "Nahariya, Safed",
                        "country": "Israel, Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Nethanel",
                "middle": [],
                "last": "Eizenbach",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Sela",
                "middle": [],
                "last": "Md",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bar-Ilan University",
                    "location": {
                        "settlement": "Nahariya, Safed",
                        "country": "Israel, Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Chedva",
                "middle": [
                    "S"
                ],
                "last": "Weiss",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bar-Ilan University",
                    "location": {
                        "settlement": "Nahariya, Safed",
                        "country": "Israel, Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Philip",
                "middle": [],
                "last": "Levin",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Cardiothoracic Imaging Unit",
                    "institution": "Shaare Zedek Medical Center",
                    "location": {
                        "settlement": "Jerusalem",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Ofer",
                "middle": [],
                "last": "Benjaminov",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Cardiothoracic Imaging Unit",
                    "institution": "Shaare Zedek Medical Center",
                    "location": {
                        "settlement": "Jerusalem",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Gil",
                "middle": [
                    "N"
                ],
                "last": "Bachar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sakler School of Medicin",
                    "location": {
                        "addrLine": "Jabotinsky Rd 39",
                        "settlement": "Petah Tikva"
                    }
                },
                "email": ""
            },
            {
                "first": "Shlomit",
                "middle": [],
                "last": "Tamir",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sakler School of Medicin",
                    "location": {
                        "addrLine": "Jabotinsky Rd 39",
                        "settlement": "Petah Tikva"
                    }
                },
                "email": ""
            },
            {
                "first": "Yael",
                "middle": [],
                "last": "Rapson",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sakler School of Medicin",
                    "location": {
                        "addrLine": "Jabotinsky Rd 39",
                        "settlement": "Petah Tikva"
                    }
                },
                "email": ""
            },
            {
                "first": "Dror",
                "middle": [],
                "last": "Suhami",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sakler School of Medicin",
                    "location": {
                        "addrLine": "Jabotinsky Rd 39",
                        "settlement": "Petah Tikva"
                    }
                },
                "email": ""
            },
            {
                "first": "Amiel",
                "middle": [
                    "A"
                ],
                "last": "Dror",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Bar-Ilan University",
                    "location": {
                        "settlement": "Nahariya, Safed",
                        "country": "Israel, Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Naama",
                "middle": [
                    "R"
                ],
                "last": "Bogot",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Cardiothoracic Imaging Unit",
                    "institution": "Shaare Zedek Medical Center",
                    "location": {
                        "settlement": "Jerusalem",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Ahuva",
                "middle": [],
                "last": "Grubstein",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sakler School of Medicin",
                    "location": {
                        "addrLine": "Jabotinsky Rd 39",
                        "settlement": "Petah Tikva"
                    }
                },
                "email": ""
            },
            {
                "first": "Nogah",
                "middle": [],
                "last": "Shabshin",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "HaEmek Medical Center",
                    "location": {
                        "settlement": "Afula",
                        "country": "Israel"
                    }
                },
                "email": ""
            },
            {
                "first": "Yishai",
                "middle": [
                    "M"
                ],
                "last": "Elyada",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Mobileye Vision Technologies, Ltd",
                    "location": {
                        "settlement": "Hartom 13, Jerusalem"
                    }
                },
                "email": ""
            },
            {
                "first": "Yonina",
                "middle": [
                    "C"
                ],
                "last": "Eldar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Weizmann Institute of Science",
                    "location": {
                        "settlement": "Rehovot",
                        "country": "Israel"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "medRxiv preprint ROC -receiver operating characteristic P-R curve -precision-recall curve AUC -area under the curve GT -ground truth FPR -false positive rate TPR -true positive rate Abstract Background In the midst of the coronavirus disease 2019 (COVID-19) outbreak, chest X-ray (CXR) imaging is playing an important role in the diagnosis and monitoring of patients with COVID-19. Machine learning solutions have been shown to be useful for X-ray analysis and classification in a range of medical contexts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The purpose of this study is to create and evaluate a machine learning model for diagnosis of COVID-19, and to provide a tool for searching for similar patients according to their X-ray scans. in four hospitals in Israel. A nearest-neighbors algorithm was implemented based on the network results that identifies the images most similar to a given image. The model was evaluated using accuracy, sensitivity, area under the curve (AUC) of receiver operating characteristic (ROC) curve and of the precision-recall (P-R) curve.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The dataset sourced for this study includes 2362 CXRs, balanced for positive and negative COVID-19, from 1384 patients (63 +/-18 years, 552 men). Our model achieved 89.7% (314/350) accuracy and 87.1% (156/179) sensitivity in classification of COVID-19 on a test dataset comprising 15% (350 of 2326) of the original data, with AUC of ROC 0.95 and AUC of the P-R curve 0.94. For each image we retrieve images with the most similar DNN-based image embeddings; these can be used to compare with previous cases. A machine learning model was able to detect chest X-ray (CXR) images of patients tested positive for coronavirus disease 2019 with accuracy of 89.7%, sensitivity of 87.1%",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "and area under receiver operating characteristic curve of 0.95.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "A tool was created for finding existing CXR images with imaging characteristics most similar to a given CXR, according to the model's image embeddings.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The Coronavirus Disease 2019 (COVID-19) pandemic, caused by the SARS-CoV-2 virus, poses tremendous challenges to healthcare systems around the world, and requires physicians to make clinical decisions with limited prior knowledge. Medical decisions are based also on imaging, and can be supported by a method for automatically retrieving prior patients that had similar imaging findings. Moreover, an ongoing concern is to rapidly identify and isolate SARS-CoV-2 carriers in order to contain the disease.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Reaction (RT-PCR) (1, 2) . However, a recent study suggests that RT-PCR tests result in up to 30% false negatives, depending on the respiratory specimens (3), possibly from non-specific amplification and sample contamination. Taken together, the prominent undetected fraction of active patients inevitably leads to uncontrolled viral dissemination, masking hidden essential epidemiological data (4) (5) (6) . Additionally, RT-PCR testing kits are expensive and processing them requires dedicated personnel and can take days. Characteristics of COVID-19 such as . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 18,
                    "end": 21,
                    "text": "(1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 22,
                    "end": 24,
                    "text": "2)",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 395,
                    "end": 398,
                    "text": "(4)",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 399,
                    "end": 402,
                    "text": "(5)",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 403,
                    "end": 406,
                    "text": "(6)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "The prevalent test used for COVID-19 identification is Reverse Transcription Polymerase Chain"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020. 10 .01.20204073 doi: medRxiv preprint consolidations and ground-glass opacities can be identified in both CXRs and CT scans (5, 7, 8) .",
            "cite_spans": [
                {
                    "start": 108,
                    "end": 110,
                    "text": "10",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 232,
                    "end": 235,
                    "text": "(5,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 236,
                    "end": 238,
                    "text": "7,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 239,
                    "end": 241,
                    "text": "8)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Both are often used to support RT-PCR diagnosis, and are strong candidates for alternative means of COVID-19 testing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Portable X-ray machines play a central role in COVID-19 handling (9) , and most available CXRs of patients with COVID-19 in Israel come from portable X-rays. While COVID-19 is easier to detect in CT (10) , CT is more expensive, exposes the patient to higher radiation, and its decontamination process is lengthy and causes severe delays between patients.",
            "cite_spans": [
                {
                    "start": 65,
                    "end": 68,
                    "text": "(9)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 199,
                    "end": 203,
                    "text": "(10)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Deep learning models have shown impressive abilities in image related tasks, including in many radiological contexts (11, 12) . They have great potential in assisting COVID-19 management efforts, but require large amounts of training data. When training neural networks for image classification, images from different classes should only differ in the task specific characteristics;",
            "cite_spans": [
                {
                    "start": 117,
                    "end": 121,
                    "text": "(11,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 122,
                    "end": 125,
                    "text": "12)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "it is important, therefore, that all images are taken from the same machines. Otherwise, the network could learn the differences, e.g., between machines associated with different classes rather than identifying physiological and anatomical COVID-19 characteristics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "This study aims to provide machine learning tools for COVID-19 identification and management.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "A large dataset of images from portable X-rays was sourced and used to train a network that can detect COVID-19 in the images with high reliability and to develop a tool for retrieving CXR images that are similar to each other. The network affords a detection accuracy of 89.7% and sensitivity of 87.1%.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "This retrospective study was approved by the Institutional Review Board (IRB) and the Helsinki committee of the participating medical centers in compliance with the public health regulations and provisions of the current harmonized international guidelines for good clinical practice (ICH-GCP) and in accordance with Helsinki principles. Informed consent was waived by the IRB for the purpose of this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Approval statement"
        },
        {
            "text": "The code development and analysis was performed by six of the authors who are not radiologists For the control dataset we obtained CXRs taken by the same X-ray machines prior to December . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data and patients"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint 2019. These are patients without COVID-19, typically with another respiratory disease.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data and patients"
        },
        {
            "text": "The test set was taken from the full CXR dataset and contains 350 CXR (15%) of which 179 (51%) are positive for COVID-19 and 171 (49%) are negative. To prevent the model from identifying patient-specific image features (e.g., medical implants) and associating them with the label, each patient was either used for the training or the test set.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data and patients"
        },
        {
            "text": "All images were used in the highest available resolution without lossy compression (e.g. jpeg); 4% (101/2426) of the images were excluded due to lateral positioning, or due to rectangular artifacts in the image, of these 98 were COVID-19 positive. No additional selection criteria were used to exclude CXR images based on clinical radiological findings.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data and patients"
        },
        {
            "text": "The model pipeline (Figure 1 ), begins with a series of preprocessing steps, including augmentation, normalization, and segmentation of the images.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 19,
                    "end": 28,
                    "text": "(Figure 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Image Processing"
        },
        {
            "text": "Augmentations are transformations that change features such as image orientation and brightness. These properties are irrelevant for correct classification, but may vary during image acquisition, and can affect the training performance of the network because of its rigid registration with respect to orientation and pixel values. They serve to enlarge the dataset by creating a diverse set of images, increasing model robustness and generalizability (13, 14) .",
            "cite_spans": [
                {
                    "start": 451,
                    "end": 455,
                    "text": "(13,",
                    "ref_id": null
                },
                {
                    "start": 456,
                    "end": 459,
                    "text": "14)",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Image Processing"
        },
        {
            "text": "Importantly, augmentations should correspond to normal variation in CXR acquisition; to ensure this we consulted with radiologists when defining the augmentation parameters (see Appendix).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Processing"
        },
        {
            "text": "The normalization process aims to standardize image properties and scale. It consists of cropping black edges, standardizing the brightness and scaling the size of each image to 1024X1024 pixels using bilinear interpolation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Processing"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Processing"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint To enhance performance we created an additional image channel using lung segmentation via a U-net (15) pre-trained on a different dataset. This network produces a pixel-mask of the CXR indicating the probability that each pixel belongs in the lungs, allowing the network to access this information while training. Input images contain 3 channels: the original CXR, the segmentation map, and one filled with zeroes. This is done to accommodate the pre-trained models we used that use 3-channel RGB images. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Processing"
        },
        {
            "text": "We compared five network models: ResNet34, ResNet50, ResNet152 (16), VGG16 (17) and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Network architecture and output"
        },
        {
            "text": "Chexpert (11) . We additionally classify the images by aggregating the results of these networks ia R ss he ed nd ks . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 9,
                    "end": 13,
                    "text": "(11)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Network architecture and output"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . using a majority vote. The general approach of these architectures is to reduce images from a high-dimensional to a low-dimensional space such that a simple boundary can be used separate image classes. The models were trained using transfer learning, i.e. using pre-trained weights and subsequently retraining them on our data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Training was performed with the Adam optimizer with an initial learning rate of 1e-6 which was exponentially decreased as epochs progressed. We used cross-entropy as a loss function with an L2 regularizer with regularization coefficient 1e-2. The best test accuracy scores were achieved after 32 epochs. The models were built and trained using Pytorch 1.6; All code will be made available upon publication.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In addition to classification, we propose a method for retrieving a number of CXR images that are the most similar to a given image. The activation of layers of the neural network serve as embeddings of the images into a vector space, and should capture information about clinical indications observed in the images. We use these embeddings to search for similarity between the resulting vectors, and retrieve the nearest neighbors of each image.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "For model evaluation we used accuracy, precision, and area under the curve (AUC) for receiver operating characteristic (ROC) and precision recall (P-R) curves.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Statistical analysis"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data acquisition"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The patient data included in this study are shown in Table 1 . The imaging dataset consists of a total of 2426 CXRs, of which 53% (1289/2426) are positive for COVID-19 and 47% (1138/2426) are negative; 4% (101 of 2426) of the images were excluded due to lateral positioning or having rectangular artifacts covering parts of the image. 98 of these were COVID-19 positive. To our knowledge this is one of the largest datasets of original COVID-19 labeled X-ray images. The demographic statistics of the patients in this study can be seen in Table 1 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 53,
                    "end": 60,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 539,
                    "end": 546,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The performance of the network was tested upon 15% (350 of 2426) of the images that were taken from the total dataset and was set aside before training. The metrics we used are accuracy, namely the proportion of successful classifications overall, sensitivity (also -recall), which is the proportion of positive images that the network classified correctly and specificity, the proportion of correctly classified negative images. We trained five deep network models whose accuracy and sensitivity rates can be seen in Table 2 . We selected ResNet50 for the rest . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 518,
                    "end": 525,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Quantitative analysis of the model"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. We then train ResNet50 on the dataset with and without all the preprocessing stages. As seen in Table 2 , preprocessing incurs an improvement of 4% in accuracy and 5% in sensitivity. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 172,
                    "end": 179,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In addition to the binary decision of whether a patient has COVID-19, we provide a score between 0 and 1, corresponding to the probability the network assigns to the positive label. It is given by the activation of the network's last layer, before it is passed through an activation function that produces the binary output. Whenever this score is above the threshold of 0.5, an image is classified as positive for COVID-19. We generate a histogram of these scores, as can be seen in Figure 3 , and observe that the majority of the correctly classified points are accumulated at the edges, while the wrongly classified images are more spread out along the xaxis. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 484,
                    "end": 492,
                    "text": "Figure 3",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Qualitative analysis of the model"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . vectors into two dimensions, making it possible to visualize the data points and reveal similarities and dissimilarities between them. We used one of the last layers of the networks, which essentially provides an embedding of the images into a vector space. These vector embeddings of the images are given as input to the t-SNE. In Figure 4 it can be seen that the arrangement of the dots, representing the features of the images, colored by their GT labels.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 410,
                    "end": 418,
                    "text": "Figure 4",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The figure depicts two distinct clusters, revealing a similarity between most of the images with the same GT. In order to test the model on a more difficult task, we were supplied with 22 CXRs, 9 positive for COVID-19 and 13 as control, classified by radiologists as difficult to diagnose and used as a test on our model. The accuracy on the test was 77% and sensitivity of 77%. In Figure 5 is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 382,
                    "end": 390,
                    "text": "Figure 5",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint between training and test images is 3.9+/-2.5 (mean +/-std). The mean distance between all positive training and positive test images is 1.4+/-1.9, between negative training and negative test images 2.2+/-1.3, and between images from different classes is 5.8 +/-1.9. Images from different classes are further away from each other, but whether a close distance truly corresponds to similar lung findings still requires verification.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In this study we developed a deep neural network pipeline to classify chest X-ray (CXR) images . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. with 473 COVID-19 X-ray images. The performance reported in these research papers is generally high with accuracy rate ranging from 89%-99% and specificity ranging from 80% to 100% (19, 21) .",
            "cite_spans": [
                {
                    "start": 257,
                    "end": 261,
                    "text": "(19,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 262,
                    "end": 265,
                    "text": "21)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "However, these results were obtained via testing solely on subsets of the data available to the research. These have a number of drawbacks. They include a limited number of positive COVID-19 CXR images, which can cause the model to overfit, as it is exposed to a relatively small number of characteristics from the data which can impair the ability to generalize to external datasets. These models' reliability still need to be verified on external data. As machine learning models tend to improve and generalize better when the amount of data increases (22) , a dataset with more positive COVID-19 images as the one used in this study, with 1191 positive CXR, tends to be more stable. In addition, these datasets were compiled from various sources, . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [
                {
                    "start": 554,
                    "end": 558,
                    "text": "(22)",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint often using one source only for COVID-19 images and another only for COVID-19 negative images. Positive and negative images in these datasets may therefore be produced by different X-ray machines, in particular portable and fixed machines, which give rise to images with different expressions of optical features. This can allow the network's predictions to rely on features related to the source more than on the relevant medical information (23) . In this research we used CXR from the same machines both for patients with both positive and negative COVID-19 outcomes.",
            "cite_spans": [
                {
                    "start": 587,
                    "end": 591,
                    "text": "(23)",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "As future work, we intend to deploy our model for testing in a clinical setting. We will further investigate the scoring process for the image similarities we provide. We would ideally like to compare the disease progression for patients that were found by our tool to have similar lung findings. Additionally, we will examine how CXR are influenced by progression of the disease.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Lung damage may remain after the virus leaves the body, leading to false positives in classification in later stages of the disease. Lastly, our classifier is tailored towards portable Xrays within the four Israeli hospitals that provided the data. It may need further fine tuning to be used in other hospitals or diagnostic settings.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "In summary, we showed a deep neural network which is able to reliably detect patients with coronavirus disease 2019. Even though medical imaging has not yet been approved as a standalone diagnosis tool (9), we believe it can be used as an aid to medical judgement with the advantage of immediate outcome. We also created a tool for X-ray image retrieval based on lung similarities. This tool can help physicians draw connections between patients with similar disease manifestations, by referring them to images with similar lung characteristics. These images can be linked internally to the corresponding patients, and the treatment and outcome of these patients can then inform their decision upon treatment for the current patient.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": ". CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . preserve the image labels -a coronavirus patient must still be identifiable as one. To ensure this, we consulted with radiologists when defining the transformations and their parameter ranges. The augmentations are performed randomly, with parameters chosen uniformly within the defined range as seen in Figure 1 . Not all augmentations are applied each time, but rather each augmentation has a certain probability of being applied, represented by p below: We decided to apply left to right flips, as COVID-19 is known to affect the lungs symmetrically.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 382,
                    "end": 390,
                    "text": "Figure 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "Thus, flipping will not change the characteristic manifestation of the disease. Moreover, some Xray images may be taken from the back, and we do not always have clear labels as to the direction in which the X-ray was taken. Adding flips of the images can make the network robust . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint to this. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "(which was not certified by peer review)"
        },
        {
            "text": "A novel aspect of our model architecture is adding an additional input channel to each image in the form of a probability vector, which indicates for each pixel the probability it belongs to the lung. These probabilities are obtained by applying a pre-trained U-net to segment the lung area from the image. Adding this mask as an additional channel to the X-ray image helps the network focus on the lung area while training. An example of segmentation can be seen in CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint Based on that, our network architecture consists of two main parts -feature extraction, and decision head. The feature extractor is a neural network based on a Resnet50 architecture that gets an image as input (in our case -2D image), performs mathematical operations on it and outputs a feature map, namely a matrix of numbers which describe the image. This matrix of features is converted to a vector (with the same values) and then goes into the decision head which is a simple neural network. In our case it consists of 3 fully connected layers. The output of the decision head is two numbers which describe the confidence of the algorithm about the classification results: COVID-positive or COVID-negative. In addition, the last layer (a vector) in the decision head is referred to as the \"embedding\" and is used as an input to the t-SNE and KNN algorithms described in the text. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation"
        },
        {
            "text": "The copyright holder for this preprint this version posted October 4, 2020. . https://doi.org/10.1101/2020.10.01.20204073 doi: medRxiv preprint",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Analytical sensitivity and efficiency comparisons of SARS-COV-2 qRT-PCR assays. medRxiv",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Vogels",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Brito",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "L"
                    ],
                    "last": "Wyllie",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Diagnosing COVID-19: The Disease and Tools for Detection",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Udugama",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kadhiresan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "N"
                    ],
                    "last": "Kozlowski",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ACS Nano. NLM (Medline)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1021/acsnano.0c02624"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Evaluating the accuracy of different respiratory specimens in the laboratory diagnosis and monitoring the viral shedding of 2019-nCoV infections. medRxiv",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Modes of contact and risk of transmission in COVID-19 among close contacts. medRxiv",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "FALSE-NEGATIVE RESULTS OF INITIAL RT-PCR ASSAYS FOR COVID-19: A SYSTEMATIC REVIEW. medRxiv",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Arevalo-Rodriguez",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Buitrago-Garcia",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Simancas-Racines",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Sensitivity of chest CT for COVID-19: Comparison to RT-PCR",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology. Radiological Society of North America",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020200432"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Chest Imaging Appearance of COVID-19 Infection. Radiol Cardiothorac Imaging",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "P"
                    ],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Initial CT findings and temporal changes in patients with the novel coronavirus pneumonia (2019-nCoV): a study of 63 patients in Wuhan",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "ACR Recommendations for the use of Chest Radiography and Computed Tomography (CT) for Suspected COVID-19 Infection | American College of Radiology",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Statements/Recommendations-for-Chest-Radiography-and-CT-for-Suspected-COVID19-Infection. Accessed",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Imaging Profile of the COVID-19 Infection: Radiologic Findings and Literature Review. Radiol Cardiothorac Imaging",
            "authors": [
                {
                    "first": "M-Y",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ko",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc AAAI Conf Artif Intell. Association for the Advancement of Artificial Intelligence (AAAI)",
            "volume": "33",
            "issn": "",
            "pages": "590--597",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Deep Learning in Ultrasound Imaging",
            "authors": [
                {
                    "first": "Rjg",
                    "middle": [],
                    "last": "Van Sloun",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "C"
                    ],
                    "last": "Eldar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proc IEEE",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "The Effectiveness of Data Augmentation in Image Classification using Deep Learning",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Perez",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. Conf. Learn. Represent",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Visualizing Data using t-SNE",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Mach. Learn. Res",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "COVID-19 Image Data Collection: Prospective Predictions Are the Future",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "Q"
                    ],
                    "last": "Duong",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-Ray Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "M"
                    ],
                    "last": "Covid-Net ; Shah",
                    "suffix": ""
                },
                {
                    "first": "Sks",
                    "middle": [],
                    "last": "Joy",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comprehensive Survey of COVID-19 Detection Using Medical Images. engrXiv",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "The unreasonable effectiveness of data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Halevy",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Norvig",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pereira",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Intell Syst. Institute of Electrical and Electronics Engineers Inc",
            "volume": "24",
            "issn": "2",
            "pages": "8--12",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "A Critic Evaluation of Methods for COVID-19 Automatic Detection",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Maguolo",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Nanni",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Y.E., D.K., D.Y., Y.S., E.G., A.B.). The clinical images were collected and approved by the authors (L.C., E.A., L.L, D.L., Z.N., M.M., M.H., N.E., E.S., B.N.G, S.T., Y.R., D.S., A.D., N.R.B., A.G., N.S.), who are employed as physicians of multiple disciplines including radiologists in the hospitals which provided the data. This study includes CXR images from 1384 patients, 360 with a positive COVID-19 diagnosis and 1024 negative, totaling 2427 CXRs. Patients' COVID-19 labels were determined by a combination of RT-PCR testing and clinical assessment by the physicians. The COVID-19 positive images include all CXRs performed with portable X-ray machines on patients admitted to four hospitals in Israel during the pandemic's first wave (December 2019 through April 2020).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Full pipeline workflow overview. First each image undergoes processing consisting of: augmentation, which is a set of visual transformations (transformations shown: (a) original image, (b) brighten, (c) horizontal flip, (d) 7 degrees rotation, (e) Clahe transformation, (f) scale), normalization, in order to set a standard scale of image size and color, and segmentation, which emphasizes the area of the lungs and is combined to the image. The entire image set is then fed into a Neuronal Network which produces a classification outcome for each image as positive for coronavirus disease 2019 (COVID-19) or negative for COVID-19. In addition, embedded features are extracted from the last layer of the network and are used to find images with similar characteristics to a given image as learned by the network.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "curve is 0.95. The ROC curve is provided inFigure 2a, showing the relationship between the false positive rate (FPR) and the true positive rate (TPR) for different classification threshold values. The curve shows that for a broad range of thresholds, both a high TPR and a low FPR can be achieved. InFigure 2bwe present the P-R curve, which shows the tradeoff between precision (the proportion of images labeled positive from all images that the network classified as positive) and recall as the value of the threshold is varied. This P-R curve shows a broad range of thresholds for which both high precision and high recall are attainable. The AUC of the P-R is 0.94. These ROC and P-R curves attest to the stability of the model across different confidence thresholds.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Performance of the model. (a) Confusion Matrix of the classification. True positive rate (TPR) at the bottom right corner, true negative rate (TNR) at the top left corner, false positive rate (FPR) at the top right corner, and false negative rate (FNR) at the bottom left corner. (b) Receiver Operating Characteristic (ROC) curve. The curve shows the relation between true positive rate (TPR) and false positive rate (FPR) as the threshold of the separation between positive and negative classification is varied. The performance of the model is measured by the area under the curve (AUC). Ideally, the curve should cover as much area as possible up to the upper left corner (AUC score of 1), which minimizes the FPR while maximizing the TPR. The AUC is 0.95 and a good stretch of the curve is marked on the graph where the model achieved a TPR of 87.1% and FPR of 12.8% which can be used as a threshold; (b) Precision-Recall curve. Shows the relation between Precision and Recall. Precision and Recall are affected from different classes of the data, thus can vary in scores when data is imbalanced (e.g more observations of positive or negative compared to the other). We would like to have the AUC as large as possible up to the upper right corner, which maximizes both Precision and Recall. The mark on the graph represents such an optimal spot where the model achieved Precision of 92% and recall of 87%.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Classification score histogram. Ground truth (GT) labels are in colors. Every image is scored on a scale between 0 and 1 with threshold of 0.5, seen as a dashed line, such that all images with a higher score will be classified as positive for COVID-19 and images below as negative. Negatively labeled images that received a score above 0.5 are, therefore, incorrectly classified images, and vice versa with respect to positively labeled images. However, the closer the image score is to one of the edges (0 or 1), the stronger the confidence in the image's classification. The accumulation of two distinct colors on the edges point to good separation of many observations with strong confidence in the classification.We additionally visualize the distinction made by the model using t-distributed Stochastic Neighbor Embedding (t-SNE)(18). t-SNE uses a nonlinear method to reduce high",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "t-distributed Stochastic Neighbor Embedding (t-SNE). A high-dimensional feature vector is extracted for each image from one of the decision layers, which are used for decision of the output of the neural network, and is reduced into 2 dimensions. Each point on the graph represents the features of an image after dimension reduction and arrangement in space. Next the images were colored according to their ground truth (GT), thus revealing two main clusters. The clusters are mostly in one color each, which essentially shows a strong association of the features, extracted from the decision layer and are used to arrange in space, with the GT of the images, represented by the colors.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": ", three correctly classified images from this test are shown with the network's classification score and the GT.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Three images labeled by a radiologist as hard to diagnose. Despite this, the model was able to classify them correctly. Each image is scored with classification score on a scale between 0 and 1 with threshold of 0.5 such that all images with confidence score above the threshold will be labeled as positive for COVID-19 and images below as negative. The ground truth (GT) of each image is also shown.Finally, we applied K-Nearest Neighbors (KNN) on the image embeddings in order to retrieve images similar to each other as shown inFigure 6. For each image we retrieve 4 images with the closest image embeddings; averaging over these images' predictions achieves 87% accuracy (305/350) and 83.2% sensitivity (149/179), meaning that the nearest images typically have the same labels.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "In the figures, the left image is a CXR from the test set, and the two on the right are the two images closest to it from the training set, given the image embeddings from the network's last layer. (a) All three images are COVID-19 Negative. The distances between the middle and rightmost images to the left one are 0.54 and 0.56 respectively. (b) All three images are COVID-19 positive. The distances between the middle and rightmost images to the left one are 0.51 and 0.55 respectively. The overall mean distance",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "scans are similar to each other. The dataset we used is compiled to be as representative as possible of images from patients that would enter a healthcare unit with a suspicion of COVID-19 in a real clinical scenario. The ResNet50 model we trained for classification achieved 89.7% accuracy, 87.1% sensitivity and area under Receiver Operating Characteristic (ROC) curve of 0.95 in classifying COVID-19 images. In addition we created a tool that retrieves the CXR images most similar to a given image. This can provide physicians with a reference to previous patients that had similar lung findings. They can use the internal information they have from the hospital about these previous patients to infer decisions upon treatment. The method for image retrieval has not previously been well established in the literature in the context of COVID-19 CXR. Other groups have worked on COVID-19 classification using neural networks, mostly based on publicly available image sources, such as COVID-19 image data collection (19) with 481 COVID-19 positive images and COVID-Net open source (20) initiative",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Image augmentation. In order to increase the number of images which can improve training performance, several different transformations are performed with a certain probability. The transformations showed: On top: (a) Original image, (b )Brighten, (c) Sharpen, (d) Gamma contrast, (e) Shear. On bottom: (f) Rotate 7 degrees, (g) Clahe, (h) Gaussian blur, (i) Scale, (j) Horizontal flip.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Figure 2.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Lung segmentation using a U-net architecture 2 Network architecture Deep learning-based automated diagnosis approaches have been gaining interest in recent years, mainly due to their ability to extract sophisticated features from images. This allows to describe an image in an alternative way from which we can derive computational conclusions.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Pipeline of the neural network stage in inference time. Input images are passed through a sequence of convolutional layers that extract lower-dimensional vector representations for each image; these representations are optimized for the task at hand, in our case -separation in the vector space between images belonging to different label classes. al at .",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Demographic statistics on patients and chest images in this study.* Age is given mean years +/-std. ** Numbers are after all record exclusions.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Comparison of accuracy, sensitivity and specificity of various deep networks trained and tested on the same test set.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": ")",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Note -The model with best accuracy and sensitivity is the Majority Vote shown in bold. This model is a Majority Vote -as a vanilla (simplest) version of \"ensemble\" method, we gathered all algorithms' results and made a prediction by taking the label which was chosen the most.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "1. brighten, p=0.4 2. gamma contrast, p=0.3 3. CLAHE, p=0.4 4. rotate d \u2208 [7,7] degrees p=0.4 5. shear d \u2208 [7,7] degrees p=0.4 6. scale up to 0.2 on each axis p=0.4 7. flip from left to right, p=0.5 8. either sharpen or apply Gaussian blur 9. horizontal flip, p =0.5",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "In this appendix, we elaborate further on the data processing and the neural network design.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appendix"
        },
        {
            "text": "Before training, each image goes through a preprocessing pipeline. We start by cropping out areas that contain only text around the images themselves. We then unify the image sizes, preserving the original aspect ratios via padding, and apply a CLAHE (filter that was seen to enhance images and improve deep learning performance 10 ). On the training data, we also apply a series of augmentations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data preprocessing"
        },
        {
            "text": "Augmentations are transformations performed on the data that serve a dual purpose. First, applying the augmentations creates additional diverse set of images from the existing ones and enables one to artificially increase a dataset to improve performance 11 . Augmentations are therefore very commonly used on medical images, where datasets tend to be relatively small 12 .Second, these transformations can help the network generalize better 13 , as they alter features that are unimportant to the identification of COVID-19 in the lungs. This way the network can learn the important features and ignore the irrelevant ones. Crucially, the transformations must",
            "cite_spans": [
                {
                    "start": 255,
                    "end": 257,
                    "text": "11",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Augmentation"
        }
    ]
}