{
    "paper_id": "d3e6a5df6152bf8e168dfd5848793beadab98f07",
    "metadata": {
        "title": "The External Validity of Combinatorial Samples and Populations",
        "authors": [
            {
                "first": "Andre",
                "middle": [
                    "F"
                ],
                "last": "Ribeiro",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Harvard University",
                    "location": {
                        "addrLine": "79 John F. Kennedy St",
                        "postCode": "02138",
                        "settlement": "Cambridge",
                        "region": "MA",
                        "country": "United States"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The widely used 'Counterfactual' definition of Causal Effects was derived for unbiasedness and accuracy -and not generalizability. We propose a simple definition for the External Validity (EV) of Interventions, Counterfactual statements and Samples. We use the definition to discuss several issues that have baffled the counterfactual approach to effect estimation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "out-of-sample validity, reliance on independence assumptions or estimation, concurrent estimation of many effects and full-models, bias-variance tradeoffs, statistical power, omitted variables, and connections to supervised and explaining techniques. Methodologically, the definition also allow us to replace the parametric and generally ill-posed estimation problems that followed the counterfactual definition by combinatorial enumeration problems on non-experimental samples. We use over 20 contemporary methods and simulations to demonstrate that the approach leads to accuracy gains in standard out-of-sample prediction, intervention effect prediction and causal effect estimation tasks. The COVID19 pandemic highlighted the need for learning solutions to provide general predictions in small samples -many times with missing variables. We also demonstrate applications in this pressing problem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Donald Rubin's seminal research 25, 32, 33 still provides the most broadly-used and well-accepted definition for what is a causal effect. If y is an outcome of interest and a is a treatment indicator, then the causal effect of a is the difference",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 35,
                    "text": "25,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 36,
                    "end": 39,
                    "text": "32,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 40,
                    "end": 42,
                    "text": "33",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "where y +a i is the outcome of individual i under the treatment. The central concept behind Eq.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "(1) was inspired by experimental estimation: by fixing every factor, other than the treatment, we can declare that the observed difference in outcome was certainly caused by the treatment -and the treatment alone. The definition is an ideal, as it is impossible to observe outcomes for an individual, concurrently, in two different and totally fixed conditions. The theory goes that we may, instead, 'fix' factors in expectation, and across individuals. If the treated and non-treated subpopulations have the same expected values across all factors then any difference between the groups is due to the treatment -given large enough samples. This can be paraphrased with an independence statement:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "the treatment must be conditionally independent on all other relevant factors. This train-of-thought lead to the notion of Sample Balance in non-experimental estimation and the objective most current causality estimators minimize.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We consider, instead,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "where \u03a0 S (m) is a set of permutations of a very large number of factors m, and y < is the outcome of the set of elements before a in the permutation order, and y \u2264 the set including a. This is also an ideal, but defines causal effects in a way that is almost opposite to Eq. (1). It calls for effects to be observed under large variation -as opposed to no variation. The most important element of this definition is \u03a0 S , the number of permutations observed in a sample. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "EV is here the inverse of the variance (i.e. the precision) of effects under a large \u03a0 S . Very importantly, these definitions can be extended to multiple causes, a\u2208X. We demonstrate that, due to their high number of permutations and equal subpopulation representation, causes defined this way are both predictive and free of sample-biases. We thus look at non-experimental samples as random draws of squares. This is in contrast to simply permuting sample observation orders 34 ",
            "cite_spans": [
                {
                    "start": 476,
                    "end": 478,
                    "text": "34",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A maximally accurate estimator (i.e., one with minimum variance) minimizes the covariance between the individuals, or individual states, it is comparing. Combinatorically, this can be seen as maximizing their intersecting factors, Fig.1 intersecting factors) with the first. A partial permutation is a permutation with d fixed-points, d<m.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 231,
                    "end": 236,
                    "text": "Fig.1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "The number of permutations, derangements and partial permutations 12 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "The last number indicates that, to form a partial permutation, we select d unique Sample Representation Expected effects for a population can be decomposed into sums of frequencies and effects across all its subpopulations. For",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "are subpopulation frequencies and higher-order effects are additive interactions. This is, for example, the sample representation behind Factorial Experimental Designs and Analysis of Variance 30 We therefore look at a difference in outcomes \u2206 i (X) from the individual x i as Sample Power A square transversal defines an ordering of population members or sample observations. Horizontal and vertical transversals differ in respect to ACC but follows similar patterns in respect to EV and CF. The transversal also defines a random walk and geometric progression of X m subset sizes. The first factor in the transversal splits X into two subsets, those with factor",
            "cite_spans": [
                {
                    "start": 193,
                    "end": 195,
                    "text": "30",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "is the reference's value for a. The second factor splits each of these subsets into two further subsets,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": ". This is easily visualized as a progression of interval bisections whose lengths correspond the cardinality of factors not yet drawn. Interval lengths follow, Consider what happens as we increase CF and take subpopulations with pairwise differences of 2 (instead of 1). This corresponds to squares with size (m/2) 2 . At each t, the subsequent individuals have two common factors selected from m 2 . These, arbitrarily named a and b, lead to the split",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "x i (ab) andx i (ab). We miss, in a full square, differences that could parse out a and b's individual effects. A transversal and full sequence of individuals leads now to a geometric progression with shrinking lengths 18, 24 , (1/2) 2t . Fig.1 (e) illustrates how this impacts the generated permutations.",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 222,
                    "text": "18,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 223,
                    "end": 225,
                    "text": "24",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 239,
                    "end": 244,
                    "text": "Fig.1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "8"
        },
        {
            "text": "It shows permutation distributions with (1/2) 2n mod m (dark-grey) and (1/2) 3n mod m (light-grey).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "Remember that each permutation corresponds to an ordering of factors, a < b < c < d < ... Sample permutations are, in this case, biased towards a heading set of factors a < b < ... ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "for the first and many (tending to n) squares scenarios. The number of permutations in observational data are, this way, determined by its rare factors, which demand samples with increasing sizes to match the number of permutations in their balanced counterparts. We will not always assume that m is large, infinite or appropriate. In some cases, we observe m < m. In this case, the previous errors are no longer independent, and we assume a common and additive component \u03b5 sq across cells, ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "8"
        },
        {
            "text": "Simulations We consider simulations with increasing complexity, then a real-world application.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "Simulations follow common generative models 6 , with m = 10 Binomial factors, X 10 , and sigmoidal outcomes, y (as in logistic and many categorization models). The cases are: probabilities and effects constant and additive (hypercube), both probabilities and effects sampled from a Uniform distribution U ([0, 1]) (additive), variables random sampled but correlated with the previous (correlated), and, 3 variables randomly omitted from samples (omitted). Fig.2(a) shows the number of observed permutations on runs with increasing sample sizes, n (hypercube). The right panel show combinatorial limits for m=10, Eq. (6) . The same is shown as histograms of square member counts, Fig.2(b) . This illustrates how sample sizes directly affect observed permutation counts, with distinct numbers of fixed-points. We expect these non-parametric counts to impact biases and predictive performance, Eq. An understanding of the relationship among samples, ACC and EV is necessary to devise accurate and maximally general models, with minimal samples. To that end, we consider ACC (percentage of correctly classified cases in validation sections) as we increase n. We use two validation sections: internal and external. The internal section is divided in typical training and validation subsections. We use cross validation in the internal section with 4 folds across cases.",
            "cite_spans": [
                {
                    "start": 616,
                    "end": 619,
                    "text": "(6)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [
                {
                    "start": 456,
                    "end": 464,
                    "text": "Fig.2(a)",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 679,
                    "end": 687,
                    "text": "Fig.2(b)",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "Experiments"
        },
        {
            "text": "When ordered arbitrarily or randomly, the internal-external division is inconsequential (as long as steps contain enough samples). We will define however different sample orderings and consider how they impact learning performance. Starting with n=0, we train several algorithms with increasing n.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "We study out-of-sample prediction, y \u223c X, out-of-sample counterfactual prediction, \u2206y \u223c (x i \u2212x j ), For the next cases, we enumerate squares from Y X and consider transversals with increasing ACC only (vertical). We use the previous transversal, from X, but repeat it for Y X in each training fold. This increases ACC, without using data (outcomes) unavailable in typical validation. Results are in Fig.2(d,e) Learning in this case no longer minimizes the expected risk, but the risk in the combinatorial set of all subpopulations. In these cases, there is little difference in performance among the widely different models, with low variance, suggesting analytic limits and explanations. Recommended sample sizes for the many squares asymptotic case, Eq.8, are marked with a dotted line across simulated (mean over runs) and real-word cases.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 400,
                    "end": 410,
                    "text": "Fig.2(d,e)",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "Experiments"
        },
        {
            "text": "The figure also shows an alternative 'Travel-Salesman' order (rightmost). It is obtained by solving a TSP: individuals are cities, and their factor differences are distances. This order shares an important characteristic with square transversals: differences between sample units are kept small in the output, full-sample order. The orders differ, however, in an important way: differences in the TSP are arbitrary and non-cyclic (following empirical sample frequencies). In this case, EV is steeply reducing, in direct contrast to square enumerations, Fig.2(d,e) . This is not due to algorithms becoming sensitive to sample noise -as typical in overfitting and lack of generalization. It portrays the expected behavior from algorithms when supplied with an increasingly complex population, generating models from specialized to general. The algorithmic stack includes regularized solutions (LASSO and Ridge regressions). Fig.2 (d,e) repeat across generative models, but we observe increased gains proceeding from the hypercube to the correlated case, Fig.2(g) . Current solutions are expected to perform well in samples whose variables are indepedent and unbiased (Sect.2). Fig.2(g) shows increasing EV gains with correlations \u03c1 = {0.1, 0.25, 0.5} (additive). While the concepts above can give researchers larger control over the generalizability of learning solutions, we started with the goal of studying the EV of counterfactual predictions. This case is show in Fig.2(f) . We take this to be the prediction of effect differences from covariate contrasts. The figure illustrates that everyday algorithms are ineffective in this case. The intuition, and why the problem is rarely framed this way, was articulated above: using differences implies loss of large quantities of information in the form of permutations and pairwise overlaps, decreasing the capability of algorithms to generalize effectively. The figure shows, however, that models can generalize effectively if overlaps are considered carefully. This echoes the increased performance over correlated data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 553,
                    "end": 563,
                    "text": "Fig.2(d,e)",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 922,
                    "end": 927,
                    "text": "Fig.2",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1052,
                    "end": 1060,
                    "text": "Fig.2(g)",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1175,
                    "end": 1183,
                    "text": "Fig.2(g)",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1467,
                    "end": 1475,
                    "text": "Fig.2(f)",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "Experiments"
        },
        {
            "text": "Our current emphasis is on the use of supervised solutions that are highly tuned to gener-20 alizability, but we mention implications to causal and explaining techniques. Fig.3(b) shows the performance of 3 widely used causal effect estimators and the IME with random and square orders (additive, \u03c1=0.25). The first estimator is the recent Deconfounder 42 (Sect. 3.1, linear Bayesian factor model fit with Variational Bayes, logistic outcomes and Normal priors). The second is gcomputation 6 , a extremely efficient solution popular in epidemiology. A propensity score matching estimator 31 is included for its popularity and baseline significance. The y-axis has sum of square differences between estimated and ground truth (for all variables). These algorithms (causal and explainer) make contrasting assumptions. The first focuses on biasedness, the second combines (biased and often heuristic) predictive regressions for model selection. Performance increases in both fronts under square enumerations. Notice that both the Deconfounder and g-computations are highly-tuned to the used generative models, as all both rely on logistic regressions. This exemplifies the attraction of nonparametric insights that can take the burden of perfect specification away from researchers.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 179,
                    "text": "Fig.3(b)",
                    "ref_id": "FIGREF14"
                }
            ],
            "section": "Patterns in"
        },
        {
            "text": "The COVID19 pandemic continues to threaten the lives and livelihoods of billions around the world. As of the break of the pandemic, there was a rush and expectations for ML solutions to help inform policy and individuals' decisions 13, 19, 41 . In practice, few of these approaches were truly useful, with SIR semi-deterministic models 7 , or their specializations, used almost exclusively. These offer predictions at high aggregate levels -most often country and city levels -taking all individuals therein to be the same. Some sources of heterogeneity have been identified, age being the most obvious. We discuss two issues, how to (1) generate general models as fast as possible, and, (2) make predictions with unobservables. We consider two data sources. The first is the UK Biobank 5 : a dataset with \u223c500K UK citizens, 100K infected, 5K",
            "cite_spans": [
                {
                    "start": 232,
                    "end": 235,
                    "text": "13,",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 236,
                    "end": 239,
                    "text": "19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 240,
                    "end": 242,
                    "text": "41",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Real-World Example and Omitted Variables"
        },
        {
            "text": "variables. It includes a wide variety of variables -not only from individuals' electronic medical records, but also sociodemographic, economic, living, behavior and psychological annotations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Real-World Example and Omitted Variables"
        },
        {
            "text": "The attraction is its completeness, high-dimensionality, and level (individual). We also consider a recent data dump from the American Center for Disease Control (CDC) 8 with \u223c24M cases but limited variables (age, geographic, race, ethnicity and sex). The interest is as platform to discuss the unobserved factors case. Binary outcome is COVID19 infection in both cases. Fig.1(a) . This is a case that squares address directly. Errors across pairs are approximately constant for a given square size (horizontal lines). That's because errors affect all subpopulations uniformly, Eq.(9). Increasing square sizes leads to error increases at regular and linear rates (lines with different colors), due to \u03b5 d . Enumeration of multiple squares, with distinct references, reduces these errors for individual population members. Fig.3 (c) also shows the impact of omitted variables (rightmost panels). This is the impact of omitting variables from the sample, and not across individual pairs. Introduction of unobservables leads to an additive increase in horizontal and vertical errors. The presence of this common and latent error component suggests an ANOVA decomposition of empirical sample errors, Eq.9. The COVID19 Case Surveillance database 8 includes patient-level data reported by US states to the CDC. We use the subsample with simultaneously non-missing age, sex, race, ethnicity and location (county-level). This leads to 10 binary variables and \u223c11M cases. We additionally generated a set of synthetic controls from the same variables in the 2019 American census (county level). Fig.3(c) repeats the previous plots for the 5 counties with highest case counts. As expected, ANOVA estimates of \u03b5 sq (i.e., from unobserved variables) vary significantly across locations (right) but these have little impact over observed variable pairwise errors (as they affect observed square subpopulations uniformly and can be proxied-out). Fig.3(e) shows MSE of a Leave-One-Out task for every American county using 3 of the best performers in the previous tasks. Case information from all other counties are used to predict a given location's COVID19 incidence. Fig.3 (f) repeats the task with the \u03b5 sq ANOVA estimate as added feature.",
            "cite_spans": [
                {
                    "start": 168,
                    "end": 169,
                    "text": "8",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 371,
                    "end": 379,
                    "text": "Fig.1(a)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 822,
                    "end": 827,
                    "text": "Fig.3",
                    "ref_id": "FIGREF14"
                },
                {
                    "start": 1585,
                    "end": 1593,
                    "text": "Fig.3(c)",
                    "ref_id": "FIGREF14"
                },
                {
                    "start": 1931,
                    "end": 1939,
                    "text": "Fig.3(e)",
                    "ref_id": "FIGREF14"
                },
                {
                    "start": 2153,
                    "end": 2158,
                    "text": "Fig.3",
                    "ref_id": "FIGREF14"
                }
            ],
            "section": "Real-World Example and Omitted Variables"
        },
        {
            "text": "The central methodological challenge in the Sciences, Policy-making and Design remains the evaluation of counterfactual statements (Did this treatment caused the result of interest? Did this policy?) The counterfactual definition of effects formulated sample properties necessary for effects to be free of selection biases, Eq.(1). We formulated sample properties necessary for their External Validity, Eq.(4). We discussed out-of-sample, counterfactual, correlated and missing variables prediction, as well as effect estimation, in simulations and an important real-world example. A central result demonstrated here is that the EV of interventions are, to some extent, predictable from combinatorial properties of the populations they act upon. To a broad audience, ML methods are inherently limited due to the lack of EV, CF and ACC guarantees and bounds when compared to, for example, experimental hypothesis testing. We believe the work could help build further connections between predictive and causal techniques.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Large sample properties of matching estimators for average treatment effects",
            "authors": [
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Abadie",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Guido",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Imbens",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Econometrica",
            "volume": "74",
            "issn": "1",
            "pages": "235--267",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Estimating the effects of continuousvalued interventions using generative adversarial networks",
            "authors": [
                {
                    "first": "Ioana",
                    "middle": [],
                    "last": "Bica",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Jordon",
                    "suffix": ""
                },
                {
                    "first": "Mihaela",
                    "middle": [],
                    "last": "Van Der Schaar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Invariance, causality and robustness",
            "authors": [
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Buehlmann",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Statistical science",
            "volume": "35",
            "issn": "3",
            "pages": "404--426",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A review of instrumental variable estimators for mendelian randomization. Statistical methods in medical research",
            "authors": [
                {
                    "first": "Stephen",
                    "middle": [],
                    "last": "Burgess",
                    "suffix": ""
                },
                {
                    "first": "Dylan",
                    "middle": [
                        "S"
                    ],
                    "last": "Small",
                    "suffix": ""
                },
                {
                    "first": "Simon G",
                    "middle": [],
                    "last": "Thompson",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "26",
            "issn": "",
            "pages": "2333--2355",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Peter Donnelly, and Jonathan Marchini. The uk biobank resource with deep phenotyping and genomic data",
            "authors": [
                {
                    "first": "Clare",
                    "middle": [],
                    "last": "Bycroft",
                    "suffix": ""
                },
                {
                    "first": "Colin",
                    "middle": [],
                    "last": "Freeman",
                    "suffix": ""
                },
                {
                    "first": "Desislava",
                    "middle": [],
                    "last": "Petkova",
                    "suffix": ""
                },
                {
                    "first": "Gavin",
                    "middle": [],
                    "last": "Band",
                    "suffix": ""
                },
                {
                    "first": "Lloyd",
                    "middle": [
                        "T"
                    ],
                    "last": "Elliott",
                    "suffix": ""
                },
                {
                    "first": "Kevin",
                    "middle": [],
                    "last": "Sharp",
                    "suffix": ""
                },
                {
                    "first": "Allan",
                    "middle": [],
                    "last": "Motyer",
                    "suffix": ""
                },
                {
                    "first": "Damjan",
                    "middle": [],
                    "last": "Vukcevic",
                    "suffix": ""
                },
                {
                    "first": "Olivier",
                    "middle": [],
                    "last": "Delaneau",
                    "suffix": ""
                },
                {
                    "first": "Jared O&apos;",
                    "middle": [],
                    "last": "Connell",
                    "suffix": ""
                },
                {
                    "first": "Adrian",
                    "middle": [],
                    "last": "Cortes",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Nature",
            "volume": "562",
            "issn": "7726",
            "pages": "203--209",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Gcomputation, propensity score-based methods, and targeted maximum likelihood estimator for causal inference with different covariates sets: a comparative simulation study",
            "authors": [
                {
                    "first": "Arthur",
                    "middle": [],
                    "last": "Chatton",
                    "suffix": ""
                },
                {
                    "first": "Clemence",
                    "middle": [],
                    "last": "Florent Le Borgne",
                    "suffix": ""
                },
                {
                    "first": "Florence",
                    "middle": [],
                    "last": "Leyrat",
                    "suffix": ""
                },
                {
                    "first": "Chloe",
                    "middle": [],
                    "last": "Gillaizeau",
                    "suffix": ""
                },
                {
                    "first": "Laetitia",
                    "middle": [],
                    "last": "Rousseau",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "Barbin",
                    "suffix": ""
                },
                {
                    "first": "Maxime",
                    "middle": [],
                    "last": "Laplaud",
                    "suffix": ""
                },
                {
                    "first": "Bruno",
                    "middle": [],
                    "last": "Leger",
                    "suffix": ""
                },
                {
                    "first": "Yohann",
                    "middle": [],
                    "last": "Giraudeau",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Foucher",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Nature Scientific reports",
            "volume": "10",
            "issn": "1",
            "pages": "9219--9219",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Causation, prediction, and search / Peter Spirtes, Clark Glymour, and Richard Scheines",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Clark",
                    "suffix": ""
                },
                {
                    "first": "Richard",
                    "middle": [],
                    "last": "Glymour",
                    "suffix": ""
                },
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Scheines",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Spirtes",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Kernel methods for measuring independence",
            "authors": [
                {
                    "first": "Arthur",
                    "middle": [],
                    "last": "Gretton",
                    "suffix": ""
                },
                {
                    "first": "Ralf",
                    "middle": [],
                    "last": "Herbrich",
                    "suffix": ""
                },
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Smola",
                    "suffix": ""
                },
                {
                    "first": "Olivier",
                    "middle": [],
                    "last": "Bousquet",
                    "suffix": ""
                },
                {
                    "first": "Bernhard",
                    "middle": [],
                    "last": "Scholkopf",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Journal of Machine Learning Research",
            "volume": "6",
            "issn": "70",
            "pages": "2075--2129",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Na\\\"ive regression requires weaker assumptions than factor models to adjust for multiple cause confounding",
            "authors": [
                {
                    "first": "Justin",
                    "middle": [],
                    "last": "Grimmer",
                    "suffix": ""
                },
                {
                    "first": "Dean",
                    "middle": [],
                    "last": "Knox",
                    "suffix": ""
                },
                {
                    "first": "Brandon M",
                    "middle": [],
                    "last": "Stewart",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Matchings, derangements, rencontres. Mathematics Magazine",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hanson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Seyffarth",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Weston",
                    "suffix": ""
                }
            ],
            "year": 1983,
            "venue": "",
            "volume": "56",
            "issn": "",
            "pages": "224--229",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Individual and community-level risk for covid-19 mortality in the united states",
            "authors": [
                {
                    "first": "Jin",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "Neha",
                    "middle": [],
                    "last": "Agarwala",
                    "suffix": ""
                },
                {
                    "first": "Prosenjit",
                    "middle": [],
                    "last": "Kundu",
                    "suffix": ""
                },
                {
                    "first": "Benjamin",
                    "middle": [],
                    "last": "Harvey",
                    "suffix": ""
                },
                {
                    "first": "Yuqi",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Eliza",
                    "middle": [],
                    "last": "Wallace",
                    "suffix": ""
                },
                {
                    "first": "Nilanjan",
                    "middle": [],
                    "last": "Chatterjee",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Nature Medicine",
            "volume": "27",
            "issn": "2",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Learning representations for counterfactual inference",
            "authors": [
                {
                    "first": "Uri",
                    "middle": [],
                    "last": "Fredrik D Johansson",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "Shalit",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Sontag",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Entropy and diversity",
            "authors": [
                {
                    "first": "Lou",
                    "middle": [],
                    "last": "Jost",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Oikos",
            "volume": "113",
            "issn": "2",
            "pages": "363--375",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Why propensity scores should not be used for matching",
            "authors": [
                {
                    "first": "Gary",
                    "middle": [],
                    "last": "King",
                    "suffix": ""
                },
                {
                    "first": "Richard",
                    "middle": [],
                    "last": "Nielsen",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Political analysis",
            "volume": "27",
            "issn": "4",
            "pages": "435--454",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Large-scale parallel breadth-first search",
            "authors": [
                {
                    "first": "Richard",
                    "middle": [
                        "E"
                    ],
                    "last": "Korf",
                    "suffix": ""
                },
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Schultze",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proceedings of the 20th National Conference on Artificial Intelligence",
            "volume": "3",
            "issn": "",
            "pages": "1380--1385",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Random walk with shrinking steps",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Krapivsky",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Redner",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "American journal of physics",
            "volume": "72",
            "issn": "5",
            "pages": "591--598",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Individual-level fatality prediction of covid-19 patients using ai methods",
            "authors": [
                {
                    "first": "Yun",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Melanie",
                    "middle": [
                        "Alfonzo"
                    ],
                    "last": "Horowitz",
                    "suffix": ""
                },
                {
                    "first": "Jiakang",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Aaron",
                    "middle": [],
                    "last": "Chew",
                    "suffix": ""
                },
                {
                    "first": "Hai",
                    "middle": [],
                    "last": "Lan",
                    "suffix": ""
                },
                {
                    "first": "Qian",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Dexuan",
                    "middle": [],
                    "last": "Sha",
                    "suffix": ""
                },
                {
                    "first": "Chaowei",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Frontiers in Public Health",
            "volume": "8",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Causal inference on discrete data via estimating distance correlations",
            "authors": [
                {
                    "first": "Furui",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Laiwan",
                    "middle": [],
                    "last": "Chan",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Neural computation",
            "volume": "28",
            "issn": "5",
            "pages": "801--814",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Causal effect inference with deep latent-variable models",
            "authors": [
                {
                    "first": "Christos",
                    "middle": [],
                    "last": "Louizos",
                    "suffix": ""
                },
                {
                    "first": "Uri",
                    "middle": [],
                    "last": "Shalit",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Joris",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "Mooij",
                    "suffix": ""
                },
                {
                    "first": "Richard",
                    "middle": [],
                    "last": "Sontag",
                    "suffix": ""
                },
                {
                    "first": "Max",
                    "middle": [],
                    "last": "Zemel",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Welling",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "30",
            "issn": "",
            "pages": "6446--6456",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Domain adaptation by using causal inference to predict invariant conditional distributions",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Joris",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mooij",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Identification of treatment effects under conditional partial independence",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Matthew",
                    "suffix": ""
                },
                {
                    "first": "Alexandre",
                    "middle": [],
                    "last": "Masten",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Poirier",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Econometrica",
            "volume": "86",
            "issn": "1",
            "pages": "317--351",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Similarity and selfsimilarity in random walk with fixed, random and shrinking steps",
            "authors": [
                {
                    "first": "Tushar",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                },
                {
                    "first": "Santo",
                    "middle": [],
                    "last": "Hossain",
                    "suffix": ""
                },
                {
                    "first": "Md",
                    "middle": [],
                    "last": "Banerjee",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Hassan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Chaos, solitons and fractals",
            "volume": "145",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Counterfactuals and Causal Inference: Methods and Principles for Social Research",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Stephen",
                    "suffix": ""
                },
                {
                    "first": "Christopher",
                    "middle": [],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Winship",
                    "suffix": ""
                }
            ],
            "year": 1926,
            "venue": "Judea Pearl. Causality : models, reasoning, and inference",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Includes bibliographical references",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "K"
                    ],
                    "last": "Cambridge",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": ") and indexes",
            "volume": "",
            "issn": "",
            "pages": "359--373",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Game Theory: A Multi-Leveled Approach",
            "authors": [
                {
                    "first": "Hans",
                    "middle": [],
                    "last": "Peters",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Causal inference by using invariant prediction: identification and confidence intervals",
            "authors": [
                {
                    "first": "Jonas",
                    "middle": [],
                    "last": "Peters",
                    "suffix": ""
                },
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "B\u00fchlmann",
                    "suffix": ""
                },
                {
                    "first": "Nicolai",
                    "middle": [],
                    "last": "Meinshausen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of the Royal Statistical Society. Series B, Statistical methodology",
            "volume": "78",
            "issn": "5",
            "pages": "947--1012",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Learning representations by maximizing mutual information in variational autoencoders",
            "authors": [
                {
                    "first": "Ali",
                    "middle": [],
                    "last": "Lotfi Rezaabad",
                    "suffix": ""
                },
                {
                    "first": "Sriram",
                    "middle": [],
                    "last": "Vishwanath",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "What can the millions of random treatments in nonexperimental data reveal about causes?",
            "authors": [
                {
                    "first": "Andre",
                    "middle": [
                        "F"
                    ],
                    "last": "Ribeiro",
                    "suffix": ""
                },
                {
                    "first": "Frank",
                    "middle": [],
                    "last": "Neffke",
                    "suffix": ""
                },
                {
                    "first": "Ricardo",
                    "middle": [],
                    "last": "Hausmann",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "The central role of the propensity score in observational studies for causal effects",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "Donald B",
                    "middle": [],
                    "last": "Rosenbaum",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 1983,
            "venue": "Biometrika",
            "volume": "70",
            "issn": "1",
            "pages": "41--55",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Estimating causal effects of treatments in randomized and nonrandomized studies",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Donald B Rubin",
                    "suffix": ""
                }
            ],
            "year": 1974,
            "venue": "Journal of educational psychology",
            "volume": "66",
            "issn": "5",
            "pages": "688--701",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Causal inference using potential outcomes: Design, modeling, decisions",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Donald B Rubin",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Journal of the American Statistical Association",
            "volume": "100",
            "issn": "469",
            "pages": "322--331",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
            "authors": [
                {
                    "first": "Cynthia",
                    "middle": [],
                    "last": "Rudin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Nature machine intelligence",
            "volume": "1",
            "issn": "5",
            "pages": "206--215",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Topological properties of hypercubes",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Saad",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schultz",
                    "suffix": ""
                }
            ],
            "year": 1988,
            "venue": "IEEE Transactions on Computers",
            "volume": "37",
            "issn": "7",
            "pages": "867--872",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Elements of Causal Inference : Foundations and Learning Algorithms",
            "authors": [
                {
                    "first": "Bernhard",
                    "middle": [],
                    "last": "Scholkopf",
                    "suffix": ""
                },
                {
                    "first": "Dominik",
                    "middle": [],
                    "last": "Janzing",
                    "suffix": ""
                },
                {
                    "first": "Jonas",
                    "middle": [],
                    "last": "Peters",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Toward causal representation learning",
            "authors": [
                {
                    "first": "Bernhard",
                    "middle": [],
                    "last": "Scholkopf",
                    "suffix": ""
                },
                {
                    "first": "Francesco",
                    "middle": [],
                    "last": "Locatello",
                    "suffix": ""
                },
                {
                    "first": "Stefan",
                    "middle": [],
                    "last": "Bauer",
                    "suffix": ""
                },
                {
                    "first": "Nan",
                    "middle": [
                        "Rosemary"
                    ],
                    "last": "Ke",
                    "suffix": ""
                },
                {
                    "first": "Nal",
                    "middle": [],
                    "last": "Kalchbrenner",
                    "suffix": ""
                },
                {
                    "first": "Anirudh",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "Yoshua",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proceedings of the IEEE",
            "volume": "109",
            "issn": "5",
            "pages": "612--634",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Estimating individual treatment effect: generalization bounds and algorithms",
            "authors": [
                {
                    "first": "Uri",
                    "middle": [],
                    "last": "Shalit",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Fredrik",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "Johansson",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Sontag",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 34th International Conference on Machine Learning",
            "volume": "70",
            "issn": "",
            "pages": "6--11",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Identification and estimation of causal effects from dependent data",
            "authors": [
                {
                    "first": "Eli",
                    "middle": [],
                    "last": "Sherman",
                    "suffix": ""
                },
                {
                    "first": "Ilya",
                    "middle": [],
                    "last": "Shpitser",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Estimates of the severity of coronavirus disease 2019: a model-based analysis",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Verity",
                    "suffix": ""
                },
                {
                    "first": "Dorigatti",
                    "middle": [],
                    "last": "Okell",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "20",
            "issn": "",
            "pages": "116--116",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "The blessings of multiple causes",
            "authors": [
                {
                    "first": "Yixin",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "David",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Blei",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of the American Statistical Association",
            "volume": "114",
            "issn": "528",
            "pages": "1574--1596",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Transformers: State-of-the-art natural language processing",
            "authors": [
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Wolf",
                    "suffix": ""
                },
                {
                    "first": "Lysandre",
                    "middle": [],
                    "last": "Debut",
                    "suffix": ""
                },
                {
                    "first": "Victor",
                    "middle": [],
                    "last": "Sanh",
                    "suffix": ""
                },
                {
                    "first": "Julien",
                    "middle": [],
                    "last": "Chaumond",
                    "suffix": ""
                },
                {
                    "first": "Clement",
                    "middle": [],
                    "last": "Delangue",
                    "suffix": ""
                },
                {
                    "first": "Anthony",
                    "middle": [],
                    "last": "Moi",
                    "suffix": ""
                },
                {
                    "first": "Pierric",
                    "middle": [],
                    "last": "Cistac",
                    "suffix": ""
                },
                {
                    "first": "Tim",
                    "middle": [],
                    "last": "Rault",
                    "suffix": ""
                },
                {
                    "first": "Remi",
                    "middle": [],
                    "last": "Louf",
                    "suffix": ""
                },
                {
                    "first": "Morgan",
                    "middle": [],
                    "last": "Funtowicz",
                    "suffix": ""
                },
                {
                    "first": "Joe",
                    "middle": [],
                    "last": "Davison",
                    "suffix": ""
                },
                {
                    "first": "Sam",
                    "middle": [],
                    "last": "Shleifer",
                    "suffix": ""
                },
                {
                    "first": "Clara",
                    "middle": [],
                    "last": "Patrick Von Platen",
                    "suffix": ""
                },
                {
                    "first": "Yacine",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Julien",
                    "middle": [],
                    "last": "Jernite",
                    "suffix": ""
                },
                {
                    "first": "Canwen",
                    "middle": [],
                    "last": "Plu",
                    "suffix": ""
                },
                {
                    "first": "Teven",
                    "middle": [
                        "Le"
                    ],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Sylvain",
                    "middle": [],
                    "last": "Scao",
                    "suffix": ""
                },
                {
                    "first": "Mariama",
                    "middle": [],
                    "last": "Gugger",
                    "suffix": ""
                },
                {
                    "first": "Quentin",
                    "middle": [],
                    "last": "Drame",
                    "suffix": ""
                },
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Lhoest",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Rush",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
            "volume": "",
            "issn": "",
            "pages": "38--45",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Counterfactual prediction for bundle treatment",
            "authors": [
                {
                    "first": "Hao",
                    "middle": [],
                    "last": "Zou",
                    "suffix": ""
                },
                {
                    "first": "Peng",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "Bo",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Zheyan",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Jianxin",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Hongxia",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Yue",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Advances in Neural Information Processing Systems",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "33",
            "issn": "",
            "pages": "19705--19715",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "We say an effect is Externally Valid (EV) if it holds under a wide range of population variations. The consequent definition for EV is EV(a) : Var \u22121 \u2206 y(a)|\u03a0 S .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "(a) Combinatorial representation of an ideal Counterfactual, (b) 3\u00d73 Latin Square ('square'), (c) 3 disjoint paths in a 3-dimensional hypercube, (d) square transversals and random split simulations. where \u03a0 2 S (m) are sets of Latin-Squares. We use Latin-Squares (or, 'squares') to represent permutations (and pairwise differences) in datasets, Fig.1(b). Its columns and rows are permutations, simultaneously, and they have the highest number of permutations per m 2 sample units. The inner summations in Eq. (4) correspond to square diagonals and sets of differences for each",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "populations with their set of discrete differences (each corresponding to a counterfactual observation of effect). Together, the set of differences in a sample amount to 'observed' permutations of the sample population. Toward that end, we first differentiate pairs according to two reciprocal characteristics. Each difference between two members of size d changes d factors while keeping m\u2212d constant between them -thus being a permutation with m\u2212d fixed-points. A pair with large differences permute many factors, in respect to \u2206y, and we say it has large EV. The pair cannot reveal, however, the effect for any individual factor. To distinguish the effect of a factor from all others we need pairs with small differences -or small CF. Samples without a complete set of singular differences {a}, {b}, {c}, ... require effect estimators to go beyond the data and introduce model assumptions. Samples whose effects are simultaneously 'unconfounded' and 'externally valid' require combinations of both types of differences. The organization of sample permutations into squares, and their enumeration, reflects these two simultaneous requirements, Eq.(4). Each individual square is a set of permutations with minimal CF for all sample subpopulations. A set of squares is, correspondingly, a set of permutations with minimal CF and increasing EV. More specifically, consider the m d subpopulations determined by m factors, 0\u2264d\u2264m. Each subpopulation is associated with a set of factors [0, 1] m and its members are sample units with the same factors. A derangement of a permutation is another permutation with no fixed-points (i.e.,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "factors to be organized in m d ways -each with D m\u2212d possible disjoint orderings of non-selected factors. To connect differences, permutations and combinations, fix an individual x i and take it as a 'reference frame' -making each other member a difference from the first. Thus we say a member x with m differences from the first, |x i \u2212x|=m, is at EV m (for x i ) and defines a derangement of X. As noted, a maximum accuracy (ACC) pair has EV of only 1 and m\u22121 fixed-points. Let this represent the first column of a square. The second column has EV of 2 (for x i ) and m\u22122 fixed-points. The last column has an EV of m\u22121 and 1 fixed-point. For each d, there are as many subpopulations to be collected as numbers on the d-th row of Pascal's triangle. Therefore, to increase the EV for x i (while keeping CF low) means selecting m d other members, and unique differences, at increasing distances d. Each square is a derangement of a subpopulation, or one of its members, and a collection \u03a0 i of partial permutations. It enumerates effects for all a \u2208 X and subpopulations, albeit with different ACC across subpopulations. The set of squares is a set of permutations \u03a0 S = \u222a n i=1 \u03a0 i of population members. According to Eq.(4), EV of samples is equated with the full set of permutations (where all members take at some point the reference, and largest ACC, position). A sample with these properties has maximum ACC observations for all members.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": ". Each subpopulation can be seen as the vertex of a m-dimensional hypercube,Fig.1(c). There are 2 m vertices and m2 m\u22121 edges. Associated with each vertex is an estimated effect\u2206(x) from a given estimator.Instead of effect estimates, we consider, effect observations. Each subpopulation is equally represented with f (\u00b7) = 1 and each hypercube edge has a singular effect observation for a subpopulation (from differences to the chosen reference). For example, edges x i + {ab} and x i + {a} lead to an observation of the effect of b for subpopulation a. We are interested in the complete set of effect observations. This can be described by sets of disjoint paths in the hypercube,Fig.1(c). A corresponding combinatorial representation is a Latin-Square Experimental Design. There are m disjoint paths of size m in the hypercube35 and therefore the square has m 2 positions. We use this representation, in particular, to organize sets of permutations. A square collects a derangement, its partial permutations and complete set of effect observations.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "and the full set of observations as \u2206(X) = \u2206 1 (X) + ... + \u2206 i (X) + ...\u2206 n (X). Reversely, we look at the effect of factors as\u2206(a) = 1 n [\u2206 1 (a) + ... + \u2206 i (a) + ...\u2206 n (a)]. Each sample is a version of this full set of observations, and we are interested in understanding the impact of missing differences in the performance of learning algorithms and estimators. The estimated sample EV is V ar[\u2206(a)], corresponding to square diagonals, Eq.(3). Each subpopulation shares a series of observed effects. Estimating factors concurrently can be therefore extremely advantageous, and why the Shapley value (a coalitional solution) 27 appears naturally, Eq.(4).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "t with t = (n mod m) and n \u2208 N + . Stochastically, it corresponds to m sequntial throws of a dice, selecting factor presence or absence in each case. Each of the 2 m possible intervals of size 1/2 m corresponds to a given (partial) permutation. The m bisections, repeated enough times, enumerates all permutations \u03a0 i for x i .Fig.1(e) shows simulations of (1/2) n mod m with increasing n. It leads to a uniform distribution over permutations (black). Since they are sampled uniformly, no particular factor, or factor subsequences, are privileged and there are no biases among in this sample. A square transversal thus shares properties with experimental or balanced samples, where p(a| t\u22121 i X i ) = 0.5, X t is the t-th variable sampled and a is the treatment indicator. This follows from a \u22a5 X \u2212 {a}.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Observational samples may contain subsamples that are unbiased and predictive. Finding such subsamples shifts the requirement from one of carrying out an experimental intervention to 12 one of accruing sufficient sample sizes across the required combinatorial conditions. How much larger should an observational dataset be, such that we can expect it to contain a subsample that reproduces properties of the equivalent experimental dataset? If \u03a0 2 E is the set of permutations in the balanced set and \u03a0 2 S in the unbalanced, we want a sample size for the latter where |\u03a0 2S | \u2265 |\u03a0 2 E |.Associate a given permutation with its series of split probabilities. When probabilities are not 1/2,the effective number of draws refers to the number of draws needed for the proportions to equal the one in the balanced dataset. This is \u03bb min = (1/M ) where M is the minimum across permutations' split probabilities. This is related to the Inverse Simpson index 15 which is a leading diversity index in Ecology and defines the number of equally abundant species necessary to produce an observed mean. The balanced sample asymptotic requirements are simple, with a minimum of 2 m draws for a single square (without replacement) and 2 m (n/e) for many squares (when n m). The latter is due to Eq.(6) which requires approximately n/e observations to find a derangement 12 . For the case of unbalanced datasets, distinct permutations have distinct sample requirements. This is largely due to sample correlations. A permutation with \u03bb min requires approximately 2 m \u03bb min , n2 m \u03bb min /e,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Variables We decompose errors in each square cell (k, d) as \u03b5 k,d (a) = \u03b5(a) + \u03b5 d , where a is the cell's allocated variable and \u03b5 d is a cell 'positioning' error -introduced by differences in ACC across the observed square's columns and the increasing fixation of partial permutations. Because every variable a is observed at every position, \u03b5(a) \u22a5 \u03b5 d . Due to the presence of all subpopulations (accounting for all factor interactions), we expect \u03b5 d to increase linearly with d. The rate of increase describes the impact of sample fixations on ACC.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "to the situation where subpopulations are approximated by others containing a superset of its factors. This impacts CF and illustrates its two possible sources of increase (whose impacts, in turn, were discussed in the last section). Missing pairwise differences are the result of under-sampling. Missing variables are the result of mispecification. The two impact performance in similar ways, but have typically different solutions. Large m and no positioning errors, make \u03b5(a) indicate variable EV, Eq.(3). We return to the issue of omitted variables in the Experimental Section.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "squares, we first enumerate all observed permutations in a sample then assemble them into squares. The first is simple: the set of all pairs of units with singleton differences, a \u2208 X, are placed in the first column of a square-like matrix. Then all pairs with difference b \u2208 X and overlap a are placed in the second column and row containing a. If there are m 2 unique differences b (with overlap a) at this stage, the procedure adds m 2 \u22121 new rows to the matrix. The process is repeated for all subsequent singleton pairwise differences and antecedent overlaps. After m repetitions, each matrix row contains a sample permutation. To assemble these permutations into squares we first code each (partial) permutation with a Lehmer code. Richard Korf proposed a way of encoding permutations in linear time when proposing a Rubik's cube solver 17 . It converts the Lehmer code into a base-10 number. Indices for partial permutations can be obtained in the same way but with one difference. For a full permutation, each digit in the Lehmer code has a base of (m\u22121\u2212i)!, where i is the digit position. For a partial permutation, the base of each digit is D d\u22121\u2212i m\u22121\u2212i , where d is the number of items fixed. The procedure generates a unique index for all partial permutations and derangements. We also create an inverted index with (row number, permutation code). From each permutation it is then easy to find all its unique rotations. To enumerate squares, it suffices to select all permutations with full squares (m rotations) and follow its unique rotation order. Due to the indexing of partial permutations, this also allows for the enumeration of incomplete and partial squares. Enumerated this way, squares provide enumeration of subpopulations. Given the observed sample, subpopulation members are (a) Observed permutations and limits (m=10, log-scale), (b) square histograms with increasing n, (c) square member enumeration from X 10 , (d) ACC vs. n for the additive, (e)hypercube, (f) counterfactual prediction, (g) correlated cases.indistinguishable but may have different y i . When enumerating square subpopulation members, we pick them without replacement. When m>10, this process is repeated hierarchically, hashing permutations based on their overlaps to all previous permutations. Permutations are, this way, represented by sets of log 10 (m) indices, and consequently, sets of permutations with increasing fixed-points.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": ", irrespective of generative assumptions. At n=200 no differences of size larger than 2 are observed. A full square of size 10 is completely observed only at n=1023 (rightmost) in the hypercube case, and n \u2248 20K in the additive case. The latter has rare factors, E[min(P (X))] = 0.05, which leads to an approximate sample requirement of n = 2 10 /0.05 = 20480, Eq.(8).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "regressions, five pre-specified GBMs, a near-default Deep Neural Net, an Extremely Randomized Forest (XRT), a random grid of XGBoost GBMs, a random grid of GBMs, and a random grid of Deep Neural Nets, as well as Stacked Ensembles with all previous models. Search parameters are listed in the Appendix and no class balance heuristics are used. In a preliminary case, we enumerate squares with only variables X (dependent variable omitted). The enumeration leads to a sample unit ordering. Curves in Fig.2(c) correspond to the mean ACC (and errors) of the best performing algorithm and parameter set (leader) across 100 runs. The figure shows how ACC changes under alternative orders: random, vertical square transversal and horizontal square transversal. Both square transversals supply systems with equally-represented subpopulations but their performance is symmetrical in respect to ACC. The random sample ordering strikes a balance between these extremes.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "for the additive and hypercube cases. Curves for all algorithms are now shown (best parameter set), bold curves mark the leader. Error bars are shown only for the leader. For the random case, ACC (both external and internal) remain at constant levels. Since sampling is random, algorithms minimize the empirical, expected error in sample populations -which can reflect both subpopulation frequencies and sample selection biases. For the square case, there is a steep increase (a) UK Bioback COVID19 infection prediction, (b) causal and importance estimation, (c) square size (color) and columns' (x-axis) pairwise errors and omitted variables case (log-scale), (d) infection error decomposition for US counties (log-scale), (e) Leave-one-out infection prediction error with missing variables, (f) with added \u03b5 sq eror component. in EV. This indicates that maximizing the number of squares in data can lead to increases in EV.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "(a) shows performance of the previous supervised solutions in the UK Biobank 5 . These achieve out-of-sample ACC of \u223c80% with random sampling. We see a pattern similar to those in previous results under square ordering: EV increases precipitately. Taking a fourth of the sample leads to 10% increase in ACC over the unseen data. As before, the TSP ordering leads to a sharp decrease in EV in the first-half section. At a fourth of the sample, we have larger confidence over the amount of subpopulation predictive coverage the trained models can offer.The 10 variables with highest EV (according to Eq.3) and their biobank codes (parenthesis) were: overcrowded-household (26432), [pop-density (20118), traffic-intensity (24011), time-to-services (26433)], [health-rank (2178), smoking (20116), expiratory-flow (3064), age (24)], job-physical (816), risk-taking (2040). The first is a deprivation index marking individuals in overcrowded households. This is in line with research showing that infection rates for families happen in a logical-OR fashion (i.e., members multiply their individual exposures to the disease). Variables in brackets have \u03c1 > 0.1. There are many 10-size squares, which indicates that, despite correlations, there are enough observations to also parse out correlated variables' effects. Population density 22 is favored over neighborhood traffic intensity, and general health over age, for example. Further description of these variables can be found on 40 from their codes. Fig.3(c) shows mean error among pairs, (\u2206 ij y \u2212 \u2206 uv y) 2 , (y-axis) across a square, its columns d (x-axis) and distinct simulations (additive and hypercube). Colors correspond to squares with increasing sizes (m ). Square size fixes the maximum amount of variation across pairs, up to a complete derangement. Larger d leads to pairs with both decreasing fixed-points and ACC. Vertical and horizontal transversals are shown. The figure illustrates the two sources of confounding in pairwise errors. For a pair with m\u22121 fixed-points there are m\u22121 omitted (overlapping) factors in pairwise estimation,",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "-a common practice in bootstrapping, permutation tests and black-box explaining techniques -that leads to the accumulation of biases from their multiple",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "(a). There is, however, a serious problem with this definition. It is only guaranteed to hold under a very strict set of conditions. Namely, it holds only if all factors of relevance are held constant among individuals. Such estimates are poised to not generalize across populations. According to Eq. (2,3), the estimate is, in fact, the one with minimal EV.Related Work The previous definition, Eq.(1), has been adopted by most estimators in use today.They solve the estimation problem largely from a model inference and dimensionality reduction perspective. If a low-dimensional signal bal(X) : X m \u2192 [0, 1] can summarize the set of expected values of confounders in a nonexperimental dataset, then it can be used to select subsamples that are approximately balanced. In Rubin's original work, the signal was denoted propensity scores25,31 , while logistic regressions solved the dimensionality reduction problem and offered some analytic guarantees. Many recent models use contemporary techniques to solve sample balance optimizations -such as deep learning21 and Bayesian 42 techniques. There are doubts16 , however, over whether this problem can be typically achieved in practice and, still, few guarantees or theory to 5 show otherwise. These approaches' emphasis is in selection-biases. The counterfactual formulation, and propensity scores, have also led to several approaches to the prediction of counterfactuals2,14,44 .tests such as kernel-based 10 , distance correlations 20 and mutual information 29 require very large samples to be reliable and provide few guarantees surrounding the learned models.A related weakness in all previous approaches is their exclusive use of uncorrelated data37,39 , leading to a consequent 'loss-of-sample'. This leads to a tension between their 'thinness' -i.e., reliance on the outcomes of single tests -and lessons from several highly successful ML supervised approaches. Learning solutions like Boosting and Ensemble methods demonstrate the value of combining many and redundant tests or models to obtain robust predictions. Concerns about",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}