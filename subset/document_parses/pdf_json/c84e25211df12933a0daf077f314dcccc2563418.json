{
    "paper_id": "c84e25211df12933a0daf077f314dcccc2563418",
    "metadata": {
        "title": "QAIS-DSNN: Tumor Area Segmentation of MRI Image with Optimized Quantum Matched-Filter Technique and Deep Spiking Neural Network",
        "authors": [
            {
                "first": "Mohsen",
                "middle": [],
                "last": "Ahmadi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Urmia University of Technology (UUT)",
                    "location": {
                        "postBox": "P.O. Box",
                        "postCode": "57166-419",
                        "settlement": "Urmia",
                        "country": "Iran"
                    }
                },
                "email": "mohsen.ahmadi@ine.uut.ac.ir"
            },
            {
                "first": "Abbas",
                "middle": [],
                "last": "Sharifi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Urmia University of Technology (UUT)",
                    "location": {
                        "postBox": "P.O. Box",
                        "postCode": "57166-419",
                        "settlement": "Urmia",
                        "country": "Iran"
                    }
                },
                "email": ""
            },
            {
                "first": "Shayan",
                "middle": [],
                "last": "Hassantabar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Princeton University",
                    "location": {
                        "postBox": "P.O. Box: 08544",
                        "settlement": "Princeton",
                        "region": "NJ",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Saman",
                "middle": [],
                "last": "Enayati",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Temple University",
                    "location": {
                        "postBox": "P.O. Box: 19122",
                        "settlement": "Philadelphia",
                        "country": "USA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Tumor segmentation in brain MRI images is a noted process that can make the tumor easier to diagnose and lead to effective radiotherapy planning. Providing and building intelligent medical systems can be considered as an aid for physicians. In many cases, the presented methods' reliability is at a high level, and such systems are used directly. In recent decades, several methods of segmentation of various images, such as MRI, CT, and PET, have been proposed for brain tumors. Advanced brain tumor segmentation has been a challenging issue in the scientific community. The reason for this is the existence of various tumor dimensions with disproportionate boundaries in medical imaging. This research provides an optimized MRI segmentation method to diagnose tumors. It first offers a preprocessing approach to reduce noise with a new method called Quantum Matched-Filter Technique (QMFT). Then, the deep spiking neural network (DSNN) is implemented for segmentation using the conditional random field structure. However, a new algorithm called the Quantum Artificial Immune System (QAIS) is used in its SoftMax layer due to its slowness and nonsegmentation and the identification of suitable features for selection and extraction. The proposed approach, called QAIS-DSNN, has a high ability to segment and distinguish brain tumors from MRI images. The simulation results using the BraTS2018 dataset show that the accuracy of the proposed approach is 98.21%, average errorsquared rate is 0.006, signal-to-noise ratio is 97.79 dB, and lesion structure criteria including the tumor nucleus are 80.15%. The improved tumor is 74.50%, and the entire tumor is 91.92%, which shows a functional advantage over similar previous methods. Also, the execution time of this method is 2.58 seconds.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Brain tumors, which are well known to be one of the most common diseases of the nervous system, can cause many damages to human health and can also result in death. In this matter, the most common type of brain tumor among adults is glioma [1] . These tumors can be classified based on their grades as follows: Low-Grade Gliomas (LGG) exhibit benign trends and provide better patient awareness, whereas High-Grade Gliomas (HGG) are malignant, which may lead to receiving worse patient awareness [2] . The medical image of brain tumors helps assess disease development before and after treatment. Several imaging techniques, such as MRI, CT, PET, and SPECT imaging, have been used to examine brain tumors. However, MRI imaging is now the main imaging technique that can be used for glioma's diagnosis and treatment, because it has advantages such as good softtissue disparity, multiplied parameters, shooting in the desired direction, noninvasive photography, and so on. It also has various sequences, such as T1 weight images, T1 or T1ce-enhanced contrast, T2 weight, and Fluid Attenuation Inversion Retrieval (FLAIR). These sequences offer additional details about different parts of brain tumors [3] . For instance, the tumor area via peritumoral edema may be diagnosed in FLAIR and T2 images. Conversely, the tumor nucleus area without peritumoral edema is more prominent in images of T1 and T1ce. In this way, the different main MRI methods focus on detailed information of images, which describe the features of brain tumors under several sides.",
            "cite_spans": [
                {
                    "start": 240,
                    "end": 243,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 495,
                    "end": 498,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1198,
                    "end": 1201,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "For a medical diagnosis, accurate segmentation of these tumors is critical and needs therapeutic planning. Segmentation of brain tumors in an automatic way and existing infrastructures from medical imaging allow for accurate diagnosis of tumors. It can help plan surgery and the treatment of brain tumors by providing a more efficient and better diagnosis [4] . In particular, it is critical to divide these tumor tissues, such as enhancing core, necrosis, edema, and nonenhancing core in terms of the natural brain tissue, containing white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF). Nevertheless, the precise automatic segmentation of these tumors is a challenging issue due to several reasons. In image segmentation operations, the outlines between the normal tissues and brain tumor are blurred because of the partial size effects, the gradient filtering intensity, and the magnetic field artifacts. Moreover, brain tumors are very varied in terms of size, shape, and location in patients. It is recommended to utilize a novel, robust, and fast method with the utmost care in the field of image segmentation. The segmentation of different images is a separate issue, and the right method should be designed according to each structure that should be segmented with a specific purpose. Deep convolutional neural networks have done very well in recent years in brain tumor segmentation [5] . In this regard, the convolutional neural network (so-called CNN) is a popular deep learning model that can elicit some favorite features for the original data classification [6] .",
            "cite_spans": [
                {
                    "start": 356,
                    "end": 359,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1406,
                    "end": 1409,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1586,
                    "end": 1589,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This article proposes a new optimal framework of the brain tumor segmentation of MRI images that uses the structure of an optimized deep spiking network with the Quantum Artificial Immune System (QAIS). This framework is fully integrated with the QAIS-DSNN and conditional random field (CRF) combination. In the first step, a multiplied level architecture network is proposed to consider interdependence segmentation among neighboring pixels and supplementary information in various layers and measures. The background textual information of the three-dimensional MRI images is essential for brain tumor segmentation that is not taken into account by the CNNs. The study also introduces connected CRFs to correct the mapping probability attained by QAIS-DSNN.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To date, several methods have been proposed for MRI imaging. This section examines an overview of several classified methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Literature Review"
        },
        {
            "text": "Learning-Based Methods. The importance of MRI imaging methods for brain tumors in recent years with deep learning principles and methods due to high applications and relevant results has been highly regarded. In [7] , the design of different types of convolutional neural network architecture is proposed in the form of 3 \u00d7 3 windowing with a deep layer in different grades of gliomas specimens using small nuclei. A two-way convolutional neural network model has been proposed in [8] , and one channel provides detailed features of local and the other provides universal feature extraction. In [9] , a convolutional neural network architecture has been created as a cascaded CNN to obtain the local dependencies of tags, achieving better performance in segmentation. Besides, they selected a two-step training strategy to address label imbalance distribution. Recently, there are advantages of multiscale features of the convolutional neural network in segmentation work [10] [11] [12] [13] [14] [15] [16] . In general, there are two methods to elicit features of multiplied scales: the first method is to use feature mapping of different network levels to show multiscale features [10] .",
            "cite_spans": [
                {
                    "start": 212,
                    "end": 215,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 481,
                    "end": 484,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 595,
                    "end": 598,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 972,
                    "end": 976,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 977,
                    "end": 981,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 982,
                    "end": 986,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 987,
                    "end": 991,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 992,
                    "end": 996,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 997,
                    "end": 1001,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1002,
                    "end": 1006,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1183,
                    "end": 1187,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Research on Deep"
        },
        {
            "text": "In this respect, a multiscale convolutional neural network has been suggested to divide the retinal vein in [17] . Scale images are identified at different stages of the convolutional neural network to obtain the retinal arteries' probability mappings. Also, in [18] , the structure of the Fully Convolutional Neural Network (FCNN) was developed for training with CRF; however, the process of training them was extremely time-consuming and expensive in terms of memory consumption. The second case is the transfer of versions on a different scale from the input image using the same network [10] . Also, multiscale features have been obtained by the convolutional neural network in [18] . This paper adopted three-dimensional CRFs to process segmentation results, but configuring three-dimensional CRFs is a complex process. In [18] , different sizes from a convolutional neural network architecture have been used as cascaded CNN to record multiscale features. Due to this research and, of course, many other types of research that are beyond the scope of this research, the convolutional neural network has achieved significant achievements. The ability to learn neural networks with architecture and fixed parameters is limited, and the useful information, for three-dimensional MRI data, may be overlooked.",
            "cite_spans": [
                {
                    "start": 108,
                    "end": 112,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 262,
                    "end": 266,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 591,
                    "end": 595,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 682,
                    "end": 686,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 828,
                    "end": 832,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Research on Deep"
        },
        {
            "text": "Some researchers use two-dimensional [19] or threedimensional convolutional neural network models [18, 20, 21] to deal with three-dimensional images. For brain tumor segmentation, a three-dimensional semantic segmentation network based on the encoder-decoder architecture was developed in this way [22] . A hierarchical segmentation system that has varied the segmentation into three binary tasks has been proposed [19, 23, 24] . They also taught models of segmentation from sagittal, coronal, and axial perspectives. In the practical step, to achieve the final results, they averaged the SoftMax outputs obtained in the mentioned perspectives. Even though these methods do work very well, they raise both memory consumption and fiscal complexity. Thus, fiscal models, such as conditional random fields (CRFs) and Markov Random Fields (MRFs), are mainly employed to investigate spatial text information. In [25] , a neonatal structure of a deep neural network called the Growing Deep Convolutional Neural Network (GCNN) is presented to segment MRI images to diagnose brain tumors.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 41,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 98,
                    "end": 102,
                    "text": "[18,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 103,
                    "end": 106,
                    "text": "20,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 107,
                    "end": 110,
                    "text": "21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 298,
                    "end": 302,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 415,
                    "end": 419,
                    "text": "[19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 420,
                    "end": 423,
                    "text": "23,",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 424,
                    "end": 427,
                    "text": "24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 907,
                    "end": 911,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Research on Deep"
        },
        {
            "text": "There is also another method combined with GCNN that is a Stationary Wavelet Transform (SWT). The hybrid deep 2",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Research on Deep"
        },
        {
            "text": "BioMed Research International learning method is simulated with the use of BraTS2018 dataset and evaluated using the peak signal-to-noise ratio (PSNR), the average square error, and so on. In [26] , a complete convolutional neural network with pyramidal features is presented as an Atrous convolution for brain tumor segmentation by MRI images. This research uses data sets from BraTS2013, BraTS2015, and BraTS2018, the results of which have a functional advantage over lesion structure, including tumor nucleus, improved tumor, and the whole tumor, compared to previous methods, especially the convolutional neural network. These results are based on the Dice criterion, 76.88% for the tumor nucleus, 74.43% for the optimized nucleus, and 86.58% for the entire tumor. Also, in [27] , the convolutional neural network is used in three dimensions based on a method called Test-Time Augmentation. This research uses BraTS2018 data and shows the results of its evaluation with a lesion structure, including tumor nucleus, improved tumor, and whole tumor, with functional superiority over many convolutional methods and deep networks. These results were in two ways using the Dice criterion, which was 90.21% for the tumor nucleus, 79.72% for the optimized nucleus, and 85.83% for the entire tumor. In a similar study, in [28] , the convolutional neural network is considered to be multicascaded (CNN) and conditional random field proposed as MCCNN. The results of this study, based on the lesion structure criteria, were 71.78% for the improved nucleus, 88.24% for the total tumors, and 74.81% for the tumor nucleus. For breast imaging monitoring and data system ranking, Kang et al. [29] indicated a dominant fuzzy full-connected layer. The aim of the model was to establish complementary scoring properties for semantic segmentation with fuzzy rules.",
            "cite_spans": [
                {
                    "start": 192,
                    "end": 196,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 778,
                    "end": 782,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1318,
                    "end": 1322,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1681,
                    "end": 1685,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Research on Deep"
        },
        {
            "text": "First of all, it should be noted that sparks are the neurons of the neural network that use spikes instead of neurons in the spiking neural network, and a set of neurons in an input layer with spikes is called a spark. spiking neural networks (SNNs) are driven by the processing of biological knowledge, which communicates in parallel scattered and nonsynchronous binary signals. In neuromorphic hardware, SNNs indicate some appropriate features such as fast inference, low energy use, and eventdependent processing of information. It creates interesting applicants to apply deep learning (DL) networks effectively and a selection process for several learning tasks at a computer. Here, SNNs consider a wide range of training methods, including the conversion of convolutional deep networks to SNNs, limited preconversion training, and a variety of biological motivations [30] . Neural networks are usually read if they have at least two hidden layers of nonlinear input conversion. In this study, only feedback networks are considered to calculate mapping from input to output. Spiking neural networks were initially studied as biological information processing models in which neurons exchange information through spikes. Here, all spikes are expected to be stereotypical events; in this way, data processing is minimized to two main factors: First of all, the timing of spikes, for example, firing frequency, the relative timing of pre-/postsynapse spikes, and special patterns of movement. Secondly, the identification of the synapses used means it is possible to connect nerve cells, whether the synapse is stimulating or inhibitory. With regard to the degree of detail of the simulation neurons, the two neurons are the point at which the input spikes alter their (somatic) membrane potential immediately or are built together with complex (dendritic) spatial structures as multichamber models. Hence, the dendritic currents will communicate before that. There were also changes to physical capacity. Here, several models of spike neurons, such as Hodgkin's Huxley model, integrate-and-fire, and spike response, explain the evolution of membrane potential and the spike of different rates of detail in development. Essentially, the membrane potential of the stream merges with the entry of the spikes and generates a new spike since the threshold is crossed. After the spike is obtained, the small axon is sent to all the linked nerve cells by a delay via the axon, based on which the membrane potential is adjusted to a certain base. Figure 1 shows this.",
            "cite_spans": [
                {
                    "start": 872,
                    "end": 876,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 2541,
                    "end": 2549,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "A Review of Deep Spiking Neural Network."
        },
        {
            "text": "Direct communication between spiking and analog neural networks is formed by assuming a stable state, by considering the activation of an analog neuron is equal to the firing rate of a spiking neuron. Many geometric models used those rate codes to describe brain computational processes. Nevertheless, more complex processes can also form the neural spike models, which depend on some reference signals or relative timing between spikes, such as network fluctuations. Temporary codes are very important in biology; even a spike or small time-consuming changes in neuron firing may cause different reactions, as most decisions must be calculated before a reliable estimation of the spike [30] .",
            "cite_spans": [
                {
                    "start": 687,
                    "end": 691,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "A Review of Deep Spiking Neural Network."
        },
        {
            "text": "In addition to the biological definition of SNNs, they contain a pragmatic functional representation in the field of neural engineering; SNNs are commonly referred to as spikes and are event-based. An event here is a collection of digital information defined by a time marker's origin and destination address. Unlike biologically motivated SNNs, it may have several bits of load information. The source for this protocol is the address index or AER (Address Event Representation) protocol, which is used after processing to link to event-based sensors through digital connection to neural chips or digital hardware. Event-based visual sensors use the loading bit to differentiate between silent and visual events; however, the loading bit can also be used to send other types of information to postsynapse targets, potentially to calculate more advanced functions than the fire integration method or integrate and fire used. The reason for researching SNNs is that, in real-world activities, the brains display considerable cognitive function. With continuing efforts to enhance our perception of brain-like calculations, models closer to biology are closer to achieving human intelligence than more abstract, or at least more computationally effective, models [30] .",
            "cite_spans": [
                {
                    "start": 1261,
                    "end": 1265,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "A Review of Deep Spiking Neural Network."
        },
        {
            "text": "In this way, SNN methods are ideally appropriate to process the space-time information based on neuro sensors, which are themselves energy-efficient. Sensors collect precise environmental information, and SNNs can use some useful time codes for their calculations. This information processing is also the focus of the event, which is denoted whenever 3 BioMed Research International a small amount of information is not recorded in the SNN; it does not do much calculation, but the SSN creates more spikes when an activity explosion is recorded. It leads to a very efficient way of calculation, assuming that information from the outside world is usually scattered. Also, timedomain input is another precious piece of information compared to framework-based approaches, where an artificial timeline is introduced entered by the sensor. It can result in an effective calculation features such as optical current or ste-reo inequality combined with spike-sensitive learning rules. In deep SNNs, asynchronous axis-based computing mode results in the rapid dissemination of prominent information through multiple network layers. In practical terms, SNNs must be run on neuromorphic hardware to take advantage of this effect. This process is a quasisimultaneous data processing combined with an event-based sensor, which implies that after the first input spikes are registered, the first estimated output of the final layer is immediately available. Also, for multilayered networks, it is right as the spikes extend immediately to the higher layers as soon as enough activity is generated by the bottom layer. You do not have to wait to complete of the complete input series, which is unlike traditional deep neural networks, where it is important to completely charge all layers until the final output is calculable. The primary performance spikes are inevitably based on incomplete data. It was thus concluded that deep SNNs would increase their efficiency in classification and decrease the processing time of the spike more than their input. To decrease the expected delays in inference, SNNs can also be specifically fitted. SNNs are the computational model chosen to run highly energy-efficient neuromorphic hardware devices supporting a data-driven processing mode and maintaining local calculations, thus prohibiting access to expensive memory [30] .",
            "cite_spans": [
                {
                    "start": 2348,
                    "end": 2352,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "A Review of Deep Spiking Neural Network."
        },
        {
            "text": "Here, despite recent advances, one of the major deep SNN disadvantages is their accuracy in standard metrics such as MNIST, CIFAR, or ImageNet which is not as good as that of their machine learning counterparts. The existence of the benchmarks present in traditional frame-based images can perhaps be attributed to this, to some extent. A sort of conversion of the picture to the Spark sequence that is typically inefficient is therefore required. The lack of training algorithms that take advantage of Spark neurons' features, such as efficient timescales, is another limiting factor. In contrast, several approaches employ many approximations according to the rate of use of convolutional deep learning neural networks, denoting that no progress can be expected. Deep SNNs may be practical in these cases and maybe faster, in which they get more efficient than convolutional systems, where SNN runs on diagonal neural hardware. For SNNs, the training algorithms are difficult to analyze due to their noncomputational and discontinuous computational methods, which generated direct use of successful techniques behind the scenes, especially for deep neural networks be difficult [30] . In traditional AI standards, the performance of SNNs should only be considered as concept proof, but not as the ultimate research goal. If biology is the model of spike networks, it can be concluded that they are designed for behavioral tasks such as making decisions based on continuous current input when moving in the real world. Whereas brains may solve these things, they are certainly not optimal for it. Recently, the Internet environment lacks good metrics and evaluation metrics that can measure effective performance in the real world [30] .",
            "cite_spans": [
                {
                    "start": 1180,
                    "end": 1184,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1732,
                    "end": 1736,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "A Review of Deep Spiking Neural Network."
        },
        {
            "text": "The preprocessing phase of the proposed approach is aimed at reducing the initial noise. In the following, the operation of segmentation and extraction of features is aimed at distinguishing tumor masses from the data set. The preprocessing section applies a method called Quantum Matched-Filter Technique, followed by a CRF-based QAIS-DSNN combination approach.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "3.1. Preprocessing Phase. Initially, there will be a preprocessing phase involving noise reduction. Every single image is displayed in a combination of local threshold and active contouring using a two-dimensional array of pixels; their values are integers in the range of [0,255]. Local thresholds initialize images in two steps. First, the input noise image is considered the primary image to which image noise removal will be applied. This operation is mainly utilized as a local search operator to enhance the initial images, using the Quantum Matched-Filter Technique (QMFT). The use of local thresholds and active contours has been used in this paper because they are computationally faster than other methods in the literature. Thus, at the end of the first step, there will be a decomposed image. In the second step, thresholding is done on the detail coefficients, and one of these decomposed sections is randomly selected and sent to a reconstruction operation. The reconstruction section can be defined: (iv) Implement light-intensive sections in quantum and reverse processing that performs the QMFT Then, the following operations are performed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "(i) One-point row: a pixel row is chosen randomly (ii) One-point column: it is identical to the preceding form, but instead of a row, the column is considered (iii) Point-to-point random: accidentally, every pixel is selected from the decomposition until a new image is created (iv) Identify all points in a row and column in the image to reduce the majority of noise as QMFT After analysis, when the selected range value [0.1] is less than the local search rate in the QMFT, a new image of the local search operator may pass. As the decomposition is complete, the entire image is sorted by its pixel value. Then the best aspect ratio in the image is considered as a quantum value in the sequel. A signal in MRI images may be broken down into multiple displaced or resized displays of features known at the feature extraction stage. Local thresholds and active contours can be used to analyze an image into its components. It is possible to perform image segmentation operations after applying QMFT along with local and active contouring thresholds. In this case, the local threshold coefficients and the active contour based on QMFT can be destroyed to eliminate some details. Local thresholds and QMFT-based active contours have a tremendous advantage in separating fine detail in an image. Active contour can be used to isolate very fine details of an image. At the same time, local thresholds can detect large details, combining fine and 5 BioMed Research International large details, and reading all rows and columns linearly and diagonally. Quantum satisfies QMFT to minimize the noise in the MRI image. QMFT based on local thresholds and active contours can create a sparse display. A local and active contouring threshold function with QMFT has two main features, the first of which is a function of oscillation or wave appearance, such as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "In this case, most of the energy in \u03a8 (t) is limited to a limited time, which is in the form of",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "The proposed method is generally calculated to reduce the noise in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "In Equation (3), the term \u00f0I \u2212 I 0 \u00de 2 ensures a certain degree of validity and accuracy between the rated and original image, in which I denotes the rated image while I 0 means the noisy image. The \u2207I parameter is defined as the sum of the variable adjustment periods, \u03b2 and \u03bb are the balancing parameters, and \u03a9 is the sum of the image's points. The purpose of minimizing Equation (3) is to decrease total image diversity while maintaining accuracy and validity. The balancing values are changed from 1 to the size of the image for both \u03b2 and \u03bb to minimize Equation (3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Approach"
        },
        {
            "text": "The deep spiking neural network presented in this study, due to its high flexibility, can use a linear and nonlinear functions such as sigmoid or sinusoidal in hidden layers. Use nonderivative as well as intermittent activation. By default, DSNN has",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "According to Equation (4), \u03b2 i displays the weights between the input and the hidden layers, and \u03b2 j displays the weights between the output and the input layers (b j ). The value of the neuron threshold is in the hidden layer or the bias. g\u00f0:\u00de is an activator or stimulus function. The weights of the input layer, w \u00f0i, j\u00de, and bias, b j , are randomly assigned. The beginning of the neuron number on the input layer n and the neuron number on the hidden layer m is assigned to activation function g\u00f0\u22ef\u00de. If the known param-eters in the general equilibrium are combined and controlled on the basis of this information, the output layer will be similar to",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The main goal is to minimize errors as much as possible in all models of training-based algorithms. The y p the output error function is obtained by the actual y main output in DSNN, which can be done with two training sections, \u2211 s k \u00f0y main \u2212 y p \u00de and the test section, k\u2211 s k \u00f0y main \u2212 y p \u00de 2 k. The output y p generated by the real output, y main , must be identical with the same y p for both functions. An unknown parameter is specified when this equation is performed and the results are satisfying. While spikes have been used to understand local label dependencies, for medical images such as MRI, they are not appropriate. Typically, that is because anatomical forms have complex shapes for models that are distinct.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "Moreover, either the temporal or the spatial relationship of MRI data also plays a critical role in classification, which should be paid attention to with regard to the method. Therefore, it is better to modify the mapping of the probability achieved by DSNN. A rather low-probability matrix may be the H-matrix, which means that the amount of data in the training process will not be identical to the total number of data characteristics. But it would be a big challenge to reverse \u00bdH and find weights or \u03b2. A fully connected CRF matrix is used to overcome this challenge in DSNN, which can develop an approximate reversal of the matrix that cannot be reversed. It can reduce the size, selection, and extraction of features at the segmentation with high precision and incredible speed compared to other methods. Currently, CRFs have been implemented in many medical imaging applications because they perform well when modeling some complex spatial data dependencies. In this way, to segment brain tumors, CRFs can be used not only to model the relationship between an image pixel and poster properties but also to make local pixel properties and their labels dependent. As discussed earlier, in [11] and [26] , CRFs were employed to visualize images through image formulation as neural networks. Nevertheless, the process of training their method is cumbersome and mathematically complex. In contrast, CRFs will be utilized as a suitable hash method. Using the fully connected matrix and CRF layer, the output matrix \u03b2 * and the matrix H * are all inverted and generalized by H. Therefore, due to the improvement of DSNN as CRF-DSNN in this section, the problem of the output weights in DSNN has been resolved and converted to B * = H * . In general, CRF-DSNN becomes a series of repeating units over time in the training phase. CRF-DSNN will be able to act as a belt conveyor and add or subtract information to neurons. Unlike deep learning structures and other classification models, such as backup conveyor machines or nanoscale works, no weight update is performed during training. CRF-DSNN can define features 6 BioMed Research International at the segmentation. By reducing CRF energy performance, a suitable model is taught that can be modeled as",
            "cite_spans": [
                {
                    "start": 1196,
                    "end": 1200,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1205,
                    "end": 1209,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 2116,
                    "end": 2117,
                    "text": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "where u, p \u2208 f1, 2, \u22ef, C n \u00de are the designations of the segmentation and i, j \u2208 f1, 2, \u22ef, Ng properties are specific pixels of the original image or I. \u03a8 p \u00f0y i \u00de = \u2212log P\u00f0y i | I\u00de is the negative logarithmic probability where P\u00f0y i | I\u00de is a probability obtained by DSNN per pixel i. While measuring the capabilities of a matrix pair of CRFs in a fully connected layer, it deals with the relationship between each pixel that is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "where M = 2, the number of Gaussian nuclei and w \u00f0m\u00de indicate a weight for the Gaussian nucleus mth, and \u03bc\u00f0y i , y j \u00de = \u00bdy i \u2260 y j is the label of consistent function. k \u00f01\u00de displays the core appearance, which tries to assign the same class labels to neighboring and adjacent pixels with the same intensity. k \u00f02\u00de displays the kernel smoothness, which is associated with eliminating unnecessary areas. These two steps are shown as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "e i and e j are the light intensities of the pixel i and j and s i and s j are the corresponding spatial coordinates. f i and f j mean the characteristics of each pixel pair, i.e., the brightness intensity and spatial information. \u03b8 \u03b1 , \u03b8 \u03b2 , and \u03b8 \u03b3 show the parameters of the Gaussian nucleus, respectively. However, some points in the mass may not be segmented in this way, so this algorithm optimization will be done in layers. In general, the DSNN method's layers are the use of the input layer with the number of neurons (spikes). Then, the structure of the training and testing layer used convolution, pooling, and fully connected layers along with CRF. Then, a SoftMax layer is embedded for it and then an output layer to display the work. The training layer window is in the form of a matrix, 9 \u00d7 9 in the convolution layer, 7 \u00d7 7 in the pooling layer, and 5 \u00d7 5 in the maximum section (Maxpool). The structure of the fully connected layer is 9 \u00d7 9. The SoftMax layer is also 7 \u00d7 7.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The Quantum Artificial Immune System (QAIS) is used to optimize the segmentation process during high-altitude neural network training in the SoftMax layer section. The QAIS uses a factor called an antigen. In an MRI image, all antigens are detected through a memory-based adult detection system, which has a fault tolerance experiment with a choice of the colon and immune mutations. Colonial choices and immune mutations are the other two factors of the QAIS algorithm. The more MRI data, the more copies are duplicated. In this algorithm, reproduction is plural, especially like a crossover in the genetic algorithm [12, 13] . Antibodies focus on modern quantum memory detection systems in mass segmentation in real time and examine detection and cross-sectional states against the MRI image structure.",
            "cite_spans": [
                {
                    "start": 618,
                    "end": 622,
                    "text": "[12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 623,
                    "end": 626,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The display of MRI image data is performed by a set of antigens Ag = fad | ad \u2282 Sg, in which the antigens determine the ad. They display one bit of binary string bits' properties that are represented by MRI image data antigens. These bits contain Trait codes. Also, S is the spatial state in the QAIS that is presented by S = f0, 1g l and displays all the activities of the primary population in the image in segmentation. l is the natural state number in the QAIS algorithm, which is considered as a constant value. There are two states of selfadjusting and non-self-adjusting in the artificial immune system algorithm. The self-adjusting state (self \u2282 Ag) displays all MRI image data and the non-self-adjusting state (nonself \u2282 Ag) displays all the segmented data. Therefore, there is a relationship between self-adjusting and non-selfadjusting states, represented by self \u222a nonself = Ag and self \u2229 nonself = \u2205 equations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The safety diagnostic set is also D = fab, p, t, age, cntj ab \u2208 S, p \u2208 R, t, age, cnt \u2208 Ng, where ab is the antibody, p is the concentration of the antibody, t is the tolerance of error, age indicates the age of memory and the maturity of genes, R is a set of real numbers, and N is the case number natural genes. Memory detection set M d = fd | d \u2208 D, d \u00b7 cnt > \u03b2g and the gene recognition maturity group are shown as T d = fd jd \u2208 D, d \u00b7 age < \u03bb, d \u00b7 cnt < \u03b2g. There is also immaturity, which is defined as the immaturity of genes that are expressed as I d = fdjd \u2208 D, d:t < \u03b1g. In these relationships, D = M d \u222a T d \u222a I d , where \u03b1 represents the threshold for error in detecting immature status, \u03bb represents the gene life cycle, and \u03b2 represents the threshold value for detecting gene maturity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "In order to establish and evaluate the structure of diagnostic development, an immature gene detector becomes the mature state detector, which will be successful in the fault tolerance phase. When the adaptive time between the adult gene detector in the gene's life cycle and the antigens activated exceeds the \u03b2 threshold, the adult detector clones or collects itself and then evolves into a memory detector. It means that genes and antigens will have a memory. Once the antigens are recognized by a specialist, he/she assembles the mature diagnostic compound. To ensure that antigens are effectively detected and that a variety of antibodies are detected in the reagent (mature or immature), they will detect known or unknown attacks. A total of three operators are used for the QAIS algorithm to improve the transverse distribution of MRI image data, which includes dependency assessment, reproduction selection, or safety and mutation combination, which are described separately.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "Hamming distance is used to compute the correlation for antigen detection. For example, the error tolerance mode is considered to create a model of correlation assessment. An unsuccessful identifier can succeed, if the immature identifier has never been compared to all elements of the self-organizing group in the \u03b1 variable. On the contrary, it can lead to the death of genes and antigens. The s \u2208 self is assumed, and Equation (10) shows how id is determined by the s.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "According to Equation (10), 1, 0 indicate whether the id is compatible with s and l d is the size of the id detector, so f affinity is used to calculate the correlation between s and id. Likewise, \u03b3 as \u03b3\u00f00 \u2264 \u03b3 \u2264 1\u00de represents the correlation threshold. Equation (11) is used to implement the mature error detector of the immature id, and Equation (12) is used to add the self-enforced identifier time when the results of the Equation (11) return to 1, and if t \u2265 \u03b1, the immature identity must develop into a mature",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The colonial or combination choice operator performs cellular operators in mature and memory diagnosis. Equation (13) is used to detect cloning state and a mixture of genes and antigens.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "According to Equation (13), \u03be \u00f0>0\u00de is a colonial or combination constant. N d = T d \u222a M d shows all the combinations. The colonial determinant or combination factor is used to analyze the performance of cellular operators in mature and memory diagnosis. Equation (13) is used to detect the cloning state and a mixture of genes and antigens. In Equation (14), T cln and M cln display the colonic selection group or group of memory and mature detectors. After making a colonial selection or group of genes and antigens in a generation, the cloned or combined section is added to the adult diagnostic group, and the same detector d t \u00f0\u2208T d \u00de, in the colonial selection group, or the T cln and M cln combination will be removed.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 267,
                    "text": "(13)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "The goal of the immune mutation operator is to enhance the detector's diversity with the mutation of the antibody generation in the corresponding detector, which is used to improve the ability to detect antigens. Considering the \u00f0l d \u2212 f affinity \u00f0d, ag\u00de\u00de bit, the d\u00f0\u2208N d \u00de detector set is matched by the ag\u00f0\u2208Ag\u00de antigen; these bits are used by 0.1 instead of randomly. l d displays the size of d. The mutant detector is used as an immature detector by the self-regulating set. To detect the adult mode, if the adaptive time is greater than the activated threshold \u03b2, the stimulus operation is performed using Equation (13) and then combined with the memory detector according to",
            "cite_spans": [
                {
                    "start": 619,
                    "end": 623,
                    "text": "(13)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "Equation (15) is assumed to represent the arranged numbers of the reagent that can be matched with antigens. Therefore, the memory diagnosis segment is combined with Equation (16) , but this occurs when the memory diagnosis segment can be successfully matched with antigens.",
            "cite_spans": [
                {
                    "start": 175,
                    "end": 179,
                    "text": "(16)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "Equation (17) also illustrates a different type of antigen removed in the MRI image data for display.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "Intensity and variety are two important features of swarm intelligence algorithms. The intensity is in the search of the best-obtained solutions and choosing the best candidate points. It is worthwhile to mention that the diversification procedure can allow the optimizer to explore the search space more efficiently. Inertial weight parameters \u00f0w n , w f \u00de indicate changes in optimal global attractiveness that affect the convergence rate and update each mass's position in the combination algorithm QAIS-DSNN. In the proposed QAIS-DSNN hybrid algorithm, the inertial weights \u00f0w n , w f \u00de are set to a large value to emphasize exploration, i.e., 0.9, which are set in the initial search mode, finally reduced to 0.1 linearly for the importance of linear optimization. Inspired by the classic artificial immune system, it is guaranteed that quantitatively, global characteristics for optimal segmentation can be determined when using the spiking neural network. As the number of repetitions increases, the initial population is encouraged to local search. Finally, the population should only carefully search for a local area without discovery to find out if there are any other masses. As a result, the first quantum combination strategy is to provide a linear weight reduction of the new frequency. The model \u00f0w n , w f \u00de is created as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "where \u00bd0:1, 0:9 is the inertial weight range and MI is the maximum number of repetitions, in which J denotes the number of repetitions. As such, both w n and w f are linearly decreased from 0.9 to 0.1 in the repeat cycle. The developed mixed QAIS-DSNN algorithm may be trapped in local improvement due to the presence of different iterative cycles in the tumor fractionation improvement process, in addition to the high research capacity. Therefore, to solve this problem, it is possible to provide a comparative update strategy for the C best parameter that is best to assist neurons and primary residents of the proposed algorithm out of the optimal local areas. In this strategy, C best is considered the best at a great value in the initial phase of finding the optimum value of the QAIS-DSNN algorithm with strong exploration ability (global search) and gradually decreasing with increasing frequency for accurate searching. Equation (19) displays the optimal value for the better adaptive update scheme C best used here.",
            "cite_spans": [
                {
                    "start": 939,
                    "end": 943,
                    "text": "(19)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "where J means the number of repetitions, whereas MI denotes the maximum number of repetitions. The next step is to introduce a novel method for updating the neurons and the initial population to accelerate global convergence. Initially, the status vector is updated by ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Segmentation with QAIS-DSNN Combined Approach."
        },
        {
            "text": "where NV is the total number of variables, UB j is the upper limit, and LB j is the lower limit of the variable in the j th variable. C t is the search environment, the same as the main input image. Randomization is then performed that prevents trapping in the optimal local solution, so randomization is introduced in Equation (21) with the value of \u03b1 rand , which is a randomization parameter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "BioMed Research International"
        },
        {
            "text": "where X gbets is the position of each neuron, and the initial population of the combination approach and rand is a random number generated, represented as a uniform distribution in the range of \u00bd0, 1. In general, the flowchart of the proposed approach is shown in Figure 2 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 264,
                    "end": 272,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "BioMed Research International"
        },
        {
            "text": "where t is the maximum repetition cycle, n denotes the number of neurons or initial population, and d is the dimensions of the problem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Investigating the Computational"
        },
        {
            "text": "BraTS data is a collection of brain tumor MRI images, including 145 folders for patients under different conditions. The dataset consists of 4 versions from 2012 to 2018. Database versions are getting better every year. The primary data is in DICOM format which have been converted to JPEG format for easier use through DICOM Viewer software. The input images are three-dimensional. Due to the large size of the images in the BraTS, we used 1000 video input samples to study the proposed approach. The simulation will be done in MATLAB 2015b environment and a system with 7-core processor specifications with 6 MB of cache and 3.6 MHz and 6 GB of memory in Windows 10. When the simulation is performed, all BraTS2018 data are trained and tested by the proposed method. For visualization, an example of images is shown to examine the proposed approach's results, step by step. Initially, the input image is given to the system, as shown in Figure 3 . In all BraTS2018 data images, an initial noise reduction is required, using the QMFT algorithm, in which the image is read linearly, columnar, and diagonally without any repetition to reduce noise. The schematic of this output is in the form of Figure 4 , and the result of the image that the noise reduction operation and its initial highlighting is in Figure 5 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 939,
                    "end": 947,
                    "text": "Figure 3",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1195,
                    "end": 1203,
                    "text": "Figure 4",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1304,
                    "end": 1312,
                    "text": "Figure 5",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Simulation and Results"
        },
        {
            "text": "The value of peak signal-to-noise ratio (PSNR) is illustrated in Figure 6 . The analysis is done for 1120 MRI images. The mean value of PSNR is 87.35. It can be seen that the noise reduction provides an interesting picture in which a good segmentation can be applied. For this purpose, a deep neural network spiking or DSNN method is applied to the noise reduction operation output, and the BraTS2018 video data set is trained, which will be 75% training and 25% test. But the combined DSNN approach with the QAIS algorithm is made in this section so that the overall result is visible. According to the DSNN structure, it is observed that five input layers are considered, in which all BraTS2018 video data are placed. Then, there are three rows of training layers, the first of which is the training deep layer. In this row, from the deep layer, one by one, the convolution layer with 9 \u00d7 9 windowing, and then the random polarizing layer with 7 \u00d7 7 windowing, again the convolution layer with 9 \u00d7 9 windowing, and then the maximum polarization layer as 5 \u00d7 5 is located. The stimulus function of this layer is a zygomatic logarithm in that the number of general layers is 20. Then, the fully connected layer is associated with CRF, which is considered as 10 layers.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 65,
                    "end": 73,
                    "text": "Figure 6",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Simulation and Results"
        },
        {
            "text": "Then, there is a SoftMax layer with the QAIS algorithm designed to optimize DSNN segmentation during training and testing, more accurate mass detection, and feature selection operations. Its drive function is linear. There are separate settings for the QAIS algorithm. The initial population of this algorithm is considered to be 200. The colonial rate is 0.04, and its repetition rate is 10 cycles for optimizing the DSNN algorithm segmentation and selecting features in the SoftMax layer. In the end, there is an output layer that is a layer to display the output. The number of raw data training and testing rounds in QAIS-DSNN is equal to 7000 rounds. The QAIS-DSNN core is resilient back-propagation, and its performance is measurable with average error squares. The training process is illustrated in Figure 7 . The termination criterion for the training process is mean square error as 10 \u22125 . Regrading Figure 7 , 1342 epochs lead to converge the training process. When the proposed approach is applied to multiple images, the overall result will be Figure 8 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 807,
                    "end": 815,
                    "text": "Figure 7",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 911,
                    "end": 919,
                    "text": "Figure 7",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1058,
                    "end": 1066,
                    "text": "Figure 8",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Simulation and Results"
        },
        {
            "text": "The ROC chart and the AUC rate are the proposed approach in Figure 9 . This curve is known as one of the most important evaluation criteria, which measures the efficiency of classification operations in a system. In general, in a binary classification system in which the differentiation threshold differs, the ROC curve is a graphical representation of the degree of sensitivity or correct prediction versus false prediction. The ROC curve is also shown by plotting the correct positives against the predicted false positives. A number which measures and evaluates an aspect of performance is the area below the ROC curve. This area below the curve is called the AUC. A value above 0.7 to 1 indicates an excellent level of prediction and classification performance. According to Figure 9 , it is observed that the value of AUC is a number below one, which shows the optimization of the proposed approach as much as possible. The presence of some similar sections with cancerous masses in the available data and presented method led to the creation of a series of minor errors that have not been adapted to the fitting line. The blue circles are the criterion values, and the red line is the ROC diagram on which the data is fitted. In some areas where the data is a bit far away, an error occurs and leads to a decrease in inaccuracy. Also in the middle line is regression called the ROC peak relative to regression, and the area below it is AUC. After applying the proposed approach, it is necessary to compare the proposed approach with other proposed methods, which are examined in terms of different evaluation criteria to determine the guarantee of the proposed approach. For this purpose, Table 1 shows a comparison in terms of average error squares, signal-to-noise ratio, and accuracy. Also, a comparison has been made in terms of Dice evaluation criteria for tumor nucleus, total tumor, and tumor areas, the results of which can be seen in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 60,
                    "end": 68,
                    "text": "Figure 9",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 780,
                    "end": 788,
                    "text": "Figure 9",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1696,
                    "end": 1703,
                    "text": "Table 1",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 1950,
                    "end": 1957,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "BioMed Research International"
        },
        {
            "text": "The next comparison is the percentage-based accuracy for segmentation to distinguish the mass region from the images, which are averaged from the BraTS data set. The results are reported in Table 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 190,
                    "end": 197,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "BioMed Research International"
        },
        {
            "text": "Finally, a comparison is made in terms of computational complexity in terms of time between the method presented in [25] , the results of which are shown in Table 4 . It is noteworthy that this study has listed the system used during the processing of the proposed method, and this comparison is made on a case-bycase basis with reference [25] . Based on the results of the comparisons in terms of evaluation, it is observed that the proposed approach is optimal in terms of the mean error squares of most methods, but the GCNN [25] and BAT-IT2 FCM [38] algorithms have better results than the research approach. In terms of signal-tonoise ratio, the proposed method of compared algorithms has had better results. In terms of Dice evaluation criteria, most research is on the same level. There are differences in the parts of the whole tumor, the tumor nucleus, or the improved part of the tumor, depending on the different methods available. In terms of accuracy, the prediction approach has better results, but with the GCNN [25] algorithm, it is 0.01% more efficient. Also, the results were obtained at the level of convolutional methods, and the computational complexity of the proposed approach has been implemented in the system; however, the computational complexity can be seen by combining the existing algorithms.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 120,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 339,
                    "end": 343,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 528,
                    "end": 532,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1027,
                    "end": 1031,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 157,
                    "end": 164,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "BioMed Research International"
        },
        {
            "text": "This article is innovative in the field of noise reduction and segmentation of MRI images to detect the area of tumor masses. Also, we used the QMFT method to find noise and reconstruct it with adjacent pixels to process them horizontally, vertically, and diagonally. It is formed in the fastest time and has been able to move the noise by identifying and reviewing neighbors and matching the pixel data with neighbors based on the edge of the image. Then, the segmentation operation was performed with a QAIS-DSNN combination approach. In this approach, the deep neural network of spiking with CRF is considered, so that after the input layer-including neurons (spikes)-the training layer has convolution and polarizing layers. All of them are connected to the CRF format. Then, there is a SoftMax layer outside the training layer, which is optimized for segmentation and detection to accurately identify tumor features, in this method with the QAIS. The simulation results show that the proposed QAIS-DSNN approach has a functional advantage over the previous methods evaluation criteria. Among these evaluation results, we can point out the accuracy in segmentation and detection of the exact mass area in MRI images with an accuracy of 98.21%. Also, the average rate of error squares is 0.006, and the peak rate of the signal-to-noise ratio is 97.79 decibels. The use of lesion structural criteria includes a tumor nucleus of 80.15%, improved tumor of 74.50%, and a total tumor of 91.92%, which is a functional advantage over similar previous methods. Reducing computational complexity compared to previous methods and improving execution time by 2.58 seconds also confirms it. In the future, the plan is to use a huge dataset or transfer this system to the breast, lung, and some other tumor detection tasks. Moreover, we are going to add this automated segmentation method for CNN-based segmentation ground truth images. Furthermore, the presented filtering system can be added as a layer in the CNN method and change the resolution of the matrix in each iteration.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The data that support the findings of this study are openly available in BraTS2013, BraTS2015, and BraTS2018 at https://www.med.upenn.edu/sbia/brats2018/data.html",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data Availability"
        },
        {
            "text": "The funding sources had no involvement in the study design, collection, analysis or interpretation of data, and writing of the manuscript or in the decision to submit the manuscript for publication.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Disclosure"
        },
        {
            "text": "We declare no conflict of interest. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflicts of Interest"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A survey of MRI-based medical image analysis for brain tumor studies",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bauer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wiest",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "P"
                    ],
                    "last": "Nolte",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Reyes",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Physics in Medicine and Biology",
            "volume": "58",
            "issn": "13",
            "pages": "97--129",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The 2016 world health organization classification of tumors of the central nervous system: a summary",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "N"
                    ],
                    "last": "Louis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Perry",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Reifenberger",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Acta Neuropathologica",
            "volume": "131",
            "issn": "6",
            "pages": "803--820",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "The multimodal brain tumor image segmentation benchmark (BRATS)",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "H"
                    ],
                    "last": "Menze",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jakab",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bauer",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "34",
            "issn": "10",
            "pages": "1993--2024",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bakas",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Scientific Data",
            "volume": "4",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A survey on deep learning in medical image analysis",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Litjens",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kooi",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "E"
                    ],
                    "last": "Bejnordi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Analysis",
            "volume": "42",
            "issn": "",
            "pages": "60--88",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Diagnosis and detection of infected tissue of COVID-19 patients based on lung X-ray image using convolutional neural network approaches",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hassantabar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sharifi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos, Solitons & Fractals",
            "volume": "140",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Brain tumor segmentation using convolutional neural networks in MRI images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pinto",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Alves",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Silva",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1240--1251",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "The multimodal brain tumor image segmentation based on convolutional neural networks",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Mengqiao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jie",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yilei",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Hao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 2nd IEEE International Conference on Computational Intelligence and Applications (ICCIA)",
            "volume": "",
            "issn": "",
            "pages": "336--339",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Brain tumor segmentation with deep neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Havaei",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Davy",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Warde-Farley",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Analysis",
            "volume": "35",
            "issn": "",
            "pages": "18--31",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "DeepIGeoS: a deep interactive geodesic framework for medical image segmentation",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Zuluaga",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "41",
            "issn": "7",
            "pages": "1559--1572",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "A deep learning model integrating FCNNs and CRFs for brain tumor segmentation",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical Image Analysis",
            "volume": "43",
            "issn": "",
            "pages": "98--111",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Presentation of a new hybrid approach for forecasting economic growth using artificial intelligence approaches",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jafarzadeh-Ghoushchi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Taghizadeh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sharifi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Neural Computing and Applications",
            "volume": "31",
            "issn": "12",
            "pages": "8661--8680",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Application of gene expression programming and sensitivity analyses in analyzing effective parameters in gastric cancer tumor size and location",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dorosti",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Ghoushchi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Sobhrakhshankhah",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sharifi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Soft Computing",
            "volume": "8",
            "issn": "",
            "pages": "1--22",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Brain tumor segmentation using large receptive field deep convolutional neural networks",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Isensee",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kickingereder",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bonekamp",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Bildverar-beitung f\u00fcr die Medizin",
            "volume": "",
            "issn": "",
            "pages": "86--91",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Dual-force convolutional neural networks for accurate brain tumor segmentation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Pattern Recognition",
            "volume": "88",
            "issn": "",
            "pages": "90--100",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Deep Learning Based Brain Tumor Segmentation: A Survey",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Retinal vessel segmentation of color fundus images using multiscale convolutional neural network with an improved cross-entropy loss function",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Niu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Neurocom-puting",
            "volume": "309",
            "issn": "",
            "pages": "179--191",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kamnitsas",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ledig",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "F J"
                    ],
                    "last": "Newcombe",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Analysis",
            "volume": "36",
            "issn": "",
            "pages": "61--78",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Automatic brain tumor segmentation using cascaded anisotropic convolutional neural networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ourselin",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Vercauteren",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings International MIC-CAI Brainlesion Workshop",
            "volume": "",
            "issn": "",
            "pages": "178--190",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Conditional random fields as recurrent neural networks,\" in Proceedings of the IEEE international conference on computer vision",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jayasumana",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Romera-Paredes",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1529--1537",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The virtual skeleton database: an open access repository for biomedical research and collaboration",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kistler",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bonaretti",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pfahrer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Niklaus",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "B\u00fcchler",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Journal of Medical Internet Research",
            "volume": "15",
            "issn": "11",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "3D MRI brain tumor segmentation using autoencoder regularization",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Myronenko",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings International MIC-CAI Brainlesion Workshop",
            "volume": "",
            "issn": "",
            "pages": "311--320",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Semantic image segmentation with deep convolutional nets and fully connected CRFs",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "C"
                    ],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Papandreou",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kokkinos",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Murphy",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "L"
                    ],
                    "last": "Yuille",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Conditional random fields as recurrent neural networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jayasumana",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Romera-Paredes",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 IEEE International Conference on Computer Vision (ICCV)",
            "volume": "",
            "issn": "",
            "pages": "1529--1537",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Deep learning based enhanced tumor segmentation approach for MR brain images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mittal",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "Jude"
                    ],
                    "last": "Hemanth",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Applied Soft Computing",
            "volume": "78",
            "issn": "",
            "pages": "346--354",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "AFPNet: a 3D fully convolutional neural network with atrous-convolution feature pyramid for brain tumor segmentation via MRI images",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Neurocomputing",
            "volume": "402",
            "issn": "",
            "pages": "235--244",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Automatic brain tumor segmentation using convolutional neural networks with test-time augmentation",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ourselin",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Vercauteren",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "International MICCAI Brainlesion Workshop",
            "volume": "",
            "issn": "",
            "pages": "61--72",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Brain tumor segmentation using multi-cascaded convolutional neural networks and conditional random field",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kai",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Qinghai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "8",
            "pages": "92615--92629",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A heuristic neural network structure relying on fuzzy logic for images scoring",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Fuzzy Systems",
            "volume": "29",
            "issn": "1",
            "pages": "34--45",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Deep learning with spiking neurons: opportunities and challenges",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pfeiffer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pfeil",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Frontiers in neuroscience",
            "volume": "12",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "https:/www.frontiersin.org/articles/10.3389/fnins.2018.00774/full"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Multi-channeled MR brain image segmentation: a new automated approach combining BAT and clustering technique for better identification of heterogeneous tumors",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Alagarsamy",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kamatchi",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Govindaraj",
                    "suffix": ""
                },
                {
                    "first": "Y.-D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Thiyagarajan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Biocybernetics and Biomedical Engineering",
            "volume": "39",
            "issn": "4",
            "pages": "1005--1035",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Active deep neural network features selection for segmentation and recognition of brain tumors using MRI images",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "I"
                    ],
                    "last": "Sharif",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Saleem",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Pattern Recognition Letters",
            "volume": "129",
            "issn": "",
            "pages": "181--189",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "An integrated design of particle swarm optimization (PSO) with fusion of features for detection of brain tumor",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sharif",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Amin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yasmin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "C"
                    ],
                    "last": "Satapathy",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Pattern Recognition Letters",
            "volume": "129",
            "issn": "",
            "pages": "150--157",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "General structure and mechanism of a spiking neural network or SNN [",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Gaussian blur: uses a Gaussian filter to filter the image. Between 3 \u00d7 3 pixels and 5 \u00d7 5 pixels, the filter size is accidentally selected (ii) Mean filter (averaging filter): filters the image using an average filter (iii) Intensity change: all image pixels are multiplied by a similar criterion randomly selected in the range [0.7, 1.3]",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Flowchart of the proposed approach.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Input image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "QMFT noise reduction algorithm applied in a row, column, and diagonal without repetition.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The result of image noise reduction and highlighting.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The PSNR criterion for noise reduction measurement. Mean square error of the training process for 1342 epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Display of training operations to test the segmentation of the image and identify the masses. From left to right: the overall result of noise reduction as input in QAIS-DSNN and QAIS-DSNN approach segmentation, finding necrosis, and finding edema (part completely black) and nucleus (the almost white part inside the edema).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Complexity of the QAIS-DSNN Method. Here, the computational complexity of the developed QAIS-DSNN algorithm is investigated. Computational complexity includes temporal and spatial complexity. The time complexity of the QAIS-DSNN algorithm depends on two steps including calculation of the motion and updating of the positions of the neurons and the initial population. Therefore, the complexity of time can be defined in O QAIS-DSNN \u00f0 \u00de = O\u00f0t\u00f0O intensity neighbor edges \u00f0 \u00de + O position update \u00f0 \u00de \u00de\u00de,\u00f022\u00de",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "ROC diagram and AUC rate.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "The comparison of the proposed approach with previous ones in terms of Dice evaluation criteria.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Comparison of the proposed approach with previous methods in terms of accuracy in terms of percentage.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The comparison of the proposed approach with previous ones in terms of mean square error, peak signal-to-noise ratio, and accuracy.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Comparison of the proposed approach with previous methods in terms of computational complexity over time.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}