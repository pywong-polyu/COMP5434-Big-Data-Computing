{
    "paper_id": "c4962b4c1a92cc82dc5788a5dd56488cc6d56780",
    "metadata": {
        "title": "Artificial intelligence applied to bailout decisions in financial systemic risk management",
        "authors": [
            {
                "first": "Daniele",
                "middle": [],
                "last": "Petrone",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Queen Mary University of London. Mile End Road",
                    "location": {
                        "postCode": "E1 4NS",
                        "settlement": "London",
                        "country": "UK"
                    }
                },
                "email": ""
            },
            {
                "first": "Neofytos",
                "middle": [],
                "last": "Rodosthenous",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Queen Mary University of London. Mile End Road",
                    "location": {
                        "postCode": "E1 4NS",
                        "settlement": "London",
                        "country": "UK"
                    }
                },
                "email": ""
            },
            {
                "first": "Vito",
                "middle": [],
                "last": "Latora",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Queen Mary University of London. Mile End Road",
                    "location": {
                        "postCode": "E1 4NS",
                        "settlement": "London",
                        "country": "UK"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "We describe the bailout of banks by governments as a Markov Decision Process (MDP) where the actions are equity investments. The underlying dynamics is derived from the network of financial institutions linked by mutual exposures, and the negative rewards are associated to the banks' default. Each node represents a bank and is associated to a probability of default per unit time (PD) that depends on its capital and is increased by the default of neighbouring nodes. Governments can control the systemic risk of the network by providing additional capital to the banks, lowering their PD at the expense of an increased exposure in case of their failure. Considering the network of European global systemically important institutions, we find the optimal investment policy that solves the MDP, providing direct indications to governments and regulators on the best way of action to limit the effects of financial crises.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "We describe the bailout of banks by governments as a Markov Decision Process (MDP) where the actions are equity investments. The underlying dynamics is derived from the network of financial institutions linked by mutual exposures, and the negative rewards are associated to the banks' default. Each node represents a bank and is associated to a probability of default per unit time (PD) that depends on its capital and is increased by the default of neighbouring nodes. Governments can control the systemic risk of the network by providing additional capital to the banks, lowering their PD at the expense of an increased exposure in case of their failure. Considering the network of European global systemically important institutions, we find the optimal investment policy that solves the MDP, providing direct indications to governments and regulators on the best way of action to limit the effects of financial crises. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "In times of crisis, as during the recession of 2008 or the economic disruption triggered by the COVID-19 pandemic, the governments face difficult decisions regarding bailing-out strategically important companies. In particular, large banks are critical for the stability of the financial system and are closely monitored by central banks and governments. As an example, to rescue Royal Bank of Scotland (RBS) in 2008-2009, the UK government became the majority shareholder of the bank, purchasing shares for a total 45.5 billion pounds [5] . The government achieved its objectives to stabilise the financial system, and no depositor in UK banks lost money. However, the cost for taxpayers has been estimated by the Office for Budget Responsibility (OBR) to be in the region of 27 billion pounds as of March 2018 [2] . The price of RBS shares plummeted after the purchase and the government has since sold part of its investment at a loss. Was the government intervention value for money? The National Audit Office (NAO) is the UK's public spending watchdog and in December 2009 released the report \"Maintaining financial stability across the United Kingdom's banking system\" [3] where they analysed the government support for the banking sector and the conclusion was that: \"If the support measures had not been put in place, the scale of the economic and social costs if one or more major UK banks had collapsed is difficult to envision. The support provided to the banks was therefore justified, but the final cost to the taxpayer of the support will not be known for a number of years\". NAO did not produce an estimate of the impact in case of inaction of the government. In this paper, we propose a mathematical framework that allows a quantitative comparison between investment decisions by the government. * Electronic address: v.latora@qmul.ac.uk Our framework is based on the three following building blocks: (a) a dynamical network model of the financial system with a contagion mechanism between financial institutions; (b) a set of allowed government interventions to control the network; and (c) a quantitative way to assess the government actions at each time step. A network model [11] [14] [19] [20] is essential, as the main concern is not the direct cost of a default but the systemic risk that it entails. Systemic risk can be defined as the risk that large part of the financial system is disrupted and as such it requires connections between financial institutions that can transfer the distress along the network [12] [13] [16] . The contagion mechanism that we use is the impact that a bank default has on other banks [6] . The impact can be due to direct losses in bilateral credit exposures [23] [22] (for example if they had lent money to the defaulting bank), or indirect losses due to fire selling of assets by the defaulting bank [15] , that would lower the market value of similar assets in the balance sheet of the other financial institutions. The impact would lower the capital buffer of the affected banks, weakening the network and its ability to withstand future shocks. In particular, the probability of default per unit time (PD) of the nodes (banks or financial institutions) would increase, hence increasing the expected loss in the network [6] . One main novelty of our model is that we allow for the network to be controlled by a government investment in the capital of the banks. Such an investment would, conversely, decrease the PD of the banks that receive the additional capital, but also increase the loss for the government in case of default. In our framework, the connection between the change in PD and the variation in the amount of capital is provided by the Merton model of credit risk [18] . To follow the evolution in time of the network, we simulate the default process given the PD of the nodes and their tendency of defaulting during the same time step. Finally, we use artificial intelligence techniques [24] [26] [28] to assess the optimality of government decisions (no investment vs different amounts of investment), recasting the system as a Markov Decision Process (MDP) [29] where the actions (controls) are government investments at each time step.",
            "cite_spans": [
                {
                    "start": 536,
                    "end": 539,
                    "text": "[5]",
                    "ref_id": null
                },
                {
                    "start": 812,
                    "end": 815,
                    "text": "[2]",
                    "ref_id": null
                },
                {
                    "start": 1175,
                    "end": 1178,
                    "text": "[3]",
                    "ref_id": null
                },
                {
                    "start": 2195,
                    "end": 2199,
                    "text": "[11]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 2200,
                    "end": 2204,
                    "text": "[14]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 2210,
                    "end": 2214,
                    "text": "[20]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 2534,
                    "end": 2538,
                    "text": "[12]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 2544,
                    "end": 2548,
                    "text": "[16]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 2640,
                    "end": 2643,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 2715,
                    "end": 2719,
                    "text": "[23]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 2720,
                    "end": 2724,
                    "text": "[22]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 2858,
                    "end": 2862,
                    "text": "[15]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 3280,
                    "end": 3283,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 3740,
                    "end": 3744,
                    "text": "[18]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 3964,
                    "end": 3968,
                    "text": "[24]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 3974,
                    "end": 3978,
                    "text": "[28]",
                    "ref_id": null
                },
                {
                    "start": 4136,
                    "end": 4140,
                    "text": "[29]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The paper is structured as follows. In section II A we describe the network of financial institutions, its dynamics and contagion mechanism, and then in section II B we introduce a Markov Decision Process based on the network, in order to model government interventions on bailed-out banks. We continue in section II C with presenting our strategy to solve the MDP, by finding the optimal government investment decision for each state of the network and time. Section III contains our results, obtained by applying our model to a homogeneous network organised as a Krackhardt kite graph (see Fig.  1 ) and to the network of the European Global Systemically Important Institutions. We have found that a preexisting investment in a distressed node makes it convenient for the government to intervene again to try to save the invested capital (creating moral hazard as the node could act haphazardly relying on the implicit government guarantee). Moreover, by changing the parameter \u03b1, that accounts for the taxpayers' loss in case a bank defaults, we have observed that there is a 'critical' value that separates networks for which the inaction of the government is the best option from networks where an investment of the government would be the optimal decision as it would lower the overall expected loss of the system. Finally, we provide our conclusions in section IV.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 592,
                    "end": 599,
                    "text": "Fig.  1",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "We consider a network G with a set I = {1, ..., N } of nodes representing financial institutions. Each node i \u2208 I is characterised at time t by a probability of default P D i (t) \u2208 (0, 1] per time interval \u2206t, a total asset W i (t) and an equity E i (t) (such that E i (t) \u2264 W i (t)), that is the capital used by node i as a buffer to withstand financial losses . The edges w ij of the network represent the exposure of node i to the default of node j for all i = j \u2208 I. To take into account government interventions aimed at limiting the overall losses, we use an adaptation of the 'PD Model' described in [6] by extending it to allow the possibility for the nodes (banks) to incur positive shocks, via investments in the nodes, rather than just negative shocks due to the default of other nodes. The focus has also changed from the one in [6] , as we are now exclusively interested in the losses incurred by the taxpayers, disregarding the losses sustained by private investors. In the following, we will measure the time in discrete time steps that are multiples of \u2206t, i.e. t + 1 is equivalent to t + \u2206t.",
            "cite_spans": [
                {
                    "start": 607,
                    "end": 610,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 841,
                    "end": 844,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "We define the total impact I i (t) on node i at time t, due to the default of other nodes j \u2208 I \\ {i} in the network as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "where \u03b4 j (t) = 1 if and only if node j defaults at time t and \u03b4 j (t) = 0 otherwise. The impact I i (t) represents a loss for the total asset W i , which in turn decreases also the equity E i of node i, hence reducing their value at time t + 1. This can be seen from the accounting equation for each node i, namely",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "which states that the total asset W i is always equal at all times to the equity E i plus the total liability B i . Note that B i is not affected by the losses as it is comprised of loans from other banks, deposits, etc., that are due in full unless the bank i defaults. Hence, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "where we define \u2206X i (t) := X i (t + 1) \u2212 X i (t). We can therefore write",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "where \u2206J i (t) denotes the potential increase in the current investment J i (t) of the government in node i at time t.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "On the other hand, the probability of default P D i (t) of node i is increased by the impact I i (t) at time t, since part of the capital buffer (equity E i ) is lost. In order to model the effect of the impact I i (t) on P D i (t), we use the Merton model for credit risk [18] to calculate the 'implied probability of default' P DM as a function of the parameters of each node:",
            "cite_spans": [
                {
                    "start": 273,
                    "end": 277,
                    "text": "[18]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "where the term W \u2212 E represents the total liability B of each bank, \u03a6 is the univariate standard Gaussian distribution, \u00b5 is the drift and \u03c3 is the volatility of the geometric Brownian motion associated to the total asset W in the Merton model. We then use (6) to obtain where we introduced the fixed number \"P DM f loor i \" representing the lower bound of the P D i that is used to exclude unreasonably low probabilities of default. For example, it is a standard assumption for the P D i of a bank i to be greater or equal to the probability of default of the country where it is based. In this context, the latter is the probability of a country defaulting on its debt. Now, if node i loses an amount of capital I i (t) at some time t greater or equal to its buffer E i (t), the total asset W i (t) becomes less than its liability B i (t) and it is convenient for the shareholders to exercise their option to default. In practice, when this occurs, we set P D i (t+1) = 1 and node i will default at time t + 1. Moreover, recall that node i may also default at any time t with probability P D i (t) due to its own individual characteristics given by (7) ; see also the default mechanism in (11) below. Now, when node i defaults, we denote by LGD i the \"Loss Given Default\" of node i, which is a fixed number representing the percentage of the investments J i on node i by the government, that cannot be recovered after a default. In case of default of node i, we further assume that in addition to the aforementioned loss of investments, the taxpayers' loss L i is also comprised of a fixed percentage \u03b1 i (for convenience) of the total asset W i of the node. That is, the taxpayers' overall loss L i is given by",
            "cite_spans": [
                {
                    "start": 1151,
                    "end": 1154,
                    "text": "(7)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "To complete our framework we need to specify the probability of more than one default happening during the same time step, given the P D i of each node i obtained by (7) . For example, if the nodes were independent the probability of nodes i and j defaulting at the same time step, denoted by P D [ij] , would be the product of the individual probabilities P D i and P D j . In this paper, we allow nodes to depend on each other and use a Gaussian latent variable model [17] to calculate the probabilities of simultaneous defaults of two or more nodes.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 169,
                    "text": "(7)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 297,
                    "end": 301,
                    "text": "[ij]",
                    "ref_id": null
                },
                {
                    "start": 470,
                    "end": 474,
                    "text": "[17]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "To be more precise, the probability of a finite subset of nodes {i, j, k, ...} \u2286 I in the network G defaulting at the same time, is given by the following integral",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "where \u03a6 N is the standardised multivariate Gaussian density function with zero mean and a symmetric correlation matrix \u03a3 \u2208 [\u22121, 1] N \u00d7N given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "and |\u03a3| is the determinant of \u03a3. We further note that the integration domain D in (9) is the Cartesian product of the intervals [\u2212\u221e, \u03a6 \u22121 1 (P D i )] for each node i that belongs to the set of defaulting nodes, and the intervals [\u2212\u221e, \u221e] for the remaining nodes, where \u03a6 1 is the univariate standard Gaussian distribution.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "In the sequel, this model will also be used to simulate the default mechanism. To be more precise, by sampling values x 1 , ..., x N of the random vector X = (X 1 , X 2 , ..., X N ) T with the multivariate Gaussian distribution mentioned above, at each time step t, we will assume that node i defaults according to the rule:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Network of financial institutions"
        },
        {
            "text": "We describe the government decisions of bailing out banks as a Markov Decision Process (MDP) driven by the network framework described above. We assume that the government estimated that the crisis will likely be over at time M, and in any case it will be able to sell the shares of the rescued banks to the private sector for a price that is similar to the purchasing price. We define the 4-tuple (S, A s , P a , R a ) of the set S of all the states, set A s of all actions available from state s \u2208 S, transition probabilities P a (s, s ) = P (s t+1 = s |s t = s, a t = a) between state s at any time t and state s at time t + 1 having taken action a \u2208 A s at time t, and rewards (negative losses in our model) R a (s, s ) received after taking action a at any time t while being at state s and landing in state s at time t + 1, where s, s \u2208 S. Furthermore, a constant discount factor \u03b3 is defined with 0 \u2264 \u03b3 < 1, so that rewards obtained sooner are more relevant in the calculation of the cumulative reward CR over M steps. The latter is therefore defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Formulation of the banks bailout problem as a Markov Decision Process"
        },
        {
            "text": "In the remaining of this section, we expand on the 4-tuple (S, A s , P a , R a ) that defines our MDP.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Formulation of the banks bailout problem as a Markov Decision Process"
        },
        {
            "text": "MDP states. The states s t \u2208 S, at each time t, are defined by three main pilars: (a) all the parameters of ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Formulation of the banks bailout problem as a Markov Decision Process"
        },
        {
            "text": "The MDP actions in our model are injections of capital a t \u2192 \u2206J a (t) = (\u2206J a 1 (t), \u2206J a 2 (t), ..., \u2206J a N (t)) by the government to the nodes (1, 2, ..., N ). These additional resources on one hand, make the nodes more resilient, hence diminishing their probability of default via (4)- (7), but on the other hand they will be at risk in case of default since they increase each J i in (8) . These actions are the control variables of the government when trying to minimise the losses of the network (i.e. maximise the expected CR in (12) , see Section II C for more details).",
            "cite_spans": [
                {
                    "start": 388,
                    "end": 391,
                    "text": "(8)",
                    "ref_id": null
                },
                {
                    "start": 536,
                    "end": 540,
                    "text": "(12)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "We further assume that these government investments (relative to action a t ) decided at time t are implemented immediately, so that the probability of default P D i (t) given by (7), the default mechanism in (11) and subsequently the impacts I i (t), for each node i \u2208 I, are implemented using the updated",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": ". MDP transition probabilities. Within our framework, a node that has defaulted does not contribute to future losses and cannot become active again, i.e. the cardinality of the set of defaulted nodes |I def (t)| is a nondecreasing function of time t. Hence the transition probability P a (s, s ) from state s to s will be non-zero only for states s that: (a) have the same number or more defaulted nodes than state s; (b) are \"reachable\", in the sense that their P D i (t + 1), W i (t + 1) and E i (t + 1), for i \u2208 I \\ I def (t + 1) (the set of remaining active nodes in s ) take values that are coherent with equations (4)-(7) after calculating the impacts I i (t) from the nodes i \u2208 I def (t + 1) \\ I def (t). In order to illustrate the above we consider the following example.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "Example 1 Let us consider a network with three nodes I = {1, 2, 3} and w ij = 1 \u2200 i = j \u2208 I, at a time t, such that node 3 \u2208 I def (t) has already defaulted, while the remaining nodes have W i (t) = 100, E i (t) = 3 and P D i (t) = 0.001 for i \u2208 I \\ I def (t) = {1, 2}. In case the government does not intervene, the states s that can be reached are the ones where: (i) all the nodes default at time t, i.e. I def (t + 1) = I; (ii) nodes 1 and 2 are still active and W i (t+1), E i (t+1) and P D i (t+1) for i \u2208 {1, 2} are the same as for state s; (iii) node 1 defaults at time t while node 2 remains active, i.e. I def (t + 1) = {1, 3}, W 2 (t + 1) = 99 and E 2 (t + 1) = 2 (since the impact I 2 (t) = w 21 = 1) and P D 2 (t + 1) needs to take the value calculated via (7) using the W 2 (t+1) and E 2 (t+1) inputs; and (iv) node 2 defaults at time t but node 1 remains active, which is analogous to (iii) by swapping indices 1 and 2. Now, if the government decides to invest, i.e. a \u2192 (\u2206J a 1 (t), \u2206J a 2 (t)) on nodes 1 and 2, respectively, at time t, we need to update the capitals",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": ", 2} according to the government intervention and then use the updated E i (t), W i (t) to perform the same analysis as above to identify the reachable states.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "For states s t+1 with a non-zero transition probability P at (s t , s t+1 ), we can calculate the latter via the Gaussian latent variable model, thus they will depend exclusively on the parameters P D i and \u03a3 ij with i, j \u2208 I \\I def (t). To be more precise, we first create an intermediate state s by applying the government investments relative to action a t to state s t ; hence each node i of s will have an increased",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "and a probability of default given by (7) with inputs W i (t) and E i (t). Using the intermediate state s with updated E i (t), W i (t), J i (t) and updated P D i (t), we calculate the transition probability via (see also (9) ) the following integral",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 225,
                    "text": "(9)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "where \u03a6 is the density given by (10) with dimension equal to the cardinality of the set of surviving nodes",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 36,
                    "text": "(10)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "for all the remaining active nodes i \u2208 I \\ I def (t + 1) at state s t+1 -upon recalling the default mechanism in (11) . The \u03a3 sub is the sub-matrix of the original correlation matrix \u03a3 after removing the rows and the columns corresponding to defaulted nodes i \u2208 I def (t) at state s t .",
            "cite_spans": [
                {
                    "start": 113,
                    "end": 117,
                    "text": "(11)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "MDP rewards. In our model the \"rewards\" take nonpositive values, since their overall maximisation has to translate for our MDP into the minimisation of the overall taxpayers' losses L i (t) given by (8) , for all nodes i \u2208 I \\ I def (t) at each time t. Namely,",
            "cite_spans": [
                {
                    "start": 199,
                    "end": 202,
                    "text": "(8)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "where only the nodes defaulting at time t with \u03b4 i (t) = 1 contribute to the sum of losses, hence the \"reward\" is 0 if there are no additional defaults at time t. The expected \"reward\" depends on the action taken, as it influences the total asset W i and investment J i corresponding to the intermediate state s described previously, as well as the P D i , i.e. the probability of having \u03b4 i (t) = 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "MDP actions."
        },
        {
            "text": "Solving the MDP means to find the optimal action for each possible state s t . In our context, we expect our model to indicate if the government should intervene and if so, which amount it should invest for a given configuration of the financial system network. To find a solution and describe it mathematically, we need to define a few concepts as described below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Optimal policy. The optimal policy \u03c0 * (s t ) \u2192 a * t , is a function that returns the optimal action a * \u2208 A s for each state s at time t. The optimal action is the one that obtains the maximum expected cumulative reward as defined in (12) .",
            "cite_spans": [
                {
                    "start": 236,
                    "end": 240,
                    "text": "(12)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Optimal value function. The optimal value function V * (s t ) is defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "This is the expected cumulative reward starting from state s t and following the optimal policy \u03c0 * for any of the successive time steps till the end of the episode (recall that a full episode consists of M time steps). One way to obtain this expected cumulative reward is to run the MDP starting at s t multiple times and average the results. Given the definition of \u03c0 * , V * (s t ) represents the maximum expected cumulative reward that can be obtained starting from s t .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Optimal action value function. The optimal action value function Q * (s t , a t ) is the expected cumulative reward we obtain if we first take action a t at state s t and then follow the optimal policy \u03c0 * for any of the successive steps from t + 1 until the end of the episode M . It is defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Similarly to the previous paragraph, this represents the maximum expected cumulative reward that can be obtained starting from s t after taking action a t .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Notice that, finding Q * is equivalent to solving the MDP, since the optimal action for each state s t (hence the optimal policy \u03c0 * ) can be obtained by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Relationships between Q * and V * . From the definitions of V * (s t ) and Q * (s t , a t ), it follows that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "i.e. the maximum cumulative reward from s t is the one corresponding to the maximum value of Q * after looking at all the potential alternative actions a t . Conversely, we can write Q * (s t , a t ) in terms of V * (s t ) as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "In other words, Q * (s t , a t ) can be expressed as the immediate expected reward at time t, given by s t+1 P at (s t , s t+1 )R at (s t , s t+1 ), plus the expected cumulative reward from time t + 1 onwards, given by \u03b3 s t+1 P at (s t , s t+1 )V * (s t+1 ). Merging together equations (18) and (19) we then obtain the Bellman Optimality Equation:",
            "cite_spans": [
                {
                    "start": 287,
                    "end": 291,
                    "text": "(18)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "Our strategy to solve the MDP. We have a complete description of our MDP (in particular, we have the transition probabilities P at (s t , s t+1 ) and the rewards R at (s t , s t+1 )), hence, in theory, we could enumerate all the possible states, use Dynamic Programming and the Value Iteration algorithm [30] to find V * and calculate Q * via equation (19) , thus solve the MDP. However, this is not a scalable approach due to the complexity of the MDP states and the very large number of successor states s for all but trivial networks. Instead, we use a Fitted Value Iteration algorithm [25] that involves: (a) devising a parametric representation V * (s, \u03b2) for the optimal value function V * (s) in (20) , where \u03b2 is a placeholder for a set of parameters to fit (see section II C 1 and V B); (b) using the approximate Bellman Optimality Equation (i.e. substituting V * (s ) with V * (s , \u03b2) in (20) to fit \u03b2 so that eventually V * (s) \u2248 V * (s, \u03b2 f it ) via a learning process (see section II C 2); and finally (c) calculating Q * (s, a) from V * (s, \u03b2 f it ) hence solve the MDP.",
            "cite_spans": [
                {
                    "start": 304,
                    "end": 308,
                    "text": "[30]",
                    "ref_id": null
                },
                {
                    "start": 352,
                    "end": 356,
                    "text": "(19)",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 589,
                    "end": 593,
                    "text": "[25]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 703,
                    "end": 707,
                    "text": "(20)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 898,
                    "end": 902,
                    "text": "(20)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "C. Solving the Markov Decision Process"
        },
        {
            "text": "In order to solve our MDP using the Fitted Value Iteration algorithm, we need a parametric representation of the optimal value function V * (s t ). In our case, V * (s t ) is minus the minimum expected cumulative losses from s t (i.e. the maximum expected cumulative reward from state s t ) incurred between time t to the end of the episode time M (see also (14) - (15)). The greater the number of nodes in the financial network and the number of residual steps m := M \u2212 t, the greater is the potential for additional losses. It is natural to try to express V * (s t ) as a sum of the loss contributions due to each individual node at each of the remaining m time steps. Hence, we introduce the matrix Z := (Z ik (s t )) with i \u2208 I \\ I def (t) and k \u2208 {1, ..., m}, where each element Z ik (s t ) represents the approximate expected loss due to the default of node i at time t + k \u2212 1, taking into account potential government investments. Our final ansatz for the parametric representation V * (s t , \u03b2) of V * (s t ) is that it is given by a linear combination of the elements Z ik in which the coefficients \u03b2 are arranged in a matrix that can change with time, i.e. \u03b2 \u2261 \u03b2 t := (\u03b2 ik (t)). Namely,",
            "cite_spans": [
                {
                    "start": 358,
                    "end": 362,
                    "text": "(14)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Value function approximation"
        },
        {
            "text": "for i \u2208 I \\ I def (t), k \u2208 {1, ..., m}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Value function approximation"
        },
        {
            "text": "We then let the system learn the parameters \u03b2 ik (t) that maximise the expected cumulative reward (minimise the losses). In the following section, we describe how we fit the parameters \u03b2 ik (t) to achieve the aforementioned task, while in section V B we detail our choice of Z(s t ) in terms of the characteristics of the network.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Value function approximation"
        },
        {
            "text": "In order to learn the parameters \u03b2 ik (t) we use the Bellman Optimality Equation (20) and we define the \"Bellman value\" as its right hand side after substituting V * (s ) with the approximation V * (s , \u03b2) from the previous section. Namely, we define VB(st, \u03b2t+1)",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 85,
                    "text": "(20)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "Pa t (st, s t+1 ) Ra t (st, s t+1 ) + \u03b3V * (s t+1 , \u03b2t+1) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "We can initialise \u03b2 with \u03b2 ik (t) = 1 for all i, k, t, as a natural starting point due to our initial approximation of expected direct losses Z ik (s t ) in (21) (see also Section V B for more details). We can then compare V * (s t , \u03b2 t ) from (21) with V B (s t , \u03b2 t+1 ) from (22) at state s t (starting from the initial state s 0 at time 0 and moving forward to time t), and adjust \u03b2 so that the two values come closer. Afterwards, we move to another state s t+1 and repeat the same procedure until the difference between V * and V B is \"small enough\", within the subset of the state space S that is reachable from s 0 . Notice however, that the above approach does not converge in general, unless we use specific learning strategies. The issue is that V B itself depends on \u03b2, which is what we want to fit, potentially triggering a divergent loop. To resolve this issue, we notice that V * (s t , \u03b2 t ) depends on \u03b2 at time t, while the corresponding V B (s t , \u03b2 t+1 ) is a function of \u03b2 at time t + 1. Using this fact, if we fit \u03b2 backwards in time, then V * (s t , \u03b2 t ) is compared with a value V B (s t , \u03b2 t+1 ) that is fixed (because \u03b2 t+1 would have been already fitted), thus solving the convergence problem.",
            "cite_spans": [
                {
                    "start": 245,
                    "end": 249,
                    "text": "(21)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "The primary issue that we now need to address is to find a way to calculate V B from (22), despite the fact that the set of states s that can be reached from state s is huge, even for relatively small networks. We first notice that s P a (s, s )R a (s, s ) is the 'one-step' expected reward that can be rewritten in terms of the nodes of the network:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "with",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "Secondly, the term s P a (s, s ) V * (s , \u03b2) can be estimated via Monte Carlo simulations, which involve (a) sampling s using the distribution P a (s) defined by the probability mass function P a (s, s ) and (b) calculating the expected value E Pa(s) [V * (s , \u03b2)] by averaging the values V * (s , \u03b2). Essentially,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "However, it is not feasible to calculate P a (s, s ) for all the states s that can be reached from s after taking action a, due to the huge number of these states s . Once again, we use our knowledge of the underlying network dynamics to describe the right hand side of (26) in terms of nodes defaulting instead of MDP transition probabilities. We observe that the transition probability P a (s, s ) was defined through the Gaussian latent variable model (see (13) ) and that there is a one-to-one correspondence between additional nodes defaulting from state s and the state s reached given action a. In particular, we denote by G a s the probability distribution of states s which are derived by using our Gaussian latent variable model in order to first simulate which nodes default via the default mechanism in (11) and then to obtain the corresponding state s . Since G a s is equivalent to P a (s) due to the aforementioned one-to-one correspondence, we can therefore rewrite (26) as",
            "cite_spans": [
                {
                    "start": 460,
                    "end": 464,
                    "text": "(13)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "Putting all these together (using essentially (23) and (27)) we can eventually rewrite V B (s t , \u03b2 t+1 ) from (22) for all t \u2208 [0, M \u2212 1] in the form of",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 50,
                    "text": "(23)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 111,
                    "end": 115,
                    "text": "(22)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "+ \u03b3 E G a t s t V * (s t+1 , \u03b2t+1) Now, given that our episode ends at time step M , we observe that V * (s t ) = 0 for all t \u2265 M . Hence, at time",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": ", since it will not depend on \u03b2, and we can thus write",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "where the latter equality follows from (20) and (23) . Now that we can calculate the exact optimal value function V * for each state at time M \u2212 1, we notice from (28) that",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 52,
                    "text": "(23)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "We then fit \u03b2 backwards in time for the decreasing se- ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Learning process"
        },
        {
            "text": "Finally, we can solve the MDP by combining all the above results to calculate Q * (s t , \u03b1 t ). In particular, by substituting V * (s t+1 ) in (19) with its approximation V * (s t+1 , \u03b2 f it t+1 ) obtained in Section II C 2, and applying the same analysis performed to obtain (28), we conclude that",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 147,
                    "text": "(19)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Solution of MDP"
        },
        {
            "text": "which provides the solution to the MDP.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution of MDP"
        },
        {
            "text": "The main result of this paper is the creation of the framework itself. A professional calibration of our model would require the effort of a central bank or a government office. To show how our model works, we explore two instances of our framework: In Section III A we use a network with homogeneous nodes organised as the Krackhardt kite [1] (KK) graph (Fig. 1) , while in Section III B we use the network of the European Global Systemically Important Institutions (GSIIs) obtained from the data in the European Banking Authority website [31] (EBA network). We assume the number of steps to be M = 7, the discount factor \u03b3 = 0.98 and for each node i, J i = 0 (unless otherwise specified), \u00b5 i = 0 (assuming conservatively that the expected value of the assets' return is zero), \u03b1 i = \u03b1 (the same for each node) and that the government can invest only in \"risky\" banks i with \"relatively high\" P D i (in our examples, \"risky\" banks will have P D i > 0.009). We have used an homogeneous correlation matrix that takes into account the average correlation between banks and following [21] we have set \u03a3 ij = 0.5 for i = j \u2208 I \\ I def . The value of \u03c3 i , for each node i, is calculated at time t = 0 from P D i (0), E i (0) and W i (0), by inverting (6) . Finally, we set P DM F loor i = 0.00021 which is the upper end of the AAA default probability bracket, within the internal credit rating methodology used by Credit Suisse [8] . The available actions are expressed with the notation: <node> @ <capital investment as a tenth of a percent of the total asset W>. For example, 8@05 means an investment of 50 bp W 8 or 0.5% W 8 in node 8. An action that considers all the nodes is indicated with <node>= 0. Hence 0@15 stands for an investment of 1.5% W i in each \"risky\" node i \u2208 I \\ I def .",
            "cite_spans": [
                {
                    "start": 340,
                    "end": 343,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1082,
                    "end": 1086,
                    "text": "[21]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1248,
                    "end": 1251,
                    "text": "(6)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1425,
                    "end": 1428,
                    "text": "[8]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 355,
                    "end": 363,
                    "text": "(Fig. 1)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "The common theme is that adding external resources makes the network more resilient but they can be lost in a subsequent default, which creates a trade-off for the decision maker. For relatively low values of \u03b1, it is generally not convenient to invest, while for relatively high values of \u03b1, the best action is to invest an amount of capital that makes the network sufficiently resilient. In the EBA network (see Section III B), we have shown that there exists a \"critical\" \u03b1 c that splits the space of \u03b1-values into two \"regimes\" of low/high values, where \u03b1 c \u2248 0.0025 in the original network and \u03b1 c \u2248 0.00096 in the distressed network where the capital of the banks was halved. e nodes 4, 8, 10 ). For small values of alpha, the best action is not to invest (0@0), as alpha increases, so does the convenience of investing more capital. For alpha = 1e \u2212 02 the best action is to invest 1.5 in nodes 4, 8 and 10 (0@15).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 682,
                    "end": 698,
                    "text": "e nodes 4, 8, 10",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "We have chosen this particular network to assess if our algorithm can distinguish between central nodes and peripheral ones. All the nodes have W (0) = 100, E(0) = 3, \u00b5 = 0, LGD = 1 (we assume, conservatively, that all the investment would be lost in case of a default), P D(0) = 0.001 for all but nodes 4, 8 and 10 with P D(0) = 0.01. The edges between nodes are oriented and homogeneous, assuming the value w ij = 1 \u2200i = j. We have restricted the potential investment amounts, for each node, to be: 0, 0.5% W , 1% W , 1.5% W or 2%W . Furthermore, the government can choose to invest in a single node or all the nodes for each time step, provided that the nodes are considered distressed. In our example, a node i is defined as risky or distressed if P D i > 0.009.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS"
        },
        {
            "text": "We have analysed the system for different values of alpha (0.0001, 0.001, 0.01) and reported the optimal action values at time t = 0 in (Fig. 2) . For \u03b1 = 0.0001 the best action is 0@0 (i.e. no investment in any node) followed by investing the minimum amount of capital in individual nodes. As alpha increases, not to invest becomes less and less convenient compared to the other options. For alpha = 0.01 the best action is to invest 1.5 in all the risky nodes (0@15). It is interesting to note that action 0@2 (i.e. investing the maximum amount, 2, in all the risky nodes) is never the best choice, while 0@05 is always the worst, as it provides too few capital to each node to make them resilient. In Fig. 3(a) we can see that the optimal action values corresponding to investments in different nodes tend to converge as the time to the end of the episode decreases because the contagion has less time to propagate and the node position becomes less and less relevant.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 136,
                    "end": 144,
                    "text": "(Fig. 2)",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 704,
                    "end": 713,
                    "text": "Fig. 3(a)",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "In Fig. 3(a) , we focus our analysis on nodes 4 and 10 for \u03b1 = 0.0001 and we note that investing in node 4 is always better than in node 10 for the same amount of capital. In Fig. 3(b) , we show how the results would change in the case when the government had already invested 0.5 in node 10 (i.e. J 10 (0) = 0.5). In this case, a substantial investment in node 10 (10@15 or 10@20) largely outperform investments in node 4. The government needs to keep investing a sufficient amount of capital in node 10 to protect its previous investment. For example, an investment of 0.5 in node 10 is not sufficient to strengthen it and the corresponding action value is the worst among the one considered at time t = 0 (time to end = 7). (a) The algorithm 'feels' the network structure and suggests to invest in node 4 rather than node 10. (b) In case the government had previously invested in node 10, the government needs to protect its investment, risking an additional investment in node 10. In the legend, 0@0 means no investment, 10@05 means investing 0.5 in node 10, 4@10 means investing 1 in node 4, etc.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 12,
                    "text": "Fig. 3(a)",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 175,
                    "end": 184,
                    "text": "Fig. 3(b)",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "We use the data from the European Banking Authority website about the Global Systemically Important Institutions, relative to the year 2014 (EBA network) [4] . The data does not contain the complete bilateral network (as this is considered business sensitive information) but aggregates of credit exposures vs other financial institutions. For our analysis, we have used the algorithm described in our previous paper [6] (see also [27] ) to reconstruct the network.",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 157,
                    "text": "[4]",
                    "ref_id": null
                },
                {
                    "start": 417,
                    "end": 420,
                    "text": "[6]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 431,
                    "end": 435,
                    "text": "[27]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "B. European GSII network"
        },
        {
            "text": "We set LGD = 0.6 as this is the standard rule of thumb in financial credit risk [7] . The values of the asset volatility \u03c3 have been obtained inverting (6) at time zero and assuming it remains constant during the simulation. We have restricted the potential investment amounts to be: 0, 0.5% W , 1% W , 1.5% W , 2%W , 2.5%W , 3%W . Furthermore, if the government decides to invest, it needs to provide additional capital to all the risky nodes, defined in our example, as the nodes with P D > 0.009. For this exercise, we pretend that the European Union (including UK) is also a fiscal union with a single government that is accountable to all the European taxpayers. In particular, we consider investments that individual states might have in banks as of 2014 as 'private' investments, hence we start with with J i (0) = 0 \u2200i. We define the 'Convenience' to intervene as: with a 0 t representing the action at time t corresponding to no investments. In Fig. 5(a) we have reported the Convenience vs the time (number of steps) to the end of the episode. We have found that the Convenience is positive and almost constant for large values of \u03b1 (\u03b1 = 0.01, \u03b1 = 0.005), and is negative and decreasing for smaller values of \u03b1 (\u03b1 = 0.001, \u03b1 = 0.0001). In Fig. 5(b) we have the same chart but for a severely distressed version of the network, where the capital of the banks has been halved. The distress has the effect of lowering the value of alpha at which the Convenience is positive, for example the Convenience is now positive for \u03b1 = 0.001.",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 83,
                    "text": "[7]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [
                {
                    "start": 954,
                    "end": 963,
                    "text": "Fig. 5(a)",
                    "ref_id": null
                },
                {
                    "start": 1249,
                    "end": 1258,
                    "text": "Fig. 5(b)",
                    "ref_id": null
                }
            ],
            "section": "B. European GSII network"
        },
        {
            "text": "To explore the transition between positive and negative Convenience, we have reported the optimal action values at time t = 0 as a function of \u03b1 in (Fig. 6(a) ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 148,
                    "end": 158,
                    "text": "(Fig. 6(a)",
                    "ref_id": null
                }
            ],
            "section": "B. European GSII network"
        },
        {
            "text": "For \u03b1 > \u03b1 c \u2248 0.0025, the inaction is no longer the most convenient choice, \"0@05\" (investing 0.5%W in the risky nodes) becomes the best action. It is also interesting to notice that the optimal action becomes \"0@10\" for higher values of \u03b1. In (Fig. 6b) ) we have the optimal action values at time t = 0 when the capital of the banks has been halved. We notice that the value \u03b1 c at which a government intervention becomes favourable is lower at \u03b1 c \u2248 0.00096. Table I ). The graph as been reconstructed from aggregated data available at the European Banking Authority (EBA) website and it can be different from the actual network of bilateral exposures. The darker edges identify stronger exposures. The nodes with higher PD are Monte dei Paschi di Siena (MPS) and BFA. . The optimal action value at time t = 0 is reported as a function of \u03b1 for different actions. 0@0 means no investment. As \u03b1 increases, 0@0 becomes less and less convenient and for \u03b1 = \u03b1c = 0.0025 the best action becomes investing 0.5%W in each of the risky nodes. For even higher values of alpha, the best action becomes 0@10 (i.e investing 1%W for each of the risky nodes). b) The chart is relative to a distressed version of the 'EBA network' where the capital of the banks has been halved. The value of \u03b1c at which a government intervention is convenient is lower than in a): \u03b1c \u2248 0.00096.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 244,
                    "end": 253,
                    "text": "(Fig. 6b)",
                    "ref_id": null
                },
                {
                    "start": 461,
                    "end": 468,
                    "text": "Table I",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "B. European GSII network"
        },
        {
            "text": "We have shown how to cast a bank bailout decision by a government into an action in a Markov Decision Process (MDP) where the states of the MDP are defined in terms of the underlying network of financial exposures and the MDP dynamics is derived from the network dynamics. In our example, that uses the data relative to the European Global Systemically Important Institutions, we have found that government interventions do not improve the expected loss of the financial network if the loss for the taxpayer as a fraction of the bank total assets \u03b1 satisfies \u03b1 < \u03b1 c \u2248 0.0025. The value of \u03b1 c becomes lower as the distress of the network increases. It is evident from our analysis that the parameter alpha plays a central role in systemic risk modelling and even if there are works [9] [10] studying the impact for the taxpayers linked to a bank default, additional analysis need to be performed for its reliable estimation. Using a simplified Krackhardt kite network, we have found that the government becomes biased toward investing in a risky node if it had already invested in it in the past. The government needs to evaluate carefully a potential investment. The rescued bank could increase its risky investments knowing that it would be bailed-out in case it became distressed again, thus leading to moral hazard.",
            "cite_spans": [
                {
                    "start": 783,
                    "end": 786,
                    "text": "[9]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "IV. CONCLUDING REMARKS"
        },
        {
            "text": "In section II C 1 we have expressed the approximated value function V * (s t , \u03b2) as a linear combination of terms Z ik (s t ) with coefficients \u03b2 ik (t) given by (21) .",
            "cite_spans": [
                {
                    "start": 163,
                    "end": 167,
                    "text": "(21)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "A. Representative portfolio of MDP states"
        },
        {
            "text": "In order to fit these \u03b2 ik (t), we first identify a representative portfolio of MDP states that can be reached, at time t, from the initial state s 0 , and for which we can calculate the Bellman value V B using (28)- (29) . Equating V * (s t , \u03b2 t ) with the corresponding V B (s t , \u03b2 t+1 ), for each state s t in the portfolio, we derive a set of linear equations that we use to obtain the coefficients \u03b2 ik (t) via a ridge regression (with a 5-fold cross-validation). The states in the representative portfolio, at time t, are obtained from the initial state s 0 , after changing the time to maturity from M to M \u2212 t (i.e. the states are 'moved' forward in time) and forcing a set U of nodes to default. The representative portfolio contains: (a) the state corresponding to U = \u2205, plus (b) all the states corresponding to U = {i} for i \u2208 I (i.e. with one additional defaulted node with respect to s 0 ), plus (c) a selection of states corresponding to |U | > 1 (i.e. with multiple additional defaulted nodes), which are chosen randomly with probabilities proportional to exp (\u2212|U |) (a greater importance is given to states with fewer number of additional defaults as they are more likely to be reached in an actual simulation). In addition, we obtain elements in the representative portfolio by performing a government action on s 0 and then move the corresponding state at time t (i.e. at time to maturity M \u2212 t). The number of states in the representative portfolio needs to be chosen taking into account the trade-off between stable results and computational resources.",
            "cite_spans": [
                {
                    "start": 217,
                    "end": 221,
                    "text": "(29)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "A. Representative portfolio of MDP states"
        },
        {
            "text": "In this section, we detail our choice for (Z ik (s t )) used in our ansatz for the value function approximation V * (s t , \u03b2) in (21) , with node i \u2208 I \\ I def (t) and step k \u2208 {1, ..., m = M \u2212 t} until the end of the episode. We introduce the auxiliary matrix Z, with elements Z ik (s t ; a 1 , ..., a k ) representing the approximated contribution of the expected direct loss, due to the default of node i, at time t + k \u2212 1, taking into account the government actions a j at time t+j \u22121, for all j = 1, ..., k.",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 133,
                    "text": "(21)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "That is, we define Z ik := P D ik L ik , if k = 1; P D ik L ik \u03b3 k\u22121 k\u22121 r=1 (1 \u2212 P D ir ), if k > 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "Here, the value P D ik is the modified probability of default and the value L ik is the modified loss, associated to the node i at time t + k \u2212 1, that take into account the expected cumulative impact I ik and the potential cumulative investment from the government J ik on node i from time t up to time t + k \u2212 1. Note that for k > 1, a node i can contribute to the expected loss only if it has not defaulted in the previous time steps (hence the presence of the survival probabilities (1 \u2212 P D ir )).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "To be more precise, we firstly define Then, the cumulative impact I ik depends on the modified probability of default of all the nodes j \u2208 H := I \\ (I def (t) \u222a {i}) and is defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "Moreover, the cumulative government investment J ik in node i is a function of the actions (a 1 , ..., a k ) that the government can take between t and t+k\u22121 and is defined by J ik (a 1 , ..., a k ) := k r=1 \u2206J ar i (t + r \u2212 1)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "Finally, the modified loss incurred is defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "In light of the above equations, we observe that Z ik = Z ik (s t ; a 1 , ..., a k ) depend on the actions (a 1 , ..., a k ) via the terms J ik (a 1 , ..., a k ) involved in both P D ik and L ik . We now call a 0 the action corresponding to no additional government investment and define the total expected direct loss for all i \u2208 I \\ I def (t) and k \u2208 {1, ..., m} as T L(s t ; a 1 , a 2 , .., a m ) := i,k Z ik (s t ; a 1 , a 2 , .., a k ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "Then, the specific matrix Z = (Z ik (s t )) involved in our value function approximation is defined by Z ik (s t ) := Z ik (s t ; a 1 , ..., a k ),",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        },
        {
            "text": "where each a j is calculated sequentially for each j \u2208 {1, ..., m} as follows: ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Value function parametrisation"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Assessing the Political Landscape: Structure, Cognition, and Power in Organizations",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Krackhardt",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "Adm. Sci. Q",
            "volume": "35",
            "issn": "2",
            "pages": "342--369",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A dynamic approach merging network theory and credit risk techniques to assess systemic risk in financial networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Petrone",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Latora",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sci Rep",
            "volume": "8",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Default recovery rates in credit risk modelling: a review of the literature and empirical evidence",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Altman",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Resti",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sironi",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Econ. Notes",
            "volume": "33",
            "issn": "",
            "pages": "183--208",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Snethlage, D. Estimating the size and incidence of bank resolution costs for selected banks in OECD countries",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Blix Grimaldi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hofmeister",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Schich",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "OECD Journal: Financial Market Trends",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Reducing and sharing the burden of bank failures",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cariboni",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Fontana",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Langedijk",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Maccaferri",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pagano",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Giudici",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rancan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Schich",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "OECD Journal: Financial Market Trends",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Network models of financial systemic risk: a review",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Caccioli",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Barucca",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kobayashi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J Comput Soc Sc",
            "volume": "1",
            "issn": "",
            "pages": "81--114",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Contagion in financial networks",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Gai",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kapadia",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proc. Royal Soc. A",
            "volume": "466",
            "issn": "",
            "pages": "2401--2423",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Managing global finance as a system",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Haldane",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Complex networks: Structure and dynamics",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Boccaletti",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Latora",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Moreno",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chavez",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hwang",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Phys. Rep",
            "volume": "424",
            "issn": "",
            "pages": "175--308",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Running for the exit: distressed selling and endogenous correlation in financial markets",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cont",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wagalath",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Math. Finance",
            "volume": "23",
            "issn": "",
            "pages": "718--741",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "DebtRank: too central to fail? financial networks, the FED and systemic risk",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Battiston",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Puliga",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kaushik",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Tasca",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Caldarelli",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Sci. Rep",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "The gaussian latent variable model in Modelling Single-name and Multi-name Credit Derivatives",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "O&apos;kane",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "241--259",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "On the pricing of corporate debt: The risk structure of interest rates",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "C"
                    ],
                    "last": "Merton",
                    "suffix": ""
                }
            ],
            "year": 1974,
            "venue": "J. Finance",
            "volume": "29",
            "issn": "",
            "pages": "449--470",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Measuring systemic risk: A risk management approach",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lehar",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "J. Bank. Finance",
            "volume": "29",
            "issn": "",
            "pages": "2577--2603",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Interbank exposures: Quantifying the risk of contagion",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Furfine",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "J. Money Credit Bank",
            "volume": "35",
            "issn": "",
            "pages": "111--128",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "A framework for assessing the systemic risk of major financial institutions",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "J. Bank. Finance",
            "volume": "33",
            "issn": "",
            "pages": "2036--2049",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Simulation methods to assess the danger of contagion in interbank markets",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Upper",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J. Financial Stab",
            "volume": "7",
            "issn": "",
            "pages": "111--125",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Estimating bilateral exposures in the german interbank market: Is there a danger of contagion?",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Upper",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Worms",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Eur. Econ. Rev",
            "volume": "48",
            "issn": "",
            "pages": "827--849",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Reinforcement Learning: An Introduction",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Sutton",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Barto",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Approximate solutions to markov decision processes",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gordon",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Tom",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mitchell",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "An Artificial Intelligence Approach to Regulating Systemic Risk",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "O&apos;halloran",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Nowaczyk",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Front. Artif. Intell",
            "volume": "2",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Filling in the blanks: Network structure and interbank contagion",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Anand",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Craig",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Von Peter",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Quant. Finance",
            "volume": "15",
            "issn": "",
            "pages": "625--636",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A Markovian decision process",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "E"
                    ],
                    "last": "Bellman",
                    "suffix": ""
                }
            ],
            "year": 1957,
            "venue": "J. Math. Mech",
            "volume": "6",
            "issn": "5",
            "pages": "679--684",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "PACS numbers: 02.70.-c, 64.60.aq, 05.40.-a, 07.05.Mh, 89.65.Gh",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Di(t) := max{P DM (Wi(t), Ei(t), \u00b5i, \u03c3i), P DM f loor i } (7)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "containing all defaulted nodes prior to time t and (c) the time to maturity M \u2212 t.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "quence of time steps (M \u2212 2, ..., 0), creating a representative portfolio of MDP states for each time step (see section V A) and performing a ridge regression (with a 5-fold cross-validation) comparingV * (s t , \u03b2 t ) with V B (s t , \u03b2 t+1 ). Firstly, for time step M \u22122, we compare V * (s M \u22122 , \u03b2 M \u22122 ) with V B (s M \u22122 ),for all the states in the representative portfolio, and we fit \u03b2 M \u22122 . Then, for time step M \u2212 \u22123 [V * (s M \u22122 , \u03b2M\u22122)] (31) and compare it with V * (s M \u22123 , \u03b2 M \u22123 ), for all the states of the representative portfolio, to obtain once again \u03b2 M \u22123 via a ridge regression. We continue the procedure backward in time until we successfully obtain \u03b2 f it , i.e. the fitted \u03b2 t for each time t.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Krackhardt kite (KK) graph. In our example we consider: set of nodes I = {1, ..., 10}, total asset Wi(0) = 100, capital Ei(0) = 3, \u00b5i = 0, LGDi = 1, for all i \u2208 I, P Di(0) = 0.01 for i \u2208 {4, 8, 10} and P Di(0) = 0.001 for i \u2208 I \\ {4, 8, 10}",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The picture is relative to the KK network and shows the optimal action value at time t = 0 for different actions and values of \u03b1. In the legend, 0@0 means no investment, 0@05 means investing 0.5 in all the nodes with P D > 0.009 (i.e nodes 4, 8, 10), 10@05 means investing 0.5 in node 10, 4@10 means investing 1 in node 4, etc. It is never convenient investing the maximum amount of capital (0@20): 2 for each node with P D > 0.009 (i.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The pictures are relative to the Krackhardt kite graph (KK) and shows the optimal action value vs time to end of the episode, with alpha = 0.0001, for different actions, and focusing on nodes 4 (central node) and 10 (peripheral node).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Maximum spanning tree of the EBA graph. Each node represents a financial institution (see",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "EBA network with half capital E FIG. 5: (a) The Convenience, expressed in million of EUR in the charts, and defined as the difference between the optimal action value corresponding to the best government intervention, and the optimal action value associated to inaction (see (33)), is almost constant vs time to the end of the episode for positive values, and a decreasing function for negative values. (b) If we stress the EBA network, halving the capital of the nodes, we obtain a chart similar to a) but the minimum value of alpha for which the Convenience is positive is lower. \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c \u03b1c EBA network with half capital EFIG. 6: a)The chart is relative to the 'EBA network' (European Global Systemically Important Institutions)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "= P D(Wi + J ik \u2212 I ik , Ei + J ik \u2212 I ik , \u00b5i, \u03c3i, P DM f loor i ).",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}