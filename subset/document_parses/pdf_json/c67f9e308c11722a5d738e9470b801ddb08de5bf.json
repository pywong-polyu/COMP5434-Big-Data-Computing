{
    "paper_id": "c67f9e308c11722a5d738e9470b801ddb08de5bf",
    "metadata": {
        "title": "A holistic overview of deep learning approach in medical imaging",
        "authors": [
            {
                "first": "Rammah",
                "middle": [],
                "last": "Yousef",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [],
                "last": "Gaurav Gupta",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Nabhan",
                "middle": [],
                "last": "Yousef",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "Manju"
                ],
                "last": "Khari",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Medical images are a rich source of invaluable necessary information used by clinicians. Recent technologies have introduced many advancements for exploiting the most of this information and use it to generate better analysis. Deep learning (DL) techniques have been empowered in medical images analysis using computer-assisted imaging contexts and presenting a lot of solutions and improvements while analyzing these images by radiologists and other specialists. In this paper, we present a survey of DL techniques used for variety of tasks along with the different medical image's modalities to provide critical review of the recent developments in this direction. We have organized our paper to provide significant contribution of deep leaning traits and learn its concepts, which is in turn helpful for non-expert in medical society. Then, we present several applications of deep learning (e.g., segmentation, classification, detection, etc.) which are commonly used for clinical purposes for different anatomical site, and we also present the main key terms for DL attributes like basic architecture, data augmentation, transfer learning, and feature selection methods. Medical images as inputs to deep learning architectures will be the mainstream in the coming years, and novel DL techniques are predicted to be the core of medical images analysis. We conclude our paper by addressing some research challenges and the suggested solutions for them found in literature, and also future promises and directions for further developments.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "R. Yousef et al.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Convolutional neural networks: CNN [10] have taken the major role in many aspects and have lead the work in imagebased tasks, including image reconstruction, enhancement, classification, segmentation, registration, and localization. CNNs are considered to be the most deep learning algorithm regarding images and visual processing because of its robustness in image dimensionality reduction without losing image's important features; in this way, CNN algorithm deals with less parameters which mean increasing the computational efficiency. Another key term about CNN is that this architecture is suitable for hospitals use, because it can handle both 2D and 3D images, because some of medical images modalities like X-ray images are 2D-based images, while MRI and CT scan images are 3-dimensional images. In this section, we will explain the framework of CNN architecture as the heart of deep learning in medical imaging.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Convolutional layer: Before deep learning and CNN, in image processing, convolution terminology was used for extracting specific features from an image, such as corners, edges (e.g., sobel filter), and noise by applying a particular filters or kernels on the image. This operation is done by sliding the filter all over the image in a sliding window form until all the image is covered. In CNN, usually, the startup layers are designed to extract low-level features, such as lines and edges, and the progressive layers are built up for extracting higher features like full objects within an image. The goodness of using modern CNNs is that the filters could be 2D or 3D filters using multiple filters to form a volume and this depends on the application. The main discrimination in CNN is that this architecture obliges the elements in a filter to be the network weights. The idea behind CNN architecture is the convolution operation which is denoted by the symbol *. Equation (1) represents the convolution operation where s(t) is the output feature map and I(t) is the original image to be convolved with the filter K(a).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Activation function: Activation functions are the enable button of a neuron; in CNN, there are multiple popular activation functions which are widely used such as, sigmoid, tanh, ReLU, Leaky ReLU, and Randomized ReLU. Especially, in medical imaging, most papers found in literature uses ReLU activation function which is defined using the formula where x represents the input of a neuron.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "There are other used activation functions used in CNN, such as sigmoid, tanh, and leaky-ReLu Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Health no doubt is on the top of concerns hierarchy in our life. Through the lifetime, human has struggled of diseases which cause death; in our life scope, we are fighting against enormous number of diseases, moreover, improving life expectancy and health status significantly. Historically medicine could not find the cure of numerous diseases due to a lot of reasons starting from clinical equipment and sensors to the analytical tools of the collected medical data. The fields of big data, AI, and cloud computing have played a missive role at each aspect of handling these data. Across the worldwide, Artificial Intelligence (AI) has been widely common and well known enough to most of the people due to the rapid progress achieved in almost every domain in our life. The importance of AI comes from the remarkable progress within the last 2 decades only, and it is still growing and specialists from different fields are investing. AI's algorithms were attributed to the availability of big data and the efficiency of modern computing criteria that is provided lately.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This paper aims to give a holistic overview in the field of healthcare as an application of AI and deep learning particularly. The paper starts by giving an overview of medical imaging as an application of deep learning and then moving to why do we need AI in healthcare; in this section, we will give the key terms of how AI is used in both the main medical data types which are medical imaging and medical signals. To provide a moderate and rich general perspective, we will mention the well-known data which are widely used for generalization and the main pathologies, as well. Starting from classification and detection of a disease to segmentation and treatment and finally survival rate and prognostics. We will talk in detail about each pathology with the relevant Communicated by B. Xiao.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "* Manju Khari manjukhari@yahoo.co.in 1 key features and the significant results found in literature. In the last section, we will discuss about the challenges of deep learning and the future scope of AI in healthcare. Generally, AI is being a fundamental path in nowadays medicine which is in short a software that can learn from data like human being and it can develop an experience systematically and finally deliver a solution or diagnostic even faster than humans. AI has become an assistive tool in medicine with benefits like error reduction, improving accuracy, fast computing, and better diagnosis were introduced to help doctors efficiently. From clinical perspective, AI is used now to help the doctors in decision-making due to faster pattern recognition from the medical data which also in turn are registered more precisely in computers than humans; moreover, AI has the ability to manage and monitor the patients' data and creating a personalized medical plan for future treatments. Ultimately, AI has proved to be helpful in medical field with different levels, such as telemedicine diagnosis diseases, decision-making assistant, and drug discovery and development. Machine learning (ML) and deep learning (DL) have tremendous usages in healthcare such as clinical decision support (CDS) system which incorporate human's knowledge or large datasets to provide clinical recommendations. Another application is to analyze large historical data and get the insights which can predict the future cases of a patient using pattern identification. In this paper, we will highlight the top deep learning advancement and applications in medical imaging. Figure 1 shows the workflow chart of paper highlights.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 38,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [
                {
                    "start": 1661,
                    "end": 1669,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Deep learning in medical imaging [1] is the contemporary scope of AI which has the top breakthroughs in numerous scientific domains including computer vision [2] , Natural Language Processing (NLP) [3] and chemical structure analysis, where deep learning is specialized with highly complicated processes. Lately due to deep learning robustness while dealing with images, it has attracted big interest in medical imaging, and it holds big promising future for this field. The main idea that DL is preferable is that medical data are large and it has different varieties such as medical images, medical signals, and medical logs' data of patients Fig. 1 Deep learning implementation and traits for medical imaging application monitoring of body sensed information. Analyzing these data especially historical data by learning very complex mathematical models and extracting meaningful information is the key feature where DL scheme outperformed humans. In other words, DL framework will not replace the doctors, but it will assist them in decision-making and it will enhance the accuracy of the final diagnosis analysis. Our workflow procedure is shown in Fig. 1 .",
            "cite_spans": [
                {
                    "start": 33,
                    "end": 36,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 158,
                    "end": 161,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 198,
                    "end": 201,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 645,
                    "end": 651,
                    "text": "Fig. 1",
                    "ref_id": null
                },
                {
                    "start": 1153,
                    "end": 1159,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Medical imaging"
        },
        {
            "text": "There are plenty of medical image types, and selecting the type depends on the usage, in a study which was held in US [4] , it was found that there are some basic and widely used modalities of these medical images which also have increased, and these modalities are Magnetic Resonance Images (MRI), Computed Tomography (CT) scans, and Positron Emission Tomography (PET) to be on the top and some other common modalities like, X-ray, Ultrasound, and histology slides. Medical images are known to be so complicated, and in some cases, acquisition of these images is considered to be long process and it needs specific technical implications, e.g., an MRI which may need over 100 Mega Byte of memory storage.",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 121,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Types of medical imaging"
        },
        {
            "text": "Because of a lack of standardization while image acquisition and diversity in the scanning devices' settings, a phenomenon called \"distribution drift\" might arise and cause non-standard acquisition. From a clinical need perspective, medical images are the key part of diagnosis of a disease and then the treatment too. In traditional diagnosis, a radiologist reviews the image, and then, he provides the doctors with a report of his findings. Images are an important part of the invasive process to be used in further treatment, e.g., surgical operations or radiology therapies for example [5, 6] .",
            "cite_spans": [
                {
                    "start": 590,
                    "end": 593,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 594,
                    "end": 596,
                    "text": "6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Types of medical imaging"
        },
        {
            "text": "Conceptually, Artificial Neural Networks (ANN) are a mimic of the human neuro system in the structure and work. Medical imaging [7] is a field by which is specialized in observing and analyzing the physical status of the human body by generating visual representations like images of internal tissues or some organs of the body through either invasive or non-invasive procedure.",
            "cite_spans": [
                {
                    "start": 128,
                    "end": 131,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "DL frameworks"
        },
        {
            "text": "Historically, AI scheme has been proposed in 1970s and it has mainly the two major subcategories, such as Machine Learning (ML) and Deep Learning (DL). The earlier AI used heuristics-based techniques for extracting features from data, and further developments started using handcrafted features' extraction and finally to supervised learning. Where basically Convolutional Neural Networks (CNN) [8] is used in images and specifically in medical images. CNN is known to be hungry for data, so it is the most suitable methodology for images, and the recent developments in hardware specifications and GPUs have helped a lot in performing CNN algorithms for medical image analysis. The generalized formulation of how CNN work was proposed by Lecun et al. [9] , where they have used the error backpropagation for the first example of digits hand written recognition. Ultimately, CNNs have been the predominant architecture among all other algorithms which belong to AI, and the number of research of CNN has increased especially in medical images analysis and many new modalities have been proposed. In this section, we explain the fundamentals of DL and its algorithmic path in medical imaging. The commonly known categories of deep learning and their subcategories are discussed in this section and are shown in Fig. 2 . ",
            "cite_spans": [
                {
                    "start": 395,
                    "end": 398,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 752,
                    "end": 755,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [
                {
                    "start": 1310,
                    "end": 1316,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "Pooling layer: Mainly, this layer is used to reduce the parameters needed to be computed and it reduces the size of the image but not the number of channels. There are few pooling layers, such as Max-pooling, average-pooling, and L2-normalization pooling, where Max-pooling is the widely used pooling layer. Max-pooling means taking the maximum value of a position of the feature map after convolution operation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "Fully connecter layer: This layer is the same layer that is used in a casual ANN where usually in such network each neuron is connected to all other neurons in both the previous and next layer's neurons; this makes the computation very expensive. A CNN model can get the help of the stochastic gradient descent to learn significant associations from the existing examples used for training. Thus, the benefit of a CNN usage is that it gradually reduces the feature map size before finally is get flatten to feed the fully connected layer which in turn computes the probability scores of the targeted classes for the classification. Fc-connected layer is the last layer in a CNN model, Furthermore, this layer processes the strongly extracted features from an image due to the convolutional a pooling layer before and finally fc-layer indicate to which class is an image belong to.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "Recurrent neural networks: RNN is a major part from supervised deep learning models, and this model is specific with analyzing sequential data and time series. We can imagine an RNN as a casual neural network, while each layer of it represents the observations at a particular time (t). In [11] , RNN was used for text generating which further connected to speech recognition and text prediction and other applications too. RNN are recurrent, because same work is done for every element in a sequence and the output depends on the previous output computation of the previous element in that sequence general, the output of a layer is fed as an input to the new input of the same layer as it is shown in Fig. 3 . Moreover, since the backpropagation of the output will suffer of vanishing gradient with time, so commonly a network is evolved which is Long Short-Term Memory (LSTM).",
            "cite_spans": [
                {
                    "start": 290,
                    "end": 294,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [
                {
                    "start": 703,
                    "end": 709,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "In network and three bidirectional gated recurrent units is (BGRU) to help the RNN to hold long-term dependencies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "There were few papers found in the literature of RNN in medical imaging and particularly in segmentation, in [12] , Chen et al. have used RNN along with CNN for segmenting fungal and neuronal structures from 3D images. Another application of RNN is in image caption generation [13] , where these models can be used for annotating medical images like X-ray with text captions extracted and trained from radiologists' reports [14] . RuoxuanCui et al. [15] have used a combination of CNN and RNN for diagnosing",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 113,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 277,
                    "end": 281,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 424,
                    "end": 428,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 449,
                    "end": 453,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "Alzheimer disease where their CNN model was used for classification task, after that the CNN model's output is fed to an RNN model with cascaded bidirectional gated recurrent units (BGRU) layers to extract the longitudinal features of the disease. In summary, RNN is commonly used with a CNN model in medical imaging. In [16] , authors have developed a novel RNN for speeding up an iterative MAP estimation algorithm.",
            "cite_spans": [
                {
                    "start": 321,
                    "end": 325,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Key technologies and deep learning"
        },
        {
            "text": "Beside the CNN as a supervised machine leaning algorithm in medical imaging, there are a few unsupervised learning algorithms for this purpose as well, such as Deep Belief Networks (DBNs), Autoencoders, and Generative Adversarial Networks (GANs), where the last has been used for not only performing the image-based tasks but as a data synthesis and augmentation too. Unsupervised learning models have been used for different medical imaging applications, such as motion tracking [17] general modeling, classification improvement [18] , artifact reduction [19] , and medical image registration [20] . In this section, we will list the mostly used unsupervised learning structures. [21, 22] are an unsupervised deep learning algorithm by which this model refers to the important features of an input data and dismisses the other data. These important representations of features are called 'codings' where it is commonly called represen-tation learning. The basic architecture is shown in Fig. 3 . The robustness of autoencoders stems from the ability to reconstruct output data, which is similar to the input data, because it has cost function which applies penalties to the model when the output and input data are different. Moreover, autoencoders are considered as an automatic features detector, because they do not need labeled data to learn from due to the unsupervised manner. Autoencoders architecture is similar to a formal CNN model, but with the feature is that the number of input neurons must be equal to the number in the output layer. Reducing dimensionality of the raw input data is one of the features of autoencoders, and in some cases, autoencoders are used for denoising purpose [23] , where this autoencoders are called denoising autoencoders. In general, there are few kinds of autoencoders used for different purposes, we mention here the common autoencoders, for example, Sparse Autoencoders [24] where the neurons in the hidden layer are deactivated through a threshold which means limiting the activated neurons to get a representation in the output similar to the input where for extracting most of the features from the input, most of the hidden layer neurons should be set to zero. Variational autoencoders (VAEs) [25] are generative model with two networks (Encoder and Decoder) where the encoder network projects the input into latent representation using Gaussian distribution approximation, and the decoder network maps the latent representations into the output data. Contractive autoencoders [26] and adversarial autoencoders are mostly similar to a Generative Adversarial Network (GAN). ",
            "cite_spans": [
                {
                    "start": 480,
                    "end": 484,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 530,
                    "end": 534,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 556,
                    "end": 560,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 594,
                    "end": 598,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 681,
                    "end": 685,
                    "text": "[21,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 686,
                    "end": 689,
                    "text": "22]",
                    "ref_id": null
                },
                {
                    "start": 1699,
                    "end": 1703,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1916,
                    "end": 1920,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 2243,
                    "end": 2247,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 2527,
                    "end": 2531,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 988,
                    "end": 994,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Unsupervised deep learning"
        },
        {
            "text": "GANs [27] 28 were first introduced by Ian Goodfellow in 2014; it consists basically on a combination of two CNN networks: the first one is called Generative model and another is the discriminator model. For better understanding how GANs work, scientists describe the two networks as a two players who competing against each other, where the generator network tries to fool the discriminator network by generating near authentic data (e.g., artificial images), while the discriminator network tries to distinguish between the generator output and the real data, Fig. 3 . The name of the network is inspired from the objective of the generator to overcome the discriminator. After the training process, both the generator and discriminator networks get better, where the first generates more real data, and the second learns how to differentiate between both previously mentioned data better until the end-point of the whole process where the discriminator network is unable to distinguish between real and artificial data (images). In fact, the criteria by which both networks learn from each other are using the backpropagation for the both, Markov chains, and dropout too. Recently, we have seen tremendous usage of GANs for different applications in medical imaging such as, synthetic images for generating new images and enhance the deep learning models efficiency by increasing the number of training images in the dataset [29] , classification [30, 31] , detection [32] , segmentation [33, 34] , image-to-image translation [35] , and other application too. In a study by Kazeminia et al. [36] , they have listed all the applications of GANs in medical imaging and the most two used applications of this unsupervised models are image synthesis and segmentation.",
            "cite_spans": [
                {
                    "start": 5,
                    "end": 9,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1427,
                    "end": 1431,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1449,
                    "end": 1453,
                    "text": "[30,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1454,
                    "end": 1457,
                    "text": "31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1470,
                    "end": 1474,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1490,
                    "end": 1494,
                    "text": "[33,",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1495,
                    "end": 1498,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 1528,
                    "end": 1532,
                    "text": "[35]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 1593,
                    "end": 1597,
                    "text": "[36]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [
                {
                    "start": 561,
                    "end": 567,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Generative Adversarial Networks"
        },
        {
            "text": "Axkley et al. were the first to introduce the Boltzmann machines in 1985 [37] , Fig. 3 , also known as Gibbs distribution, and further Smolensky has modified it to be known as Restricted Boltzmann Machines (RBMs) [38] . RBMs consist on two layers of neural networks with stochastic, generative, and probabilistic capabilities, and they can learn probability distributions and internal representations from the dataset. RBMs work using the backpropagation path of input data for generating and estimating the probability distribution of the original input data using gradient descent loss. These unsupervised models are used mostly for dimensionality reduction, filtering, classification, and features representation learning. In medical imaging, Tulder et al. [39] have modified the RBMs and introduced a novel convolutional RBMs for lung tissue classification using CT scan images; they have extracted the features using different methodologies (generative, discriminative, or mixed) to construct the filters; after that, Random Forest (RF) classifier was used for the classification objective. Ultimately, a stacked version of RBMs is called Deep Belief Networks (DBNs) [40] . Each RBM model performs non-linear transformation which will again be the input for the next RBM model; performing this process progressively gives the network a lot of flexibility while expansion.",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 77,
                    "text": "[37]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 213,
                    "end": 217,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 760,
                    "end": 764,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 1172,
                    "end": 1176,
                    "text": "[40]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [
                {
                    "start": 80,
                    "end": 86,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Restricted Boltzmann machines"
        },
        {
            "text": "DBNs are generative models, which allow them to be used as a supervised or unsupervised settings. The feature learning is done through an unsupervised manner by doing the layer-by-layer pre-training. For the classification task, a backpropagation (gradient descent) through the RBM stacks is done for fine-tuning on the labeled dataset. In medical imaging applications, DBNs were used widely; for example, Khatami et al. [41] used this model for classification of X-ray images of anatomic regions and orientations; in [42] , AVN Reddy et al. have proposed a hybrid deep belief networks (DBN) for glioblastoma tumor classification from MRI images. Another significant application of DBNs was reported in [43] where they have used a novel DBNs' framework for medical images' fusion.",
            "cite_spans": [
                {
                    "start": 421,
                    "end": 425,
                    "text": "[41]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 518,
                    "end": 522,
                    "text": "[42]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 703,
                    "end": 707,
                    "text": "[43]",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "Restricted Boltzmann machines"
        },
        {
            "text": "Self-supervised learning is basically a subtype of unsupervised Learning, by which it learns features' representations using a proxy task where the data contain supervisory signals. After representation learning, it is fine-tuned using annotated data. The benefit of self-supervised learning is that it eliminates the need of humans to label the data, where this system extracts the visibly natural relevant context from the data and assign metadata with the representations as supervisory signals. This system matches with unsupervised learning, because both systems learn representations without using explicitly provided labels, but the difference is that self-supervised learning does not learn inherent structure of data and it is not centered around clustering, anomaly detection, dimensionality reduction, and density estimation. The genesis model of this system can retrieve the original image from a distorted image (e.g., non-linear gray-value transformation, image inpainting, image out-painting, and pixels shuffle) using proxy task [44] . Zhu et al. [45] have used self-supervised learning and its proxy task to solve Rubik's cube which mainly contain three operations (rotating, masking, and ordering) the robustness of this model comes from that the network is robust to noise and it learns features that are invariant to rotation and translation. Shekoofeh et al. [46] have exploited the effectiveness of selfsupervised learning in pre-training strategy used to classify medical images for tow tasks (dermatology skin condition classification, and multi-label chest X-ray classification). Their study has improved the classification accuracy after using two self-supervised learning systems: the first one is trained on ImageNet dataset and the second one is trained on unlabeled domain specific medical images.",
            "cite_spans": [
                {
                    "start": 1045,
                    "end": 1049,
                    "text": "[44]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 1063,
                    "end": 1067,
                    "text": "[45]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 1380,
                    "end": 1384,
                    "text": "[46]",
                    "ref_id": "BIBREF49"
                }
            ],
            "ref_spans": [],
            "section": "Self-supervised learning"
        },
        {
            "text": "Semi-supervised learning is a system by which it stands in between supervised learning and unsupervised learning systems, because for example, it is used for classification task (supervised learning) but without having all the data labeled (Unsupervised learning). Thus, this system is trained on small, labeled dataset, and then generates pseudo-labels to get larger dataset with labels, and the final model is trained by mixing up both the original dataset and the generated one of images. Nie et al. [47] have proposed semi-supervised learning-based deep network for image segmentation, the proposed method trains adversarially a segmentation model, from the confidence map is computed, and the semi-supervised learning strategy is used to generate labeled data. Another application of semisupervised learning is used for cardiac MRI segmentation, [48] . Liu et al. [49] have presented a novel relation-driven semi-supervised model to classify medical images, they have introduced a novel Sample Relation Consistency (SRC) paradigm to use unlabeled data by generalizing and modeling the relationship information between different samples; in their experiment, they have applied the novel method on two benchmark medical images for classification, skin lesion diagnosis from ISIC 2018 challenge, and thorax disease classification from the publicly dataset ChestX-ray14, and the results have achieved the state-ofthe-art criteria.",
            "cite_spans": [
                {
                    "start": 503,
                    "end": 507,
                    "text": "[47]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 851,
                    "end": 855,
                    "text": "[48]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 869,
                    "end": 873,
                    "text": "[49]",
                    "ref_id": "BIBREF52"
                }
            ],
            "ref_spans": [],
            "section": "Semi-supervised learning"
        },
        {
            "text": "Weak supervision is basically a branch of machine learning used to label unlabeled data by exploiting noisy, limited sources to provide supervision signal that is responsible of labeling large amount of training data using supervised manner. In general, the new labeled data in \"weakly-supervised learning\" are imperfect, but it can be used to create a robust predictive model. The weakly supervised method uses image-level annotations and weak annotations (e.g., dots and scribbles) [50] . Weakly supervised multi-label disease system was used for classification task of chest X-ray [51] , Also, it is used for multi-organ segmentation, [52] by learning single multi-class network from a combination of multiple datasets, where each one of these datasets contains partially organ labeled data and low sample size. Roth et al. [53] have used weakly supervised learning system for medical image segmentation and their results has speeded up the process of generating new training dataset used for the development purpose of deep learning in medical images analysis. Schleg et al. [54] have used this type of deep learning approach to detect abnormal regions from test images. Hu et al. [55] proposed an end-to-end CNN approach for displacement field prediction to align multiple labeled corresponding structures, and the proposed work was used for medical image registration of prostate cancer from T2-weighted MRI and 3D transrectal ultrasound images; the results reached 0.87 of Mean Dice score. Another application is applied in diabetic retinopathy detection in a retinal image dataset [56] .",
            "cite_spans": [
                {
                    "start": 484,
                    "end": 488,
                    "text": "[50]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 584,
                    "end": 588,
                    "text": "[51]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 638,
                    "end": 642,
                    "text": "[52]",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 827,
                    "end": 831,
                    "text": "[53]",
                    "ref_id": "BIBREF56"
                },
                {
                    "start": 1079,
                    "end": 1083,
                    "text": "[54]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 1185,
                    "end": 1189,
                    "text": "[55]",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 1589,
                    "end": 1593,
                    "text": "[56]",
                    "ref_id": "BIBREF59"
                }
            ],
            "ref_spans": [],
            "section": "Weakly (partially) supervised learning"
        },
        {
            "text": "Reinforcement learning (RL) is subtype of deep learning by which it takes the beneficial action toward maximizing the rewards of specific situation. The main difference between supervised learning and reinforcement learning is that in the first one, the training data have the answer within it, but in case of reinforcement learning, the agent decides how to act with the task where in the absence of the training dataset the model learn from its experience. Al Walid et al. [57] have used reinforcement learning for landmark localization in 3D medical images; they have introduced the partial policy-based RL, by learning optimal policy of smaller partial domains; in this paper, the proposed method was used on three different localization task in 3D-CT scans and MR images and proved that learning the optimal behavior requires significantly smaller number of trials. Also in [58] , RL was used for object detection PET images. RL was also used for color image classification on neuromorphic system [59] .",
            "cite_spans": [
                {
                    "start": 475,
                    "end": 479,
                    "text": "[57]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 879,
                    "end": 883,
                    "text": "[58]",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 1002,
                    "end": 1006,
                    "text": "[59]",
                    "ref_id": "BIBREF63"
                }
            ],
            "ref_spans": [],
            "section": "Reinforcement learning"
        },
        {
            "text": "Transfer learning is one of the powerful enablers of deep learning [60] , which involves training a deep leaning model by re-using of a an already trained model with related or un-related large dataset. It is known that medical data face the problem of lacking and insufficient for training deep learning models perfectly, so Transfer learning can provide the CNN models with large learned features from non-medical images which in turn can be useful for this case [61] . Furthermore, Transfer Learning is a key feature for time-consuming problem while training a deep neural network, because it uses the freeze weights and hyperparameters of another model. In usual using transfer learning the weights which is already trained on different data (images) are freezed to be used for another CNN model, and only in the few last layers, modifications are done and these few last layers are trained on the real data for tuning the hyperparameters and weights. For these reasons, transfer learning was widely used in medical imaging, for example a classification of the interstitial lung disease [61] and detecting the thoraco-abdominal lymph nodes from CT scans; it was found that transfer learning is efficient, even though the disparity between the medical images and natural images. Transfer learning as well could be used for different CNN models (e.g., VGG-16, Resnet-50, and Inception-V3), Xue et al. [62] , have developed transfer learning-based model for these models, and furthermore, they have proposed an Ensembled Transfer Learning (ETL) framework for classification enhancement of cervical histopathological images. Overall, in many computer vision tasks, tuning the last classification layers (fully connected layers) which is called \"shallow tuning\" is probably efficient, but in medical imaging, a deep tuning for more layers is needed [63] , where they have studied the benefit of using transfer learning in four applications within three imaging modalities (polyp detection from colonoscopy videos, segmentation of the layers of carotid artery wall from ultrasound scans, and colonoscopy video frame classification), their study results found that training more CNN layers on the medical images is efficient more than training from the scratch.",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 71,
                    "text": "[60]",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 465,
                    "end": 469,
                    "text": "[61]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 1091,
                    "end": 1095,
                    "text": "[61]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 1403,
                    "end": 1407,
                    "text": "[62]",
                    "ref_id": null
                },
                {
                    "start": 1848,
                    "end": 1852,
                    "text": "[63]",
                    "ref_id": "BIBREF66"
                }
            ],
            "ref_spans": [],
            "section": "Transfer learning"
        },
        {
            "text": "Convolutional Neural Networks (CNNs) based models are usually used in different ways with keeping in minds that CNNs remains the heart of any model; in general, CNN could be trained on the available dataset from the scratch when the available dataset is very large to perform a specific task (e.g., segmentation, classification, detection, etc.), or a pre-trained model with a large dataset (e.g., ImageNet) where this model could be used to train new datasets (e.g., CT scans) with fine-tuning some layers only; this approach is called transfer learning (TL) [60] . Moreover, CNN models could be used for feature extraction only from the input images with more representation power before proceeding to the next stage of processing these features. In the literature, there were commonly used CNN models which has proven their effectiveness, and based on these models, some developments have arisen; we will mention the most efficient and used models of deep learning in medical images analysis. First, it was AlexNet which was introduced by Alex Krizhevsky [64] and Siyuan Lu et al. [65] , have used transfer learning with a pre-trained AlexNet with replacing the parameters of the last three layers with a random parameters for pathological brain detection. Another frequently used model is Visual Geometry Group (VGG-16) [66] where 16 refers to the number of layers; later on, some developments were proposed for VGG-16 like VGG-19; in [67] , they have listed medical imaging applications using different VGGNet architectures. Inception Network [68] is one of the most common CNN architectures which aim to limit the resources consumption. And further modifications on this basic network were reported with new versions of it [69] . Gao et al. [70] have proposed a new architecture of Residual Inception Encoder-Decoder Neural Network (RIEDNet) for medical images synthesis. Later on, Inception network was called Google Net [71] . ResNet [72] is a powerful architecture for very deep architectures sometimes over than 100 layers, and it helps in limiting the loss of gradient in the deeper layers, because it adds residual connections between some convolutional layers Fig. 4 . Some of ResNet models in medical imaging are mostly used for robust classification [73, 74] , for pulmonary nodes and intracranial hemorrhage.",
            "cite_spans": [
                {
                    "start": 560,
                    "end": 564,
                    "text": "[60]",
                    "ref_id": "BIBREF64"
                },
                {
                    "start": 1058,
                    "end": 1062,
                    "text": "[64]",
                    "ref_id": null
                },
                {
                    "start": 1084,
                    "end": 1088,
                    "text": "[65]",
                    "ref_id": "BIBREF68"
                },
                {
                    "start": 1324,
                    "end": 1328,
                    "text": "[66]",
                    "ref_id": "BIBREF69"
                },
                {
                    "start": 1439,
                    "end": 1443,
                    "text": "[67]",
                    "ref_id": "BIBREF70"
                },
                {
                    "start": 1548,
                    "end": 1552,
                    "text": "[68]",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 1729,
                    "end": 1733,
                    "text": "[69]",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 1747,
                    "end": 1751,
                    "text": "[70]",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 1928,
                    "end": 1932,
                    "text": "[71]",
                    "ref_id": "BIBREF74"
                },
                {
                    "start": 1942,
                    "end": 1946,
                    "text": "[72]",
                    "ref_id": "BIBREF75"
                },
                {
                    "start": 2265,
                    "end": 2269,
                    "text": "[73,",
                    "ref_id": "BIBREF76"
                },
                {
                    "start": 2270,
                    "end": 2273,
                    "text": "74]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 2173,
                    "end": 2179,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Best deep learning models and practices"
        },
        {
            "text": "DenseNet exploits same aspect of residual CNN (ResNet) but in a compact mode for achieving good representations and feature extraction. Each layer of the network has in its input outputs from the previous layers, so comparing to a traditional CNN, DenseNet contains more connections (L) than CNN (L connections) where DenseNet has [L(L \u2212 1)]/2 connections. DenseNet is widely used with medical images, Mahmood et al. [78] have proposed a Multimodal DenseNet for fusing multimodal data to give the model the flexibility of combining information from multiple resources, and they have used this novel model for polyp characterization and landmark identification in endoscopy. Another application used transfer learning with DenseNet for fundus medical images [79] .",
            "cite_spans": [
                {
                    "start": 417,
                    "end": 421,
                    "text": "[78]",
                    "ref_id": null
                },
                {
                    "start": 757,
                    "end": 761,
                    "text": "[79]",
                    "ref_id": "BIBREF82"
                }
            ],
            "ref_spans": [],
            "section": "Best deep learning models and practices"
        },
        {
            "text": "U-net [80] is one of the most popular network architectures used mostly for segmentation, Fig. 4 . The reason behind it is mostly used in medical images is that because it is able to localize and highlight the borders between classes (e.g., brain normal tissues and malignant tissues) by doing the classification for each pixel. It is called U-net, because the network architecture takes the shape of U alphabet and it contains concatenation connections; Fig. 4 shows the basic structure of the U-Net. Some developments of U-Net were U-Net + + [75] , have proposed a new architecture U-Net + + for medical image segmentation, and in their experiments, U_Net + + has outperformed both U-Net and wide U-Net architectures for multiple medical image segmentation tasks, such as liver segmentation from CT scans, polyp segmentation in colonoscopy videos, and nuclei segmentation from microscopy images. From these popular and basic DL models, some other models were inspired and even some of these models were inspired and rely on the insights from others (e.g., inception and ResNet); Fig. 5 shows the timeline of the mentioned models and other popular models too.",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "text": "[80]",
                    "ref_id": "BIBREF83"
                },
                {
                    "start": 544,
                    "end": 548,
                    "text": "[75]",
                    "ref_id": "BIBREF78"
                }
            ],
            "ref_spans": [
                {
                    "start": 90,
                    "end": 96,
                    "text": "Fig. 4",
                    "ref_id": null
                },
                {
                    "start": 455,
                    "end": 461,
                    "text": "Fig. 4",
                    "ref_id": null
                },
                {
                    "start": 1081,
                    "end": 1087,
                    "text": "Fig. 5",
                    "ref_id": null
                }
            ],
            "section": "Best deep learning models and practices"
        },
        {
            "text": "For the purpose of studying the most applications of deep learning in medical imaging, we have organized a study based on the most-cited papers found in literature from 2015 to 2021; the number of surveyed literatures for segmentation, detection, classification, registration, and characterization are: 30, 20, 30, 10, and 10, respectively. Figure 6 shows the pie chart of these applications.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 341,
                    "end": 349,
                    "text": "Figure 6",
                    "ref_id": null
                }
            ],
            "section": "Deep learning applications in medical imaging"
        },
        {
            "text": "Deep learning is used to segment different body structures from different imaging modalities such as, MRI, CT scans, PET, and ultrasound images. Segmentation means portioning an image into different segments where usually these segments belongs to specific classes (tissue classes, organ, or biological structure) [81] . In general overview, for CNN models, there are two main approaches for segmenting a medical image; the first is using the entire image as an input and the second is using patches from the image. Segmentation process of Liver tumor using CNN architecture is shown in Fig. 7 according to Li et al., and both the methods work well in generating an output map which provides Fig. 4 The basic models used in medical imaging: A ResNet architecture, B U-Net architecture [75] , C CNN AlexNet architecture for breast cancer [76] , and D Dense Net architecture [77] the segmented output image. Segmentation is potential for surgical planning and determining the exact boundaries of sub-regions (e.g., tumor tissues) for better guidance during the direct surgery resection. Most likely segmentation is common in neuroimaging field and with brain segmentation more than other organs in the body. Akkus et al. [82] have reviewed different DL models for segmentation of different organs with their datasets. Since CNN architecture can handle both 2-dimensional and 3-dimensional images, it is considered suitable for MRI which is in 3D scheme; Milleteria et al. [83] have used 3D MRI images and applier 3D-CNN for segmenting prostate images. They have proposed new CNN architecture which is V-Net which relies on the insights of U-Net [80] and their output results have achieved 0.869 dice similarity coefficient score; this is Liver tumor segmentation using CNN architecture [86] considered as efficient model regarding to the small dataset (50 MRI for training and 30 MRI for testing). Havaei et al. [84] have worked on Glioma segmentation from BRATS-2013 with 2D-CNN model and this model took only 3 min to run. From clinical point of view, segmentation of organs is used for calculating clinical parameters (e.g., volume) and improving the performance of Computer-Aided Detection (CAD) to define the regions accurately. Taghanaki et al. [85] have listed the segmentation challenges from 2007 to 2020 with different imaging modalities; Fig. 8 shows the number of these challenges. We have summarized Deep Learning models for segmentation for different organs in the body, based on the highly cited paper and variations in deep learning models shown in Table 1 3",
            "cite_spans": [
                {
                    "start": 314,
                    "end": 318,
                    "text": "[81]",
                    "ref_id": "BIBREF84"
                },
                {
                    "start": 785,
                    "end": 789,
                    "text": "[75]",
                    "ref_id": "BIBREF78"
                },
                {
                    "start": 837,
                    "end": 841,
                    "text": "[76]",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 873,
                    "end": 877,
                    "text": "[77]",
                    "ref_id": "BIBREF80"
                },
                {
                    "start": 1219,
                    "end": 1223,
                    "text": "[82]",
                    "ref_id": "BIBREF85"
                },
                {
                    "start": 1470,
                    "end": 1474,
                    "text": "[83]",
                    "ref_id": "BIBREF86"
                },
                {
                    "start": 1643,
                    "end": 1647,
                    "text": "[80]",
                    "ref_id": "BIBREF83"
                },
                {
                    "start": 1784,
                    "end": 1788,
                    "text": "[86]",
                    "ref_id": "BIBREF89"
                },
                {
                    "start": 1910,
                    "end": 1914,
                    "text": "[84]",
                    "ref_id": "BIBREF87"
                },
                {
                    "start": 2249,
                    "end": 2253,
                    "text": "[85]",
                    "ref_id": "BIBREF88"
                }
            ],
            "ref_spans": [
                {
                    "start": 587,
                    "end": 593,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 692,
                    "end": 698,
                    "text": "Fig. 4",
                    "ref_id": null
                },
                {
                    "start": 2347,
                    "end": 2353,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 2563,
                    "end": 2570,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Image segmentation"
        },
        {
            "text": "Detection simply means is to identify a specific region of interest in an image and finally to draw a bounding box around it. Localization is just another terminology of detection which means to determine the location of a particular structure in images. In deep learning for medical images, analysis detection is referred as Computer-Aided Detection (CAD), Fig. 9 . CAD is divided commonly for anatomical structure detection or for lesions (abnormalities) detection. Anatomical structure detection is a crucial task in medical images analysis due to determining the locations of organs substructures and landmarks which in turn guide for better organ segmentation and radiotherapy planning for analysis and further surgical purposes. Deep learning for organ or lesion detection can be either classification-based or regression-based methods; the first one is used for discriminating body parts, while the second method is used for determining more detailed locations information. In fact, most of the deep learning pathologies are connected; for example, Yang et al. [114] have proposed a custom CNN classifier for locating landmarks which is the initialization steps for the femur bone segmentation. In case of lesion detection which is considered to be clinically time-consuming for the radiologists and physicians and it may lead to errors due to the lack of data needed to find the abnormalities and also to the visual similarity of the normal and abnormal tissues in some cases (e.g., low contrast lesions in mammography). Thus, the potential of CAD systems comes from overcoming these cons, where it reduces the times needed, computational cost, providing alternative way for the people who live in areas that lacks specialists and improve the efficiency of thereby streamlining in the clinical workflow. Some CNN custom models were developed specifically for lesion detection [115, 116] . Both organ anatomical structures and lesion detection are applicable for mostly all body's organs (e.g., Brain, Eye, Chest, Abdominal, etc.), and CNN architectures are used for both 2D and 3D medical images. When using 3D volumes like MRI, it is better to use patches fashion, because it is more efficient than sliding window fashion, so in this way, the whole CNN architecture will be trained using patches before the fully connected layer, [117] . Table 2 shows top-cited papers with different deep learning models for both structure and lesion detection within different organs.",
            "cite_spans": [
                {
                    "start": 1068,
                    "end": 1073,
                    "text": "[114]",
                    "ref_id": "BIBREF118"
                },
                {
                    "start": 1884,
                    "end": 1889,
                    "text": "[115,",
                    "ref_id": "BIBREF119"
                },
                {
                    "start": 1890,
                    "end": 1894,
                    "text": "116]",
                    "ref_id": "BIBREF120"
                },
                {
                    "start": 2339,
                    "end": 2344,
                    "text": "[117]",
                    "ref_id": "BIBREF122"
                }
            ],
            "ref_spans": [
                {
                    "start": 358,
                    "end": 364,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 2347,
                    "end": 2354,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": ".2 Image detection/localization"
        },
        {
            "text": "This task is the fundamental task for the computer-aided diagnosis (CAD), and it aims to discover the presence of disease indicators. Commonly in medical images, the deep learning classification model's output is a number that represents the disease presence or absence. A subtype of classification is called lesion classification and is used in a segmented images from the body [136] . Traditionally, classification used to rely on the color, shape, and texture, etc. but in medical images, features are more complicated to be categorized as these low-level features which lead to poor model generalization due to the high-level features for medical image. Recently, deep learning has provided an efficient way of building an n end-to-end model which produce classification labels-based from different medical images' modalities. Because of the high resolution of medical images, expensive computational costs arise and limitations in the number of deep model layers and channels; Lai Zhifei et al. [137] have proposed the Coding Network with Multilayer Perceptron (CNMP) to overcome these problems by combining high-level features extracted by CNN and other manually selected common features. Xiao et al. [138] have used parallel attention module (PAM-DenseNet) for COVID-10 diagnosis, and their model can learn strong features automatically from channel-wise and spatial-wise which help in making the network to automatically detect the infected areas in CT scans of lungs without the need [139] ; classifying medical images is essential part for clinical aiding and further treatments, for example detecting and classifying pneumonia presence from chest X-ray scans [140] ; CNN-based models have introduced various stratifies to better the classification performance especially when using small datasets, for example data augmentation [141, 142] . GANs' network was widely used for data augmentation and image synthesis [143] . Another robust strategy is transfer learning [61] . Rajpurkar Another 3D-CNN architecture employed in an autoencoder architecture is also used to classify Alzheimer disease using transfer learning on a pre-trained CAD Dementia dataset, they have reported accuracy of 99% on the publicly dataset ADNI, and the fine-tuning process is done in a supervised manner [145] . Diabetic Retinopathy (DR) could be diagnosed using fundus photographs of the eye, Abramoff et al. [146] have used custom CNN inspired from Alexnet and VGGNet to train a device (IDx-DR) version X2.1 on a dataset of 1.2 million DR images to record 0.98 AUC score. Figure 10 shows the classification of medical images. A few notable results found in literature are summarized in Table 3 .",
            "cite_spans": [
                {
                    "start": 379,
                    "end": 384,
                    "text": "[136]",
                    "ref_id": "BIBREF142"
                },
                {
                    "start": 1000,
                    "end": 1005,
                    "text": "[137]",
                    "ref_id": "BIBREF143"
                },
                {
                    "start": 1207,
                    "end": 1212,
                    "text": "[138]",
                    "ref_id": "BIBREF144"
                },
                {
                    "start": 1493,
                    "end": 1498,
                    "text": "[139]",
                    "ref_id": "BIBREF145"
                },
                {
                    "start": 1670,
                    "end": 1675,
                    "text": "[140]",
                    "ref_id": "BIBREF146"
                },
                {
                    "start": 1839,
                    "end": 1844,
                    "text": "[141,",
                    "ref_id": "BIBREF147"
                },
                {
                    "start": 1845,
                    "end": 1849,
                    "text": "142]",
                    "ref_id": "BIBREF149"
                },
                {
                    "start": 1924,
                    "end": 1929,
                    "text": "[143]",
                    "ref_id": "BIBREF150"
                },
                {
                    "start": 1977,
                    "end": 1981,
                    "text": "[61]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 1984,
                    "end": 1993,
                    "text": "Rajpurkar",
                    "ref_id": null
                },
                {
                    "start": 2292,
                    "end": 2297,
                    "text": "[145]",
                    "ref_id": "BIBREF152"
                },
                {
                    "start": 2398,
                    "end": 2403,
                    "text": "[146]",
                    "ref_id": "BIBREF153"
                }
            ],
            "ref_spans": [
                {
                    "start": 2562,
                    "end": 2571,
                    "text": "Figure 10",
                    "ref_id": null
                },
                {
                    "start": 2676,
                    "end": 2683,
                    "text": "Table 3",
                    "ref_id": null
                }
            ],
            "section": "Image classification"
        },
        {
            "text": "Image registration means to allow images' spatial alignment to a common anatomical field. Previously, image registration was done manually by clinical experts, but after deep learning, image registration has changed [176] [177] [178] . Practically, this task is considered main scheme in medical images, and it relies on aligning and establishing accurate anatomical correspondences between a source image and target image using transformations. In the main theme of image registration, both handcrafted and selected features are employed in a supervised manner. Wu et al. [179, 180] have employed unsupervised deep learning approach for learning the basis filters which in turn represent image's patches and detect the correspondence detection for image registration. Yang et al. [177] have used an autoencoder architecture for predicting of deformation diffeomorphic metrics mapping (LDDMM) to get fast deformable image registration and the results shows improvements in computational time. Commonly, image registration is employed for spinal surgery or neurosurgery in form of localization of spinal bony or tumor landmarks to facilitate the spinal screw implant or tumor removal operation. Miao et al. [181] have trained a customized CNN on X-ray images to register 3D models of hand implant and knee implant onto 2D X-ray images for pose estimation. An overview of registration operation is shown in Table 4 , which shows a summary of medical images registration as an application of deep learning.",
            "cite_spans": [
                {
                    "start": 216,
                    "end": 221,
                    "text": "[176]",
                    "ref_id": "BIBREF184"
                },
                {
                    "start": 222,
                    "end": 227,
                    "text": "[177]",
                    "ref_id": "BIBREF185"
                },
                {
                    "start": 228,
                    "end": 233,
                    "text": "[178]",
                    "ref_id": "BIBREF186"
                },
                {
                    "start": 573,
                    "end": 578,
                    "text": "[179,",
                    "ref_id": "BIBREF187"
                },
                {
                    "start": 579,
                    "end": 583,
                    "text": "180]",
                    "ref_id": "BIBREF188"
                },
                {
                    "start": 781,
                    "end": 786,
                    "text": "[177]",
                    "ref_id": "BIBREF185"
                },
                {
                    "start": 1206,
                    "end": 1211,
                    "text": "[181]",
                    "ref_id": "BIBREF189"
                }
            ],
            "ref_spans": [
                {
                    "start": 1405,
                    "end": 1412,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Image registration"
        },
        {
            "text": "Characterization of a disease within deep learning is a stage of computer-aided diagnosis (CADx) systems. For example, radiomics is an expansion of CAD systems for other tasks such as prognosis, staging, and cancer subtypes' determination. In fact, characterization of a disease will rely on the disease type in the first place and on the clinical questions related to it. There is two ways used for features extraction, either handcrafted features extraction or deep learned features, in the first, radiomic features is similar to radiologist's way of interpretation and analysis of medical images. These features might include tumor size, texture, and shape. In literature, the handcrafted features are used for many purposes, such as tumor aggressiveness, the probability of having cancer in the future, and the malignancy probability [190, 191] . There are two main categories for characterization, lesion characterization and tissue characterization. In deep learning applications of medical imaging, each computerized medical image requires some normalization plus customization to be handled and suited to the task and image modality. Conventional CAD is used for lesion characterization. For example, to track the growth of lung nodules, the characterization task is needed for the nodules and the change of lung nodules over time, and this will help of reducing the false-positive of lung cancer diagnosis. Another example of tumor characterization is found in imaging genomics, where the radiomic features are used as phenotypes for associative analysis with genomics and histopathology. A good report which was done with multi-institutes' collaboration about breast phenotype group through TGCA/TCIA [192] [193] [194] . Tissue characterization is to examine when particular tumor areas are not relevant. The main focus in this type of characterization is on the healthy tissues that are susceptible for future disease; also focusing on the diffuse disease such as interstitial lung disease and liver disease [195] . Deep learning has used conventional texture analysis for lung tissue. The characterization of lung pattern using patches can be informative of the disease which commonly is interpreted by radiologists. Many researchers have employed DL models with different CNN architectures for interstitial lung disease classification characterized by lung tissue sores [149, 196] . CADx is not only a detection/localization task only, but it is classification and characterization task as well. Finding the likelihood of disease subtyping is the output of a DL model and characteristic features' presentation of a disease too. For the characterization task, especially with limited dataset, CNN models are not trained from scratch in general, data augmentation is an essential tool for this application, and performing CNN on dynamic contrast-enhanced MRI is important too. For example, while using VGG-19-Net, researchers have used DCE-MRI temporal images with precontrast, first post-contrast, and the second post-contrast MR images as an input to the RGB channels. Antropova et al. [197] have used the maximum intensity projections (MIP) as an input to their CNN model. Table 5 shows some highlighted literature of characterization which includes diagnosis and prognosis.",
            "cite_spans": [
                {
                    "start": 838,
                    "end": 843,
                    "text": "[190,",
                    "ref_id": "BIBREF199"
                },
                {
                    "start": 844,
                    "end": 848,
                    "text": "191]",
                    "ref_id": "BIBREF200"
                },
                {
                    "start": 1711,
                    "end": 1716,
                    "text": "[192]",
                    "ref_id": "BIBREF201"
                },
                {
                    "start": 1717,
                    "end": 1722,
                    "text": "[193]",
                    "ref_id": "BIBREF202"
                },
                {
                    "start": 1723,
                    "end": 1728,
                    "text": "[194]",
                    "ref_id": "BIBREF203"
                },
                {
                    "start": 2019,
                    "end": 2024,
                    "text": "[195]",
                    "ref_id": "BIBREF204"
                },
                {
                    "start": 2383,
                    "end": 2388,
                    "text": "[149,",
                    "ref_id": "BIBREF156"
                },
                {
                    "start": 2389,
                    "end": 2393,
                    "text": "196]",
                    "ref_id": "BIBREF205"
                },
                {
                    "start": 3099,
                    "end": 3104,
                    "text": "[197]",
                    "ref_id": "BIBREF206"
                }
            ],
            "ref_spans": [
                {
                    "start": 3187,
                    "end": 3194,
                    "text": "Table 5",
                    "ref_id": "TABREF5"
                }
            ],
            "section": "Image characterization"
        },
        {
            "text": "Prognosis and staging refer to the future prediction of a disease status for example after cancer identification, further treatment process through biopsies which give a track on the stage, molecular type, and genomics which finally provides information about prognosis and the further treatment process and options. Since most of the cancers are spatially heterogeneous, specialists and radiologists are interested about the information on spatial variations that medical imaging can provide. Mostly, many imaging biomarkers include only Gonz\u00e1lez et al. [204] Lung and chest (prognosis of chronic obstructive pulmonary disease (COPD)) Custom CNN CT scans (train = 7983, test = 1000 COPDGene + 1,672 ECLIPSE) 112 Lao et al. [205] Brain (Survival) CNN-S with transfer learning Multiparametric MRI (112 patients the size and another simple enhancement procedures; therefore, the current investigators are more interested in including radiomic features and extending the knowledge from medical images. Some deep learning analysis have been investigated in cancerous tumors for prognosis and staging [192, 206] . The goal of prognosis is to analyze the medical images (MRI or ultrasound) of cancer and get the better presentation of it by gaining the prognostic biomarkers from the phenotypes of the image (e.g., size, margin morphology, texture, shape, kinetics, and variance kinetics). For example, Li et al. [192] found that texture phenotype enhancement can characterize the tumor pattern from MRI, which lead to prediction of the molecular classification of the breast cancers; in other words, the computer-extracted phenotypes provide promises regarding the quality of the breast cancer subtypes' discrimination which leads to distinct quantitative prediction in terms of the precise medicine. Moreover, with the enhancement of the texture entropy, the vascular uptake pattern related to the tumor became heterogeneous which in turn reflects the heterogeneous temperament of the angiogenesis and the treatment process applicability and this is termed as the virtual digital biopsy location based. Gonzalez et al. [204] have applied DL on thoracic CT scans for prediction of staging of chronic obstructive pulmonary disease (COPD). Hidenori et al. [207] have used CNN model for grading diabetic retinopathy and determining the treatment and prognosis which involves a non-typically visualized on fundoscopy of retinal area; their novel AI system suggests treatment and determines prognoses. Another term related to staging and prognosis is survival prediction and disease outcome, Skrede et al. [208] have performed DL using a large dataset over 12 million pathology images to predict the survival outcome for colorectal cancer in its early stages, a common evaluation metric is Hazard function which indicate the risk measures of a patient after treatment, and their results yield a hazard ration of 3.84 for poor against good prognosis in the validation set cohort of 1122 patients, and a hazard ratio of 3.04 after adjusting for prognostic markers which contain T and N stages. Sillard et al. [209] used deep learning for predicting survival outcomes after hepatocellular carcinoma resection.",
            "cite_spans": [
                {
                    "start": 555,
                    "end": 560,
                    "text": "[204]",
                    "ref_id": "BIBREF213"
                },
                {
                    "start": 709,
                    "end": 712,
                    "text": "112",
                    "ref_id": "BIBREF115"
                },
                {
                    "start": 724,
                    "end": 729,
                    "text": "[205]",
                    "ref_id": "BIBREF215"
                },
                {
                    "start": 1096,
                    "end": 1101,
                    "text": "[192,",
                    "ref_id": "BIBREF201"
                },
                {
                    "start": 1102,
                    "end": 1106,
                    "text": "206]",
                    "ref_id": "BIBREF216"
                },
                {
                    "start": 1407,
                    "end": 1412,
                    "text": "[192]",
                    "ref_id": "BIBREF201"
                },
                {
                    "start": 2115,
                    "end": 2120,
                    "text": "[204]",
                    "ref_id": "BIBREF213"
                },
                {
                    "start": 2249,
                    "end": 2254,
                    "text": "[207]",
                    "ref_id": "BIBREF217"
                },
                {
                    "start": 2596,
                    "end": 2601,
                    "text": "[208]",
                    "ref_id": "BIBREF218"
                },
                {
                    "start": 3097,
                    "end": 3102,
                    "text": "[209]",
                    "ref_id": "BIBREF219"
                }
            ],
            "ref_spans": [],
            "section": "Prognosis and staging"
        },
        {
            "text": "Basically, after COVID-19 has been identified in 31 December 2019 [210] and it is based on polymerase chain reaction (PCR) test. However, it was found that it can be analyzed and diagnosed through medical imaging, even though most radiologists' societies do not recommend it, because it has similar features of various pneumonia diseases. Simpson et al. [211] , have prospected a potential use of CT scans for clinical managing, and eventually, they have proposed four standard categories for reporting COVID-19 languages. Mahmood et al. [212] have studied 12,270 patients and recommend to be subjected for CT screening for early detection of COVID-19 to limit the speedy spread of the disease. Another approach for classification of COVID-19 is using portable (PCXR) which uses chest X-ray scans instead of the expensive CT scans; furthermore, this has the potential of minimizing the chances of spreading the virus. For the identification of COVID-19, Pereira et al. [152] have flowed using chest X-ray scans using the portable manner. For the comparison of different screening methods, it was suggested by Soldati et al. [213] , which stated the Lung Ultrasound (LUS) is needed to be compared with chest X-ray and CT scans to help designing better diagnostic system to be suitable for the technological resources. COVID-19 has gained the attention of deep learning researchers who have employed different DL models for the main pathologies for diagnosing this disease using different medical imaging modalities from different datasets. Starting with segmentation, a new proposed system for screening coronavirus disease was done by Butt et al. [214] , who have employed 3D-CNN architecture for segmenting multiple volumes of CT scans; a classification step is included to categorize patches into COVID-19 from other pneumonia diseases, such as influenza and a viral pneumonia. After that, Bayesian function is used to calculate the final analysis report. Wang et al. [215] have performed their CNN model on chest X-ray images, for extracting the feature map, classification, regression, and finally the needed mask for segmentation. Another DL model using chest X-ray scans was introduced by Murphy et al. [108] , using U-Net architecture for detecting of tuberculosis and finally classifying images, with AUC of 0.81. For the detection of COVID-19, Li et al. [124] have developed a new tool of deep learning to detect COVID-19 from CT scans; the main work consists of few steps starting from extracting the lungs as ROI using U-Net, then generating features using ResNet-50, and finally using fully connected layer for generating the probability score of COVID-19 and the final results have reported AUC of 0.96. Another COVID-19 detection system from X-rays and CT scans was proposed by Kassani et al. [126] , who have used multiple models for their strategy, DenseNet 121 have achieved accuracy of 99%, and REsNet achieved accuracy of 98% after being trained by LightGBM, and also, they have used other backbone models such as MobileNet, Xception, and Inception-ResNet-V2,NASNe, and VGG-Net. For classification of COVID-19, Wu et al. [150] have used the fusion of DL networks, starting from segmenting lung regions using thresholdbased method using CT scans, next using ResNet-50 to extract the features map which further is fed to fully connected layer to record AUC of 0.732 and 70% accuracy. Ardakani et al. [216] have compared ten DL models for classification of COVID-19, including AlexNet, VGG-16, VGG-19, GoogleNet, MobileNet, Xception, ResNet-101, ResNet-18, ResNet-50, and SqueezNet. Where ResNet-101 has recorded the best results regarding sensitivity. A few used deep learning themes that have been used for different applications of COVID-19 are listed in Tables 1, 2, 3.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 71,
                    "text": "[210]",
                    "ref_id": null
                },
                {
                    "start": 354,
                    "end": 359,
                    "text": "[211]",
                    "ref_id": "BIBREF221"
                },
                {
                    "start": 538,
                    "end": 543,
                    "text": "[212]",
                    "ref_id": "BIBREF222"
                },
                {
                    "start": 969,
                    "end": 974,
                    "text": "[152]",
                    "ref_id": "BIBREF159"
                },
                {
                    "start": 1124,
                    "end": 1129,
                    "text": "[213]",
                    "ref_id": "BIBREF223"
                },
                {
                    "start": 1647,
                    "end": 1652,
                    "text": "[214]",
                    "ref_id": "BIBREF224"
                },
                {
                    "start": 1970,
                    "end": 1975,
                    "text": "[215]",
                    "ref_id": "BIBREF226"
                },
                {
                    "start": 2209,
                    "end": 2214,
                    "text": "[108]",
                    "ref_id": "BIBREF111"
                },
                {
                    "start": 2363,
                    "end": 2368,
                    "text": "[124]",
                    "ref_id": "BIBREF129"
                },
                {
                    "start": 2807,
                    "end": 2812,
                    "text": "[126]",
                    "ref_id": "BIBREF131"
                },
                {
                    "start": 3140,
                    "end": 3145,
                    "text": "[150]",
                    "ref_id": "BIBREF157"
                },
                {
                    "start": 3417,
                    "end": 3422,
                    "text": "[216]",
                    "ref_id": "BIBREF227"
                }
            ],
            "ref_spans": [],
            "section": "Medical imaging in COVID-19"
        },
        {
            "text": "It was clearly that deep learning approach performs better than the traditional machine learning and shallow learning methods and other handcrafted feature extraction from images, because deep learning models learn image descriptors automatically for analysis. It is commonly possible to combine deep learning approach with the knowledge learned from the handcrafted features for analyzing medical images [153, 200, 217] . The main key feature of deep learning is the large-scale datasets which contain images from thousands of patients. Although some vast data of clinical images, reports, and annotations are recorded and stored digitally in many hospitals for example, Picture Archiving and Communication systems (PACS) and Oncology Information System (OIS), in practice, these kinds of large-scale datasets with semantic labels are an efficiency measure for deep learning models used in medical imaging analysis. As it is known that medical images face the lack of dataset, data augmentation has been used to create new samples either depending on the existing samples or using generative models to generate new images. The new augmented samples are emerged with the original samples; thus, the size of the dataset is increased with the variation in the data points. Data augmentation is used by default with deep learning due to its added efficiency, since it reduces the chance of overfitting and it eliminates the imbalanced issue while using multiclass datasets, because it increases the number of the training samples and this also helps in generalizing the models and enhance the testing results. The basic data augmentation techniques are simple and it was widely adopted in medical imaging, such as cropping, rotating, flipping, shearing, scaling, and translation of images [80, 218, 219] . Pezeshk et al. [220] have proposed mixing tool which can seamlessly merge a lesion patch into a CT scan or mammography modality, so the merged lesion patches can be augmented using the basic transformations and inserted to the lesion shape and characteristics.",
            "cite_spans": [
                {
                    "start": 405,
                    "end": 410,
                    "text": "[153,",
                    "ref_id": "BIBREF160"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "200,",
                    "ref_id": "BIBREF209"
                },
                {
                    "start": 416,
                    "end": 420,
                    "text": "217]",
                    "ref_id": "BIBREF228"
                },
                {
                    "start": 1786,
                    "end": 1790,
                    "text": "[80,",
                    "ref_id": "BIBREF83"
                },
                {
                    "start": 1791,
                    "end": 1795,
                    "text": "218,",
                    "ref_id": "BIBREF229"
                },
                {
                    "start": 1796,
                    "end": 1800,
                    "text": "219]",
                    "ref_id": "BIBREF230"
                },
                {
                    "start": 1818,
                    "end": 1823,
                    "text": "[220]",
                    "ref_id": "BIBREF231"
                }
            ],
            "ref_spans": [],
            "section": "Data augmentation"
        },
        {
            "text": "Zhang et al. [221] have used DCNN for extracting features and obtaining image representations and similarity matrix too, their proposed data augmentation method is called unified learning of features representation, their model was trained on seed-labeled dataset, and authors intended to classify colonoscopy and upper endoscopy medical images. The second method to tackle limited datasets is to synthesize medical data using an object model or physics principles of image formation and using generative models schemes to serve as applicable medical examples and therefore increase the performance of any deep learning task at hand. The most used model for synthesizing medical data is Generative Adversarial Networks (GANs); for example [143] , GANs were used to generate lesion samples which increase CNN performance while the classification task of liver lesions. Yang et al. [222] used Radon Transform for objects with different modeled conditions by adding noise to the data for synthesizing CT dataset and the trained CNN model does the estimation of high-dose projection from low-dose. Synthesizing medical images is used for different purposes; for example, Chen et al. [223] have generating training data for noise reduction for reconstructed CT scans by applying deep learning algorithm by synthesizing noisy projections from patient images. While, CUI et al. [224] have used simulated dynamic PET data and used stacked sparse autoencoders for dynamic PET reconstruction framework.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 18,
                    "text": "[221]",
                    "ref_id": "BIBREF233"
                },
                {
                    "start": 739,
                    "end": 744,
                    "text": "[143]",
                    "ref_id": "BIBREF150"
                },
                {
                    "start": 880,
                    "end": 885,
                    "text": "[222]",
                    "ref_id": "BIBREF234"
                },
                {
                    "start": 1179,
                    "end": 1184,
                    "text": "[223]",
                    "ref_id": "BIBREF235"
                },
                {
                    "start": 1371,
                    "end": 1376,
                    "text": "[224]",
                    "ref_id": "BIBREF236"
                }
            ],
            "ref_spans": [],
            "section": "Data augmentation"
        },
        {
            "text": "Deep learning models are famous to be dataset hungry, and the good quality of dataset has been always the key-parameter for deep learning for learning computational models and provide trusted results. The task of deep learning models is more potential when handling medical data because the accuracy is highly needed, recently many publicly available datasets have been released online for evaluating the new developed DL models. Commonly, there are different repositories which provide useful compilations of the public datasets (e.g., Github, Kaggle, and other webpages). Comparing to the datasets for general computer vision tasks (thousands to million annotated images), medical imaging datasets are considered to be too small. According to the Conference on Machine Intelligence in Medical Imaging (C-MIMI) that was held in 2016 [225] , ML and DL are starving for largescale annotated datasets, and the most common regularities and specifications (e.g., sample size, cataloging and discovery, pixel data, metadata, and post-processing) related to medical images datasets are mentioned in this white paper. Therefore, different trends in medical imaging community have started to adopt different approaches for generating and increasing the number of samples in dataset, such as generative models, data augmentation, and weakly supervised learning, to avoid overfitting on the small dataset and finally provide an end-to-end fashion reliable deep learning model. Martin et al. [226] have described the fundamental steps for preparing the medical imaging datasets for the usage of AI applications. Fig. 11 shows the flowchart of the process; moreover, they have listed the current limitations and problem of data availability of such datasets. Examples of popular used databases for medical images analysis which exploit deep learning were listed in [227] . In this paper, we provide the typically mostly used datasets in the literature of medical imaging which are exploited by deep learning approaches in Table 6 .",
            "cite_spans": [
                {
                    "start": 834,
                    "end": 839,
                    "text": "[225]",
                    "ref_id": "BIBREF237"
                },
                {
                    "start": 1481,
                    "end": 1486,
                    "text": "[226]",
                    "ref_id": "BIBREF238"
                },
                {
                    "start": 1853,
                    "end": 1858,
                    "text": "[227]",
                    "ref_id": "BIBREF239"
                }
            ],
            "ref_spans": [
                {
                    "start": 1601,
                    "end": 1608,
                    "text": "Fig. 11",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 2010,
                    "end": 2017,
                    "text": "Table 6",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Datasets"
        },
        {
            "text": "Feature extraction is the tool of converting training data and trying to establish as maximum features as possible to make deep learning algorithms much efficient and adequate. There are some common algorithms used for medical image features' extractors, such as Gray-Level-Run-Length-Matrix (GLRM), Local Binary Patterns (LBP), Local Tetra Patterns (LTrP), Completed Local Binary Patterns (CLBP), and Gray-Level-Co-Occurrence Matrix (GLCM); these techniques are used in the first place before applying the main DL algorithm for different medical imaging tasks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "GLCM: is a common used feature extractor by which it searches for the textural patterns and their nature within gray-level gradients [234] . The main extracted features through this technique are autocorrelation, contrast, Dissimilarity, correlation, cluster prominence, energy, homogeneity, variance, entropy, difference variance, sum variance, cluster shade, sum entropy, information measure of correlation.",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 138,
                    "text": "[234]",
                    "ref_id": "BIBREF247"
                }
            ],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "LBP: is another famous feature extractor which uses the locally regional statistical features [235] . The main theme of this technique is to select a central pixel and the rest pixels along a circle are taken to be binary encoded as 0 if their values are less than the central pixel, and 1 for the pixels which have values greater than the central pixel. In histogram statistics, these binary codes are encoded to decimal numbers.",
            "cite_spans": [
                {
                    "start": 94,
                    "end": 99,
                    "text": "[235]",
                    "ref_id": "BIBREF248"
                }
            ],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "Gray-Level Run Length Matrix (GLRLM): this method removes the higher order statistical texture data. In case of the maximum gray dimensions G, the image is repeatedly re-quantizing to aggregate the network. The mathematical formula of GLRLM is given as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "where (u,v) refers to the sizes of the array values, N r refers to the maximum gray-level values, and K max is the more length.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "Raj et al. [236] have used both GLCM and GLRLM as the main features' extraction techniques for extracting the optimal features from the pre-processed medical images, which further the optimal features have improved the final results of classification task. Figure 12 shows the features extraction and selection types used for dimensionality reduction. It is used to determine the dispersion from datapoints and it can be written as ANOVA performs F test to compare the variance difference between groups and within groups. And this can be done using total sum of squares which is defined as the distance between each point from the grand mean x-bar. 3 . Determining the degree of freedom 4. Calculating F value 5. Acceptance or rejection of null hypothesis Principal Component Analysis (PCA): is considered as the most used tool for extracting structural features from potentially high-dimensional datasets. It extracts the eigenvectors (q) which are connected to (q) largest eigenvalues from an input distribution. PCA results develop new features that are independent of another. The main goal of PCA is to apply linear transformation for obtaining a new set of samples, so that the components of y are uncorrelated, [239] . The linear transform is given as follows:",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 16,
                    "text": "[236]",
                    "ref_id": "BIBREF249"
                },
                {
                    "start": 650,
                    "end": 651,
                    "text": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1219,
                    "end": 1224,
                    "text": "[239]",
                    "ref_id": "BIBREF253"
                }
            ],
            "ref_spans": [
                {
                    "start": 257,
                    "end": 266,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "where x is the input element vector \u2208 R I , after that the PCA algorithm will choose the most significant components (y), and the main steps to do this are summarized as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "1. Standardize and normalization of the datapoints: after calculating the mean and standard deviation of the input distribution 2. Calculating the covariance matrix from the input datapoints:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "3. From the covariance matrix extract the eigenvalues:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "4. Choosing k eigenvectors with the highest eigenvalues by sorting the eigenvalues and eigenvectors, k refers to the number of dimensions in the dataset Another major feature of PCA algorithm is used for feature dimensionality reduction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "In medical imaging, PCA was used mostly for dimensionality reduction, Wu et al. [240] have used PCA-based nearest neighbor for estimation of local structure distribution and extracted the entire connected tree, and in their results over retinal fundus data, they have achieved stateof-the-art results by producing more information regarding the tree structure.",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 85,
                    "text": "[240]",
                    "ref_id": "BIBREF254"
                }
            ],
            "ref_spans": [],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "PCA was also used as a data augmentation process before training the discriminative CNN for different medical imaging tasks; for capturing the important characteristics of natural images, different algorithms were compared to perform data augmentation [241] (Fig. 12) .",
            "cite_spans": [
                {
                    "start": 252,
                    "end": 257,
                    "text": "[241]",
                    "ref_id": "BIBREF255"
                }
            ],
            "ref_spans": [
                {
                    "start": 258,
                    "end": 267,
                    "text": "(Fig. 12)",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Feature's extraction and selection"
        },
        {
            "text": "Features' extraction and selection types used for dimensionality reduction",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fig. 12"
        },
        {
            "text": "For the purpose of evaluating and measuring the performance of deep learning models while validating medical images, different evaluation metrics are used according to some specific regularities and criteria. For example, some particular evaluation metrics are used with specific tasks like Dice score and F1-score are mostly used for segmentation, while accuracy and sensitivity are mostly used for classification task. Here, we will focus on the most used performance measurement metrics in the literature and will cover the metrics mentioned in our tables of comparison.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "1. The Dice coefficient is the most used metric for segmentation task for validating the medical images. It is common also to use dice score to measure reproducibility [242] . The general formula to calculate the Dice coefficient is",
            "cite_spans": [
                {
                    "start": 168,
                    "end": 173,
                    "text": "[242]",
                    "ref_id": "BIBREF256"
                }
            ],
            "ref_spans": [],
            "section": "Evaluation metrics"
        },
        {
            "text": "Jaccard-index is a statistic metric used for finding the similarities between sample-sets. It is defined as the ratio between the size of intersection and the size of union of the sample-set, and the mathematical formula is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Jaccard-index (similarity coefficient) [JAC]:"
        },
        {
            "text": "Also called specificity, it measures the number of negative voxels (background) from the ground truth which are also identified to be negative after the segmentation process, and it is given by the formula However, both TNR and TPR metrics are not used commonly for medical images' segmentation due to their sensibility to the segments size.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "True-Negative Rate (TNR):"
        },
        {
            "text": "Accuracy means exactly how good the DL model at guessing the right labels (ground truth). Accuracy is commonly used to validate the classification task and it is given using the formula 6. F1-Score:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Accuracy [ACC]"
        },
        {
            "text": "It is used to get the best precision and recall together; thus, the F1-score is called the harmonic mean of precision and recall values; it is given by the formula",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Accuracy [ACC]"
        },
        {
            "text": "The predictive accuracy of a classification model is related to the F1-score; when F1-score is higher means, we have better classification accuracy. 7. F-beta score:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Accuracy [ACC]"
        },
        {
            "text": "It is a combination of advantages of precision and recall metrics when both the False-Negative (FN) and False-Positive (FP) have equal importance. F-beta-score is given using the same formula for F1-score by altering its formula a bit by including an adjustable parameter (beta), and the formula became This evaluation metric measures the effectiveness of a DL model according to a user who attaches beta times.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Accuracy [ACC]"
        },
        {
            "text": "Receiver-Operating Characteristics Curve (ROC) is a graph between True-Positive Rate (TPR) (sensitiv- ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AUC-ROC:"
        },
        {
            "text": "precision.recall precision + recall .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AUC-ROC:"
        },
        {
            "text": "precision.recall ity) and False-Positive Rate (FPR) (1-specificity) by which it shows the performance of classification model, and the plot is characterized at different classification thresholds. The biggest advantage of ROC curve is that its independency of the change in number of responders and response rate.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AUC-ROC:"
        },
        {
            "text": "AUC is the area under curve of ROC, and it measures the 2D area under the ROC curve which in turn means the integral of the ROC curve from 0 to the AUC measures the aggregate performance of classification at all the possible thresholds. One way to understand the AUC is as the probability that a model classifies random positive samples more than random negative samples. The ROC curve is shown in Fig. 13 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 398,
                    "end": 405,
                    "text": "Fig. 13",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "AUC-ROC:"
        },
        {
            "text": "In this overview paper, we have presented a review of the previous literature of deep learning applications in medical imaging. It contributed three main sections: first, we have presented the core of deep learning concepts considering the main highlights of understanding of basic frameworks in medical images analysis. The second section contains the main applications of deep learning in medical imaging (e.g., segmentation, detection, classification, and registration) and we have presented a comprehensive review of the literature. The criteria that we have built our overview consists of the mostly cited papers, the mostly recent (from 2015 to 2021), and the papers with better results. The third major part of this paper is focused on the deep learning themes regarding some challenges and the future directions of addressing those challenges. Besides focusing on the quality of the mostly recent works, we have highlighted the suitable solutions for different challenges in this field and the future directions that have been concluded from different scientific perspective. Medical imaging can get the benefit from other fields of deep learning, that have been encouraged from collaborative research works from computer vision communities, and furthermore, this collaboration is used to overcome the lack of medical dataset using transfer learning. Cho et al. [243] have answered the question of how much is the size of medical dataset needed to train a deep learning model. Creating synthetic medical images is another solution presented in deep learning using Variational Autoencoders (VAEs) and GANs for tackling the limited labeled medical data. For instance, Guibas et al. [244] have used 2 GANs for segmenting and then generating new retinal fundus images successfully. Another applications of GANs for segmentation and synthetic data generation were found [132, 245] .",
            "cite_spans": [
                {
                    "start": 1370,
                    "end": 1375,
                    "text": "[243]",
                    "ref_id": "BIBREF258"
                },
                {
                    "start": 1688,
                    "end": 1693,
                    "text": "[244]",
                    "ref_id": "BIBREF259"
                },
                {
                    "start": 1873,
                    "end": 1878,
                    "text": "[132,",
                    "ref_id": "BIBREF138"
                },
                {
                    "start": 1879,
                    "end": 1883,
                    "text": "245]",
                    "ref_id": "BIBREF260"
                }
            ],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "Data or class imbalance [246] is considered a critical problem in medical imaging, and it refers to that medical images that are used for training are skewed toward nonpathological images; rare diseases have less number of training examples which cause the problem of imbalanced data which lead to incorrect results. Data augmentation represents good solution for this, because it increases the number of samples of the small classes. Away from dataset challenges strategies, there are algorithmic modification strategies which are used to improve DL models' performance for data imbalance issue [247] .",
            "cite_spans": [
                {
                    "start": 24,
                    "end": 29,
                    "text": "[246]",
                    "ref_id": "BIBREF261"
                },
                {
                    "start": 596,
                    "end": 601,
                    "text": "[247]",
                    "ref_id": "BIBREF262"
                }
            ],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "Another important non-technical challenge is the public reception of humans that the results are being analyzed using DL models (not human). In some papers in our report, DL models have outperformed specialists in medicine (e.g., dermatologists and radiologists) and mostly in image recognition tasks. Yet, a moral culpability may arise whenever a patient is mistakenly diagnosed or morbidity cases may arise too when using DL-based diagnostic, since the work of a DL algorithms is considered a black box. However, the continued development and evolving of DL models might take a major role in the medicine as it is involving in various facets of our life.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "AI systems have started to emerge in hospitals from a clinical perspective. Bruijne [248] have presented five challenges facing the broader family of deep learning which is machine learning in medical imaging field including the data preprocessing of different modalities, interpretation of results to clinical practice, improving the access of medical data, and training the models with little training data. These challenges further have addressed the future directions of DL models improvement. Another solutions of small datasets were reported in [8, 249] .",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 89,
                    "text": "[248]",
                    "ref_id": "BIBREF264"
                },
                {
                    "start": 551,
                    "end": 554,
                    "text": "[8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 555,
                    "end": 559,
                    "text": "249]",
                    "ref_id": "BIBREF265"
                }
            ],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "DL models' architectures were found not to be the only factor that provides quality results, where data augmentation and preprocessing techniques are also substantial tools for a robust and efficient system. The big question is that how to benefit from the results of DL models for the best of medical images analysis in the community.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "Considering the historical developments of ML techniques in medical imaging gives us a future perspective how DL models will continue to improve in the same field. Accordingly, medical images quality and data annotations are crucial for proper analysis. A significant concept is the relevance between statistical sense and clinical sense, even though the statistical analysis are quiet important in research, but in this field, researchers should not lose the sight from clinical perspective; in other words, even when a good CNN models provides good answers from the statistical perspective, it does not mean that it will replace a radiologist even after using all the helping techniques like data augmentation and adding more layers to get better accuracies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Technical challenges"
        },
        {
            "text": "After reviewing literature and the most competitive challenges that face deep leaning in medical imaging, we concluded that three aspects will probably carry the revolution of DL according to most of researchers, which are the availability of large-scale datasets, advances in deep learning algorithms, and the computational power for data processing and evaluation of DL models. Thus, most of the DL techniques are directed into the above aspects for alleviating the DL performance more; moreover, the need for investigations to improve data harmonization, standards developments which is needed for reporting and evaluation, and accessibility of larger annotated data such as the public datasets which lead to better independent benchmarks' services. Some of the interesting applications in medical imaging was proposed by Nie et al. [250] , by which they have used GANs to generate or CT scans from MRI images for brain; the benefit of such work will reduce the risk of patients being exposed to ionizing radiation from CT scanners, which also reserve patients' safety. Another significant perspective relies on increasing the resolution and quality of medical images and also reduces the blurriness from CT scans and MRI images which means getting higher resolution with lower costs and better results, because it has lower field strength [251] .",
            "cite_spans": [
                {
                    "start": 836,
                    "end": 841,
                    "text": "[250]",
                    "ref_id": "BIBREF266"
                },
                {
                    "start": 1343,
                    "end": 1348,
                    "text": "[251]",
                    "ref_id": "BIBREF267"
                }
            ],
            "ref_spans": [],
            "section": "Future promises"
        },
        {
            "text": "The new trends' technology of deep learning approach is concerned about medical data collection. Wearable technologies are getting the interest of the new research which provide the benefits of flexibility, real-time monitoring of patients, and the immediate communication of the collected data. Whenever the data become available, Deep learning and AI will start to use the unsupervised data exploration, which in turn will provide better analysis power plus suggesting better treatments' methodologies in healthcare. In summary, the new trends of AI in healthcare pass through stages; the quality of performance (QoP) related to deep learning will lead to standardization in terms of wearable technology which represent the next stage of healthcare applications and personalized treatment. Diagnosing and treatment depend on specialists, but with deep learning enabled, some small changes and signs in human body can be seen and early detection becomes possible which in turn will launch the treatment process of pre-stage of diseases. DL model optimization mainly focuses on the network architecture, while the standard term of optimization means the distribution and standardization with respect to other parts of DL (e.g., optimizers, loss functions, preprocessing and post-processing, etc.). In many cases to achieve better diagnosis, medical images are not sufficient, where another data are required to be combined (e.g., historical medical reports, genetic information, lab values, and other non-image data), though by linking and normalizing these data with medical images will lead to better diagnosis of diseases, more accurately through analyzing these data in higher dimensions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Future promises"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Deep learning",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Nature",
            "volume": "521",
            "issn": "7553",
            "pages": "436--444",
            "other_ids": {
                "DOI": [
                    "10.1038/nature14539"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Threat of adversarial attacks on deep learning in computer vision: a survey",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Akhtar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mian",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Access",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2018.2807385"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Sequence to sequence learning with neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Vinyals",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Adv. Neural Inf. Process. Syst",
            "volume": "4",
            "issn": "",
            "pages": "3104--3112",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Use of diagnostic imaging studies and associated radiation exposure for patients enrolled in large integrated health care systems",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Smith-Bindman",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "JAMA",
            "volume": "307",
            "issn": "22",
            "pages": "2400--2409",
            "other_ids": {
                "DOI": [
                    "10.1001/jama.2012.5960"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Measuring and improving quality in radiology: meeting the challenge with informatics",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Radiographics",
            "volume": "31",
            "issn": "6",
            "pages": "1511--1527",
            "other_ids": {
                "DOI": [
                    "10.1148/rg.316105207"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Integrating artificial intelligence into the clinical practice of radiology: challenges and recommendations",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Recht",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Eur. Radiol",
            "volume": "30",
            "issn": "6",
            "pages": "3576--3584",
            "other_ids": {
                "DOI": [
                    "10.1007/s00330-020-06672-5"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "The influence of edge effects on the detection properties of Cadmium Telluride",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bosma",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Van Beuzekom",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "V\u00e4h\u00e4nen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Visser",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Koffeman",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "2011 IEEE Nuclear Science Symposium Conference Record IEEE",
            "volume": "",
            "issn": "",
            "pages": "4812--4817",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A survey on deep learning in medical image analysis",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Litjens",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Med. Image Anal",
            "volume": "42",
            "issn": "",
            "pages": "60--88",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2017.07.005"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Backpropagation applied to handwritten zip code recognition",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Neural Comput",
            "volume": "1",
            "issn": "4",
            "pages": "541--551",
            "other_ids": {
                "DOI": [
                    "10.1162/neco.1989.1.4.541"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Gradient-based learning applied to document recognition",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bottou",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Haffner",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Proc. IEEE",
            "volume": "86",
            "issn": "11",
            "pages": "2278--2324",
            "other_ids": {
                "DOI": [
                    "10.1109/5.726791"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Generating text with recurrent neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Martens",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proc. 28th Int. Conf. Mach. Learn. ICML",
            "volume": "",
            "issn": "",
            "pages": "1017--1024",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "The power of optimization from samples",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Balkanski",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rubinstein",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Singer",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "29",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Deep Visual-Semantic Alignments for Generating Image Descriptions -Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf. Cvpr",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Karpathy",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Learning to read chest x-rays: recurrent neural cascade model for automated image annotation",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "C"
                    ],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Demner-Fushman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "2497--2506",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2016.274"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "RNN-based longitudinal analysis for diagnosis of Alzheimer's disease",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Med. Imaging Graph",
            "volume": "73",
            "issn": "",
            "pages": "1--10",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2019.01.005"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "A deep RNN for CT image reconstruction",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zuo",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proc. SPIE",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1117/12.2549809"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Joint learning of motion estimation and segmentation for cardiac MR image sequences",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "LNCS",
            "volume": "11071",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Improving CNN training using disentanglement for liver lesion classification in CT",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ben-Cohen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mechrez",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Yedidia",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)",
            "volume": "88574",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/EMBC.2019.8857465"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "ADN: artifact disentanglement network for unsupervised metal artifact reduction",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                },
                {
                    "first": "W.-A",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "39",
            "issn": "3",
            "pages": "634--643",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2019.2933425"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Unsupervised deformable registration for multi-modal images via disentangled representations",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mansi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kamen",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "LNCS",
            "volume": "11492",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Denoising adversarial autoencoders",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Creswell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Bharath",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE transactions on neural networks and learning systems",
            "volume": "30",
            "issn": "",
            "pages": "968--984",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Vincent",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Larochelle",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Lajoie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Manzagol",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "J. Mach. Learn. Res",
            "volume": "11",
            "issn": "",
            "pages": "3371--3408",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Efficient learning of sparse representations with an energy-based model",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Ranzato",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Poultney",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chopra",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.7551/mitpress/7503.003.0147"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Auto-encoding variational bayes",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Welling",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "2nd International Conference of Learning Representation. ICLR 2014 -Conf. Track Proc., no. Ml",
            "volume": "",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Contractive auto-encoders: explicit invariance during feature extraction",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rifai",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Vincent",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Muller",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceeding 28th International Conference of Machine Learning. ICML",
            "volume": "",
            "issn": "",
            "pages": "833--840",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Triple generative adversarial nets",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "",
            "issn": "",
            "pages": "4089--4099",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Generative adversarial nets",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Goodfellow",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Advances in Neural Information Processing Systems",
            "volume": "27",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Learning from simulated and unsupervised images through adversarial training",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shrivastava",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pfister",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Tuzel",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Susskind",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Webb",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceeding -30th IEEE Conference of Computer Vission Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2242--2251",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2017.241"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "For Classification of Prostate Histopathology Whole-Slide Images",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R B I"
                    ],
                    "last": "Hacihaliloglu",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Singer",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Foran",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Computer aided Alzheimer's disease diagnosis by an unsupervised deep learning technology",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Bi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Neurocomputing",
            "volume": "392",
            "issn": "",
            "pages": "296--304",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neucom.2018.11.111"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Visual feature attribution using wasserstein GANs",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "F"
                    ],
                    "last": "Baumgartner",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Koch",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Tezcan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "X"
                    ],
                    "last": "Ang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Konukoglu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2018.00867"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Retinal Vessel Segmentation in Fundoscopic Images with Generative Adversarial Networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Son",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "K.-H",
                    "middle": [],
                    "last": "Jung",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "PnP-AdaNet: plug-and-play adversarial domain adaptation network with a benchmark at cross-modality cardiac segmentation. CoRR",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Generative adversarial networks for image-to-image translation on multi-contrast {MR} images -{A} comparison of CycleGAN and {UNIT}",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Welander",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Karlsson",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Eklund",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "GANs for medical image analysis",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kazeminia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artif. Intell. Med",
            "volume": "109",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.artmed.2020.101938"
                ]
            }
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "A learning algorithm for boltzmann machines",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Ackley",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "J"
                    ],
                    "last": "Sejnowski",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "Cogn. Sci",
            "volume": "9",
            "issn": "1",
            "pages": "80012--80016",
            "other_ids": {
                "DOI": [
                    "10.1016/S0364-0213(85)80012-4"
                ]
            }
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Information processing in dynamical systems: foundations of harmony theory",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "J. Jpn. Soc. Fuzzy Theory Syst",
            "volume": "4",
            "issn": "2",
            "pages": "220--228",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Combining generative and discriminative representation learning for lung CT analysis with convolutional restricted boltzmann machines",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Van Tulder",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "De Bruijne",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2526687"
                ]
            }
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "A fast learning algorithm for deep belief nets",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Osindero",
                    "suffix": ""
                },
                {
                    "first": "Y.-W",
                    "middle": [],
                    "last": "Teh",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Neural Comput",
            "volume": "18",
            "issn": "7",
            "pages": "1527--1554",
            "other_ids": {
                "DOI": [
                    "10.1162/neco.2006.18.7.1527"
                ]
            }
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Medical image analysis using wavelet transform and deep belief networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khatami",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosravi",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "P"
                    ],
                    "last": "Lim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Nahavandi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Expert Syst. Appl",
            "volume": "86",
            "issn": "",
            "pages": "190--198",
            "other_ids": {
                "DOI": [
                    "10.1016/j.eswa.2017.05.073"
                ]
            }
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Analyzing MRI scans to detect glioblastoma tumor using hybrid deep belief networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "V N"
                    ],
                    "last": "Reddy",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Big Data",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/s40537-020-00311-y"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Fusion of medical images using deep belief networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Cluster Comput",
            "volume": "23",
            "issn": "2",
            "pages": "1439--1453",
            "other_ids": {
                "DOI": [
                    "10.1007/s10586-019-02999-x"
                ]
            }
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Models genesis: generic autodidactic models for 3D medical image analysis",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Medical Image Computing and Computer Assisted Intervention --MICCAI 2019",
            "volume": "",
            "issn": "",
            "pages": "384--393",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Rubik's Cube+: a self-supervised feature learning framework for 3D medical image analysis",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med. Image Anal",
            "volume": "64",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2020.101746"
                ]
            }
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Big self-supervised models advance medical image classification",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Azizi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "ASDNet: attention based semi-supervised deep networks for medical image segmentation",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical Image Computing and Computer Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "370--378",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Semi-supervised learning for network-based cardiac MR image segmentation",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Computing and Computer-Assisted Intervention \u2212 MICCAI 2017",
            "volume": "",
            "issn": "",
            "pages": "253--260",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Semi-supervised medical image classification with relation-driven self-ensembling model",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Heng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "39",
            "issn": "11",
            "pages": "3429--3440",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2020.2995518"
                ]
            }
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Constrained-CNN losses for weakly supervised segmentation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kervadec",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dolz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Granger",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Boykov",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ben Ayed",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med. Image Anal",
            "volume": "54",
            "issn": "",
            "pages": "88--99",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2019.02.009"
                ]
            }
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "ChestX-ray: hospital-scale chest x-ray database and benchmarks on weakly supervised classification and localization of common thorax diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Adv. Comput. Vis. Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-030-13969-8_18"
                ]
            }
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Marginal loss and exclusion loss for partially supervised multi-organ segmentation",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Med. Image Anal",
            "volume": "70",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2021.101979"
                ]
            }
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Going to extremes: weakly supervised medical image segmentation",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Mach. Learn. Knowl. Extr",
            "volume": "3",
            "issn": "2",
            "pages": "507--524",
            "other_ids": {
                "DOI": [
                    "10.3390/make3020026"
                ]
            }
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Schlegl",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Seeb\u00f6ck",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Waldstein",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Langs",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Schmidt-Erfurth",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med. Image Anal",
            "volume": "54",
            "issn": "",
            "pages": "30--44",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2019.01.010"
                ]
            }
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Weakly-supervised convolutional neural networks for multimodal image registration",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Med. Image Anal",
            "volume": "49",
            "issn": "",
            "pages": "1--13",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2018.07.002"
                ]
            }
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Weakly supervised classification of medical images",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Quellec",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Laniard",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cazuguel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Abr\u00e0moff",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Cochener",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Roux",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)",
            "volume": "",
            "issn": "",
            "pages": "110--113",
            "other_ids": {
                "DOI": [
                    "10.1109/ISBI.2012.6235496"
                ]
            }
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Partial policy-based reinforcement learning for anatomical landmark localization in 3D medical images",
            "authors": [
                {
                    "first": "Abdullah",
                    "middle": [],
                    "last": "Al",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Yun",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "39",
            "issn": "4",
            "pages": "1245--1255",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2019.2946345"
                ]
            }
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Reinforcement learning for object detection in PET imaging",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "L"
                    ],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "M"
                    ],
                    "last": "Ackerley",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Wells",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bartley",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Paisey",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Marshall",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 IEEE Nuclear Science Symposium and Medical Imaging Conference",
            "volume": "90600",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/NSS/MIC42101.2019.9060031"
                ]
            }
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "Color image classification on neuromorphic system using reinforcement learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "2020 International Conference on Electronics, Information, and Communication (ICEIC)",
            "volume": "",
            "issn": "",
            "pages": "1--2",
            "other_ids": {
                "DOI": [
                    "10.1109/ICEIC49074.2020.9051310"
                ]
            }
        },
        "BIBREF64": {
            "ref_id": "b64",
            "title": "A survey on transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "22",
            "issn": "10",
            "pages": "1345--1359",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2009.191"
                ]
            }
        },
        "BIBREF65": {
            "ref_id": "b65",
            "title": "Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "C"
                    ],
                    "last": "Shin",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "104603--104618",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.2999816"
                ]
            }
        },
        "BIBREF66": {
            "ref_id": "b66",
            "title": "Convolutional neural networks for medical image analysis: full training or fine tuning?",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tajbakhsh",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2535302"
                ]
            }
        },
        "BIBREF68": {
            "ref_id": "b68",
            "title": "Pathological brain detection based on AlexNet and transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "D"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Comput. Sci",
            "volume": "30",
            "issn": "11",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jocs.2018.11.008"
                ]
            }
        },
        "BIBREF69": {
            "ref_id": "b69",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "3rd International Conference of Learning Representation. ICLR 2015 -Conf. Track Proc",
            "volume": "",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF70": {
            "ref_id": "b70",
            "title": "Deep learning in medical imaging and radiation therapy",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Sahiner",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med. Phys",
            "volume": "46",
            "issn": "1",
            "pages": "1--36",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.13264"
                ]
            }
        },
        "BIBREF71": {
            "ref_id": "b71",
            "title": "Rethinking the inception architecture for computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceeding of IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "volume": "2016",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2016.308"
                ]
            }
        },
        "BIBREF72": {
            "ref_id": "b72",
            "title": "Inception-v4, inception-ResNet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Alemi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "31st AAAI Conference of Artificial Intelligence. AAAI 2017",
            "volume": "",
            "issn": "",
            "pages": "4278--4284",
            "other_ids": {}
        },
        "BIBREF73": {
            "ref_id": "b73",
            "title": "Deep residual inception encoder-decoder network for medical imaging synthesis",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yoon",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Patel",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE J. Biomed. Heal. Informatics",
            "volume": "24",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/JBHI.2019.2912659"
                ]
            }
        },
        "BIBREF74": {
            "ref_id": "b74",
            "title": "{Going Deeper With Convolutions}e",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Christian",
                    "suffix": ""
                },
                {
                    "first": "Wei",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Yangqing",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "Pierre",
                    "middle": [],
                    "last": "Sermanet",
                    "suffix": ""
                },
                {
                    "first": "Scott",
                    "middle": [],
                    "last": "Reed",
                    "suffix": ""
                },
                {
                    "first": "Dragomir",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "Dumitru",
                    "middle": [],
                    "last": "Erhan",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "Rabinovich",
                    "middle": [],
                    "last": "Vincent",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Available: Szegedy, Christian, et al. %22Going deeper with convolutions.%22 Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF75": {
            "ref_id": "b75",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "S. Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "volume": "2016",
            "issn": "",
            "pages": "770--778",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2016.90"
                ]
            }
        },
        "BIBREF76": {
            "ref_id": "b76",
            "title": "Lung nodule detection in CT images using a raw patch-based convolutional neural network",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Sheng",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Digit. Imaging",
            "volume": "32",
            "issn": "6",
            "pages": "971--979",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-019-00221-3"
                ]
            }
        },
        "BIBREF78": {
            "ref_id": "b78",
            "title": "UNet++: A nested U-net architecture for medical image segmentation. In: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Rahman Siddiquee",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tajbakhsh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "3--11",
            "other_ids": {}
        },
        "BIBREF79": {
            "ref_id": "b79",
            "title": "Classification of histopathological images for early detection of breast cancer using deep learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Mohammed Senan",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Waselallah Alsaade",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ibrahim Ahmed Al-Mashhadani",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "H H"
                    ],
                    "last": "Aldhyani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hmoudal-Adhaileh",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "J. Appl. Sci. Eng",
            "volume": "24",
            "issn": "3",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.6180/jase.202106_24(3).0007"
                ]
            }
        },
        "BIBREF80": {
            "ref_id": "b80",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. -30th IEEE Conf. Comput. Vis. Pattern Recognition, CVPR 2017",
            "volume": "",
            "issn": "",
            "pages": "2261--2269",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2017.243"
                ]
            }
        },
        "BIBREF82": {
            "ref_id": "b82",
            "title": "An improved DenseNet method based on transfer learning for fundus medical images",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "7th International Conference on Digital Home (ICDH)",
            "volume": "",
            "issn": "",
            "pages": "137--140",
            "other_ids": {
                "DOI": [
                    "10.1109/ICDH.2018.00033"
                ]
            }
        },
        "BIBREF83": {
            "ref_id": "b83",
            "title": "U-Net: convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF84": {
            "ref_id": "b84",
            "title": "Parameter optimization of improved fuzzy c-means clustering algorithm for brain MR image segmentation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Forouzanfar",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Forghani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Teshnehlab",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Eng. Appl. Artif. Intell",
            "volume": "23",
            "issn": "2",
            "pages": "160--168",
            "other_ids": {
                "DOI": [
                    "10.1016/j.engappai.2009.10.002"
                ]
            }
        },
        "BIBREF85": {
            "ref_id": "b85",
            "title": "Deep learning for brain MRI segmentation: state of the art and future directions",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Akkus",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Galimzianova",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hoogi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "J"
                    ],
                    "last": "Erickson",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Digit. Imaging",
            "volume": "30",
            "issn": "4",
            "pages": "449--459",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-017-9983-4"
                ]
            }
        },
        "BIBREF86": {
            "ref_id": "b86",
            "title": "V-Net: fully convolutional neural networks for volumetric medical image segmentation",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Milletari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "S.-A",
                    "middle": [],
                    "last": "Ahmadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 Fourth International Conference on 3D Vision (3DV)",
            "volume": "",
            "issn": "",
            "pages": "565--571",
            "other_ids": {
                "DOI": [
                    "10.1109/3DV.2016.79"
                ]
            }
        },
        "BIBREF87": {
            "ref_id": "b87",
            "title": "Brain tumor segmentation with Deep Neural Networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Havaei",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Image Anal",
            "volume": "35",
            "issn": "",
            "pages": "18--31",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2016.05.004"
                ]
            }
        },
        "BIBREF88": {
            "ref_id": "b88",
            "title": "Deep semantic segmentation of natural and medical images: a review",
            "authors": [
                {
                    "first": "Asgari",
                    "middle": [],
                    "last": "Taghanaki",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abhishek",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen-Adad",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hamarneh",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Artif. Intell. Rev",
            "volume": "54",
            "issn": "1",
            "pages": "137--178",
            "other_ids": {}
        },
        "BIBREF89": {
            "ref_id": "b89",
            "title": "Automatic segmentation of liver tumor in CT images with deep convolutional neural networks",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Comput. Commun",
            "volume": "03",
            "issn": "11",
            "pages": "146--151",
            "other_ids": {
                "DOI": [
                    "10.4236/jcc.2015.311023"
                ]
            }
        },
        "BIBREF90": {
            "ref_id": "b90",
            "title": "Automatic brain tumor detection and segmentation using U-net based fully convolutional networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Mo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Understanding and Analysis",
            "volume": "",
            "issn": "",
            "pages": "506--517",
            "other_ids": {}
        },
        "BIBREF91": {
            "ref_id": "b91",
            "title": "Multimodal MRI brain tumor segmentation using random forests with features learned from fully convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Soltaninejad",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Lambrou",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Allinson",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF92": {
            "ref_id": "b92",
            "title": "Deep learning applications in medical image analysis",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ker",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Rao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Lim",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Access",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2017.2788044"
                ]
            }
        },
        "BIBREF93": {
            "ref_id": "b93",
            "title": "Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bentley",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "NeuroImage Clin",
            "volume": "15",
            "issn": "",
            "pages": "633--643",
            "other_ids": {
                "DOI": [
                    "10.1016/j.nicl.2017.06.016"
                ]
            }
        },
        "BIBREF94": {
            "ref_id": "b94",
            "title": "Brain tumor segmentation using an adversarial network",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries",
            "volume": "",
            "issn": "",
            "pages": "123--132",
            "other_ids": {}
        },
        "BIBREF95": {
            "ref_id": "b95",
            "title": "Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bakas",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Reyes",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jakab",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bauer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rempfler",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Crimi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Jambawalikar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "BRATS challenge",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1811.02629"
                ]
            }
        },
        "BIBREF96": {
            "ref_id": "b96",
            "title": "Brain tumor segmentation and radiomics survival prediction: contribution to the BRATS 2017 challenge",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Isensee",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Kickingereder",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wick",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bendszus",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Maier-Hein",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries",
            "volume": "",
            "issn": "",
            "pages": "287--297",
            "other_ids": {}
        },
        "BIBREF97": {
            "ref_id": "b97",
            "title": "Automated segmentation of hyperintense regions in FLAIR MRI using deep learning",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Korfiatis",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "L"
                    ],
                    "last": "Kline",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "J"
                    ],
                    "last": "Erickson",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Tomography",
            "volume": "2",
            "issn": "4",
            "pages": "334--340",
            "other_ids": {}
        },
        "BIBREF98": {
            "ref_id": "b98",
            "title": "Landmark-based deep multi-instance learning for brain disease diagnosis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Adeli",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Med. Image Anal",
            "volume": "43",
            "issn": "",
            "pages": "157--168",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2017.10.005"
                ]
            }
        },
        "BIBREF99": {
            "ref_id": "b99",
            "title": "Segmenting retinal blood vessels with deep neural networks",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Liskowski",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Krawiec",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "11",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2546227"
                ]
            }
        },
        "BIBREF100": {
            "ref_id": "b100",
            "title": "Automatic segmentation of nine retinal layer boundaries in OCT images of non-exudative AMD patients using deep learning and graph search",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cunefare",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "H"
                    ],
                    "last": "Guymer",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Farsiu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Biomed. Opt. Express",
            "volume": "8",
            "issn": "5",
            "pages": "2732--2744",
            "other_ids": {
                "DOI": [
                    "10.1364/BOE.8.002732"
                ]
            }
        },
        "BIBREF101": {
            "ref_id": "b101",
            "title": "Joint optic disc and cup segmentation using fully convolutional and adversarial networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Shankaranarayana",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ram",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sivaprakasam",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Fetal, Infant and Ophthalmic Medical Image Analysis",
            "volume": "",
            "issn": "",
            "pages": "168--176",
            "other_ids": {}
        },
        "BIBREF102": {
            "ref_id": "b102",
            "title": "Joint optic disc and cup segmentation based on multi-label deep network and polar transformation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "W K"
                    ],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "37",
            "issn": "7",
            "pages": "1597--1605",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2018.2791488"
                ]
            }
        },
        "BIBREF103": {
            "ref_id": "b103",
            "title": "Automatic 3D liver segmentation based on deep learning and globally optimized surface evolution",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Phys. Med. Biol",
            "volume": "61",
            "issn": "24",
            "pages": "8676--8698",
            "other_ids": {
                "DOI": [
                    "10.1088/1361-6560/61/24/8676"
                ]
            }
        },
        "BIBREF104": {
            "ref_id": "b104",
            "title": "Fully convolutional network for liver segmentation and lesions detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ben-Cohen",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Diamant",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Klang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Amitai",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Deep Learning and Data Labeling for Medical Applications",
            "volume": "",
            "issn": "",
            "pages": "77--85",
            "other_ids": {}
        },
        "BIBREF105": {
            "ref_id": "b105",
            "title": "Automatic liver segmentation using an adversarial image-to-image network",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Computing and Computer Assisted Intervention \u2212 MICCAI 2017",
            "volume": "",
            "issn": "",
            "pages": "507--515",
            "other_ids": {}
        },
        "BIBREF106": {
            "ref_id": "b106",
            "title": "Computer-aided diagnosis with deep learning architecture: applications to breast lesions in US images and pulmonary nodules in CT scans",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "Z"
                    ],
                    "last": "Cheng",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Sci. Rep",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1038/srep24454"
                ]
            }
        },
        "BIBREF107": {
            "ref_id": "b107",
            "title": "A fully integrated computer-aided diagnosis system for digital X-ray mammograms via deep learning detection, segmentation, and classification",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Al-Antari",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Al-Masni",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Int. J. Med. Inform",
            "volume": "117",
            "issn": "",
            "pages": "44--54",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijmedinf.2018.06.003"
                ]
            }
        },
        "BIBREF108": {
            "ref_id": "b108",
            "title": "Lung CT image segmentation using deep neural networks",
            "authors": [
                {
                    "first": "Ait",
                    "middle": [],
                    "last": "Skourt",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "El Hassani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Majda",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Procedia Comput. Sci",
            "volume": "127",
            "issn": "",
            "pages": "109--113",
            "other_ids": {
                "DOI": [
                    "10.1016/j.procs.2018.01.104"
                ]
            }
        },
        "BIBREF109": {
            "ref_id": "b109",
            "title": "Lung image segmentation using deep learning methods and convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kalinovsky",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kovalev",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Int. Conf. Pattern Recognit. Inf. Process",
            "volume": "",
            "issn": "",
            "pages": "21--24",
            "other_ids": {}
        },
        "BIBREF110": {
            "ref_id": "b110",
            "title": "Deep learning for classification and localization of COVID-19 markers in point-of-care lung ultrasound",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roy",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "39",
            "issn": "8",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2020.2994459"
                ]
            }
        },
        "BIBREF111": {
            "ref_id": "b111",
            "title": "COVID-19 on chest radiographs: a multireader evaluation of an artificial intelligence system",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Murphy",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "296",
            "issn": "3",
            "pages": "166--172",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020201874"
                ]
            }
        },
        "BIBREF112": {
            "ref_id": "b112",
            "title": "Performance of an artificial multi-observer deep neural network for fully automated segmentation of polycystic kidneys",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "L"
                    ],
                    "last": "Kline",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Digit. Imaging",
            "volume": "30",
            "issn": "4",
            "pages": "442--448",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-017-9978-1"
                ]
            }
        },
        "BIBREF113": {
            "ref_id": "b113",
            "title": "Ultrasound imagebased thyroid nodule automatic segmentation using convolutional neural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Int. J. Comput. Assist. Radiol. Surg",
            "volume": "12",
            "issn": "11",
            "pages": "1895--1910",
            "other_ids": {
                "DOI": [
                    "10.1007/s11548-017-1649-7"
                ]
            }
        },
        "BIBREF114": {
            "ref_id": "b114",
            "title": "Multiple supervised residual network for osteosarcoma segmentation in CT images",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Med. Imaging Graph",
            "volume": "63",
            "issn": "",
            "pages": "1--8",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2018.01.006"
                ]
            }
        },
        "BIBREF115": {
            "ref_id": "b115",
            "title": "Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "64",
            "issn": "8",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2016.2628401"
                ]
            }
        },
        "BIBREF116": {
            "ref_id": "b116",
            "title": "Extraction of skin lesions from non-dermoscopic images for surgical excision of melanoma",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "H"
                    ],
                    "last": "Jafari",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Nasr-Esfahani",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Karimi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M R"
                    ],
                    "last": "Soroushmehr",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Samavi",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Najarian",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF118": {
            "ref_id": "b118",
            "title": "Automated anatomical landmark detection ondistal femur surface using convolutional neural network",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Metaxas",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ISBI.2015.7163806"
                ]
            }
        },
        "BIBREF119": {
            "ref_id": "b119",
            "title": "An ensemble deep learning based approach for red lesion detection in fundus images",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "I"
                    ],
                    "last": "Orlando",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Prokofyeva",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Del Fresno",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "B"
                    ],
                    "last": "Blaschko",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Methods Programs Biomed",
            "volume": "153",
            "issn": "",
            "pages": "115--127",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cmpb.2017.10.017"
                ]
            }
        },
        "BIBREF120": {
            "ref_id": "b120",
            "title": "Co-trained convolutional neural networks for automated detection of prostate cancer in multi-parametric MRI",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2017.08.006"
                ]
            }
        },
        "BIBREF122": {
            "ref_id": "b122",
            "title": "Automatic detection of cerebral microbleeds from MR images via 3D convolutional neural networks",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2528129"
                ]
            }
        },
        "BIBREF123": {
            "ref_id": "b123",
            "title": "DeepLesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Med. Imaging",
            "volume": "5",
            "issn": "3",
            "pages": "1--11",
            "other_ids": {
                "DOI": [
                    "10.1117/1.JMI.5.3.036501"
                ]
            }
        },
        "BIBREF124": {
            "ref_id": "b124",
            "title": "Detecting anatomical landmarks from limited medical imaging data using two-stage task-oriented deep neural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Image Process",
            "volume": "26",
            "issn": "10",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TIP.2017.2721106"
                ]
            }
        },
        "BIBREF125": {
            "ref_id": "b125",
            "title": "Deep neural network-based computer-assisted detection of cerebral aneurysms in MR angiography",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Nakao",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Magn. Reson. Imaging",
            "volume": "47",
            "issn": "4",
            "pages": "948--953",
            "other_ids": {
                "DOI": [
                    "10.1002/jmri.25842"
                ]
            }
        },
        "BIBREF126": {
            "ref_id": "b126",
            "title": "Biopsy-guided learning with deep convolutional neural networks for prostate cancer detection on multiparametric MRI Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Department of Radiology and Imaging Science, National Institute of Health, C",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Tsehay",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE 14th Int. Symp. Biomed. Imaging",
            "volume": "",
            "issn": "",
            "pages": "642--645",
            "other_ids": {}
        },
        "BIBREF127": {
            "ref_id": "b127",
            "title": "Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Sirinukunwattana",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "E A"
                    ],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "W"
                    ],
                    "last": "Tsang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "R J"
                    ],
                    "last": "Snead",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "A"
                    ],
                    "last": "Cree",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Rajpoot",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2525803"
                ]
            }
        },
        "BIBREF128": {
            "ref_id": "b128",
            "title": "Pulmonary nodule detection in CT images: false positive reduction using multi-view convolutional networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A A"
                    ],
                    "last": "Setio",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "1160--1169",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2536809"
                ]
            }
        },
        "BIBREF129": {
            "ref_id": "b129",
            "title": "Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "296",
            "issn": "2",
            "pages": "65--71",
            "other_ids": {}
        },
        "BIBREF130": {
            "ref_id": "b130",
            "title": "Towards an effective and efficient deep learning model for COVID-19 patterns detection in X-ray images",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Luz",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Res. Biomed. Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/s42600-021-00151-6"
                ]
            }
        },
        "BIBREF131": {
            "ref_id": "b131",
            "title": "Automatic detection of coronavirus disease (COVID-19) in X-ray and CT images: a machine learning based approach",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Kassania",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "H"
                    ],
                    "last": "Kassanib",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Wesolowskic",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "A"
                    ],
                    "last": "Schneidera",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Detersa",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Biocybern. Biomed. Eng",
            "volume": "41",
            "issn": "3",
            "pages": "867--879",
            "other_ids": {
                "DOI": [
                    "10.1016/j.bbe.2021.05.013"
                ]
            }
        },
        "BIBREF133": {
            "ref_id": "b133",
            "title": "Deep learning for identifying metastatic breast cancer",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gargeya",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Irshad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Beck",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF134": {
            "ref_id": "b134",
            "title": "Multilevel contextual 3-D CNNs for false positive reduction in pulmonary nodule detection",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Heng",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "64",
            "issn": "7",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2016.2613502"
                ]
            }
        },
        "BIBREF135": {
            "ref_id": "b135",
            "title": "CheXNet: radiologist-level pneumonia detection on chest x-rays with deep learning",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "3--9",
            "other_ids": {}
        },
        "BIBREF136": {
            "ref_id": "b136",
            "title": "Cascade convolutional neural networks for automatic detection of thyroid nodules in ultrasound images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Phys",
            "volume": "44",
            "issn": "5",
            "pages": "1678--1691",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12134"
                ]
            }
        },
        "BIBREF137": {
            "ref_id": "b137",
            "title": "Ultrasound aided vertebral level localization for lumbar surgery",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Baka",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Leenstra",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Van Walsum",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "36",
            "issn": "10",
            "pages": "2138--2147",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2017.2738612"
                ]
            }
        },
        "BIBREF138": {
            "ref_id": "b138",
            "title": "Generative adversarial networks for brain lesion detection",
            "authors": [
                {
                    "first": "Alex",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Safwan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "K M"
                    ],
                    "last": "Chennamsetty",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Krishnamurthi",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Image Process",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1117/12.2254487"
                ]
            }
        },
        "BIBREF139": {
            "ref_id": "b139",
            "title": "RETOUCH: the retinal OCT fluid detection and segmentation benchmark and challenge",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Bogunovic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "38",
            "issn": "8",
            "pages": "1858--1874",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2019.2901398"
                ]
            }
        },
        "BIBREF140": {
            "ref_id": "b140",
            "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Gulshan",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Am. Med. Assoc",
            "volume": "316",
            "issn": "22",
            "pages": "2402--2410",
            "other_ids": {
                "DOI": [
                    "10.1001/jama.2016.17216"
                ]
            }
        },
        "BIBREF141": {
            "ref_id": "b141",
            "title": "Automated lung nodule detection and classification using deep learning combined with multiple strategies",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Nasrullah",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Alam",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mateen",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sensors",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s19173722"
                ]
            }
        },
        "BIBREF142": {
            "ref_id": "b142",
            "title": "Mass detection on mammogram images: a first assessment of deep learning techniques",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Domingues",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Cardoso",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "19th Portuguese Conference on Pattern Recognition (RECPAD)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF143": {
            "ref_id": "b143",
            "title": "Medical image classification based on deep features extracted by deep model and statistic feature fusion with multilayer perceptron",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lai",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Intell. Neurosci",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1155/2018/2061516"
                ]
            }
        },
        "BIBREF144": {
            "ref_id": "b144",
            "title": "PAM-DenseNet: a deep convolutional neural network for computer-aided COVID-19 diagnosis",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Trans. Cybern",
            "volume": "30428",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TCYB.2020.3042837"
                ]
            }
        },
        "BIBREF145": {
            "ref_id": "b145",
            "title": "Artificial convolution neural network techniques and applications for lung nodule detection",
            "authors": [
                {
                    "first": "S.-C",
                    "middle": [
                        "B"
                    ],
                    "last": "Lo",
                    "suffix": ""
                },
                {
                    "first": "S.-L",
                    "middle": [
                        "A"
                    ],
                    "last": "Lou",
                    "suffix": ""
                },
                {
                    "first": "J.-S",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Freedman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "V"
                    ],
                    "last": "Chien",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Mun",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "14",
            "issn": "4",
            "pages": "711--718",
            "other_ids": {
                "DOI": [
                    "10.1109/42.476112"
                ]
            }
        },
        "BIBREF146": {
            "ref_id": "b146",
            "title": "World Health Organization: Standardization of interpretation of chest radiographs for the diagnosis of pneumonia in children / World Health Organization Pneumonia Vaccine Trial Investigators' Group",
            "authors": [],
            "year": 2001,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF147": {
            "ref_id": "b147",
            "title": "Convolutional neural network with data augmentation for SAR target recognition",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Geosci. Remote Sens. Lett",
            "volume": "13",
            "issn": "3",
            "pages": "364--368",
            "other_ids": {
                "DOI": [
                    "10.1109/LGRS.2015.2513754"
                ]
            }
        },
        "BIBREF149": {
            "ref_id": "b149",
            "title": "The effectiveness of data augmentation in image classification using deep learning. CoRR",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Perez",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF150": {
            "ref_id": "b150",
            "title": "GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Diamant",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Klang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Amitai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Goldberger",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Neurocomputing",
            "volume": "321",
            "issn": "",
            "pages": "321--331",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neucom.2018.09.013"
                ]
            }
        },
        "BIBREF151": {
            "ref_id": "b151",
            "title": "Deep learning based imaging data completion for improved brain disease diagnosis",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Medical Image Computing and Computer-Assisted Intervention --MICCAI",
            "volume": "",
            "issn": "",
            "pages": "305--312",
            "other_ids": {}
        },
        "BIBREF152": {
            "ref_id": "b152",
            "title": "Alzheimer's disease diagnostics by a deeply supervised adaptable 3D convolutional network",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Hosseini-Asl",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "L"
                    ],
                    "last": "Gimel&apos;farb",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "El-Baz",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF153": {
            "ref_id": "b153",
            "title": "Improved automated detection of diabetic retinopathy on a publicly available dataset through integration of deep learning",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Abr\u00e0moff",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Invest. Ophthalmol. Vis. Sci",
            "volume": "57",
            "issn": "13",
            "pages": "16--19964",
            "other_ids": {
                "DOI": [
                    "10.1167/iovs.16-19964"
                ]
            }
        },
        "BIBREF154": {
            "ref_id": "b154",
            "title": "Lung pattern classification for interstitial lung diseases using a deep convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Anthimopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Christodoulidis",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ebner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Christe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mougiakakou",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2535865"
                ]
            }
        },
        "BIBREF155": {
            "ref_id": "b155",
            "title": "Pulmonary nodule classification with deep residual networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Nibali",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wollersheim",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Int. J. Comput. Assist. Radiol. Surg",
            "volume": "12",
            "issn": "10",
            "pages": "1799--1808",
            "other_ids": {
                "DOI": [
                    "10.1007/s11548-017-1605-6"
                ]
            }
        },
        "BIBREF156": {
            "ref_id": "b156",
            "title": "Multisource transfer learning with convolutional neural networks for lung pattern analysis",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Christodoulidis",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Anthimopoulos",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ebner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Christe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mougiakakou",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE J. Biomed. Heal. Informatics",
            "volume": "21",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/JBHI.2016.2636929"
                ]
            }
        },
        "BIBREF157": {
            "ref_id": "b157",
            "title": "Deep learning-based multi-view fusion model for screening 2019 novel coronavirus pneumonia: a multicentre study",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Eur. J. Radiol",
            "volume": "128",
            "issn": "",
            "pages": "1--9",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ejrad.2020.109041"
                ]
            }
        },
        "BIBREF158": {
            "ref_id": "b158",
            "title": "A novel approach of CT images feature analysis and prediction to screen for corona virus disease (COVID-19)",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Farid",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "I"
                    ],
                    "last": "Selim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "A A"
                    ],
                    "last": "Khater",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Int. J. Sci. Eng. Res",
            "volume": "11",
            "issn": "03",
            "pages": "1141--1149",
            "other_ids": {
                "DOI": [
                    "10.14299/ijser.2020.03.02"
                ]
            }
        },
        "BIBREF159": {
            "ref_id": "b159",
            "title": "COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bertolini",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Teixeira",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "N"
                    ],
                    "last": "Silla",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M G"
                    ],
                    "last": "Costa",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput. Methods Programs Biomed",
            "volume": "194",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cmpb.2020.105532"
                ]
            }
        },
        "BIBREF160": {
            "ref_id": "b160",
            "title": "Digital mammographic tumor classification using transfer learning from deep convolutional neural networks",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "Q"
                    ],
                    "last": "Huynh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Med. Imaging",
            "volume": "3",
            "issn": "3",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1117/1.jmi.3.3.034501"
                ]
            }
        },
        "BIBREF161": {
            "ref_id": "b161",
            "title": "Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "L B"
                    ],
                    "last": "Tseng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Comput. Med. Imaging Graph",
            "volume": "57",
            "issn": "",
            "pages": "4--9",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2016.07.004"
                ]
            }
        },
        "BIBREF162": {
            "ref_id": "b162",
            "title": "Brain tumor classification for MR images using transfer learning and fine-tuning",
            "authors": [
                {
                    "first": "Z",
                    "middle": [
                        "N K"
                    ],
                    "last": "Swati",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Med. Imaging Graph",
            "volume": "75",
            "issn": "",
            "pages": "34--46",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2019.05.001"
                ]
            }
        },
        "BIBREF163": {
            "ref_id": "b163",
            "title": "Multi-grade brain tumor classification using deep CNN with extensive data augmentation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sajjad",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Muhammad",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ullah",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "W"
                    ],
                    "last": "Baik",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Comput. Sci",
            "volume": "30",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jocs.2018.12.003"
                ]
            }
        },
        "BIBREF164": {
            "ref_id": "b164",
            "title": "Brain tumor classification using deep CNN features via transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Deepak",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "M"
                    ],
                    "last": "Ameer",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Biol. Med",
            "volume": "111",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compbiomed.2019.103345"
                ]
            }
        },
        "BIBREF165": {
            "ref_id": "b165",
            "title": "Classification of CT brain images based on deep learning networks",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Afshar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "N"
                    ],
                    "last": "Plataniotis",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [
                        "W"
                    ],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hui",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "25th IEEE International Conference on Image Processing (ICIP)",
            "volume": "84513",
            "issn": "",
            "pages": "49--56",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cmpb.2016.10.007"
                ]
            }
        },
        "BIBREF166": {
            "ref_id": "b166",
            "title": "Hybrid deep learning for detecting lung diseases from X-ray images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bharati",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Podder",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "R H"
                    ],
                    "last": "Mondal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Inform. Med. Unlocked",
            "volume": "20",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.imu.2020.100391"
                ]
            }
        },
        "BIBREF167": {
            "ref_id": "b167",
            "title": "Weakly supervised 3D deep learning for breast cancer classification and localization of the lesions in MR images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Magn. Reson. Imaging",
            "volume": "50",
            "issn": "4",
            "pages": "1144--1151",
            "other_ids": {
                "DOI": [
                    "10.1002/jmri.26721"
                ]
            }
        },
        "BIBREF169": {
            "ref_id": "b169",
            "title": "Deep learning based classification of breast tumors with shear-wave elastography",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Ultrasonics",
            "volume": "72",
            "issn": "",
            "pages": "150--157",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ultras.2016.08.004"
                ]
            }
        },
        "BIBREF170": {
            "ref_id": "b170",
            "title": "Visual explanations from deep 3D Convolutional Neural Networks for Alzheimer's disease classification",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rangarajan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ranka",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "AMIA \u2026 Annu. Symp. proceedings. AMIA Symp",
            "volume": "",
            "issn": "",
            "pages": "1571--1580",
            "other_ids": {}
        },
        "BIBREF171": {
            "ref_id": "b171",
            "title": "Automated detection of lung cancer at ultralow dose PET/CT by deep neural networks-initial results",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schwyzer",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Lung Cancer",
            "volume": "126",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.lungcan.2018.11.001"
                ]
            }
        },
        "BIBREF172": {
            "ref_id": "b172",
            "title": "Classification of patterns of benignity and malignancy based on CT using topology-based phylogenetic diversity index and convolutional neural network. Pattern Recognit",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "O"
                    ],
                    "last": "De Carvalho Filho",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "De Paiva",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Nunes",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gattass",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "81",
            "issn": "",
            "pages": "200--212",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2018.03.032"
                ]
            }
        },
        "BIBREF173": {
            "ref_id": "b173",
            "title": "Multi-crop Convolutional Neural Networks for lung nodule malignancy suspiciousness classification. Pattern Recognit",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "61",
            "issn": "",
            "pages": "663--673",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2016.05.029"
                ]
            }
        },
        "BIBREF174": {
            "ref_id": "b174",
            "title": "Automated detection of COVID-19 cases using deep neural networks with X-ray images. Comput",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "B"
                    ],
                    "last": "Baloglu",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Rajendra Acharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Biol. Med",
            "volume": "121",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compbiomed.2020.103792"
                ]
            }
        },
        "BIBREF175": {
            "ref_id": "b175",
            "title": "COVIDiagnosis-Net: Deep Bayes-SqueezeNet based diagnosis of the coronavirus disease 2019 (COVID-19) from X-ray images",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ucar",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Korkmaz",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med. Hypotheses",
            "volume": "140",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mehy.2020.109761"
                ]
            }
        },
        "BIBREF176": {
            "ref_id": "b176",
            "title": "COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "Q"
                    ],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sci. Rep",
            "volume": "10",
            "issn": "1",
            "pages": "1--12",
            "other_ids": {
                "DOI": [
                    "10.1038/s41598-020-76550-z"
                ]
            }
        },
        "BIBREF177": {
            "ref_id": "b177",
            "title": "Dermatologist level dermoscopy skin cancer classification using different deep learning convolutional neural networks algorithms",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rezvantalab",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Safigholi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Karimijeshni",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF178": {
            "ref_id": "b178",
            "title": "The skin cancer classification using deep convolutional neural network. Multimed",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "O"
                    ],
                    "last": "Dorj",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "K"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Tools Appl",
            "volume": "77",
            "issn": "8",
            "pages": "9909--9924",
            "other_ids": {
                "DOI": [
                    "10.1007/s11042-018-5714-1"
                ]
            }
        },
        "BIBREF179": {
            "ref_id": "b179",
            "title": "Dermatologist-level classification of skin cancer with deep neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Esteva",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Nature",
            "volume": "542",
            "issn": "7639",
            "pages": "115--118",
            "other_ids": {
                "DOI": [
                    "10.1038/nature21056"
                ]
            }
        },
        "BIBREF180": {
            "ref_id": "b180",
            "title": "Classification of SD-OCT images using a deep learning approach",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Awais",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Muller",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "B"
                    ],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Meriaudeau",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. 2017 IEEE Int. Conf. Signal Image Process. Appl. ICSIPA 2017",
            "volume": "c",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ICSIPA.2017.8120661"
                ]
            }
        },
        "BIBREF181": {
            "ref_id": "b181",
            "title": "Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S W"
                    ],
                    "last": "Ting",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Am. Med. Assoc",
            "volume": "318",
            "issn": "22",
            "pages": "2211--2223",
            "other_ids": {
                "DOI": [
                    "10.1001/jama.2017.18152"
                ]
            }
        },
        "BIBREF183": {
            "ref_id": "b183",
            "title": "Synthetic data augmentation using GAN for improved liver lesion classification",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Klang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Amitai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Goldberger",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)",
            "volume": "83635",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ISBI.2018.8363576"
                ]
            }
        },
        "BIBREF184": {
            "ref_id": "b184",
            "title": "Robust non-rigid registration through agentbased action learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Krebs",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Computing and Computer Assisted Intervention \u2212 MICCAI 2017",
            "volume": "",
            "issn": "",
            "pages": "344--352",
            "other_ids": {}
        },
        "BIBREF185": {
            "ref_id": "b185",
            "title": "Quicksilver: fast predictive image registration-a deep learning approach",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kwitt",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Styner",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Niethammer",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Neuroimage",
            "volume": "158",
            "issn": "",
            "pages": "378--396",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neuroimage.2017.07.008"
                ]
            }
        },
        "BIBREF186": {
            "ref_id": "b186",
            "title": "Nonrigid image registration using multi-scale 3D Convolutional Neural Networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sokooti",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "De Vos",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Berendsen",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "P F"
                    ],
                    "last": "Lelieveldt",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "I\u0161gum",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Staring",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Medical Image Computing and Computer Assisted Intervention \u2212 MICCAI 2017",
            "volume": "",
            "issn": "",
            "pages": "232--239",
            "other_ids": {}
        },
        "BIBREF187": {
            "ref_id": "b187",
            "title": "Unsupervised deep feature learning for deformable registration of MR brain images",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "649--656",
            "other_ids": {}
        },
        "BIBREF188": {
            "ref_id": "b188",
            "title": "Scalable high-performance image registration framework by unsupervised deep feature representations learning",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "C"
                    ],
                    "last": "Munsell",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "63",
            "issn": "7",
            "pages": "1505--1516",
            "other_ids": {
                "DOI": [
                    "10.1109/TBME.2015.2496253"
                ]
            }
        },
        "BIBREF189": {
            "ref_id": "b189",
            "title": "A CNN regression approach for real-time 2D/3D registration",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "J"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "5",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2521800"
                ]
            }
        },
        "BIBREF190": {
            "ref_id": "b190",
            "title": "End-to-end unsupervised deformable image registration with a convolutional neural network",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "D"
                    ],
                    "last": "De Vos",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "F"
                    ],
                    "last": "Berendsen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Viergever",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Staring",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "I\u0161gum",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)",
            "volume": "",
            "issn": "",
            "pages": "204--212",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-67558-9_24"
                ]
            }
        },
        "BIBREF191": {
            "ref_id": "b191",
            "title": "Deformable MRI-ultrasound registration using 3D convolutional neural network",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "LNCS",
            "volume": "11042",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF192": {
            "ref_id": "b192",
            "title": "A full migration BBO algorithm with enhanced population quality bounds for multimodal biomedical image registration",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Appl. Soft Comput. J",
            "volume": "93",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.asoc.2020.106335"
                ]
            }
        },
        "BIBREF193": {
            "ref_id": "b193",
            "title": "Metric learning for image registration",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Niethammer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kwitt",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "X"
                    ],
                    "last": "Vialard",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "8455--8464",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2019.00866"
                ]
            }
        },
        "BIBREF194": {
            "ref_id": "b194",
            "title": "Scalable high performance image registration framework by unsupervised deep feature representations learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Deep Learn. Med. Image Anal",
            "volume": "63",
            "issn": "7",
            "pages": "245--269",
            "other_ids": {
                "DOI": [
                    "10.1016/B978-0-12-810408-8.00015-8"
                ]
            }
        },
        "BIBREF195": {
            "ref_id": "b195",
            "title": "A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Min",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Ye",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Phys",
            "volume": "44",
            "issn": "10",
            "pages": "360--375",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12344"
                ]
            }
        },
        "BIBREF196": {
            "ref_id": "b196",
            "title": "Deep Neural Network-based feature descriptor for retinal image registration",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Abanovi\u00e8",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Stankevi\u00e8ius",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Matuzevi\u00e8ius",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 IEEE 6th Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE)",
            "volume": "85920",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/AIEEE.2018.8592033"
                ]
            }
        },
        "BIBREF197": {
            "ref_id": "b197",
            "title": "Learning deep similarity metric for 3D MR-TRUS image registration",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Haskins",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Int. J. Comput. Assist",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF199": {
            "ref_id": "b199",
            "title": "Anniversary paper: history and status of CAD and quantitative image analysis: the role of medical physics and AAPM",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                },
                {
                    "first": "H.-P",
                    "middle": [],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Boone",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Med. Phys",
            "volume": "35",
            "issn": "12",
            "pages": "5799--5820",
            "other_ids": {
                "DOI": [
                    "10.1118/1.3013555"
                ]
            }
        },
        "BIBREF200": {
            "ref_id": "b200",
            "title": "Breast image analysis for risk assessment, detection, diagnosis, and treatment of cancer",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Karssemeijer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Schnabel",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Annu. Rev. Biomed. Eng",
            "volume": "15",
            "issn": "1",
            "pages": "327--357",
            "other_ids": {
                "DOI": [
                    "10.1146/annurev-bioeng-071812-152416"
                ]
            }
        },
        "BIBREF201": {
            "ref_id": "b201",
            "title": "Quantitative MRI radiomics in the prediction of molecular classifications of breast cancer subtypes in the TCGA/ TCIA data set",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "NPJ Breast Cancer",
            "volume": "2",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1038/npjbcancer.2016.12"
                ]
            }
        },
        "BIBREF202": {
            "ref_id": "b202",
            "title": "Prediction of clinical phenotypes in invasive breast carcinomas from the integration of radiomics and genomics data",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Med. Imaging",
            "volume": "2",
            "issn": "4",
            "pages": "1--12",
            "other_ids": {
                "DOI": [
                    "10.1117/1.JMI.2.4.041007"
                ]
            }
        },
        "BIBREF203": {
            "ref_id": "b203",
            "title": "MR imaging radiomics signatures for predicting the risk of breast cancer recurrence as given by research versions of MammaPrint, Oncotype DX, and PAM50 Gene assays",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Radiology",
            "volume": "281",
            "issn": "2",
            "pages": "382--391",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2016152110"
                ]
            }
        },
        "BIBREF204": {
            "ref_id": "b204",
            "title": "Classification of normal and abnormal lungs with interstitial diseases by rule-based method and artificial neural networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Katsuragawa",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Doi",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Macmahon",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Monnier-Cholley",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ishida",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kobayashi",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "J. Digit. Imaging",
            "volume": "10",
            "issn": "3",
            "pages": "108--114",
            "other_ids": {
                "DOI": [
                    "10.1007/BF03168597"
                ]
            }
        },
        "BIBREF205": {
            "ref_id": "b205",
            "title": "Comparison of shallow and deep learning methods on classifying the regional pattern of diffuse lung disease",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "B"
                    ],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Digit. Imaging",
            "volume": "31",
            "issn": "4",
            "pages": "415--424",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-017-0028-9"
                ]
            }
        },
        "BIBREF206": {
            "ref_id": "b206",
            "title": "Use of clinical MRI maximum intensity projections for improved breast lesion classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "O"
                    ],
                    "last": "Antropova",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Med. Imaging",
            "volume": "5",
            "issn": "1",
            "pages": "1--6",
            "other_ids": {
                "DOI": [
                    "10.1117/1.JMI.5.1.014503"
                ]
            }
        },
        "BIBREF207": {
            "ref_id": "b207",
            "title": "A deep learning method for classifying mammographic breast density categories",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Mohamed",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "A"
                    ],
                    "last": "Berg",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "C"
                    ],
                    "last": "Jankowitz",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Med. Phys",
            "volume": "45",
            "issn": "1",
            "pages": "314--321",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12683"
                ]
            }
        },
        "BIBREF208": {
            "ref_id": "b208",
            "title": "Automated mammographic breast density estimation using a fully convolutional network",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Nishikawa",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Med. Phys",
            "volume": "45",
            "issn": "3",
            "pages": "1178--1190",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12763"
                ]
            }
        },
        "BIBREF209": {
            "ref_id": "b209",
            "title": "A deep feature fusion methodology for breast cancer diagnosis demonstrated on three imaging modality datasets",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Antropova",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "Q"
                    ],
                    "last": "Huynh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Phys",
            "volume": "44",
            "issn": "10",
            "pages": "5162--5171",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12453"
                ]
            }
        },
        "BIBREF210": {
            "ref_id": "b210",
            "title": "Multi-task transfer learning deep convolutional neural network: application to computer-aided diagnosis of breast cancer on mammograms",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Samala",
                    "suffix": ""
                },
                {
                    "first": "H.-P",
                    "middle": [],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Hadjiiski",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Helvie",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Cha",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Richter",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Phys. Med. Biol",
            "volume": "62",
            "issn": "23",
            "pages": "8894--8908",
            "other_ids": {
                "DOI": [
                    "10.1088/1361-6560/aa93d4"
                ]
            }
        },
        "BIBREF211": {
            "ref_id": "b211",
            "title": "Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kooi",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Van Ginneken",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Karssemeijer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Den Heeten",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Phys",
            "volume": "44",
            "issn": "3",
            "pages": "1017--1027",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12110"
                ]
            }
        },
        "BIBREF212": {
            "ref_id": "b212",
            "title": "Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Masood",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Biomed. Inform",
            "volume": "79",
            "issn": "",
            "pages": "117--128",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2018.01.005"
                ]
            }
        },
        "BIBREF213": {
            "ref_id": "b213",
            "title": "Disease staging and prognosis in smokers using deep learning in chest computed tomography",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Gonzalez",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Am. J",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF215": {
            "ref_id": "b215",
            "title": "A deep learning-based radiomics model for prediction of survival in Glioblastoma Multiforme",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lao",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Sci. Rep",
            "volume": "7",
            "issn": "1",
            "pages": "1--8",
            "other_ids": {
                "DOI": [
                    "10.1038/s41598-017-10649-8"
                ]
            }
        },
        "BIBREF216": {
            "ref_id": "b216",
            "title": "Urinary bladder cancer staging in CT urography using machine learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Garapati",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Med. Phys",
            "volume": "44",
            "issn": "11",
            "pages": "5814--5823",
            "other_ids": {
                "DOI": [
                    "10.1002/mp.12510"
                ]
            }
        },
        "BIBREF217": {
            "ref_id": "b217",
            "title": "Applying artificial intelligence to disease staging: deep learning for improved staging of diabetic retinopathy",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Takahashi",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tampo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Arai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kawashima",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "PLoS One",
            "volume": "12",
            "issn": "6",
            "pages": "1--11",
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0179790"
                ]
            }
        },
        "BIBREF218": {
            "ref_id": "b218",
            "title": "Deep learning for prediction of colorectal cancer outcome: a discovery and validation study",
            "authors": [
                {
                    "first": "O.-J",
                    "middle": [],
                    "last": "Skrede",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "19",
            "pages": "32998--33006",
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(19)32998-8"
                ]
            }
        },
        "BIBREF219": {
            "ref_id": "b219",
            "title": "Predicting survival after hepatocellular carcinoma resection using deep learning on histological slides",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Saillard",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Hepatology",
            "volume": "72",
            "issn": "6",
            "pages": "2000--2013",
            "other_ids": {
                "DOI": [
                    "10.1002/hep.31207"
                ]
            }
        },
        "BIBREF221": {
            "ref_id": "b221",
            "title": "Radiological society of North America expert consensus document on reporting chest CT findings related to COVID-19: endorsed by the society of thoracic radiology, the American College of Radiology, and RSNA. Radiol. Cardiothorac",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Simpson",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Imaging",
            "volume": "2",
            "issn": "2",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1148/ryct.2020200152"
                ]
            }
        },
        "BIBREF222": {
            "ref_id": "b222",
            "title": "COVID 19 diagnostic tests: a study of 12,270 patients to determine which test offers the most beneficial results",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mahmood",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gajula",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Gajula",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Surg. Sci",
            "volume": "11",
            "issn": "04",
            "pages": "82--88",
            "other_ids": {
                "DOI": [
                    "10.4236/ss.2020.114011"
                ]
            }
        },
        "BIBREF223": {
            "ref_id": "b223",
            "title": "Is there a role for lung ultrasound during the COVID-19 pandemic?",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Soldati",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Ultrasound Med",
            "volume": "39",
            "issn": "7",
            "pages": "1459--1462",
            "other_ids": {
                "DOI": [
                    "10.1002/jum.15284"
                ]
            }
        },
        "BIBREF224": {
            "ref_id": "b224",
            "title": "RETRACTED ARTICLE: Deep learning system to screen coronavirus disease 2019 pneumonia",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Butt",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gill",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chun",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/s10489-020-01714-3"
                ]
            }
        },
        "BIBREF226": {
            "ref_id": "b226",
            "title": "Deep convolutional neural network with segmentation techniques for chest x-ray analysis",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "U"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)",
            "volume": "88341",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ICIEA.2019.8834117"
                ]
            }
        },
        "BIBREF227": {
            "ref_id": "b227",
            "title": "Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: results of 10 convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Ardakani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "R"
                    ],
                    "last": "Kanafi",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Khadem",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput. Biol. Med",
            "volume": "121",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compbiomed.2020.103795"
                ]
            }
        },
        "BIBREF228": {
            "ref_id": "b228",
            "title": "Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Giger",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "Q"
                    ],
                    "last": "Huynh",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "O"
                    ],
                    "last": "Antropova",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Med. Imaging",
            "volume": "4",
            "issn": "4",
            "pages": "1--6",
            "other_ids": {
                "DOI": [
                    "10.1117/1.JMI.4.4.041304"
                ]
            }
        },
        "BIBREF229": {
            "ref_id": "b229",
            "title": "DeepOrgan: multi-level deep convolutional networks for automated pancreas segmentation",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "Roth",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "556--564",
            "other_ids": {}
        },
        "BIBREF230": {
            "ref_id": "b230",
            "title": "The effectiveness of data augmentation for detection of gastrointestinal diseases from endoscopical images",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Asperti",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Mastronardo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "CoRR",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF231": {
            "ref_id": "b231",
            "title": "Seamless lesion insertion for data augmentation in CAD training",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pezeshk",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Petrick",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Sahiner",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Trans",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF233": {
            "ref_id": "b233",
            "title": "Real data augmentation for medical image classification",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Tavanapong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "C"
                    ],
                    "last": "De Groen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Oh",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Intravascular Imaging and Computer Assisted Stenting, and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis",
            "volume": "",
            "issn": "",
            "pages": "67--76",
            "other_ids": {}
        },
        "BIBREF234": {
            "ref_id": "b234",
            "title": "Low-dose x-ray tomography through a deep convolutional neural network",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sci. Rep",
            "volume": "8",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1038/s41598-018-19426-7"
                ]
            }
        },
        "BIBREF235": {
            "ref_id": "b235",
            "title": "Low-dose CT via convolutional neural network",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Biomed. Opt. Express",
            "volume": "8",
            "issn": "2",
            "pages": "679--694",
            "other_ids": {
                "DOI": [
                    "10.1364/BOE.8.000679"
                ]
            }
        },
        "BIBREF236": {
            "ref_id": "b236",
            "title": "Deep reconstruction model for dynamic PET images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "PLoS One",
            "volume": "12",
            "issn": "9",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0184667"
                ]
            }
        },
        "BIBREF237": {
            "ref_id": "b237",
            "title": "Medical image data and datasets in the era of machine learning-whitepaper from the 2016 C-MIMI meeting dataset session",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Kohli",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Geis",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Digit. Imaging",
            "volume": "30",
            "issn": "4",
            "pages": "392--399",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-017-9976-3"
                ]
            }
        },
        "BIBREF238": {
            "ref_id": "b238",
            "title": "Preparing medical imaging data for machine learning",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Willemink",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "295",
            "issn": "1",
            "pages": "4--15",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020192224"
                ]
            }
        },
        "BIBREF239": {
            "ref_id": "b239",
            "title": "Going deep in medical image analysis: concepts, methods, challenges, and future directions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Altaf",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M S"
                    ],
                    "last": "Islam",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Akhtar",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "K"
                    ],
                    "last": "Janjua",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "3",
            "pages": "99540--99572",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2019.2929365"
                ]
            }
        },
        "BIBREF241": {
            "ref_id": "b241",
            "title": "The multimodal brain tumor image segmentation benchmark (BRATS)",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "H"
                    ],
                    "last": "Menze",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "34",
            "issn": "10",
            "pages": "1993--2024",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2014.2377694"
                ]
            }
        },
        "BIBREF242": {
            "ref_id": "b242",
            "title": "Alzheimer's disease neuroimaging initiative (ADNI)",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "C"
                    ],
                    "last": "Petersen",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Neurology",
            "volume": "74",
            "issn": "3",
            "pages": "201--209",
            "other_ids": {
                "DOI": [
                    "10.1212/WNL.0b013e3181cb3e25"
                ]
            }
        },
        "BIBREF243": {
            "ref_id": "b243",
            "title": "Lung image database consortium: developing a resource for the medical imaging research community",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "G"
                    ],
                    "last": "Armato",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Radiology",
            "volume": "232",
            "issn": "3",
            "pages": "739--748",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2323032035"
                ]
            }
        },
        "BIBREF244": {
            "ref_id": "b244",
            "title": "Building a reference multimedia database for interstitial lung diseases",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Depeursinge",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vargas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Platon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Geissbuhler",
                    "suffix": ""
                },
                {
                    "first": "P.-A",
                    "middle": [],
                    "last": "Poletti",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "M\u00fcller",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Comput. Med. Imaging Graph",
            "volume": "36",
            "issn": "3",
            "pages": "227--238",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2011.07.003"
                ]
            }
        },
        "BIBREF245": {
            "ref_id": "b245",
            "title": "Ridge-based vessel segmentation in color images of the retina",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Staal",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Abr\u00e0moff",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Niemeijer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Viergever",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Van Ginneken",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "23",
            "issn": "4",
            "pages": "501--509",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2004.825627"
                ]
            }
        },
        "BIBREF246": {
            "ref_id": "b246",
            "title": "Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "D"
                    ],
                    "last": "Hoover",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kouznetsova",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Goldbaum",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "19",
            "issn": "3",
            "pages": "203--210",
            "other_ids": {
                "DOI": [
                    "10.1109/42.845178"
                ]
            }
        },
        "BIBREF247": {
            "ref_id": "b247",
            "title": "Textural features for image classification",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Haralick",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shanmugam",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Dinstein",
                    "suffix": ""
                }
            ],
            "year": 1973,
            "venue": "IEEE Trans. Syst. Man. Cybern. SMC",
            "volume": "3",
            "issn": "6",
            "pages": "610--621",
            "other_ids": {
                "DOI": [
                    "10.1109/TSMC.1973.4309314"
                ]
            }
        },
        "BIBREF248": {
            "ref_id": "b248",
            "title": "Medical image classification via SVM using LBP features from saliency-based folded data",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "\u00c7amlica",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "Tizhoosh",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Khalvati",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)",
            "volume": "",
            "issn": "",
            "pages": "128--132",
            "other_ids": {
                "DOI": [
                    "10.1109/ICMLA.2015.131"
                ]
            }
        },
        "BIBREF249": {
            "ref_id": "b249",
            "title": "Optimal feature selection-based medical image classification using deep learning model in internet of medical things",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "J S"
                    ],
                    "last": "Raj",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Shobana",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "V"
                    ],
                    "last": "Pustokhina",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "A"
                    ],
                    "last": "Pustokhin",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shankar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "58006--58017",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.2981337"
                ]
            }
        },
        "BIBREF251": {
            "ref_id": "b251",
            "title": "Beyond ANOVA: basics of applied statistics",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "G"
                    ],
                    "last": "Miller",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF252": {
            "ref_id": "b252",
            "title": "2973_ Featu re_ selec tion_ using_ stepw ise_ ANOVA_ discr imina nt_ analy sis_ for_ mammo gram_ mass_ class ifica tion/ links",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Surendiran",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Vadivel",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Int. J. Signal Image Process",
            "volume": "2",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF253": {
            "ref_id": "b253",
            "title": "Sergios and Pikrakis, Aggelos and Koutroumbas, Konstantinos and Cavouras, Introduction to pattern recognition: a matlab approach",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Theodoridis",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF254": {
            "ref_id": "b254",
            "title": "Deep vessel tracking: a generalized probabilistic approach via deep learning Aaron Wu",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Mollura",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Mingchen Gao, Mario Buty, Daniel J. Mollura Department of Radiology and Imaging Sciences",
            "volume": "",
            "issn": "",
            "pages": "1363--1367",
            "other_ids": {}
        },
        "BIBREF255": {
            "ref_id": "b255",
            "title": "Differential data augmentation techniques for medical imaging classification tasks",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Gimenez",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rubin",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "AMIA \u2026 Annu. Symp. Proc. AMIA Symp",
            "volume": "",
            "issn": "",
            "pages": "979--984",
            "other_ids": {}
        },
        "BIBREF256": {
            "ref_id": "b256",
            "title": "Statistical validation of image segmentation quality based on a spatial overlap index1: scientific reports",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Zou",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/S1076-6332(03)00671-8"
                ]
            }
        },
        "BIBREF258": {
            "ref_id": "b258",
            "title": "Medical image deep learning with hospital {PACS} dataset",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cho",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Shin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Choy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Do",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF259": {
            "ref_id": "b259",
            "title": "Synthetic medical images from dual generative adversarial networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Guibas",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Virdi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "S"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF260": {
            "ref_id": "b260",
            "title": "Adversarial training and dilated convolutions for brain MRI segmentation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moeskops",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Veta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Lafarge",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "A J"
                    ],
                    "last": "Eppenhof",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P W"
                    ],
                    "last": "Pluim",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support",
            "volume": "",
            "issn": "",
            "pages": "56--64",
            "other_ids": {}
        },
        "BIBREF261": {
            "ref_id": "b261",
            "title": "Training neural network classifiers for medical decision making: the effects of imbalanced datasets on classification performance",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Mazurowski",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Habas",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Zurada",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Baker",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Tourassi",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Neural Netw",
            "volume": "21",
            "issn": "2",
            "pages": "427--436",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neunet.2007.12.031"
                ]
            }
        },
        "BIBREF262": {
            "ref_id": "b262",
            "title": "A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybrid-based approaches",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Galar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Fernandez",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Barrenechea",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Bustince",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Herrera",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Trans. Syst. Man Cybern. Part C Appl. Rev",
            "volume": "42",
            "issn": "4",
            "pages": "463--484",
            "other_ids": {
                "DOI": [
                    "10.1109/TSMCC.2011.2161285"
                ]
            }
        },
        "BIBREF264": {
            "ref_id": "b264",
            "title": "Machine learning approaches in medical image analysis: from detection to diagnosis",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "De Bruijne",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Med. Image Anal",
            "volume": "33",
            "issn": "",
            "pages": "94--97",
            "other_ids": {
                "DOI": [
                    "10.1016/j.media.2016.06.032"
                ]
            }
        },
        "BIBREF265": {
            "ref_id": "b265",
            "title": "An overview of deep learning in medical imaging focusing on MRI",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Lundervold",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lundervold",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Z. Med. Phys",
            "volume": "29",
            "issn": "2",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.zemedi.2018.11.002"
                ]
            }
        },
        "BIBREF266": {
            "ref_id": "b266",
            "title": "Estimating CT image from MRI data using 3D fully convolutional networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Deep Learning and Data Labeling for Medical Applications",
            "volume": "",
            "issn": "",
            "pages": "170--178",
            "other_ids": {}
        },
        "BIBREF267": {
            "ref_id": "b267",
            "title": "80995 02}{Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ledig",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Cvpr",
            "volume": "2",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "DL basic categories as per paper organization",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "t) = I(t) * K(a) = (I * K)(t),",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Basic common deep learning architectures. A Restricted Boltzmann machine. B Recurrent Neural Network (RNN). C Autoencoders. D GANs",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Timeline of mostly used DL models in medical imaging Surveyed DL applications in medical imagingFig. 7",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The number of challenges related to segmentation in medical imaging from 2007 to 2020 listed on Grand Challenges regarding the imaging modalities",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Lesion detection algorithm flowchart[118]",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Flowchart of medical images data handling",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "ROC and AUC graph",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Deep learning applications to medical imaging detection",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Deep learning applications to medical imaging for registration",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Deep learning applications to medical imaging for characterization",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Analysis of Variance-ANOVA: is a statistical model by which it evaluates and compares two or more experiments averages. The idea behind this model is that the difference between means are substantial to evaluate the performance of two estimates[237]. Surendiran et al.[238] have used the stepwise ANOVA Discriminant Analysis (DA) for mammogram masses' classification.The basic steps of performing ANOVA on data distribution are 1. Defining Hypothesis: 2. Calculating the sum of squares",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Conflict of interest on the behalf of all authors, the corresponding author states that there is no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}