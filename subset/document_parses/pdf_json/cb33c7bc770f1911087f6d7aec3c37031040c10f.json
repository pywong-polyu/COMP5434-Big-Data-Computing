{"paper_id": "cb33c7bc770f1911087f6d7aec3c37031040c10f", "metadata": {"title": "Hyperbolic Knowledge Graph Embeddings for Knowledge Base Completion", "authors": [{"first": "Prodromos", "middle": [], "last": "Kolyvakis", "suffix": "", "affiliation": {}, "email": "prodromos.kolyvakis@epfl.ch"}, {"first": "Alexandros", "middle": [], "last": "Kalousis", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Applied Sciences", "location": {"addrLine": "Western Switzerland Carouge"}}, "email": "alexandros.kalousis@hesge.ch"}, {"first": "Dimitris", "middle": [], "last": "Kiritsis", "suffix": "", "affiliation": {}, "email": "dimitris.kiritsis@epfl.ch"}]}, "abstract": [{"text": "Learning embeddings of entities and relations existing in knowledge bases allows the discovery of hidden patterns in them. In this work, we examine the contribution of geometrical space to the task of knowledge base completion. We focus on the family of translational models, whose performance has been lagging. We extend these models to the hyperbolic space so as to better reflect the topological properties of knowledge bases. We investigate the type of regularities that our model, dubbed HyperKG, can capture and show that it is a prominent candidate for effectively representing a subset of Datalog rules. We empirically show, using a variety of link prediction datasets, that hyperbolic space allows to narrow down significantly the performance gap between translational and bilinear models and effectively represent certain types of rules.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}, {"text": "Electronic supplementary material The online version of this chapter (https://", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Learning in the presence of structured information is an important challenge for artificial intelligence [18, 31, 41] . Knowledge Bases (KBs) such as WordNet [29] , Freebase [8] , YAGO [47] and DBpedia [27] constitute valuable such resources needed for a plethora of practical applications, including question answering and information extraction. However, despite their formidable number of facts, it is widely accepted that their coverage is still far from being complete [44, 58] . This shortcoming has opened the door for a number of studies addressing the problem of automatic knowledge base completion (KBC) or link prediction [34] . The impetus of these studies arises from the hypothesis that statistical regularities lay in KB facts, which when correctly exploited can result in the discovery of missing true facts [60] . Building on the great generalisation capability of distributed representations, a great line of research [10, 35, 36, 51, 62] has focused on learning KB vector space embeddings as a way of predicting the plausibility of a fact.", "cite_spans": [{"start": 105, "end": 109, "text": "[18,", "ref_id": "BIBREF17"}, {"start": 110, "end": 113, "text": "31,", "ref_id": "BIBREF30"}, {"start": 114, "end": 117, "text": "41]", "ref_id": "BIBREF40"}, {"start": 158, "end": 162, "text": "[29]", "ref_id": "BIBREF28"}, {"start": 174, "end": 177, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 185, "end": 189, "text": "[47]", "ref_id": "BIBREF46"}, {"start": 202, "end": 206, "text": "[27]", "ref_id": "BIBREF26"}, {"start": 474, "end": 478, "text": "[44,", "ref_id": "BIBREF43"}, {"start": 479, "end": 482, "text": "58]", "ref_id": "BIBREF57"}, {"start": 633, "end": 637, "text": "[34]", "ref_id": "BIBREF33"}, {"start": 824, "end": 828, "text": "[60]", "ref_id": "BIBREF59"}, {"start": 936, "end": 940, "text": "[10,", "ref_id": "BIBREF9"}, {"start": 941, "end": 944, "text": "35,", "ref_id": "BIBREF34"}, {"start": 945, "end": 948, "text": "36,", "ref_id": "BIBREF35"}, {"start": 949, "end": 952, "text": "51,", "ref_id": "BIBREF50"}, {"start": 953, "end": 956, "text": "62]", "ref_id": "BIBREF61"}], "ref_spans": [], "section": "Introduction"}, {"text": "An intrinsic characteristic of knowledge graphs is that they present power-law (or scale-free) degree distributions as many other networks [15, 46] . In an attempt of understanding scale-free networks' properties, various generative models have been proposed such as the models of Barab\u00e1si and Albert [6] and Van Der Hofstad [53] . Interestingly, Krioukov et al. [25] have shown that scale-free networks naturally emerge in the hyperbolic space. Recently, the hyperbolic geometry was exploited in various works [17, 37, 38, 42] as a means to provide high-quality embeddings for hierarchical structures. Hyperbolic space has the potential to bring significant value in the task of KBC since it offers a natural way to take the KB's topological information into account. Furthermore, many of the relations appearing in KBs lead to hierarchical and hierarchical-like structures [28] .", "cite_spans": [{"start": 139, "end": 143, "text": "[15,", "ref_id": "BIBREF14"}, {"start": 144, "end": 147, "text": "46]", "ref_id": "BIBREF45"}, {"start": 301, "end": 304, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 325, "end": 329, "text": "[53]", "ref_id": "BIBREF52"}, {"start": 363, "end": 367, "text": "[25]", "ref_id": "BIBREF24"}, {"start": 511, "end": 515, "text": "[17,", "ref_id": "BIBREF16"}, {"start": 516, "end": 519, "text": "37,", "ref_id": "BIBREF36"}, {"start": 520, "end": 523, "text": "38,", "ref_id": "BIBREF37"}, {"start": 524, "end": 527, "text": "42]", "ref_id": "BIBREF41"}, {"start": 875, "end": 879, "text": "[28]", "ref_id": "BIBREF27"}], "ref_spans": [], "section": "Introduction"}, {"text": "At the same time, the expressiveness of various KB embedding models has been recently examined in terms of their ability to express any ground truth of facts [23, 56] . Moreover, Guti\u00e9rrez-Basulto and Schockaert [21] have proceeded one step further and investigated the compatibility between ontological axioms and different types of KB embeddings. Specifically, the authors have proved that a certain family of rules, i.e., the quasi-chained rules which form a subset of Datalog rules [1] , can be exactly represented by a KB embedding model whose relations are modelled as convex regions; ensuring, thus, logical consistency in the facts induced by this KB embedding model. In the light of this result, it seems important that the appropriateness of a KB embedding model should not only be measured in terms of fully expressiveness but also in terms of the rules that it can model.", "cite_spans": [{"start": 158, "end": 162, "text": "[23,", "ref_id": "BIBREF22"}, {"start": 163, "end": 166, "text": "56]", "ref_id": "BIBREF55"}, {"start": 212, "end": 216, "text": "[21]", "ref_id": "BIBREF20"}, {"start": 486, "end": 489, "text": "[1]", "ref_id": "BIBREF0"}], "ref_spans": [], "section": "Introduction"}, {"text": "In this paper, we explore geometrical spaces having the potential to better represent KBs' topological properties and rules and examine the performance implications on KBC. We focus on the family of translational models [10] that attempt to model the statistical regularities as vector translations between entities' vector representations, and whose performance has been lagging. We extend the translational models by learning embeddings of KB entities and relations in the Poincar\u00e9-ball model of hyperbolic geometry. We do so by learning compositional vector representations [30] of the entities appearing in a given fact based on translations. The implausibility of a fact is measured in terms of the hyperbolic distance between the compositional vector representations of its entities and the learned relation vector. We prove that the relation regions captured by our proposed model are convex. Our model becomes, thus, a prominent candidate for representing effectively quasi-chained rules.", "cite_spans": [{"start": 220, "end": 224, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 577, "end": 581, "text": "[30]", "ref_id": "BIBREF29"}], "ref_spans": [], "section": "Introduction"}, {"text": "Among our contributions is the proposal of a novel KB embedding model as well as a regularisation scheme on the Poincar\u00e9-ball model, whose effectiveness we prove empirically. Furthermore, we prove that translational models do not suffer from the restrictions identified by Kazemi and Poole [23] in the case where a fact is considered valid when its implausibility score is below a certain nonzero threshold. We evaluate our approach on various benchmark datasets and our experimental results show that our work makes a big step towards (i) closing the performance gap between translational and bilinear models and (ii) enhancing our understanding of which KBs mostly benefit from exploiting hyperbolic embeddings. Last but not least, our work demonstrates that the choice of geometrical space plays a significant role for KBC and illustrates the importance of taking both the topological and the formal properties of KBs into account. The implementation code and the datasets are publicly available on: https://github. com/prokolyvakis/hyperkg.", "cite_spans": [{"start": 290, "end": 294, "text": "[23]", "ref_id": "BIBREF22"}], "ref_spans": [], "section": "Introduction"}, {"text": "Shallow KB Embedding Models. There has been a great line of research dedicated to the task of learning distributed representations for entities and relations in KBs. To constrain the analysis, we only consider shallow embedding models that do not exploit deep neural networks or incorporate additional external information beyond the KB facts. For an elaborated review of these techniques, please refer to Nickel et al. [34] and Wang et al. [55] . We also exclude from our comparison recent work that explores different types of training regimes such as adversarial training, and/or the inclusion of reciprocal facts [11, 23, 26, 48] to make the analysis less biased to factors that could overshadow the importance of the geometrical space.", "cite_spans": [{"start": 420, "end": 424, "text": "[34]", "ref_id": "BIBREF33"}, {"start": 441, "end": 445, "text": "[55]", "ref_id": "BIBREF54"}, {"start": 617, "end": 621, "text": "[11,", "ref_id": "BIBREF10"}, {"start": 622, "end": 625, "text": "23,", "ref_id": "BIBREF22"}, {"start": 626, "end": 629, "text": "26,", "ref_id": "BIBREF25"}, {"start": 630, "end": 633, "text": "48]", "ref_id": "BIBREF47"}], "ref_spans": [], "section": "Related Work"}, {"text": "In general, the shallow embedding approaches can be divided into two main categories; the translational [10] and the bilinear [36] family of models. In the translational family, the vast majority of models [13, 22, 57, 59] generalise TransE [10] , which attempts to model relations as translation operations between the vector representations of the subject and object entities, as observed in a given fact. In the bilinear family, most of the approaches [35, 51, 62] generalise RESCAL [36] that proposes to model facts through bilinear operations over entity and relations vector representations. In this paper, we focus on the family of translational models, whose performance has been lagging, and propose extensions in the hyperbolic space which by exploiting the topological and the formal properties of KBs bring significant performance improvements.", "cite_spans": [{"start": 104, "end": 108, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 126, "end": 130, "text": "[36]", "ref_id": "BIBREF35"}, {"start": 206, "end": 210, "text": "[13,", "ref_id": "BIBREF12"}, {"start": 211, "end": 214, "text": "22,", "ref_id": "BIBREF21"}, {"start": 215, "end": 218, "text": "57,", "ref_id": "BIBREF56"}, {"start": 219, "end": 222, "text": "59]", "ref_id": "BIBREF58"}, {"start": 241, "end": 245, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 455, "end": 459, "text": "[35,", "ref_id": "BIBREF34"}, {"start": 460, "end": 463, "text": "51,", "ref_id": "BIBREF50"}, {"start": 464, "end": 467, "text": "62]", "ref_id": "BIBREF61"}, {"start": 486, "end": 490, "text": "[36]", "ref_id": "BIBREF35"}], "ref_spans": [], "section": "Related Work"}, {"text": "Hyperbolic Embeddings. There has been a growing interest in embedding scale-free networks in the hyperbolic space [7, 39] . Hyperbolic geometry was also exploited in various works as a way to exploit hierarchical information and learn more efficient representations [17, 37, 38, 42] . However, this line of work has only focused on single-relational networks. Recently and in parallel to our work, two other works have explored hyperbolic embeddings for KBs. Contrary to our work where M\u00f6bius or Euclidean addition is used as a translational operation, Suzuki et al. [49] exploit vector fields with an attractive point to generalise translation in Riemannian manifolds. Their approach, although promising, shows a degraded performance on commonly used benchmarks. Similarly to our approach, Bala\u017eevi\u0107 et al. [5] extend to the hyperbolic space the family of translational models demonstrating significant performance improvements over state-of-theart. However, the authors exploit both the hyperbolic as well as the Euclidean space by using the M\u00f6bius Matrix-vector multiplication and Euclidean scalar biases. 1 Unlike our experimental setup, the authors also include reciprocal facts. Although their approach is beneficial for KBC, it becomes hard to quantify the contributions of hyperbolic space. This is verified by the fact that their Euclidean model analogue performs in line with their \"hybrid\" hyperbolic-Euclidean model. Finally, neither of these works studies the types of rules that their proposed models can effectively represent.", "cite_spans": [{"start": 114, "end": 117, "text": "[7,", "ref_id": "BIBREF6"}, {"start": 118, "end": 121, "text": "39]", "ref_id": "BIBREF38"}, {"start": 266, "end": 270, "text": "[17,", "ref_id": "BIBREF16"}, {"start": 271, "end": 274, "text": "37,", "ref_id": "BIBREF36"}, {"start": 275, "end": 278, "text": "38,", "ref_id": "BIBREF37"}, {"start": 279, "end": 282, "text": "42]", "ref_id": "BIBREF41"}, {"start": 567, "end": 571, "text": "[49]", "ref_id": "BIBREF48"}, {"start": 808, "end": 811, "text": "[5]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": "Related Work"}, {"text": "We introduce some definitions and additional notation that we will use throughout the paper. We denote the vector concatenation operation by the symbol \u2295 and the inner product by \u00b7, \u00b7 . We define the rectifier activation function as:", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "[\u00b7] + := max(\u00b7, 0).", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "Quasi-Chained Rules. Let E, N and V be disjoint sets of entities, (labelled) nulls and variables, respectively. 2 Let R be the set of relation symbols. A term t is an element in E \u222a N \u222a V; an atom \u03b1 is an expression of the form R(t 1 , t 2 ), where R is a relation between the terms t 1 , [21] is an expression of the form:", "cite_spans": [{"start": 289, "end": 293, "text": "[21]", "ref_id": "BIBREF20"}], "ref_spans": [], "section": "Preliminaries"}, {"text": "where for all i :", "cite_spans": [], "ref_spans": [], "section": "Preliminaries"}, {"text": "The QC rules constitute a subset of Datalog rules. A database D is a finite set of facts, i.e., a set of atoms with terms in E. A knowledge base (KB) K consists of a pair (\u03a3, D) where \u03a3 is an ontology whose axioms are QC rules and D a database. It should be noted that no constraint is imposed on the number of available axioms in the ontology. The ontology could be minimal in the sense of only defining the relation symbols. However, any type of rule, whether it is the product of the ontological design or results from formalising a statistical regularity, should belong to the family of QC rules. The Gene Ontology [4] constitutes one notable example of an ontology that exhibits QC rules.", "cite_spans": [{"start": 619, "end": 622, "text": "[4]", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "Preliminaries"}, {"text": "Matrices. An orthogonal matrix is defined as a real square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors), i.e.,", "cite_spans": [], "ref_spans": [], "section": "Circular Permutation"}, {"text": "where I is the identity matrix. Orthogonal matrices preserve the vector inner product and, thus, they also preserve the Euclidean norms. Let 1 \u2264 i < n, we define the circular permutation matrix \u03a0 i to be the orthogonal n\u00d7n matrix that is associated with the following circular permutation of a n-dimensional vector x:", "cite_spans": [], "ref_spans": [], "section": "Circular Permutation"}, {"text": "where x i is the ith coordinate of x and i controls the number of n \u2212 i successive circular shifts.", "cite_spans": [], "ref_spans": [], "section": "Circular Permutation"}, {"text": "Hyperbolic Space. In this work, we exploit the Poincar\u00e9-ball model of the hyperbolic geometry. The Poincar\u00e9-ball model is the Riemannian manifold", "cite_spans": [], "ref_spans": [], "section": "Circular Permutation"}, {"text": "The Poincar\u00e9-ball model presents a group-like structure when it is equipped with the M\u00f6bius addition [40, 52] , defined by:", "cite_spans": [{"start": 101, "end": 105, "text": "[40,", "ref_id": "BIBREF39"}, {"start": 106, "end": 109, "text": "52]", "ref_id": "BIBREF51"}], "ref_spans": [], "section": "Circular Permutation"}, {"text": "The isometries of (B n , d p ) can be expressed as a composition of a left gyrotranslation with an orthogonal transformation restricted to B n , where the left gyrotranslation is defined as L u : v \u2192 u v [2, 40] . Therefore, circular permutations constitute zero-left gyrotranslation isometries of the Poincar\u00e9-ball model.", "cite_spans": [{"start": 204, "end": 207, "text": "[2,", "ref_id": "BIBREF1"}, {"start": 208, "end": 211, "text": "40]", "ref_id": "BIBREF39"}], "ref_spans": [], "section": "Circular Permutation"}, {"text": "The database of a KB consists of a set of facts in the form of R(subject, object). We will learn hyperbolic embeddings of entities and relations such that valid facts will have a lower implausibility score than the invalid ones. To learn such representations, we extend the work of Bordes et al. [10] by defining a translationbased model in the hyperbolic space; embedding, thus, both entities and relations in the same space. Let s, r, o \u2208 B n be the hyperbolic embeddings of the subject, relation and object, respectively, appearing in the R(subject, object) fact. We define a term embedding as a function \u03be : B n \u00d7B n \u2192 B n , that creates a composite vector representation for the pair (subject, object). Since our motivation is to generalise the translation models to the hyperbolic space, a natural way to define the term embeddings is by using the M\u00f6bius addition. However, we found out empirically that the normal addition in the Euclidean space generalises better than the M\u00f6bius addition. We provide a possible explanation for this behaviour in an ablation study presented in the Results & Analysis section. To introduce non-commutativity in the term composition function, we use a circular permutation matrix to project the object embeddings. Non-commutativity is important because it allows to model asymmetric relations with compositional representations [35] . Therefore, we define the term embedding as: s + \u03a0 \u03b2 o, where \u03b2 is a hyperparameter controlling the number of successive circular shifts. To enforce the term embeddings to stay in the Poincar\u00e9-ball, we constrain all the entity embeddings to have a Euclidean norm less than 0.5. Namely, e < 0.5 and r < 1.0 for all entity and relation vectors, respectively. It should be noted that the entities' norm constraints do not restrict term embeddings to span the Poincar\u00e9-ball. We define the implausibility score as the hyperbolic distance between the term and the relation embeddings. Specifically, the implausibility score of a fact is defined as: Figure 1 provides an illustration of the HyperKG model in P 2 . We follow previous work [10] to minimise the following hinge loss function:", "cite_spans": [{"start": 296, "end": 300, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 1367, "end": 1371, "text": "[35]", "ref_id": "BIBREF34"}, {"start": 2104, "end": 2108, "text": "[10]", "ref_id": "BIBREF9"}], "ref_spans": [{"start": 2016, "end": 2024, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "HyperKG"}, {"text": "where P is the training set consisting of valid facts, N is a set of corrupted facts.", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "To create the corrupted facts, we experimented with two strategies. We replaced randomly either the subject or the object of a valid fact with a random entity (but not both at the same time). We denote with # negsE the number of negative examples. Furthermore, we experimented with replacing randomly the relation while retaining intact the entities of a valid fact. We denote with # negsR the number of \"relation-corrupted\" negative examples. We employ the \"Bernoulli \" sampling method to generate incorrect facts [22, 57, 60] . As pointed out in different studies [10, 12, 26] , regularisation techniques are really beneficial for the task of KBC. Nonetheless, very few of the classical regularisation methods are directly applicable or easily generalisable in the Poincar\u00e9ball model of hyperbolic space. For instance, the 2 regularisation constraint imposes vectors to stay close to the origin, which can lead to underflows. The same holds for dropout [45] , when a rather large dropout rate was used. 3 In our experiments, we noticed a tendency of the word vectors to stay close to the origin. Imposing a constraint to the vectors to stay away from the origin stabilised the training procedure and increased the model's generalisation capability. It should be noted that as the points in the Poincar\u00e9-ball approach the ball's boundary their distance d p (u, v) approaches d p (u, 0) + d p (0, v), which is analogous to the fact that in a tree the shortest path between two siblings is the path through their parent [42] . Building on this observation, our regulariser further imposes this \"tree-like\" property. Additionally, since the volume in hyperbolic space grows exponentially, our regulariser implicitly penalises crowding. Let", "cite_spans": [{"start": 515, "end": 519, "text": "[22,", "ref_id": "BIBREF21"}, {"start": 520, "end": 523, "text": "57,", "ref_id": "BIBREF56"}, {"start": 524, "end": 527, "text": "60]", "ref_id": "BIBREF59"}, {"start": 566, "end": 570, "text": "[10,", "ref_id": "BIBREF9"}, {"start": 571, "end": 574, "text": "12,", "ref_id": "BIBREF11"}, {"start": 575, "end": 578, "text": "26]", "ref_id": "BIBREF25"}, {"start": 955, "end": 959, "text": "[45]", "ref_id": "BIBREF44"}, {"start": 1005, "end": 1006, "text": "3", "ref_id": "BIBREF2"}, {"start": 1519, "end": 1523, "text": "[42]", "ref_id": "BIBREF41"}], "ref_spans": [], "section": "HyperKG"}, {"text": "be the set of all entity and relation vectors, where |E|, |R| denote the cardinalities of the sets E, R, respectively. R(\u0398) defines our proposed regularisation loss function:", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "The overall embedding loss is now defined as L (\u0398) = L(\u0398) + \u03bbR(\u0398), where \u03bb is a hyperparameter controlling the regularisation effect. We define a i := 0.5, if \u03b8 i corresponds to an entity vector and a i := 1.0, otherwise. To minimise L (\u0398), we solve the following optimisation problem:", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "To solve Eq. (9), we follow Nickel and Kiela [37] and use Riemannian SGD (RSGD; [9] ). In RSGD, the parameter updates are of the form:", "cite_spans": [{"start": 45, "end": 49, "text": "[37]", "ref_id": "BIBREF36"}, {"start": 80, "end": 83, "text": "[9]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "HyperKG"}, {"text": "where R \u03b8t denotes the retraction onto the open d-dimensional unit ball at \u03b8 t and \u03b7 denotes the learning rate. The Riemannian gradient of L (\u03b8) is denoted by \u2207 R \u2208 T \u03b8 B. The Riemannian gradient can be computed as", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "where \u2207 E denotes the Euclidean gradient of L (\u03b8). Similarly to Nickel and Kiela [37] , we use the following retraction operation R \u03b8 (v) = \u03b8 + v.", "cite_spans": [{"start": 81, "end": 85, "text": "[37]", "ref_id": "BIBREF36"}], "ref_spans": [], "section": "HyperKG"}, {"text": "To constrain the embeddings to remain within the Poincar\u00e9 ball and respect the additional constraints, we use the following projection:", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "where \u03b5 is a small constant to ensure numerical stability. In all experiments we used \u03b5 = 10 \u22125 . Let a be the constraint imposed on vector \u03b8, the full update for a single embedding is then of the form:", "cite_spans": [], "ref_spans": [], "section": "HyperKG"}, {"text": "We initialise the embeddings using the Xavier initialization scheme [19] , where we use Eq. (10) for projecting the vectors whose norms violate the imposed constraints. Finally, it should be noted that the space complexity of HyperKG is the same as that of TransE and, based on our measurements, the running time of HyperKG is almost double compared to that of TransE [10] and ComplEx [51] .", "cite_spans": [{"start": 68, "end": 72, "text": "[19]", "ref_id": "BIBREF18"}, {"start": 368, "end": 372, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 385, "end": 389, "text": "[51]", "ref_id": "BIBREF50"}], "ref_spans": [], "section": "HyperKG"}, {"text": "In this section, we investigate the type of rules that HyperKG can model. Recently, Wang et al. [56] proved that the bilinear models are universal, i.e., they can represent every possible fact given that the dimensionality of the vectors is sufficient. The authors have also shown that the TransE model is not universal. In parallel, Kazemi and Poole [23] have shown that the FTransE model [16] , which is the most general translational model proposed in the literature, imposes some severe restrictions on the types of relations the translational models can represent. In the core of their proof lies the assumption that the implausibility score defined by the FTransE model approaches zero for all given valid facts. Nonetheless, this condition is less likely to be met from an optimisation perspective [59] . Additionally, Guti\u00e9rrez-Basulto and Schockaert [21] studied the types of regularities that KB embedding methods can capture. To allow for a formal characterisation, the authors considered hard thresholds \u03bb R such that a fact R(s, o) is considered valid iff s R (s, o) \u2264 \u03bb R , where s R (., .) is the implausibility score. It should be highlighted that KB embeddings are often learned based on a maximum-margin loss function, which ideally leads to hard-threshold separation. The vector space representation of a given relation R can then be viewed as a region n(R) in R 2n , defined as follows:", "cite_spans": [{"start": 96, "end": 100, "text": "[56]", "ref_id": "BIBREF55"}, {"start": 351, "end": 355, "text": "[23]", "ref_id": "BIBREF22"}, {"start": 390, "end": 394, "text": "[16]", "ref_id": "BIBREF15"}, {"start": 805, "end": 809, "text": "[59]", "ref_id": "BIBREF58"}, {"start": 859, "end": 863, "text": "[21]", "ref_id": "BIBREF20"}], "ref_spans": [], "section": "Convex Relation Spaces"}, {"text": "Based on this view of the relation space, the authors prove that although bilinear models are fully expressive, they impose constraints on the type of rules they can learn. Specifically, let R 1 (X, Y ) \u2192 S(X, Y ), R 2 (X, Y ) \u2192 S(X, Y ) be two valid rules. The bilinear models impose either that R 1 (X, Y ) \u2192 R 2 (X, Y ) or R 2 (X, Y ) \u2192 R 1 (X, Y ); introducing, thus, a number of restrictions on the type of subsumption hierarchies they can model. Guti\u00e9rrez-Basulto and Schockaert [21] , additionally, prove that there exists a KB embedding model with convex relation regions that can correctly represent knowledge bases whose axioms belong to the family of QC rules. Equivalently, any inductive reasoning made by the aforementioned KB embedding model would be logically consistent and deductively closed with respect to the ontological rules. It can be easily verified that the relation regions of TransE [10] are indeed convex. This result is in accordance with the results of Wang et al. [56] ; TransE is not fully expressive. However, it could be a prominent candidate for representing QC rules consistently. Nonetheless, this result seems to be in conflict with the results of Kazemi and Poole [23] . Let s T E R (s, o) be the implausibility score of TransE, we demystify this seeming inconsistency by proving the following lemma:", "cite_spans": [{"start": 485, "end": 489, "text": "[21]", "ref_id": "BIBREF20"}, {"start": 910, "end": 914, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 995, "end": 999, "text": "[56]", "ref_id": "BIBREF55"}, {"start": 1203, "end": 1207, "text": "[23]", "ref_id": "BIBREF22"}], "ref_spans": [], "section": "Convex Relation Spaces"}, {"text": "We prove Lemma 1 in the Supplemental Material, which is also provided in [24] , by constructing counterexamples for each one of the restrictions. Since the restrictions can be lifted for the TransE model, we can safely conclude that they are not, in general, valid for all its generalisations. In parallel, we built upon the formal characterisation of relations regions, defined in Eq. (12) and we prove that the relation regions captured by HyperKG are indeed convex. Specifically, we prove: ", "cite_spans": [{"start": 73, "end": 77, "text": "[24]", "ref_id": "BIBREF23"}, {"start": 386, "end": 390, "text": "(12)", "ref_id": "BIBREF11"}], "ref_spans": [], "section": "Lemma 1. The restrictions proved by Kazemi and Poole [23] do not apply to the TransE model when a fact is considered valid iff"}, {"text": ", where the ball's radius is guaranteed to be strictly greater than zero.", "cite_spans": [], "ref_spans": [], "section": "Lemma 1. The restrictions proved by Kazemi and Poole [23] do not apply to the TransE model when a fact is considered valid iff"}, {"text": "The proof of Proposition 1 can also be found in the Supplemental Material -also provided in [24] . By exploiting the triangle inequality, we can easily verify that the relation regions captured by HyperKG are indeed convex. Figure 1 provides an illustration of the geometric loci captured by HyperKG in B 2 . This result shows that HyperKG constitutes another one prominent embedding model for effectively representing QC rules.", "cite_spans": [{"start": 92, "end": 96, "text": "[24]", "ref_id": "BIBREF23"}], "ref_spans": [{"start": 224, "end": 232, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "Lemma 1. The restrictions proved by Kazemi and Poole [23] do not apply to the TransE model when a fact is considered valid iff"}, {"text": "We evaluate our HyperKG model on the task of KBC using two sets of experiments. We conduct experiments on the WN18RR [12] and FB15k-237 [50] datasets. We also construct two datasets whose statistical regularities can be expressed as QC rules to test our model's performance in their presence. WN18RR and FB15k-237 constitute refined subsets of WN18 and FB15K that were introduced by Bordes et al. [10] . Toutanova and Chen [50] identified that WN18 and FB15K contained a lot of reversible relations, enabling, thus, various KB embedding models to generalise easily. Exploiting this fact, Dettmers et al. [12] obtained state-of-the-art results only by using a simple reversal rule. WN18RR and FB15k-237 were carefully created to alleviate this leakage of information.", "cite_spans": [{"start": 117, "end": 121, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 136, "end": 140, "text": "[50]", "ref_id": "BIBREF49"}, {"start": 397, "end": 401, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 423, "end": 427, "text": "[50]", "ref_id": "BIBREF49"}, {"start": 604, "end": 608, "text": "[12]", "ref_id": "BIBREF11"}], "ref_spans": [], "section": "Experiments"}, {"text": "To test whether the scale-free distribution provides a reasonable means for modelling topological properties of knowledge graphs, we investigate the degree distributions of WN18RR and FB15k-237. Similarly to Steyvers and Tenenbaum [46] , we treat the knowledge graphs as undirected networks. We also compare against the distribution of the frequency of word usage in the English language; a phenomenon that is known to follow a power-law distribution [63] . To do so, we used the frequency of word usage in Herman Melville's novel \"Moby Dick\" [32] . We followed the procedure described by Alstott et al. [3] . In Fig. 2 , we show our analysis where we demonstrate on a histogram with log-log axes the probability density function with regard to the observed property for each dataset, including the fitted power-law distribution. It can be seen that the power-law distribution provides a reasonable means for also describing the degree distribution of KBs; justifying the work of Steyvers and Tenenbaum [46] . The fluctuations in the cases of WN18RR and FB15k-237 could be explained by the fact that the datasets are subsets of more complete KBs; a fact that introduces noise which in turn can explain deviations from the perfection of a theoretical distribution [3] .", "cite_spans": [{"start": 231, "end": 235, "text": "[46]", "ref_id": "BIBREF45"}, {"start": 451, "end": 455, "text": "[63]", "ref_id": "BIBREF62"}, {"start": 543, "end": 547, "text": "[32]", "ref_id": "BIBREF31"}, {"start": 604, "end": 607, "text": "[3]", "ref_id": "BIBREF2"}, {"start": 1003, "end": 1007, "text": "[46]", "ref_id": "BIBREF45"}, {"start": 1263, "end": 1266, "text": "[3]", "ref_id": "BIBREF2"}], "ref_spans": [{"start": 613, "end": 619, "text": "Fig. 2", "ref_id": "FIGREF2"}], "section": "Experiments"}, {"text": "To test our model's performance on capturing QC rules, we extract from Wikidata [14, 54] two subsets of facts that satisfy the following rules:", "cite_spans": [{"start": 80, "end": 84, "text": "[14,", "ref_id": "BIBREF13"}, {"start": 85, "end": 88, "text": "54]", "ref_id": "BIBREF53"}], "ref_spans": [], "section": "Datasets"}, {"text": "The relations is a, part of correspond to the subsumption and the mereology relation, respectively, which are two of the most common relations encountered in KBs [43] . Recent studies have noted that many real world KB relations have very few facts [61] , raising the importance of generalising with limited number of facts. To test our model in the presence of sparse long-tail relations, we kept the created datasets sufficiently small. For each type of the aforementioned rules, we extract 200 facts that satisfy them from Wikidata. We construct two datasets that we dub WD and WD ++ . The dataset WD contains only the facts that satisfy rule (a). WD ++ extends WD by also including the facts satisfying rule (b). The evaluation protocol was the following: For every dataset, we split all the facts randomly in train (80%), validation (10%), and test (10%) set, such that the validation and test sets only contain a subset of the rules' consequents in the form of part of (X, Z). Table 1 provides details regarding the respective size of each dataset. ", "cite_spans": [{"start": 162, "end": 166, "text": "[43]", "ref_id": "BIBREF42"}, {"start": 249, "end": 253, "text": "[61]", "ref_id": "BIBREF60"}], "ref_spans": [{"start": 983, "end": 990, "text": "Table 1", "ref_id": "TABREF0"}], "section": "Datasets"}, {"text": "In the KBC task the models are evaluated based on their capability to answer queries such as R(subject, ?) and R(?, object) [10] ; predicting, thus, the missing entity. Specifically, all the possible corruptions are obtained by replacing either the subject or the object and the entities are ranked based on the values of the implausibility score. The models should assign lower implausibility scores to valid facts and higher scores to implausible ones. We use the \"Filtered\" setting protocol [10] , i.e., not taking any corrupted facts that exist in KB into account. We employ three common evaluation metrics: mean rank (MR), mean reciprocal rank (MRR), and Hits@10 (i.e., the proportion of the valid/test triples ranking in top 10 predictions). Higher MRR or higher Hits@10 indicate better performance. On the contrary, lower MR indicates better performance. The reported results are given for the best set of hyperparameters evaluated on the validation set using grid search. Varying the batch size had no effect on the performance. Therefore, we divided every epoch into Table 2 compares the experimental results of our HyperKG model with previous published results on WN18RR and FB15k-237 datasets. We have experimentally validated that both datasets present power-law degree distributions. Additionally, WN18RR contains more hierarchical-like relations compared to FB15k-237 [5] . We compare against the shallow KB embedding models DISTMULT [62] , Com-plEx [51] and TransE [10] , which constitute important representatives of bilinear and translational models. We exclude from our comparison recent work that explores different types of training regimes such as adversarial training, the inclusion of reciprocal facts and/or multiple geometrical spaces [5, 11, 23, 26, 48] to make the analysis less biased to factors that could overshadow the importance of the embedding space. We give the results of our algorithm under the HyperKG listing. When we compare the performance of HyperKG and TransE on WN18RR, we see that HyperKG achieves almost the double MRR score. This shows that the lower MRR performance on certain datasets is not an intrinsic characteristic of the translational models, but a restriction that can be lifted by the right choice of geometrical space. On the WN18RR dataset, HyperKG exhibits slightly lower Hits@10 performance compared to ComplEx. Moreover, HyperKG achieves a better MR score compared to the bilinear models on WN18RR, but worse compared to TransE. On the FB15k-237 dataset, HyperKG and TransE demonstrate almost the same behaviour outperforming DISTMULT and ComplEx in terms of MRR and Hits@10. Since this performance gap is small, we hypothesise that this is due to a less fine-grained hyperparameter tuning. Interestingly, HyperKG achieves a better MR score compared to TransE on FB15k-237, but, still, worse compared to DISTMULT. We also report in Table 2 two additional experiments where we explore the performance boost that our regularisation scheme brings as well as the behaviour of HyperKG when the M\u00f6bius addition is used instead of the Euclidean one. In the experiment where the M\u00f6bius addition was used, we removed the constraint for the entity vectors to have a norm less than 0.5. Although the M\u00f6bius addition is non-commutative, we found beneficial to keep the permutation matrix. Nonetheless, we do not use our regularisation scheme. Therefore, the implausibility score is d p (s \u03a0 \u03b2 o, r) . To investigate the effect of our proposed regularisation scheme, we show results where our regularisation scheme, defined in Eq. 8, is not used, keeping, however, the rest of the architecture the same. Comparing the performance of the HyperKG variation using the M\u00f6bius addition against the performance of the HyperKG without regularisation, we can observe that we can achieve better results in terms of MRR and Hits@10 by using the Euclidean addition. This can be explained as follows. Generally, there is no unique and universal geometrical space adequate for every dataset [20] . To recover Euclidean Space from the Poincar\u00e9-ball model equipped with the M\u00f6bius addition, the ball's radius should grow to infinity [52] . Instead, by using the Euclidean addition and since the hyperbolic metric is locally Euclidean, HyperKG can model facts for which the Euclidean Space is more appropriate by learning to retain small distances. Last but not least, we can observe that our proposed regularisation scheme is beneficial in terms of MR, MRR and Hits@10 on both datasets. Overall, the hyperbolic space appears more beneficial for datasets that contain many hierarchical-like relations such as WN18RR, without a significant performance degradation in the other case. Table 3 reports the results on the WD and WD ++ datasets. We compare HyperKG performance against that of TransE and ComplEx. It can be observed that none of the models manages to totally capture the statistical regularities of these datasets. All the models undergo similar Hits@10 performance on both datasets. HyperKG and TransE, that both have convex relation spaces, outperform ComplEx on both datasets in terms of MRR and Hits@10. Furthermore, the translational models show a relatively steady performance compared to Com-plEx, whose performance deteriorates in the presence of the two rules appearing in WD ++ . With regard to MR, HyperKG closes the gap between translational and bilinear models on WD and shows the best performance on WD ++ . Our results point to a promising direction for developing less expressive KB embedding models which can, however, better represent certain types of rules. ", "cite_spans": [{"start": 124, "end": 128, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 494, "end": 498, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 1382, "end": 1385, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 1448, "end": 1452, "text": "[62]", "ref_id": "BIBREF61"}, {"start": 1464, "end": 1468, "text": "[51]", "ref_id": "BIBREF50"}, {"start": 1480, "end": 1484, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 1760, "end": 1763, "text": "[5,", "ref_id": "BIBREF4"}, {"start": 1764, "end": 1767, "text": "11,", "ref_id": "BIBREF10"}, {"start": 1768, "end": 1771, "text": "23,", "ref_id": "BIBREF22"}, {"start": 1772, "end": 1775, "text": "26,", "ref_id": "BIBREF25"}, {"start": 1776, "end": 1779, "text": "48]", "ref_id": "BIBREF47"}, {"start": 4027, "end": 4031, "text": "[20]", "ref_id": "BIBREF19"}, {"start": 4167, "end": 4171, "text": "[52]", "ref_id": "BIBREF51"}], "ref_spans": [{"start": 1076, "end": 1083, "text": "Table 2", "ref_id": "TABREF1"}, {"start": 2894, "end": 2901, "text": "Table 2", "ref_id": "TABREF1"}, {"start": 3436, "end": 3448, "text": "(s \u03a0 \u03b2 o, r)", "ref_id": null}, {"start": 4715, "end": 4722, "text": "Table 3", "ref_id": "TABREF2"}], "section": "Evaluation Protocol and Implementation Details"}, {"text": "In this paper, we examined the importance of the geometrical space for the task of KBC. We showed that the lagging performance of translational models compared to the bilinear ones is not an intrinsic characteristic of them but a restriction that can be lifted in the hyperbolic space. Our results validated that the right choice of geometrical space is a critical decision that impacts the performance of KB embedding models. Our findings also shed light on understanding which KBs mostly benefit from the use of hyperbolic embeddings. Moreover, we demonstrated a new promising direction for developing models that, although not fully expressive, allow to better represent certain families of rules; opening up for more fine-grained reasoning tasks. In the future, we plan to extend our approach to the bilinear family of models.", "cite_spans": [], "ref_spans": [], "section": "Conclusion and Outlook"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Foundations of Databases: The Logical Level", "authors": [{"first": "S", "middle": [], "last": "Abiteboul", "suffix": ""}, {"first": "R", "middle": [], "last": "Hull", "suffix": ""}, {"first": "V", "middle": [], "last": "Vianu", "suffix": ""}], "year": 1995, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Invariant operators and integral representations in hyperbolic space", "authors": [{"first": "L", "middle": ["V"], "last": "Ahlfors", "suffix": ""}], "year": 1975, "venue": "Math. Scand", "volume": "36", "issn": "1", "pages": "27--43", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "powerlaw: a Python package for analysis of heavytailed distributions", "authors": [{"first": "J", "middle": [], "last": "Alstott", "suffix": ""}, {"first": "E", "middle": [], "last": "Bullmore", "suffix": ""}, {"first": "D", "middle": [], "last": "Plenz", "suffix": ""}], "year": 2014, "venue": "PloS One", "volume": "9", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Gene ontology: tool for the unification of biology", "authors": [{"first": "M", "middle": [], "last": "Ashburner", "suffix": ""}], "year": 2000, "venue": "Nat. Genet", "volume": "25", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Multi-relational Poincar\u00e9 graph embeddings", "authors": [{"first": "I", "middle": [], "last": "Bala\u017eevi\u0107", "suffix": ""}, {"first": "C", "middle": [], "last": "Allen", "suffix": ""}, {"first": "T", "middle": [], "last": "Hospedales", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Emergence of scaling in random networks", "authors": [{"first": "A", "middle": ["L"], "last": "Barab\u00e1si", "suffix": ""}, {"first": "R", "middle": [], "last": "Albert", "suffix": ""}], "year": 1999, "venue": "Science", "volume": "286", "issn": "5439", "pages": "509--512", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Sustaining the internet with hyperbolic mapping", "authors": [{"first": "M", "middle": [], "last": "Bogun\u00e1", "suffix": ""}, {"first": "F", "middle": [], "last": "Papadopoulos", "suffix": ""}, {"first": "D", "middle": [], "last": "Krioukov", "suffix": ""}], "year": 2010, "venue": "Nat. Commun", "volume": "1", "issn": "", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Freebase: a collaboratively created graph database for structuring human knowledge", "authors": [{"first": "K", "middle": [], "last": "Bollacker", "suffix": ""}, {"first": "C", "middle": [], "last": "Evans", "suffix": ""}, {"first": "P", "middle": [], "last": "Paritosh", "suffix": ""}, {"first": "T", "middle": [], "last": "Sturge", "suffix": ""}, {"first": "J", "middle": [], "last": "Taylor", "suffix": ""}], "year": 2008, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Stochastic gradient descent on Riemannian manifolds", "authors": [{"first": "S", "middle": [], "last": "Bonnabel", "suffix": ""}], "year": 2013, "venue": "IEEE Trans. Automat. Contr", "volume": "58", "issn": "9", "pages": "2217--2229", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Translating embeddings for modeling multi-relational data", "authors": [{"first": "A", "middle": [], "last": "Bordes", "suffix": ""}, {"first": "N", "middle": [], "last": "Usunier", "suffix": ""}, {"first": "A", "middle": [], "last": "Garcia-Duran", "suffix": ""}, {"first": "J", "middle": [], "last": "Weston", "suffix": ""}, {"first": "O", "middle": [], "last": "Yakhnenko", "suffix": ""}], "year": 2013, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "KBGAN: adversarial learning for knowledge graph embeddings", "authors": [{"first": "L", "middle": [], "last": "Cai", "suffix": ""}, {"first": "W", "middle": ["Y"], "last": "Wang", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Convolutional 2D knowledge graph embeddings", "authors": [{"first": "T", "middle": [], "last": "Dettmers", "suffix": ""}, {"first": "P", "middle": [], "last": "Minervini", "suffix": ""}, {"first": "P", "middle": [], "last": "Stenetorp", "suffix": ""}, {"first": "S", "middle": [], "last": "Riedel", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "TorusE: knowledge graph embedding on a lie group", "authors": [{"first": "T", "middle": [], "last": "Ebisu", "suffix": ""}, {"first": "R", "middle": [], "last": "Ichise", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Introducing Wikidata to the linked data web", "authors": [{"first": "F", "middle": [], "last": "Erxleben", "suffix": ""}, {"first": "M", "middle": [], "last": "G\u00fcnther", "suffix": ""}, {"first": "M", "middle": [], "last": "Kr\u00f6tzsch", "suffix": ""}, {"first": "J", "middle": [], "last": "Mendez", "suffix": ""}, {"first": "D", "middle": [], "last": "Vrande\u010di\u0107", "suffix": ""}], "year": 2014, "venue": "ISWC 2014", "volume": "8796", "issn": "", "pages": "50--65", "other_ids": {"DOI": ["10.1007/978-3-319-11964-9_4"]}}, "BIBREF14": {"ref_id": "b14", "title": "On power-law relationships of the internet topology", "authors": [{"first": "M", "middle": [], "last": "Faloutsos", "suffix": ""}, {"first": "P", "middle": [], "last": "Faloutsos", "suffix": ""}, {"first": "C", "middle": [], "last": "Faloutsos", "suffix": ""}], "year": 1999, "venue": "ACM SIGCOMM Comput. Commun. Rev", "volume": "29", "issn": "", "pages": "251--262", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Knowledge graph embedding by flexible translation", "authors": [{"first": "J", "middle": [], "last": "Feng", "suffix": ""}, {"first": "M", "middle": [], "last": "Huang", "suffix": ""}, {"first": "M", "middle": [], "last": "Wang", "suffix": ""}, {"first": "M", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Y", "middle": [], "last": "Hao", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Hyperbolic entailment cones for learning hierarchical embeddings", "authors": [{"first": "O", "middle": [], "last": "Ganea", "suffix": ""}, {"first": "G", "middle": [], "last": "Becigneul", "suffix": ""}, {"first": "T", "middle": [], "last": "Hofmann", "suffix": ""}], "year": 2018, "venue": "ICML", "volume": "", "issn": "", "pages": "1646--1655", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Introduction to Statistical Relational Learning", "authors": [{"first": "L", "middle": [], "last": "Getoor", "suffix": ""}, {"first": "B", "middle": [], "last": "Taskar", "suffix": ""}], "year": 2007, "venue": "", "volume": "1", "issn": "", "pages": "", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "Understanding the difficulty of training deep feedforward neural networks", "authors": [{"first": "X", "middle": [], "last": "Glorot", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2010, "venue": "", "volume": "", "issn": "", "pages": "249--256", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Learning mixed-curvature representations in product spaces", "authors": [{"first": "A", "middle": [], "last": "Gu", "suffix": ""}, {"first": "F", "middle": [], "last": "Sala", "suffix": ""}, {"first": "B", "middle": [], "last": "Gunel", "suffix": ""}, {"first": "C", "middle": [], "last": "R\u00e9", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules", "authors": [{"first": "V", "middle": [], "last": "Guti\u00e9rrez-Basulto", "suffix": ""}, {"first": "S", "middle": [], "last": "Schockaert", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Knowledge graph embedding via dynamic mapping matrix", "authors": [{"first": "G", "middle": [], "last": "Ji", "suffix": ""}, {"first": "S", "middle": [], "last": "He", "suffix": ""}, {"first": "L", "middle": [], "last": "Xu", "suffix": ""}, {"first": "K", "middle": [], "last": "Liu", "suffix": ""}, {"first": "J", "middle": [], "last": "Zhao", "suffix": ""}], "year": 2015, "venue": "ACL-IJCNLP", "volume": "", "issn": "", "pages": "687--696", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Simple embedding for link prediction in knowledge graphs", "authors": [{"first": "S", "middle": ["M"], "last": "Kazemi", "suffix": ""}, {"first": "D", "middle": [], "last": "Poole", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "4284--4295", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "HyperKG: hyperbolic knowledge graph embeddings for knowledge base completion", "authors": [{"first": "P", "middle": [], "last": "Kolyvakis", "suffix": ""}, {"first": "A", "middle": [], "last": "Kalousis", "suffix": ""}, {"first": "D", "middle": [], "last": "Kiritsis", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1908.04895"]}}, "BIBREF24": {"ref_id": "b24", "title": "Hyperbolic geometry of complex networks", "authors": [{"first": "D", "middle": [], "last": "Krioukov", "suffix": ""}, {"first": "F", "middle": [], "last": "Papadopoulos", "suffix": ""}, {"first": "M", "middle": [], "last": "Kitsak", "suffix": ""}, {"first": "A", "middle": [], "last": "Vahdat", "suffix": ""}, {"first": "M", "middle": [], "last": "Bogu\u00f1\u00e1", "suffix": ""}], "year": 2010, "venue": "Phys. Rev. E", "volume": "82", "issn": "", "pages": "", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Canonical tensor decomposition for knowledge base completion", "authors": [{"first": "T", "middle": [], "last": "Lacroix", "suffix": ""}, {"first": "N", "middle": [], "last": "Usunier", "suffix": ""}, {"first": "G", "middle": [], "last": "Obozinski", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "DBpedia-a large-scale, multilingual knowledge base extracted from Wikipedia", "authors": [{"first": "J", "middle": [], "last": "Lehmann", "suffix": ""}], "year": 2015, "venue": "Semant. Web", "volume": "6", "issn": "2", "pages": "167--195", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Hierarchy-based link prediction in knowledge graphs", "authors": [{"first": "M", "middle": [], "last": "Li", "suffix": ""}, {"first": "Y", "middle": [], "last": "Jia", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wang", "suffix": ""}, {"first": "J", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Cheng", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1145/2872518.2889387"]}}, "BIBREF28": {"ref_id": "b28", "title": "WordNet: An Electronic Lexical Database", "authors": [{"first": "G", "middle": [], "last": "Miller", "suffix": ""}], "year": 1998, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Vector-based models of semantic composition", "authors": [{"first": "J", "middle": [], "last": "Mitchell", "suffix": ""}, {"first": "M", "middle": [], "last": "Lapata", "suffix": ""}], "year": 2008, "venue": "Proceedings of ACL-08: HLT", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "Inductive logic programming: theory and methods", "authors": [{"first": "S", "middle": [], "last": "Muggleton", "suffix": ""}, {"first": "L", "middle": [], "last": "De Raedt", "suffix": ""}], "year": 1994, "venue": "J. Log. Program", "volume": "19", "issn": "", "pages": "629--679", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Power laws, Pareto distributions and Zipf's law", "authors": [{"first": "M", "middle": ["E"], "last": "Newman", "suffix": ""}], "year": 2005, "venue": "Contemp. Phys", "volume": "46", "issn": "5", "pages": "323--351", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "A novel embedding model for knowledge base completion based on convolutional neural network", "authors": [{"first": "D", "middle": ["Q"], "last": "Nguyen", "suffix": ""}, {"first": "T", "middle": ["D"], "last": "Nguyen", "suffix": ""}, {"first": "D", "middle": ["Q"], "last": "Nguyen", "suffix": ""}, {"first": "D", "middle": [], "last": "Phung", "suffix": ""}], "year": 2018, "venue": "In: NAACL", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "A review of relational machine learning for knowledge graphs", "authors": [{"first": "M", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "K", "middle": [], "last": "Murphy", "suffix": ""}, {"first": "V", "middle": [], "last": "Tresp", "suffix": ""}, {"first": "E", "middle": [], "last": "Gabrilovich", "suffix": ""}], "year": 2016, "venue": "Proc. IEEE", "volume": "104", "issn": "1", "pages": "11--33", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Holographic embeddings of knowledge graphs", "authors": [{"first": "M", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "L", "middle": [], "last": "Rosasco", "suffix": ""}, {"first": "T", "middle": [], "last": "Poggio", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "A three-way model for collective learning on multi-relational data", "authors": [{"first": "M", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "V", "middle": [], "last": "Tresp", "suffix": ""}, {"first": "H", "middle": ["P"], "last": "Kriegel", "suffix": ""}], "year": 2011, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Poincar\u00e9 embeddings for learning hierarchical representations", "authors": [{"first": "M", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "D", "middle": [], "last": "Kiela", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Learning continuous hierarchies in the Lorentz model of hyperbolic geometry", "authors": [{"first": "M", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "D", "middle": [], "last": "Kiela", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Network geometry inference using common neighbors", "authors": [{"first": "F", "middle": [], "last": "Papadopoulos", "suffix": ""}, {"first": "R", "middle": [], "last": "Aldecoa", "suffix": ""}, {"first": "D", "middle": [], "last": "Krioukov", "suffix": ""}], "year": 2015, "venue": "Phys. Rev. E", "volume": "92", "issn": "2", "pages": "", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "An inequality related to M\u00f6bius transformations", "authors": [{"first": "T", "middle": ["M"], "last": "Rassias", "suffix": ""}, {"first": "T", "middle": [], "last": "Suksumran", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1902.05003"]}}, "BIBREF40": {"ref_id": "b40", "title": "Markov logic networks", "authors": [{"first": "M", "middle": [], "last": "Richardson", "suffix": ""}, {"first": "P", "middle": [], "last": "Domingos", "suffix": ""}], "year": 2006, "venue": "Mach. Learn", "volume": "62", "issn": "1-2", "pages": "107--136", "other_ids": {"DOI": ["10.1007/s10994-006-5833-1"]}}, "BIBREF41": {"ref_id": "b41", "title": "Representation tradeoffs for hyperbolic embeddings", "authors": [{"first": "F", "middle": [], "last": "Sala", "suffix": ""}, {"first": "C", "middle": [], "last": "De Sa", "suffix": ""}, {"first": "A", "middle": [], "last": "Gu", "suffix": ""}, {"first": "C", "middle": [], "last": "Re", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF42": {"ref_id": "b42", "title": "Ontological relations", "authors": [{"first": "U", "middle": [], "last": "Schwarz", "suffix": ""}, {"first": "B", "middle": [], "last": "Smith", "suffix": ""}], "year": 2008, "venue": "Appl. Ontol. Introduction", "volume": "219", "issn": "", "pages": "", "other_ids": {}}, "BIBREF43": {"ref_id": "b43", "title": "Reasoning with neural tensor networks for knowledge base completion", "authors": [{"first": "R", "middle": [], "last": "Socher", "suffix": ""}, {"first": "D", "middle": [], "last": "Chen", "suffix": ""}, {"first": "C", "middle": ["D"], "last": "Manning", "suffix": ""}, {"first": "A", "middle": [], "last": "Ng", "suffix": ""}], "year": 2013, "venue": "NeurIPS", "volume": "", "issn": "", "pages": "926--934", "other_ids": {}}, "BIBREF44": {"ref_id": "b44", "title": "Dropout: a simple way to prevent neural networks from overfitting", "authors": [{"first": "N", "middle": [], "last": "Srivastava", "suffix": ""}, {"first": "G", "middle": [], "last": "Hinton", "suffix": ""}, {"first": "A", "middle": [], "last": "Krizhevsky", "suffix": ""}, {"first": "I", "middle": [], "last": "Sutskever", "suffix": ""}, {"first": "R", "middle": [], "last": "Salakhutdinov", "suffix": ""}], "year": 2014, "venue": "J. Mach. Learn. Res", "volume": "15", "issn": "", "pages": "1929--1958", "other_ids": {}}, "BIBREF45": {"ref_id": "b45", "title": "The large-scale structure of semantic networks: statistical analyses and a model of semantic growth", "authors": [{"first": "M", "middle": [], "last": "Steyvers", "suffix": ""}, {"first": "J", "middle": ["B"], "last": "Tenenbaum", "suffix": ""}], "year": 2005, "venue": "Cogn. Sci", "volume": "29", "issn": "1", "pages": "41--78", "other_ids": {}}, "BIBREF46": {"ref_id": "b46", "title": "Yago: a core of semantic knowledge", "authors": [{"first": "F", "middle": ["M"], "last": "Suchanek", "suffix": ""}, {"first": "G", "middle": [], "last": "Kasneci", "suffix": ""}, {"first": "G", "middle": [], "last": "Weikum", "suffix": ""}], "year": 2007, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF47": {"ref_id": "b47", "title": "Rotate: knowledge graph embedding by relational rotation in complex space", "authors": [{"first": "Z", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Z", "middle": ["H"], "last": "Deng", "suffix": ""}, {"first": "J", "middle": ["Y"], "last": "Nie", "suffix": ""}, {"first": "J", "middle": [], "last": "Tang", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF48": {"ref_id": "b48", "title": "Riemannian TransE: multi-relational graph embedding in non-euclidean space", "authors": [{"first": "A", "middle": [], "last": "Suzuki", "suffix": ""}, {"first": "Y", "middle": [], "last": "Enokida", "suffix": ""}, {"first": "K", "middle": [], "last": "Yamanishi", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF49": {"ref_id": "b49", "title": "Observed versus latent features for knowledge base and text inference", "authors": [{"first": "K", "middle": [], "last": "Toutanova", "suffix": ""}, {"first": "D", "middle": [], "last": "Chen", "suffix": ""}], "year": 2015, "venue": "Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF50": {"ref_id": "b50", "title": "Complex embeddings for simple link prediction", "authors": [{"first": "T", "middle": [], "last": "Trouillon", "suffix": ""}, {"first": "J", "middle": [], "last": "Welbl", "suffix": ""}, {"first": "S", "middle": [], "last": "Riedel", "suffix": ""}, {"first": "\u00c9", "middle": [], "last": "Gaussier", "suffix": ""}, {"first": "G", "middle": [], "last": "Bouchard", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF51": {"ref_id": "b51", "title": "Beyond the Einstein Addition Law and its Gyroscopic Thomas Precession: The Theory of Gyrogroups and Gyrovector Spaces", "authors": [{"first": "A", "middle": ["A"], "last": "Ungar", "suffix": ""}], "year": 2012, "venue": "Fundamental Theories of Physics", "volume": "117", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1007/0-306-47134-5"]}}, "BIBREF52": {"ref_id": "b52", "title": "Random graphs and complex networks", "authors": [{"first": "R", "middle": [], "last": "Van Der Hofstad", "suffix": ""}], "year": 2009, "venue": "", "volume": "11", "issn": "", "pages": "", "other_ids": {}}, "BIBREF53": {"ref_id": "b53", "title": "Wikidata: a free collaborative knowledgebase", "authors": [{"first": "D", "middle": [], "last": "Vrande\u010di\u0107", "suffix": ""}, {"first": "M", "middle": [], "last": "Kr\u00f6tzsch", "suffix": ""}], "year": 2014, "venue": "Commun. ACM", "volume": "57", "issn": "10", "pages": "78--85", "other_ids": {"DOI": ["10.1145/2629489"]}}, "BIBREF54": {"ref_id": "b54", "title": "Knowledge graph embedding: a survey of approaches and applications", "authors": [{"first": "Q", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Mao", "suffix": ""}, {"first": "B", "middle": [], "last": "Wang", "suffix": ""}, {"first": "L", "middle": [], "last": "Guo", "suffix": ""}], "year": 2017, "venue": "IEEE Trans. Knowl. Data Eng", "volume": "29", "issn": "12", "pages": "2724--2743", "other_ids": {}}, "BIBREF55": {"ref_id": "b55", "title": "On multi-relational link prediction with bilinear models", "authors": [{"first": "Y", "middle": [], "last": "Wang", "suffix": ""}, {"first": "R", "middle": [], "last": "Gemulla", "suffix": ""}, {"first": "H", "middle": [], "last": "Li", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF56": {"ref_id": "b56", "title": "Knowledge graph embedding by translating on hyperplanes", "authors": [{"first": "Z", "middle": [], "last": "Wang", "suffix": ""}, {"first": "J", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "J", "middle": [], "last": "Feng", "suffix": ""}, {"first": "Z", "middle": [], "last": "Chen", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF57": {"ref_id": "b57", "title": "Knowledge base completion via search-based question answering", "authors": [{"first": "R", "middle": [], "last": "West", "suffix": ""}, {"first": "E", "middle": [], "last": "Gabrilovich", "suffix": ""}, {"first": "K", "middle": [], "last": "Murphy", "suffix": ""}, {"first": "S", "middle": [], "last": "Sun", "suffix": ""}, {"first": "R", "middle": [], "last": "Gupta", "suffix": ""}, {"first": "D", "middle": [], "last": "Lin", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF58": {"ref_id": "b58", "title": "From one point to a manifold: knowledge graph embedding for precise link prediction", "authors": [{"first": "H", "middle": [], "last": "Xiao", "suffix": ""}, {"first": "M", "middle": [], "last": "Huang", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF59": {"ref_id": "b59", "title": "An interpretable knowledge transfer model for knowledge base completion", "authors": [{"first": "Q", "middle": [], "last": "Xie", "suffix": ""}, {"first": "X", "middle": [], "last": "Ma", "suffix": ""}, {"first": "Z", "middle": [], "last": "Dai", "suffix": ""}, {"first": "E", "middle": [], "last": "Hovy", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF60": {"ref_id": "b60", "title": "One-shot relational learning for knowledge graphs", "authors": [{"first": "W", "middle": [], "last": "Xiong", "suffix": ""}, {"first": "M", "middle": [], "last": "Yu", "suffix": ""}, {"first": "S", "middle": [], "last": "Chang", "suffix": ""}, {"first": "X", "middle": [], "last": "Guo", "suffix": ""}, {"first": "W", "middle": ["Y"], "last": "Wang", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF61": {"ref_id": "b61", "title": "Embedding entities and relations for learning and inference in knowledge bases", "authors": [{"first": "B", "middle": [], "last": "Yang", "suffix": ""}, {"first": "W", "middle": ["T"], "last": "Yih", "suffix": ""}, {"first": "X", "middle": [], "last": "He", "suffix": ""}, {"first": "J", "middle": [], "last": "Gao", "suffix": ""}, {"first": "L", "middle": [], "last": "Deng", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF62": {"ref_id": "b62", "title": "Human Behaviour and the Principle of Least Effort", "authors": [{"first": "G", "middle": ["K"], "last": "Zipf", "suffix": ""}], "year": 1949, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "A visualisation of HyperKG model in the P 2 space. The geodesics of the disk model are circles perpendicular to its boundary. The zero-curvature geodesic passing from the origin corresponds to the line : y \u2212 x = 0 in the Euclidean plane. Reflections over the line are equivalent to \u03a01 permutations in the plane. s, \u03a01o, s + \u03a01o are the subject vector, the permuted object vector and the composite term vector, respectively. g(r1), g(r2) denote the geometric loci of term vectors satisfying relations R1, R2, with relation vectors r1, r2. t1, t2, t3 are valid term vectors for the relation R2.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "The geometric locus of the term vectors, in the form of s+\u03a0 \u03b2 o, that satisfy the equation d p (s + \u03a0 \u03b2 o, r) \u2264 \u03bb R for some \u03bb R > 0 corresponds to a d-dimensional closed ball in the Euclidean space. Let \u03c1 = cosh(\u03bbR)\u22121 2 (1 \u2212 r 2 ), the geometric locus can be written as s", "latex": null, "type": "figure"}, "FIGREF2": {"text": "A visualisation of the probability density functions using a histogram with log-log axes.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "10 mini-batches. The hyperparameter search space was the following: # negsE \u2208 {1, 2, 3, 4, 5, 8, 10, 12, 15}, # negsR \u2208 {0, 1, 2}, \u03b7 \u2208 {0.8, 0.5, 0.2, 0.1, 0.05, 0.01, 0.005}, \u03b2 \u2208 { 3n 4 , n 2 , n 4 , 0}, \u03b3 \u2208 {7.0, 5.0, 2.0, 1.5, 1.0, 0.8, 0.5, 0.2, 0.1}, the embeddings' dimension n \u2208 {40, 100, 200}, and \u03bb \u2208 {2.0, 0}. We used early stopping based on the validation's set filtered MRR performance, computed every 50 epochs with a maximum number of 2000 epochs. Due to space limitation, we report the best hyper-parameters in the Supplemental Material provided in[24].", "latex": null, "type": "figure"}, "TABREF0": {"text": "Statistics of the experimental datasets.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Dataset </td><td>| E | </td><td>| R | </td><td>#Train </td><td>#Valid </td><td>#Test\n</td></tr><tr><td>WN18RR </td><td>40,943 </td><td>11 </td><td>86,835 </td><td>3,034 </td><td>3,134\n</td></tr><tr><td>FB15k-237 </td><td>14,541 </td><td>237 </td><td>272,115 </td><td>17,535 </td><td>20,466\n</td></tr><tr><td>WD </td><td>418 </td><td>2 </td><td>550 </td><td>25 </td><td>25\n</td></tr><tr><td>WD++ </td><td>763 </td><td>2 </td><td>1,120 </td><td>40 </td><td>40\n</td></tr></table></body></html>"}, "TABREF1": {"text": "Experimental results on WN18RR and FB15k-237 test sets. [ ]: Results are taken from Nguyen et al.[33].", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Method </td><td>Type </td><td>\u00a0</td><td>WN18RR </td><td>\u00a0</td><td>FB15k-237\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>MR </td><td>MRR </td><td>Hits@10 </td><td>MR </td><td>MRR </td><td>Hits@10\n</td></tr><tr><td>DISTMULT [62] [] </td><td>Bilinear </td><td>5110 </td><td>0.43 </td><td>0.49 </td><td>254 </td><td>0.24 </td><td>0.41\n</td></tr><tr><td>ComplEx [51] [] </td><td>Bilinear </td><td>5261 </td><td>0.44 </td><td>0.51 </td><td>339 </td><td>0.24 </td><td>0.42\n</td></tr><tr><td>TransE [10] [] </td><td>Translational </td><td>3384 </td><td>0.22 </td><td>0.50 </td><td>347 </td><td>0.29 </td><td>0.46\n</td></tr><tr><td>HyperKG (Mo\u0308bius addition) </td><td>Translational </td><td>4668 </td><td>0.30 </td><td>0.44 </td><td>822 </td><td>0.19 </td><td>0.32\n</td></tr><tr><td>HyperKG (no regularisation) </td><td>Translational </td><td>5569 </td><td>0.30 </td><td>0.46 </td><td>318 </td><td>0.25 </td><td>0.41\n</td></tr><tr><td>HyperKG </td><td>Translational </td><td>4165 </td><td>0.41 </td><td>0.50 </td><td>272 </td><td>0.28 </td><td>0.45\n</td></tr></table></body></html>"}, "TABREF2": {"text": "Experimental results on WD and WD++ test sets.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Method </td><td>\u00a0</td><td>WD </td><td>\u00a0</td><td>WD++\n</td></tr><tr><td>MR </td><td>MRR </td><td>Hits@10 </td><td>MR </td><td>MRR </td><td>Hits@10\n</td></tr><tr><td>ComplEx </td><td>1.22 </td><td>0.92 </td><td>0.98 </td><td>2.42 </td><td>0.81 </td><td>0.92\n</td></tr><tr><td>TransE </td><td>2.52 </td><td>0.88 </td><td>0.96 </td><td>2.01 </td><td>0.89 </td><td>0.98\n</td></tr><tr><td>HyperKG </td><td>1.32 </td><td>0.98 </td><td>0.98 </td><td>1.36 </td><td>0.93 </td><td>0.98\n</td></tr></table></body></html>"}}, "back_matter": [{"text": "We would like to thank the anonymous reviewers for their insightful comments on the paper.", "cite_spans": [], "ref_spans": [], "section": "Acknowledgments."}]}