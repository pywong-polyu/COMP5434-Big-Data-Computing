{
    "paper_id": "ce6945d32780c599d829c1995dfc1555ab33bdd1",
    "metadata": {
        "title": "We Can Detect Your Bias: Predicting the Political Ideology of News Articles",
        "authors": [
            {
                "first": "Ramy",
                "middle": [],
                "last": "Baly",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Artificial Intelligence Laboratory",
                    "institution": "",
                    "location": {}
                },
                "email": "baly@mit.edu"
            },
            {
                "first": "Giovanni",
                "middle": [],
                "last": "Da",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "San",
                "middle": [],
                "last": "Martino",
                "suffix": "",
                "affiliation": {},
                "email": "gmartino@hbku.edu.qa"
            },
            {
                "first": "James",
                "middle": [],
                "last": "Glass",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Artificial Intelligence Laboratory",
                    "institution": "",
                    "location": {}
                },
                "email": "glass@mit.edu"
            },
            {
                "first": "Preslav",
                "middle": [],
                "last": "Nakov",
                "suffix": "",
                "affiliation": {},
                "email": "pnakov@hbku.edu.qa"
            }
        ]
    },
    "abstract": [
        {
            "text": "We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology -left, center, or right-, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "In any piece of news, there is a chance that the viewpoint of its authors and of the media organization they work for, would be reflected in the way the story is being told. The emergence of the Web and of social media has lead to the proliferation of information sources, whose leading political ideology or bias may not be explicit. Yet, systematic exposure to such bias may foster intolerance as well as ideological segregation, and ultimately it could affect voting behavior, depending on the degree and the direction of the media bias, and on the voters' reliance on such media (DellaVigna and Kaplan, 2007; Iyengar and Hahn, 2009; Saez-Trumper et al., 2013; Graber and Dunaway, 2017) . Thus, making the general public aware, e.g., by tracking and exposing bias in the news is important for a healthy public debate given the important role media play in a democratic society.",
            "cite_spans": [
                {
                    "start": 583,
                    "end": 612,
                    "text": "(DellaVigna and Kaplan, 2007;",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 613,
                    "end": 636,
                    "text": "Iyengar and Hahn, 2009;",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 637,
                    "end": 663,
                    "text": "Saez-Trumper et al., 2013;",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 664,
                    "end": 689,
                    "text": "Graber and Dunaway, 2017)",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Media bias can come in many different forms, e.g., by omission, by over-reporting on a topic, by cherry-picking the facts, or by using propaganda techniques such as appealing to emotions, prejudices, fears, etc. , 2020a Bias can occur with respect to a specific topic, e.g., COVID-19, immigration, climate change, gun control, etc. It could also be more systematic, as part of a political ideology, which in the Western political system is typically defined as left vs. center vs. right political leaning.",
            "cite_spans": [
                {
                    "start": 212,
                    "end": 219,
                    "text": ", 2020a",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Predicting the bias of individual news articles can be useful in a number of scenarios. For news media, it could be an important element of internal quality assurance as well as of internal or external monitoring for regulatory compliance. For news aggregator applications, such as Google News, it could enable balanced search, similarly to what is found on AllSides. 1 For journalists, it could enable news exploration from a left/center/right angle. It could also be an important building block in a system that detects bias at the level of entire news media (Baly et al., 2018 (Baly et al., , 2020 , such as the need to offer explainability, i.e., if a website is classified as left-leaning, the system should be able to pinpoint specific articles that support this decision.",
            "cite_spans": [
                {
                    "start": 561,
                    "end": 579,
                    "text": "(Baly et al., 2018",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 580,
                    "end": 600,
                    "text": "(Baly et al., , 2020",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we focus on predicting the bias of news articles as left-, center-, or right-leaning. Previous work has focused on doing so at the level of news media (Baly et al., 2020) or social media users , but rarely at the article level (Kulkarni et al., 2018 ). The scarce article-level research has typically used distant supervision, assuming that all articles from a given medium should share its overall bias, which is not always the case. Here, we revisit this assumption. Our contributions can be summarized as follows:",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 185,
                    "text": "(Baly et al., 2020)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 242,
                    "end": 264,
                    "text": "(Kulkarni et al., 2018",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We create a new dataset for predicting the political ideology of news articles. The dataset is annotated at the article level and covers a wide variety of topics, providing balanced left/center/right perspectives for each topic.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We develop a framework that discourages the learning algorithm from modeling the source instead of focusing on detecting bias in the article. We validate this framework in an experimental setup where the test articles come from media that were not seen at training time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We show that adversarial media adaptation is quite helpful in that respect, and we further propose to use a triplet loss, which shows sizable improvements over state-of-the-art pretrained Transformers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 We further incorporate media-level representation to provide background information about the source, and we show that this information is quite helpful for improving the article-level prediction even further.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The rest of this paper is organized as follows: We discuss related work in Section 2. Then, we introduce our dataset in Section 3, we describe our models for predicting the political ideology of a news article in Section 4, and we present our experiments and we discuss the results in Section 5. Finally, we conclude with possible directions for future work in Section 6.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Most existing datasets for predicting the political ideology at the news article level were created by crawling the RSS feeds of news websites with known political bias (Kulkarni et al., 2018) , and then projecting the bias label from a website to all articles crawled from it, which is a form of distant supervision. The crawling could be also done using text search APIs rather than RSS feeds (Horne et al., 2019; Gruppi et al., 2020) .",
            "cite_spans": [
                {
                    "start": 169,
                    "end": 192,
                    "text": "(Kulkarni et al., 2018)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 395,
                    "end": 415,
                    "text": "(Horne et al., 2019;",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 416,
                    "end": 436,
                    "text": "Gruppi et al., 2020)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "The media-level annotation of political leaning is typically obtained from specialized online platforms, such as News Guard, 2 AllSides, 3 and Media Bias/Fact Check, 4 where highly qualified journalists use carefully designed guidelines to make the judgments.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "As manual annotation at the article level is very time-consuming, requires domain expertise, and it could be also subjective, such annotations are rarely available at the article level. As a result, automating systems for political bias detection have opted for using distant supervision as an easy way to obtain large datasets, which are needed to train contemporary deep learning models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Distant supervision is a popular technique for annotating datasets for related text classification tasks, such as detecting hyper-partisanship (Horne et al., 2018; Potthast et al., 2018) and propaganda/satire/hoaxes (Rashkin et al., 2017) . For example, Kiesel et al. (2019) created a large corpus for detecting hyper-partisanship (i.e., articles with extreme left/right bias) consisting of 754,000 articles, annotated via distant supervision, and additional 1,273 manually annotated articles, part of which was used as a test set for the SemEval-2019 task 4 on Hyper-partisan News Detection. The winning system was an ensemble of character-level CNNs (Jiang et al., 2019) . Interestingly, all topperforming systems in the task achieved their best results when training on the manually annotated articles only and ignoring the articles that were labeled using distant supervision, which illustrates the dangers of relying on distant supervision. Barr\u00f3n-Cedeno et al. (2019) extensively discussed the limitations of distant supervision in a text classification task about article-level propaganda detection, in a setup that is similar to what we deal with in this paper: the learning systems may learn to model the source of the article instead of solving the task they are actually trained for. Indeed, they have shown that the error rate may drastically increase if such systems are tested on articles from sources that were never seen during training, and that this effect is positively correlated with the representation power of the learning model. They analyzed a number of representations and machine learning models, showing which ones tend to overfit more, but, unlike our work here, they fell short of recommending a practical solution. Budak et al. (2016) measured the bias at the article level using crowd-sourcing. This is risky as public awareness of media bias is limited (Elejalde et al., 2018) . Moreover, the annotation setup does not scale. Finally, their dataset is not freely available, and their approach of randomly crawling articles does not ensure that topics and events are covered from different political perspectives. Lin et al. (2006) built a dataset annotated with the ideology of 594 articles related to the Israeli-Palestinian conflict published on bitterlemons. org. The articles were written by two editors and 200 guests, which minimizes the risk of modeling the author style. However, the dataset is too small to train modern deep learning approaches. Kulkarni et al. (2018) built a dataset using distant supervision and labels from AllSides. Distant supervision is fine for the purpose of training, but they also used it for testing, which can be problematic. Moreover, their training and test sets contain articles from the same media, and thus models could easily learn to predict the article's source rather than its bias. In their models, they used both the text and the URL contents of the articles.",
            "cite_spans": [
                {
                    "start": 143,
                    "end": 163,
                    "text": "(Horne et al., 2018;",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 164,
                    "end": 186,
                    "text": "Potthast et al., 2018)",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 216,
                    "end": 238,
                    "text": "(Rashkin et al., 2017)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 254,
                    "end": 274,
                    "text": "Kiesel et al. (2019)",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 652,
                    "end": 672,
                    "text": "(Jiang et al., 2019)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 946,
                    "end": 973,
                    "text": "Barr\u00f3n-Cedeno et al. (2019)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1746,
                    "end": 1765,
                    "text": "Budak et al. (2016)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1886,
                    "end": 1909,
                    "text": "(Elejalde et al., 2018)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 2146,
                    "end": 2163,
                    "text": "Lin et al. (2006)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 2488,
                    "end": 2510,
                    "text": "Kulkarni et al. (2018)",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Overall, political bias has been studied at the level of news outlet (Dinkov et al., 2019; Baly et al., 2018 Baly et al., , 2020 Zhang et al., 2019) , user , article (Potthast et al., 2018; , and sentence (Sim et al., 2013; Saez-Trumper et al., 2013) . In particular, Baly et al. (2018) developed a system to predict the political bias and the factuality of news media. In a followup work, showed that bias and factuality of reporting should be predicted jointly. A finer-grained analysis is performed in (Horne et al., 2018) , where a model was trained on 10K sentences from a dataset of reviews (Pang and Lee, 2004) , and used to discriminate objective versus non-objective sentences in news articles. Lin et al. (2006) presented a sentence-level classifier, where the labels were projected from the document level.",
            "cite_spans": [
                {
                    "start": 69,
                    "end": 90,
                    "text": "(Dinkov et al., 2019;",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 91,
                    "end": 108,
                    "text": "Baly et al., 2018",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 109,
                    "end": 128,
                    "text": "Baly et al., , 2020",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 129,
                    "end": 148,
                    "text": "Zhang et al., 2019)",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 166,
                    "end": 189,
                    "text": "(Potthast et al., 2018;",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 205,
                    "end": 223,
                    "text": "(Sim et al., 2013;",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 224,
                    "end": 250,
                    "text": "Saez-Trumper et al., 2013)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 268,
                    "end": 286,
                    "text": "Baly et al. (2018)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 505,
                    "end": 525,
                    "text": "(Horne et al., 2018)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 597,
                    "end": 617,
                    "text": "(Pang and Lee, 2004)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 704,
                    "end": 721,
                    "text": "Lin et al. (2006)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "In this section, we describe the dataset that we created and that we used in our experiments. While most of the platforms that analyze the political leaning of news media provide in-depth analysis of particular aspects of the media, AllSides stands out as it provides annotations of political ideology for individual articles, which ensures high-quality data for both training and testing, which is in contrast with distant supervision approaches used in most previous research, as we have seen above. In All-Sides, these annotations are made as a result of a rigorous process that involves blind bias surveys, editorial reviews, third-party analysis, independent reviews, and community feedback. 5 Furthermore, AllSides uses the annotated articles to enable its Balanced Search, which shows news coverage on a given topic from media with different political bias. In other words, for each trending event or topic (e.g., impeachment or coronavirus pandemic), the platform pushes news articles from all sides of the political spectrum, as shown in Figure 1 . We took advantage of this and downloaded all articles along with their political ideology annotations (left, center, or right), their assigned topic(s), the media in which they were published, their author(s), and their publication date. Thus, our dataset contains articles that were manually selected and annotated, and that are representative of the real political scenery. Note that the center class covers articles that are biased towards a centrist political ideology, and not articles that lack political bias (e.g., sports and technology), which commonly exist in news corpora that were built by scraping RSS feeds.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1047,
                    "end": 1055,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Dataset"
        },
        {
            "text": "We collected a total of 34,737 articles published by 73 news media and covering 109 topics. 6 In this dataset, a total of 1,080 individual articles (3.11%) have a political ideology label that is different from their source's. This suggests that, while the distant supervision assumption generally holds, we would still find many articles that defy it. Table 1 shows some statistics about the dataset. Figure 2 illustrates the distribution of the different political bias labels within each of the most frequent topics. We can see that our dataset is able to represent topics or events from different political perspectives. This is yet another advantage, as it enables a more challenging task for machine learning models to detect the linguistic and the semantic nuances of different political ideologies in news articles, as opposed to cases where certain topics might be coincidentally collocated with certain labels, in which case the models would be actually learning to detect the topics instead of predicting the political ideology of the target news article. It is worth noting that since most article labels are aligned with their source labels, it is likely that machine learning classifiers would end up modeling the source instead of the political ideology of the individual articles. For example, a model would be learning the writing style of each medium, and then it would associate it with a particular ideology. Therefore, we pre-processed the articles in a way that eliminates explicit markers such as the name of the authors, or the name of the medium that usually appears as a preamble to the article's content, or in the content itself. Furthermore, in order to ensure that we are actually modeling the political ideology as it is expressed in the language of the news, we created evaluation splits in two different ways: (i) randomly, which is what is typically done (for comparison only), and (ii) based on media, where all articles by the same medium appear in either the training, the validation, or the testing dataset.",
            "cite_spans": [
                {
                    "start": 92,
                    "end": 93,
                    "text": "6",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 353,
                    "end": 360,
                    "text": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 402,
                    "end": 410,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Dataset"
        },
        {
            "text": "The latter form of splitting would help us indicate what a trained classifier has actually learned. For instance, if it modeled the source, then it would not be able to perform well on the test set, since all its articles would belong to sources that were never seen during training. In order to ensure fair one-toone comparisons between experiments, we created these two different sets of splits, while making sure that they share the same test set, as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Political Ideology Count Percentage"
        },
        {
            "text": "\u2022 Media-based Split: We sampled 1,200 articles from 12 news media (100 per medium) and used them as the test set, and we excluded the remaining 5,470 articles from these media. Then, we used the articles from the remaining 61 media to create the training and the validation sets, where all articles from the same medium would appear in the same set: training, development, or testing. This ensures that the model is fine-tuned and tested on articles whose sources were not seen during training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Political Ideology Count Percentage"
        },
        {
            "text": "\u2022 Random Split: Here, the test set is the same as in the media-based split. The 5,470 articles that we excluded from the 12 media are now added to the articles from the 61 remaining media. Then, we split this collection of articles (using stratified random sampling) into training and validation sets. This ensures that the model is fine-tuned and evaluated only on articles whose sources were observed during training. Table 2 shows statistics about both splits, including the size of each set and the number of media and topics they cover. We release the dataset, along with the evaluation splits, and the code, 7 which can be used to extend the dataset as more news articles are added to AllSides. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 420,
                    "end": 427,
                    "text": "Table 2",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Political Ideology Count Percentage"
        },
        {
            "text": "The task of predicting the political ideology of news articles is typically formulated as a classification problem, where the textual content of the articles is encoded into a vector representation that is used to train a classifier to predict one of C classes (in our case, C = 3: left, center, and right).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classifiers"
        },
        {
            "text": "In our experiments, we use two deep learning architectures: (i) Long Short-Term Memory networks (LSTMs), which are Recurrent Neural Networks (RNNs), which use gating mechanisms to selectively pass information across time and to model long-term dependencies (Hochreiter and Schmidhuber, 1997) , and (ii) Bidirectional Encoder Representations from Transformers (BERT), with a complex architecture yielding high-quality contextualized embeddings, which have been successful in several Natural Language Processing tasks (Devlin et al., 2019).",
            "cite_spans": [
                {
                    "start": 257,
                    "end": 291,
                    "text": "(Hochreiter and Schmidhuber, 1997)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Classifiers"
        },
        {
            "text": "Ultimately, our goal is to develop a model that can predict the political ideology of a news article. Our dataset, along with some others, has a special property that might stand in the way of achieving this goal. Most articles published by a given source have the same ideological leaning. This might confuse the model and cause it to erroneously associate the output classes with features that characterize entire media outlets (such as detecting specific writing patterns, or stylistic markers in text). Consequently, the model would fail when applied to articles that were published in media that were unseen during training. The experiments in Section 5 confirm this. Thus, we apply two techniques to de-bias the models, i.e., to prevent them from learning the style of a specific news medium rather than predicting the political ideology of the target news article.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Removing Media Bias"
        },
        {
            "text": "This model was originally proposed by Ganin et al. (2016) for unsupervised domain adaptation in image classification. Their objective was to adapt a model trained on labelled images from a source domain to a novel target domain, where the images have no labels for the task at hand. This is done by adding an adversarial domain classifier with a gradient reversal layer to predict the examples' domains. The label predictor's is minimized for the labelled examples (from the source domain), and the adversarial domain classifier's loss is maximized for all examples in the dataset. As a result, the encoder can extract representation that is (i) discriminative for the main task and also (ii) invariant across domains (due to the gradient reversal layer). The overall loss is minimized as follows:",
            "cite_spans": [
                {
                    "start": 38,
                    "end": 57,
                    "text": "Ganin et al. (2016)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Adversarial Adaptation (AA)"
        },
        {
            "text": "where N is the number of training examples, L i y (\u00b7, \u00b7) is the label predictor's loss, the condition d i = 0 means that only examples from the source domain are used to calculate the label predictor's loss, L i d (\u00b7, \u00b7) is the domain classifier's loss, \u03bb controls the trade-off between both losses, and {\u03b8 f , \u03b8 y , \u03b8 d } are the parameters of the encoder, the label predictor, and the domain classifier, respectively. Further details about the formulation of this method is available in (Ganin et al., 2016) .",
            "cite_spans": [
                {
                    "start": 489,
                    "end": 509,
                    "text": "(Ganin et al., 2016)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Adversarial Adaptation (AA)"
        },
        {
            "text": "We adapt this architecture as follows. Instead of a domain classifier, we implement a media classifier, which, given an article, tries to predict the medium it comes from. As a result, the encoder should extract representation that is discriminative for the main task of predicting political ideology, while being invariant for the different media. This approach was originally proposed as an unsupervised domain adaptation, since labelled examples were available for one domain only, whereas in our case, all articles from different media were labelled for their political ideology. Therefore, we jointly minimize the losses of both the label predictor and the media classifier over the entire dataset. The new objective function to minimize is as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Adversarial Adaptation (AA)"
        },
        {
            "text": "where L i m (\u00b7, \u00b7) is the loss of the media classifier, and \u03b8 m is its set of parameters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Adversarial Adaptation (AA)"
        },
        {
            "text": "In this approach, we pre-train the encoder using a triplet loss (Schroff et al., 2015) . The model is trained on a set of triplets, each composed of an anchor, a positive, and a negative example. The objective in Eq. 3 ensures that the positive example is always closer to the anchor than the negative example is, where a, p and n are the encodings of the anchor, of the positive, and of the negative examples, respectively, and D(\u00b7, \u00b7) is the Euclidean distance: Figure 3 shows an example of such a triplet. The positive example shares the same ideology as the anchor's, but they are published by different media. The negative example has a different ideology than the anchor's, but they are published by the same medium. In this way, the encoder will be clustering examples with similar ideologies close to each other, regardless of their source. Once the encoder has been pre-trained, its parameters, along with the softmax classifier's, are fine-tuned on the main task by minimizing the cross-entropy loss when predicting the political ideology of articles. ",
            "cite_spans": [
                {
                    "start": 64,
                    "end": 86,
                    "text": "(Schroff et al., 2015)",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [
                {
                    "start": 464,
                    "end": 472,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Triplet Loss Pre-training (TLP)"
        },
        {
            "text": "Finally, we explore the benefits of incorporating information describing the target medium, which can serve as a complementary representation for the article. While this seems to be counter-intuitive to what we have been proposing in Subsection 4.2, we believe that medium-level representation can be valuable when combined with an accurate representation of the article. Intuitively, having an accurate understanding of the natural language in the article, together with a glimpse into the medium it is published in, should provide a more complete picture of its underlying political ideology. Baly et al. (2020) proposed a comprehensive set of representation to characterize news media from different angles: how a medium portrays itself, who is its audience, and what is written about it. Their results indicate that exploring the Twitter bios of a medium's followers offers a good insight into its political leaning. To a lesser extent, the content of a Wikipedia page describing a medium can also help unravel its political leaning. Therefore, we concatenated these representations to the encoded articles, at the output of the encoder and right before the SOFTMAX layer, so that both the article encoder and the classification layer that is based on the article and the external media representations are trained jointly and end-to-end.",
            "cite_spans": [
                {
                    "start": 595,
                    "end": 613,
                    "text": "Baly et al. (2020)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Media-level Representation"
        },
        {
            "text": "Similarly to (Baly et al., 2020) , we retrieved the profiles of up to a 1,000 Twitter followers for each medium, we encoded their bios using the Sentence-BERT model (Reimers and Gurevych, 2019) , and we then averaged these encodings to obtain a single representation for that medium. As for the Wikipedia representation, we automatically retrieved the content of the page describing each medium, whenever applicable. Then, we used the pre-trained base BERT model to encode this content by averaging the word representations extracted from BERT's second-to-last layer, which is common practice, since the last layer may be biased towards the pre-training objectives of BERT.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 32,
                    "text": "(Baly et al., 2020)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 165,
                    "end": 193,
                    "text": "(Reimers and Gurevych, 2019)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Media-level Representation"
        },
        {
            "text": "We evaluated both the LSTM and the BERT models, assessing the impact of (i) de-biasing and (ii) incorporating media-level representation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments and Results"
        },
        {
            "text": "We fine-tuned the hyper-parameters of both models on the validation set using a guided grid search trial while fixing the seeds of the random weights initialization. For LSTM, we varied the length of the input (128-1,024 tokens), the number of layers (1-3), the size of the LSTM cell (200-400), the dropout rate (0-0.8), the learning rate (1e\u22123 to 1e\u22125), the gradient clipping value (0-5), and the batch size (8-256). The best results were obtained with a 512-token input, a 2-layer LSTM of size 256, a dropout rate of 0.7, a learning rate of 1e\u22123, gradient clipping at 0.5, and a batch size of 32. This model has around 1.1M trainable parameters, and was trained with 300-dimensional GloVe input word embeddings (Pennington et al., 2014) .",
            "cite_spans": [
                {
                    "start": 713,
                    "end": 738,
                    "text": "(Pennington et al., 2014)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "For BERT, we varied the length of the input, the learning rate, and the gradient clipping value. The best results were obtained using a 512-token input, a learning rate of 2e\u22125, and gradient clipping at 1. This model has 110M trainable parameters.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "We trained our models on 4 Titan X Pascal GPUs, and the runtime for each epoch was 25 seconds for the LSTM-based models and 22 minutes for the BERT-based models. For each experiment, the model was trained only once with fixed seeds used to initialize the models' weights.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "For the Adversarial Adaptation (AA), we have an additional hyper-parameter \u03bb (see Equation 2), which we varied from 0 to 1, where 0 means no adaptation at all. The best results were obtained with \u03bb = 0.7, which means that we need to pay significant attention to the adversarial classifier's loss in order to mitigate the media bias.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "For the Triplet Loss Pre-training (PLT), we sampled 35,017 triplets from the training set, such that the examples in each triplet discuss the same topic in order to ensure that the change in topic has minimal impact on the distance between the examples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "To evaluate our models, we use accuracy and macro-F 1 score (F 1 averaged across all classes), which we also used as an early stopping criterion, since the classes were slightly imbalanced. Moreover, given the ordinal nature of the labels, we report the Mean Absolute Error (MAE), shown in Equation (4), where N is the number of instances, and y i and\u0177 i are the number of correct and of predicted labels, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "Baseline Results The results in Table 3 show the performance for LSTM and for BERT at predicting the political ideology of news articles for both the media-based and the random splits. We observe sizable differences in performance between the two splits. In particular, both models perform much better when they are trained and evaluated on the random split, whereas they both fail on the mediabased split, where they are tested on articles from media that were not seen during training. This observation confirms our initial concerns that the models would tend to learn general characteristics about news media, and then would face difficulties with articles coming from new unseen media. Removing the Source Bias In order to further confirm the bias towards modeling the media, we ran a side experiment of fine-tuning BERT on the task of predicting the medium given the article's content, which is a 73-way classification problem. We used stratified random sampling to create the evaluation splits and to make sure each set contains all labels (media). The results in Table 4 confirm that BERT is much stronger than the majority class baseline, despite the high number of classes, which means that predicting the medium in which a target news article was published is a fairly easy task.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 32,
                    "end": 39,
                    "text": "Table 3",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 1070,
                    "end": 1077,
                    "text": "Table 4",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Results"
        },
        {
            "text": "Macro F 1 Acc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Model"
        },
        {
            "text": "Majority 0.25 10.21 BERT 59.72 80.12 In order to remove the bias towards modeling the medium, we evaluated the impact of the adversarial adaptation (AA) and the Triplet Loss Pre-training (TLP) with the media-based split. The results in Table 5 show sizeable improvements when either of these approaches is used, compared to the baseline (no de-biasing). In particular, TLP yields an improvement of 14.12 points absolute in terms of accuracy, and 12.73 points in terms of macro-F 1 . Table 6 : Impact of adding media-level representations to the article-level representations (with and without debiasing). Note that the results in rows 3 and 6 are the same for both LSTM and BERT because no articles were involved, and the media-level representations were directly used to train the classifier.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 236,
                    "end": 243,
                    "text": "Table 5",
                    "ref_id": "TABREF8"
                },
                {
                    "start": 483,
                    "end": 490,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Model"
        },
        {
            "text": "Finally, we evaluated the impact of incorporating the media-level representation (Twitter followers' bios and Wikipedia content) in addition to teh articlelevel representation. Table 6 illustrates these results in an incremental way. First, we evaluated the performance of the media-level representation alone at predicting the political ideology of news articles (see rows 3 and 6). We should note that these results are identical for the LSTM and the BERT columns since no article was encoded in these experiments, and the media representation was used directly to train the logistic regression classifier. Then, adding the article representation from either model, without any de-biasing, had no or little impact on the performance (see rows 4 vs. 3, and 7 vs. 6). This is not surprising, since we have shown that, without de-biasing, both models learn more about the source than about the bias in the language used by the article. Therefore, the ill-encoded articles do not provide more information than what the medium representation already gives, which is why no or too little improvement was observed.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 177,
                    "end": 184,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Impact of Media-Level Representation"
        },
        {
            "text": "When we use the triplet loss to mitigate the source bias, the resulting article representation is more accurate and meaningful, and the medium representation does offer complementary information, and eventually contributes to sizeable performance gains (see rows 5 and 8 vs. 2). The Twitter bios representation appears to be much more important than the representation from Wikipedia, which shows the importance of inspecting the media followers' background and their point of views, which is also one of the observations in (Baly et al., 2020) .",
            "cite_spans": [
                {
                    "start": 525,
                    "end": 544,
                    "text": "(Baly et al., 2020)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Impact of Media-Level Representation"
        },
        {
            "text": "Overall, comparing the best results to the baseline (rows 8 vs. 1), we can see that (i) using the triplet loss to remove the source bias, and (ii) incorporating media-level representation from Twitter followers yields 30.51 and 28.76 absolute improvement in terms of macro F 1 on the challenging media-based split.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Impact of Media-Level Representation"
        },
        {
            "text": "We have explored the task of predicting the leading political ideology of news articles. In particular, we created a new large dataset for this task, which features article-level annotations and is well-balanced across topics and media. We further proposed an adversarial media adaptation approach, as well as a special triplet loss in order to prevent modeling the source instead of the political bias in the news article, which is a common pitfall for approaches dealing with data that exhibit high correlation between the source of a news article and its class, as is the case with our task here. Finally, our experimental results have shown very sizable improvements over using state-of-the-art pre-trained Transformers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        },
        {
            "text": "In future work, we plan to explore topic-level bias prediction as well as going beyond left-centerright bias. We further want to develop models that would be able to detect specific fragments in an article where the bias occurs, thus enabling explainability. Last but not least, we plan to experiment with other languages, and to explore to what extent a model for one language is transferable to another one given that the left-center-right division is not universal and does not align perfectly across countries and cultures, even when staying within the Western political world.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Predicting factuality of reporting and bias of news media sources",
            "authors": [
                {
                    "first": "Ramy",
                    "middle": [],
                    "last": "Baly",
                    "suffix": ""
                },
                {
                    "first": "Georgi",
                    "middle": [],
                    "last": "Karadzhov",
                    "suffix": ""
                },
                {
                    "first": "Dimitar",
                    "middle": [],
                    "last": "Alexandrov",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
            "volume": "18",
            "issn": "",
            "pages": "3528--3539",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "What was written vs. who read it: News media profiling using text analysis and social media context",
            "authors": [
                {
                    "first": "Ramy",
                    "middle": [],
                    "last": "Baly",
                    "suffix": ""
                },
                {
                    "first": "Georgi",
                    "middle": [],
                    "last": "Karadzhov",
                    "suffix": ""
                },
                {
                    "first": "Jisun",
                    "middle": [],
                    "last": "An",
                    "suffix": ""
                },
                {
                    "first": "Haewoon",
                    "middle": [],
                    "last": "Kwak",
                    "suffix": ""
                },
                {
                    "first": "Yoan",
                    "middle": [],
                    "last": "Dinkov",
                    "suffix": ""
                },
                {
                    "first": "Ahmed",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL '20",
            "volume": "",
            "issn": "",
            "pages": "3364--3374",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media",
            "authors": [
                {
                    "first": "Ramy",
                    "middle": [],
                    "last": "Baly",
                    "suffix": ""
                },
                {
                    "first": "Georgi",
                    "middle": [],
                    "last": "Karadzhov",
                    "suffix": ""
                },
                {
                    "first": "Abdelrhman",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 17th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT '19",
            "volume": "",
            "issn": "",
            "pages": "2109--2116",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Proppy: Organizing the news based on their propagandistic content",
            "authors": [
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Barr\u00f3n-Cedeno",
                    "suffix": ""
                },
                {
                    "first": "Israa",
                    "middle": [],
                    "last": "Jaradat",
                    "suffix": ""
                },
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Information Processing & Management",
            "volume": "56",
            "issn": "5",
            "pages": "1849--1864",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Fair and balanced? Quantifying media bias through crowdsourced content analysis",
            "authors": [
                {
                    "first": "Ceren",
                    "middle": [],
                    "last": "Budak",
                    "suffix": ""
                },
                {
                    "first": "Sharad",
                    "middle": [],
                    "last": "Goel",
                    "suffix": ""
                },
                {
                    "first": "Justin",
                    "middle": [
                        "M"
                    ],
                    "last": "Rao",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Public Opinion Quarterly",
            "volume": "80",
            "issn": "S1",
            "pages": "250--271",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "SemEval-2020 task 11: Detection of propaganda techniques in news articles",
            "authors": [
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "Henning",
                    "middle": [],
                    "last": "Barr\u00f3n-Cede\u00f1o",
                    "suffix": ""
                },
                {
                    "first": "Rostislav",
                    "middle": [],
                    "last": "Wachsmuth",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Petrov",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the International Workshop on Semantic Evaluation, SemEval '20",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A survey on computational propaganda detection",
            "authors": [
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Stefano",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Cresci",
                    "suffix": ""
                },
                {
                    "first": "Seunghak",
                    "middle": [],
                    "last": "Barr\u00f3n-Cede\u00f1o",
                    "suffix": ""
                },
                {
                    "first": "Roberto",
                    "middle": [
                        "Di"
                    ],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Pietro",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "the 29th International Joint Conference on Artificial Intelligence and the 17th Pacific Rim International Conference on Artificial Intelligence, IJCAI-PRICAI '20",
            "volume": "",
            "issn": "",
            "pages": "4826--4832",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Fine-grained analysis of propaganda in news articles",
            "authors": [
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Seunghak",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Rostislav",
                    "middle": [],
                    "last": "Barron-Cedeno",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Petrov",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, EMNLP '19",
            "volume": "",
            "issn": "",
            "pages": "5636--5646",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Unsupervised user stance detection on Twitter",
            "authors": [
                {
                    "first": "Kareem",
                    "middle": [],
                    "last": "Darwish",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Aupetit",
                    "suffix": ""
                },
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Stefanov",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, ICWSM '20",
            "volume": "",
            "issn": "",
            "pages": "141--152",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "The Fox News effect: Media bias and voting",
            "authors": [
                {
                    "first": "Stefano",
                    "middle": [],
                    "last": "Dellavigna",
                    "suffix": ""
                },
                {
                    "first": "Ethan",
                    "middle": [],
                    "last": "Kaplan",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "The Quarterly Journal of Economics",
            "volume": "122",
            "issn": "3",
            "pages": "1187--1234",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "authors": [
                {
                    "first": "Jacob",
                    "middle": [],
                    "last": "Devlin",
                    "suffix": ""
                },
                {
                    "first": "Ming-Wei",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "Kenton",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "Kristina",
                    "middle": [],
                    "last": "Toutanova",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT '19",
            "volume": "",
            "issn": "",
            "pages": "4171--4186",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Predicting the leading political ideology of YouTube channels using acoustic, textual, and metadata information",
            "authors": [
                {
                    "first": "Yoan",
                    "middle": [],
                    "last": "Dinkov",
                    "suffix": ""
                },
                {
                    "first": "Ahmed",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "Ivan",
                    "middle": [],
                    "last": "Koychev",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 20th Annual Conference of the International Speech Communication Association, INTERSPEECH '19",
            "volume": "",
            "issn": "",
            "pages": "501--505",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "On the nature of real and perceived bias in the mainstream media",
            "authors": [
                {
                    "first": "Erick",
                    "middle": [],
                    "last": "Elejalde",
                    "suffix": ""
                },
                {
                    "first": "Leo",
                    "middle": [],
                    "last": "Ferres",
                    "suffix": ""
                },
                {
                    "first": "Eelco",
                    "middle": [],
                    "last": "Herder",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PloS one",
            "volume": "13",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Domain-adversarial training of neural networks",
            "authors": [
                {
                    "first": "Yaroslav",
                    "middle": [],
                    "last": "Ganin",
                    "suffix": ""
                },
                {
                    "first": "Evgeniya",
                    "middle": [],
                    "last": "Ustinova",
                    "suffix": ""
                },
                {
                    "first": "Hana",
                    "middle": [],
                    "last": "Ajakan",
                    "suffix": ""
                },
                {
                    "first": "Pascal",
                    "middle": [],
                    "last": "Germain",
                    "suffix": ""
                },
                {
                    "first": "Hugo",
                    "middle": [],
                    "last": "Larochelle",
                    "suffix": ""
                },
                {
                    "first": "Fran\u00e7ois",
                    "middle": [],
                    "last": "Laviolette",
                    "suffix": ""
                },
                {
                    "first": "Mario",
                    "middle": [],
                    "last": "Marchand",
                    "suffix": ""
                },
                {
                    "first": "Victor",
                    "middle": [],
                    "last": "Lempitsky",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "The Journal of Machine Learning Research",
            "volume": "17",
            "issn": "1",
            "pages": "2096--2030",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Mass media and American politics",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Doris",
                    "suffix": ""
                },
                {
                    "first": "Johanna",
                    "middle": [],
                    "last": "Graber",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Dunaway",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "NELA-GT-2019: A large multi-labelled news dataset for the study of misinformation in news articles",
            "authors": [
                {
                    "first": "Maur\u00edcio",
                    "middle": [],
                    "last": "Gruppi",
                    "suffix": ""
                },
                {
                    "first": "Benjamin",
                    "middle": [
                        "D"
                    ],
                    "last": "Horne",
                    "suffix": ""
                },
                {
                    "first": "Sibel",
                    "middle": [],
                    "last": "Adal\u0131",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.08444"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Long Short-Term Memory",
            "authors": [
                {
                    "first": "Sepp",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                },
                {
                    "first": "J\u00fcrgen",
                    "middle": [],
                    "last": "Schmidhuber",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "Neural Computation",
            "volume": "9",
            "issn": "8",
            "pages": "1735--1780",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Assessing the news landscape: A multi-module toolkit for evaluating the credibility of news",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Benjamin",
                    "suffix": ""
                },
                {
                    "first": "William",
                    "middle": [],
                    "last": "Horne",
                    "suffix": ""
                },
                {
                    "first": "Sara",
                    "middle": [],
                    "last": "Dron",
                    "suffix": ""
                },
                {
                    "first": "Sibel",
                    "middle": [],
                    "last": "Khedr",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Adali",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the The Web Conference, WWW '18",
            "volume": "",
            "issn": "",
            "pages": "235--238",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Different spirals of sameness: A study of content sharing in mainstream and alternative media",
            "authors": [
                {
                    "first": "Jeppe",
                    "middle": [],
                    "last": "Benjamin D Horne",
                    "suffix": ""
                },
                {
                    "first": "Sibel",
                    "middle": [],
                    "last": "N\u00f8rregaard",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Adal\u0131",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, ICWSM '19",
            "volume": "",
            "issn": "",
            "pages": "257--266",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Red media, blue media: Evidence of ideological selectivity in media use",
            "authors": [
                {
                    "first": "Shanto",
                    "middle": [],
                    "last": "Iyengar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kyu",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Hahn",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of communication",
            "volume": "59",
            "issn": "1",
            "pages": "19--39",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Team Bertha von Suttner at SemEval-2019 Task 4: Hyperpartisan news detection using ELMo sentence representation convolutional network",
            "authors": [
                {
                    "first": "Ye",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Johann",
                    "middle": [],
                    "last": "Petrak",
                    "suffix": ""
                },
                {
                    "first": "Xingyi",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Kalina",
                    "middle": [],
                    "last": "Bontcheva",
                    "suffix": ""
                },
                {
                    "first": "Diana",
                    "middle": [],
                    "last": "Maynard",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation, Se-mEval '19",
            "volume": "",
            "issn": "",
            "pages": "840--844",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "SemEval-2019 Task 4: Hyperpartisan news detection",
            "authors": [
                {
                    "first": "Johannes",
                    "middle": [],
                    "last": "Kiesel",
                    "suffix": ""
                },
                {
                    "first": "Maria",
                    "middle": [],
                    "last": "Mestre",
                    "suffix": ""
                },
                {
                    "first": "Rishabh",
                    "middle": [],
                    "last": "Shukla",
                    "suffix": ""
                },
                {
                    "first": "Emmanuel",
                    "middle": [],
                    "last": "Vincent",
                    "suffix": ""
                },
                {
                    "first": "Payam",
                    "middle": [],
                    "last": "Adineh",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "Corney",
                    "suffix": ""
                },
                {
                    "first": "Benno",
                    "middle": [],
                    "last": "Stein",
                    "suffix": ""
                },
                {
                    "first": "Martin",
                    "middle": [],
                    "last": "Potthast",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval '19",
            "volume": "",
            "issn": "",
            "pages": "829--839",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Multi-view models for political ideology detection of news articles",
            "authors": [
                {
                    "first": "Vivek",
                    "middle": [],
                    "last": "Kulkarni",
                    "suffix": ""
                },
                {
                    "first": "Junting",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "Steven",
                    "middle": [],
                    "last": "Skiena",
                    "suffix": ""
                },
                {
                    "first": "William",
                    "middle": [
                        "Yang"
                    ],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
            "volume": "18",
            "issn": "",
            "pages": "3518--3527",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Which side are you on? Identifying perspectives at the document and sentence levels",
            "authors": [
                {
                    "first": "Wei-Hao",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Theresa",
                    "middle": [],
                    "last": "Wilson",
                    "suffix": ""
                },
                {
                    "first": "Janyce",
                    "middle": [],
                    "last": "Wiebe",
                    "suffix": ""
                },
                {
                    "first": "Alexander",
                    "middle": [],
                    "last": "Hauptmann",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLL '06",
            "volume": "",
            "issn": "",
            "pages": "109--116",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts",
            "authors": [
                {
                    "first": "Bo",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "Lillian",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, ACL '04",
            "volume": "",
            "issn": "",
            "pages": "271--278",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "GloVe: Global vectors for word representation",
            "authors": [
                {
                    "first": "Jeffrey",
                    "middle": [],
                    "last": "Pennington",
                    "suffix": ""
                },
                {
                    "first": "Richard",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "Christopher D",
                    "middle": [],
                    "last": "Manning",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP '14",
            "volume": "",
            "issn": "",
            "pages": "1532--1543",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A stylometric inquiry into hyperpartisan and fake news",
            "authors": [
                {
                    "first": "Martin",
                    "middle": [],
                    "last": "Potthast",
                    "suffix": ""
                },
                {
                    "first": "Johannes",
                    "middle": [],
                    "last": "Kiesel",
                    "suffix": ""
                },
                {
                    "first": "Kevin",
                    "middle": [],
                    "last": "Reinartz",
                    "suffix": ""
                },
                {
                    "first": "Janek",
                    "middle": [],
                    "last": "Bevendorff",
                    "suffix": ""
                },
                {
                    "first": "Benno",
                    "middle": [],
                    "last": "Stein",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL '18",
            "volume": "",
            "issn": "",
            "pages": "231--240",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
            "authors": [
                {
                    "first": "Eunsol",
                    "middle": [],
                    "last": "Hannah Rashkin",
                    "suffix": ""
                },
                {
                    "first": "Jin",
                    "middle": [
                        "Yea"
                    ],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "Svitlana",
                    "middle": [],
                    "last": "Jang",
                    "suffix": ""
                },
                {
                    "first": "Yejin",
                    "middle": [],
                    "last": "Volkova",
                    "suffix": ""
                },
                {
                    "first": "Paul G",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Allen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP '17",
            "volume": "",
            "issn": "",
            "pages": "2931--2937",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
            "authors": [
                {
                    "first": "Nils",
                    "middle": [],
                    "last": "Reimers",
                    "suffix": ""
                },
                {
                    "first": "Iryna",
                    "middle": [],
                    "last": "Gurevych",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
            "volume": "19",
            "issn": "",
            "pages": "3973--3983",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Social media news communities: Gatekeeping, coverage, and statement bias",
            "authors": [
                {
                    "first": "Diego",
                    "middle": [],
                    "last": "Saez-Trumper",
                    "suffix": ""
                },
                {
                    "first": "Carlos",
                    "middle": [],
                    "last": "Castillo",
                    "suffix": ""
                },
                {
                    "first": "Mounia",
                    "middle": [],
                    "last": "Lalmas",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 22nd ACM International Conference on Information & Knowledge Management, CIKM '13",
            "volume": "",
            "issn": "",
            "pages": "1679--1684",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Team QCRI-MIT at SemEval-2019 Task 4: Propaganda analysis meets hyperpartisan news detection",
            "authors": [
                {
                    "first": "Abdelrhman",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "Ramy",
                    "middle": [],
                    "last": "Baly",
                    "suffix": ""
                },
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Barr\u00f3n-Cede\u00f1o",
                    "suffix": ""
                },
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Mitra",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Mohtarami",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval '19",
            "volume": "",
            "issn": "",
            "pages": "1041--1046",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "FaceNet: A unified embedding for face recognition and clustering",
            "authors": [
                {
                    "first": "Florian",
                    "middle": [],
                    "last": "Schroff",
                    "suffix": ""
                },
                {
                    "first": "Dmitry",
                    "middle": [],
                    "last": "Kalenichenko",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Philbin",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR '15",
            "volume": "",
            "issn": "",
            "pages": "815--823",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Measuring ideological proportions in political speeches",
            "authors": [
                {
                    "first": "Yanchuan",
                    "middle": [],
                    "last": "Sim",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Brice",
                    "suffix": ""
                },
                {
                    "first": "Justin",
                    "middle": [
                        "H"
                    ],
                    "last": "Acree",
                    "suffix": ""
                },
                {
                    "first": "Noah",
                    "middle": [
                        "A"
                    ],
                    "last": "Gross",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP '13",
            "volume": "",
            "issn": "",
            "pages": "91--101",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Predicting the topical stance and political leaning of media using tweets",
            "authors": [
                {
                    "first": "Peter",
                    "middle": [],
                    "last": "Stefanov",
                    "suffix": ""
                },
                {
                    "first": "Kareem",
                    "middle": [],
                    "last": "Darwish",
                    "suffix": ""
                },
                {
                    "first": "Atanas",
                    "middle": [],
                    "last": "Atanasov",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL '20",
            "volume": "",
            "issn": "",
            "pages": "527--537",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Tanbih: Get to know what you are reading",
            "authors": [
                {
                    "first": "Yifan",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Da San",
                    "suffix": ""
                },
                {
                    "first": "Alberto",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "Salvatore",
                    "middle": [],
                    "last": "Barr\u00f3n-Cede\u00f1o",
                    "suffix": ""
                },
                {
                    "first": "Jisun",
                    "middle": [],
                    "last": "Romeo",
                    "suffix": ""
                },
                {
                    "first": "Haewoon",
                    "middle": [],
                    "last": "An",
                    "suffix": ""
                },
                {
                    "first": "Todor",
                    "middle": [],
                    "last": "Kwak",
                    "suffix": ""
                },
                {
                    "first": "Israa",
                    "middle": [],
                    "last": "Staykovski",
                    "suffix": ""
                },
                {
                    "first": "Georgi",
                    "middle": [],
                    "last": "Jaradat",
                    "suffix": ""
                },
                {
                    "first": "Ramy",
                    "middle": [],
                    "last": "Karadzhov",
                    "suffix": ""
                },
                {
                    "first": "Kareem",
                    "middle": [],
                    "last": "Baly",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Darwish",
                    "suffix": ""
                },
                {
                    "first": "Preslav",
                    "middle": [],
                    "last": "Glass",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Nakov",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
            "volume": "19",
            "issn": "",
            "pages": "223--228",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "AllSides: balanced search on the topic of reopening after the coronavirus lockdown.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Political ideology for the most frequent topics: elections, immigration, coronavirus, and politics.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "An example triplet used for de-biasing.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "1 http://allsides.com/ arXiv:2010.05338v1 [cs.CL] 11 Oct 2020",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 1: Statistics about our dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Train Valid.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Statistics about our dataset and its two splits: media-based and random.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Predicting the medium in which a target news article was published.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Macro F 1 Acc. MAE",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Impact of de-biasing (adversarial adaptation and triplet loss) on article-level bias detection. Acc. MAE Macro F 1 Acc. MAE",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This research is part of the Tanbih project 8 , which aims to limit the effect of \"fake news,\" propaganda and media bias by making users aware of what they are reading. The project is developed in collaboration between the Qatar Computing Research Institute, HBKU and the MIT Computer Science and Artificial Intelligence Laboratory.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}