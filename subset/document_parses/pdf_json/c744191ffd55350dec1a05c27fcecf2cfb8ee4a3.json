{
    "paper_id": "c744191ffd55350dec1a05c27fcecf2cfb8ee4a3",
    "metadata": {
        "title": "Representation Based Regression for Object Distance Estimation",
        "authors": [
            {
                "first": "Mete",
                "middle": [],
                "last": "Ahishali",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Mehmet",
                "middle": [],
                "last": "Yamac",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Serkan",
                "middle": [],
                "last": "Kiranyaz",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Moncef",
                "middle": [],
                "last": "Gabbouj",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "In this study, we propose a novel approach to predict the distances of the detected objects in an observed scene. The proposed approach modifies the recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are designed to compute a direct mapping for the Support Estimation (SE) task in a representation-based classification problem. We further propose and demonstrate that representation-based methods (sparse or collaborative representation) can be used in welldesigned regression problems. To the best of our knowledge, this is the first representation-based method proposed for performing a regression task by utilizing the modified CSENs; and hence, we name this novel approach as Representation-based Regression (RbR). The initial version of CSENs has a proxy mapping stage (i.e., a coarse estimation for the support set) that is required for the input. In this study, we improve the CSEN model by proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly optimize the so-called proxy mapping stage along with convolutional layers. The experimental evaluations using the KITTI 3D Object Detection distance estimation dataset show that the proposed method can achieve a significantly improved distance estimation performance over all competing methods. Finally, the software implementations of the methods are publicly shared at https://github.com/meteahishali/CSENDistance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Abstract-In this study, we propose a novel approach to predict the distances of the detected objects in an observed scene. The proposed approach modifies the recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are designed to compute a direct mapping for the Support Estimation (SE) task in a representation-based classification problem. We further propose and demonstrate that representation-based methods (sparse or collaborative representation) can be used in welldesigned regression problems. To the best of our knowledge, this is the first representation-based method proposed for performing a regression task by utilizing the modified CSENs; and hence, we name this novel approach as Representation-based Regression (RbR). The initial version of CSENs has a proxy mapping stage (i.e., a coarse estimation for the support set) that is required for the input. In this study, we improve the CSEN model by proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly optimize the so-called proxy mapping stage along with convolutional layers. The experimental evaluations using the KITTI 3D Object Detection distance estimation dataset show that the proposed method can achieve a significantly improved distance estimation performance over all competing methods. Finally, the software implementations of the methods are publicly shared at https://github.com/meteahishali/CSENDistance. Index Terms-Representation-based regression, object distance estimation, sparse support estimation, convolutional support estimator networks",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Representation Based Regression for Object Distance Estimation Mete Ahishali, Mehmet Yamac, Serkan Kiranyaz, and Moncef Gabbouj"
        },
        {
            "text": "D ISTANCE estimation has been a crucial task since its application plays a vital role in many autonomous frameworks, e.g., autonomous driving, unmanned aerial vehicles, and robotics. One can estimate the object specific distance from the depth scene produced by depth sensors such as LiDAR or utilizing such methods that use only visual information. Naturally, the latter is preferable because of the extra cost of LiDAR. Moreover, even though the LiDAR sensor can operate under varying weather conditions, it has a limited coverage area such as 5% of the image space [1] . Hence, there have been various methods [1] , [2] , [3] , [4] , [5] , [6] , [7] that focus on developing computer vision solutions for the depth estimation including supervised and unsupervised approaches. For example, the method in [6] has utilized multiple cameras to compensate for the lack of sensors. On the other hand, the need for multiple cameras and processing costs are disadvantages of a stereo-camera based depth estimation method. Thus, several methods have studied monocular depth estimation [4] , Mete Ahishali, Mehmet Yamac, and Moncef Gabbouj are with the Faculty of Information Technology and Communication Sciences, Tampere University, 33720 Tampere, Finland (email: name.surname@tuni.fi).",
            "cite_spans": [
                {
                    "start": 568,
                    "end": 571,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 613,
                    "end": 616,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 619,
                    "end": 622,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 625,
                    "end": 628,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 631,
                    "end": 634,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 637,
                    "end": 640,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 643,
                    "end": 646,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 649,
                    "end": 652,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 806,
                    "end": 809,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1079,
                    "end": 1082,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1085,
                    "end": 1089,
                    "text": "Mete",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Serkan Kiranyaz is with the Department of Electrical Engineering, Qatar University, 2713 Doha, Qatar (email: mkiranyaz@qu.edu.qa). [5] , and they have revealed that by following recent trends in neural networks, i.e., fully convolutional neural networks, depth estimation performance with a single RGB image can be comparable enough with a stereo-camera based approaches. As unsupervised learning strategies, studies in [4] , [5] , propose to learn depth information from structural changes within consequent frames. Additionally, besides using the visual data alone, a hybrid approach combining and utilizing both visual and sensor data can be another alternative for enhancing the noisy or erroneous depth predictions. For example, the authors claim in [1] that their method can be integrated into various learning-based methods that use visual information, and it can improve the performance of the methods by sparse LiDAR measurements.",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 134,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 420,
                    "end": 423,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 426,
                    "end": 429,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 755,
                    "end": 758,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Nevertheless, the aforementioned methods except [2] , [3] , and [7] have focused on producing dense depth maps which means computing a heat-map that gives a sense of relative depth distance information in an observed scene. On the other hand, the necessity of dense depth maps varies among applications, i.e., in an autonomous driving application, the distance information of the objects is more desirable than providing the depth map of the scene. There are only a few studies, [2] , [3] , [7] that propose object distance estimation for the objects in an observed scene.",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 51,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 54,
                    "end": 57,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 64,
                    "end": 67,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 479,
                    "end": 482,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 485,
                    "end": 488,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 491,
                    "end": 494,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The pioneer study [2] of object distance estimation on land proposes a two-tiers methodology: i) first, detection of the location, and then the classification of an object. ii) extraction of the related features such as the bounding box information (the width, the height, etc.), and class-specific ones (such as predefined average length of detected class). (iii) Finally, using a Multi-Layer Perceptron (MLP) to predict the camera distance of the bounding box in meters. However, their approach directly depends on the performance of object classification, while a misclassification of the given ROI may lead to a complete failure in distance estimation. Similarly, the study in [7] proposes to use only the geometric information of the bounding box as features and train a Support Vector Regressor (SVR). On the other hand, in [3] , a Convolutional Neural Network (CNN) is used to extract representative features and these features have then been used for the regression and the classification tasks by two MLPs to predict the distance of the object and its category. Since the overall framework in [3] is trained jointly by combining the classification and regression losses, the categorical information of the objects has boosted the estimation of the distance.",
            "cite_spans": [
                {
                    "start": 18,
                    "end": 21,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 681,
                    "end": 684,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 830,
                    "end": 833,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1102,
                    "end": 1105,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Overall, comparing recent improvements in the dense depth estimation [4] , [5] , [1] , there is a lack of existing research focusing on object distance estimation. In this study, we believe that the importance of object distance estimation is obvious as the number of recent advances in the state-of-theart object detectors has been growing and further analysis over these objects can provide better assistance to autonomous systems.",
            "cite_spans": [
                {
                    "start": 69,
                    "end": 72,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 75,
                    "end": 78,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 81,
                    "end": 84,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Deep Learning approaches with the recent advances in Convolutional Neural Networks (CNNs) have provided stateof-the-art performance levels in various computer vision tasks such as object detection, image recognition, and image segmentation. To achieve such performance levels, the deep learning-based approaches require a massive training dataset. On the other hand, the proposed solution for the object distance estimation task should be suitable to work with relatively small-scale annotated data. For example, one can compare KITTI 3D Object Detection [8] dataset having annotated 7481 scenes with Imagenet [9] having over a million samples.",
            "cite_spans": [
                {
                    "start": 555,
                    "end": 558,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 610,
                    "end": 613,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "To address this need, in this study, we first formulate the distance estimation problem as a multi-class classification task by quantizing the distance in meters and use representation-based classification techniques including two categories: Sparse Representation-based Classification (SRC) and Collaborative Representation-based Classification (CRC). The approaches for SRC [10] , [11] and CRC [12] are well suited for the limited data and they are commonly used for the classification in the existing studies as follows. A representative dictionary D is constructed by grouping training samples column-wise. In the inference phase, a test sample y will be attempted to be represented by the linear combination of the atoms of the formed dictionary D, i.e., solving y = Dx for x where x is a vector of representation coefficients. Accordingly, in SRC methods, it is aimed to find a sparsex (just have enough nonzero components so that the query sample is represented with a small error margin). Alternatively, in CRC, the least-square sense solution is applied, i.e.,",
            "cite_spans": [
                {
                    "start": 376,
                    "end": 380,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 383,
                    "end": 387,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 396,
                    "end": 400,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "where \u03bb is the regularization parameter. Overall, the same motivation is valid for both categories: the atoms having higher estimated representation coefficient values,x, are likely to have the same class label with the query sample y. It has been observed in [12] that the CRC approach has provided marginally reduced classification performance compared to SRC methods. However, the computational complexity of the methods that rely on SRC is significant considering that they require iterative computations to solve the problem. In this study, we propose the following approach of using a representation-based scheme in the object distance estimation task. First, the cropped objects are resized to have fixed size images for each object, and then their corresponding features are obtained by using pre-trained networks DenseNet-121 [13] , VGG19 [14] , and ResNet-50 [15] over the ImageNet dataset. Next, a dictionary is created with atoms of relative features that are from the classes obtained by discretizing the distances of the object. Finally, a representation-based classification method is applied to detect the class which will correspond to the discretized distance of the query object. The main advantage of the proposed approach is that the categorical information of the object is not used in the distance estimation unlike the methods in [2] , [3] ; hence the classification performance of a single-stage object detector does not affect the distance prediction performance.",
            "cite_spans": [
                {
                    "start": 260,
                    "end": 264,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 835,
                    "end": 839,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 848,
                    "end": 852,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 869,
                    "end": 873,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1354,
                    "end": 1357,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1360,
                    "end": 1363,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "As an alternative approach, we propose to consider this as a regression problem. In order to make a direct distance estimation without discretization during the inference phase, we modify Convolutional Support Estimator Network (CSEN) that was originally proposed as a representationbased classifier in [16] . The CSEN approach combines the conventional representation-based classification technique with the learning-based approach involving CNNs. We define the task of Support Estimation (SE) to estimate locations of the non-zero components of x. Indeed, the support of the nonzero coefficient forms sufficient information to obtain the class of the query sample. The previous works [16] , [17] , [18] have shown that CSENs provide state-of-the-art classification performance levels and their computational complexity are insignificant since they can directly map the support set of the query sample. Moreover, they are well-suited for limited annotated data since they do not have the tendency to overfit due to their compact structures. Up to date, the CSEN approach has never been designed and evaluated for a regression task. In this study, we show that using the modified CSEN configuration, it is possible to perform a regression task that is henceforth called as Representation-based Regression (RbR). Finally, we propose further improvements over the CSEN framework. The initial CSEN version [16] has required the socalled proxy,x, estimation based on the least-square solution, i.e.,x = D T D + \u03bbI \u22121 D T y. In this study, we propose an end-to-end learning, the so-called Compressive Learning CSEN (CL-CSEN) framework that jointly optimizes the proxy mapping and SE estimation. Overall, the novel and significant contributions of this study can be summarized as follows:",
            "cite_spans": [
                {
                    "start": 303,
                    "end": 307,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 686,
                    "end": 690,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 693,
                    "end": 697,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 700,
                    "end": 704,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1403,
                    "end": 1407,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "\u2022 Representation-based classification approaches are used in an object-specific distance estimation task for the first time. \u2022 To the best of our knowledge, this is the first study that formulates a regression task in the form of representationbased estimation approach. The proposed methodology is henceforth named as Representation-based Regression (RbR). \u2022 With the proposed approach, the state-of-the-art performance level is achieved using compact configurations and a non-iterative SE. This does not only enables an accurate estimation with a limited number of annotated data, it further yields an elegant efficiency in terms of computational complexity. \u2022 The improved framework with CL-CSEN enables the joint optimization of CSEN framework with the denoiser matrix B in order to be used in proxy mapping, i.e., x = By. \u2022 Finally, contrary to the depth estimation, there is a limited number of studies proposed for the object-specific distance estimation including [2] , [3] , [7] . Furthermore, the studies in [2] , [3] require additional information besides a single RGB image such as the object class information and camera projection matrix.",
            "cite_spans": [
                {
                    "start": 972,
                    "end": 975,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 978,
                    "end": 981,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 984,
                    "end": 987,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1018,
                    "end": 1021,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1024,
                    "end": 1027,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Our experimental evaluations over the KITTI benchmark dataset [8] show that the distance estimation performance with the proposed CSEN approach outperforms all competing methods, i.e., the competing distance estimator SVR [7] and alternative representation-based approaches including CRC [12] and SRC approaches [10] , [11] . Moreover, although the direct comparison of the proposed approach is not fair against the method in [3] due to the reasoning mentioned earlier, the proposed approach still outperforms [3] considering their reported performance metrics. The rest of the paper is structured as the following: the theoretical background and the prior art will be presented in Section II. Then, the proposed object distance estimation with CSEN and CL-CSEN will be detailed in Section III. Next, the experimental evaluations over the KITTI dataset are presented in Section IV. Finally, concluding remarks will be drawn in Section V.",
            "cite_spans": [
                {
                    "start": 62,
                    "end": 65,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 222,
                    "end": 225,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 288,
                    "end": 292,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 312,
                    "end": 316,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 319,
                    "end": 323,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 426,
                    "end": 429,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 510,
                    "end": 513,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this section, we shall first provide a brief background of sparse representation, then, discuss the representation-based classification theory including SRC and CRC methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "The following notations and terms are defined in this study. For a vector, x \u2208 R n , the p -norm is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "where p \u2265 1, whereas the 0 -norm and \u221e -norm are defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "..,n (|x i |) for the vector x, respectively. Let a signal s is sparsely represented in a domain \u03a6 such that s = \u03a6 x where x 0 \u2264 k, then it is said that the signal s is strictly k-sparse since it can be represented using less than k + 1 non-zero coefficients in a proper domain. That is to say, it is possible to represent the signal s with only a few basis vectors in a proper domain \u03a6. The sparse support set \u039b is then a set that contains locations of these non-zero coefficients of x such that \u039b := {i : x i = 0} and \u039b \u2282 {1, 2, 3, ..., n}.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "Let A is a subspace for the signal s such that y = As. Accordingly, a signal y can be projected to the subspace A as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "where A \u2208 R m\u00d7d is called compression matrix, D \u2208 R m\u00d7n is the equivalent dictionary, and m << n; and hence the corresponding system is underdetermined. We necessitate a priori information regarding the unknown x to solve such an ill-posed problem in (1) since it is non-uniquely solvable. The study in [19] has shown that at least k-sparse signal pairs in a sparsifying basis \u03a6 are distinguishable in the dictionary D if D satisfies some properties. Consequently, it immediately indicates that the below solution is unique,",
            "cite_spans": [
                {
                    "start": 303,
                    "end": 307,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "if x 0 \u2264 k, m \u2265 2k, and the minimum number of linearly independent columns in D is also greater than 2k [19] .",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 108,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "On the other hand, the solution of (2) is NP hard and the problem is non-convex. Fortunately, we can relax the optimization problem, 0 -minimization, to its closest norm based problem defined as Basis Pursuit [20] that is 1 -norm:",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 213,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "where (y) = {x : Dx = y}. The equivalent to the one of the sparse representation problem (2), but more tractable solution can be achieved by solving 1 -minimization defined in (3) under some conditions such as m > k(log(n/k)) and D satisfied Restricted Isometry Property [21] .",
            "cite_spans": [
                {
                    "start": 271,
                    "end": 275,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "A. Generic Sparse Support Estimation (SE) Support estimation can be defined as finding the non-zero locations of a corresponding sparse signal. Indeed, in many practical problems, the full signal recovery; the recovery of the signal magnitude, sign, and support set, may not be necessary. For example, in a representation-based classification problem as in [10] , [11] , [12] , estimating the locations of non-zero elements in x so-called the support set, \u039b, is enough to determine the corresponding class. Let the linear feed-forward model be y = Dx + z with an additive noise z, then a support estimator E(.) will estimate the indices of the nonzero elements given D and y, i.e.,",
            "cite_spans": [
                {
                    "start": 357,
                    "end": 361,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 364,
                    "end": 368,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 371,
                    "end": 375,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "The works in the literature targeting SE from y, i.e., \u039b = E (y, D), are based on by first applying a signal recovery method then applying component-wise thresholding over the estimated signal,x, to compute\u039b. Accordingly, they can be divided into three categories depending on their reconstruction schemes: (i) estimators that are based on 1 -minimization, (ii) least-square sense approximate methods such as LMSEE The approaches in (i) work in an iterative manner and they are computationally costly; and hence, not efficient if the aim is to only recover support information. The methods in (ii) are non-iterative and direct approaches but their performances are limited compared to the previous ones (see [22] for a detailed discussion). Finally, deep learning-based approaches [24] in the group (iii) target a direct mapping for the signal reconstruction task. However, the major concern is that the signal reconstruction task is harder than SE, and it requires deep networks having complex architectures with millions of parameters to enable a direct mapping. This further requires a massive size of training data for a proper generalization. Furthermore, these deep unfolding networks [24] consist of dense layers making them computationally intensive and more sensitive to the additional noises [16] . As a remedy, our recent approach, CSEN [16] , which can perform direct SE without first applying signal recovery, provides an alternative and computationally efficient solution. The compact design of CSEN enables elegant performance even with small-scale training data. Moreover, compared to deep networks with dense layers, CSEN with convolution layers provide robust SE in noisy cases. For a more detailed analysis, the readers are referred to [16] in which we compare the performances of the traditional support estimators with the proposed CSEN approach and we address the major limitations and drawbacks with the classical support estimator methods. ",
            "cite_spans": [
                {
                    "start": 708,
                    "end": 712,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 781,
                    "end": 785,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1191,
                    "end": 1195,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1302,
                    "end": 1306,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1348,
                    "end": 1352,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1755,
                    "end": 1759,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "II. BACKGROUND AND PRIOR ART"
        },
        {
            "text": "As discussed earlier, in representation-based classification task, predicting the locations of the non-zero elements in x is more important than computing the exact values. In the following sub-sections, we shall provide a brief explanation about how SRC and CRC methods perform classification. Basically, SRC methods are in the aforementioned first group of support estimators, whereas the CRC method belongs to the second group.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "1) Sparse Representation-based Classification: When a test sample y is introduced, the query sample y is tried to be represented as a linear combination of the atoms of the dictionary D. In general, SRC methods estimate sparse representation coefficientsx that only a few non-zero coefficients exist to represent the query sample. We expect that these active components ofx will correspond to the samples having the same label as the test sample. There are many existing studies that utilize the SRC approach for various classification tasks such as face recognition [11] , coronavirus disease 2019 (COVID-19) recognition [18] , early COVID-19 detection [17] , human action recognition [25] , and hyper-spectral image classification [26] .",
            "cite_spans": [
                {
                    "start": 567,
                    "end": 571,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 622,
                    "end": 626,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 654,
                    "end": 658,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 686,
                    "end": 690,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 733,
                    "end": 737,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "In the previous discussion regarding (2) and (3), the statements were valid for the exactly k-sparse signal pairs, whereas in practice, the signal x may not be exactly k-sparse due to the modeling errors or noise in the data. Consequently, given the measurement with the additive noise: y = Dx + z, the exact recovery of the signal is unfeasible. However, the stable signal recovery is still possible in which the stable recovery refers thatx obeys x \u2212x \u2264 \u03ba z hold for the estimated sparse signalx, where \u03ba is a relatively small constant. For instance, it is provided in [27] that using the following so-called Lasso formulation:",
            "cite_spans": [
                {
                    "start": 571,
                    "end": 575,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "the partial recovery of the sparse x is achievable. Correspondingly, it is also proven in [27] that 1 solution can still provide exact computing of x in noise-free cases.",
            "cite_spans": [
                {
                    "start": 90,
                    "end": 94,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "In [11] , a four-step approach is proposed instead of using (5) directly: i) normalize all the atoms in D and y to have unit 2 -norm, ii) apply the signal reconstruction step:",
            "cite_spans": [
                {
                    "start": 3,
                    "end": 7,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "wherex i is the estimated coefficients corresponding the class i, (iv) estimated label: Class (y) = arg min (e i ). Although this four-step solution introduces an additional residual finding step, it provides performance improvements over direct SE with (5) since the samples from different classes are actually correlated as in real life. The other SRC techniques in [25] , [26] have followed similar approaches with [11] .",
            "cite_spans": [
                {
                    "start": 368,
                    "end": 372,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 375,
                    "end": 379,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 418,
                    "end": 422,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "2) Collaborative Representation-based Classification: The study in [12] proposes to follow 2 -minimization instead of 1 -minimization in (5) as follows:",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 71,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "x = arg min",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "Hence, they form the CRC approach in [12] by changing the second step of the four-step solution in [11] with the following closed-form solution:x = D T D + \u03bbI n\u00d7n \u22121 D T y. The motivation is that for a given a query signal y or vectorized image, the computedx should have minimum energy with relatively small coefficients that correspond to samples in the dictionary D from the same class with the query y.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 41,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 99,
                    "end": 103,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "Hence, due to the least-square sense minimization technique, a collaborative representation is sought between the atoms of the dictionary. In representation-based classification scheme, the dictionary D mostly fails to satisfy the defined exact or robust recovery properties due to the correlation between samples. It is indeed discussed in [12] that if formulating the problem with the collaborative representation operates the classification rather than the sparse representation. It is reported that the followed 2 -minimization based solution provides especially high classification performances for a high compression ratio that is defined as m/d. In those cases, the CRC approach can even produce comparable or better classification results comparing with SRC. Note the fact that the CRC approach is considerably faster due to the presence of the closed-form solution in (6) .",
            "cite_spans": [
                {
                    "start": 341,
                    "end": 345,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 877,
                    "end": 880,
                    "text": "(6)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "B. Representation-based Classification"
        },
        {
            "text": "In the sequel, we will introduce the feature extraction procedure and the framework about using classical representation-based classification methods: SRC and CRC on the distance estimation task with the quantization. Then, the proposed CSEN based regression approach will be presented to directly predict the distance information without the quantization in the inference. Finally, a novel CL-CSEN framework will be introduced that is specifically designed to jointly optimize the denoiser and the regression parts of the CSEN during the training phase.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. THE PROPOSED METHODOLOGY"
        },
        {
            "text": "The representative dictionary that is needed to form in the representation-based classification methods can be formed by vectorized samples. However, we have revealed in [16] that for some cases, the atoms of the collected dictionary for a representation-based classification method are not representative enough if they are formed by directly putting the vectorized raw images. Hence, in the regression task as well, we propose to use a pre-trained CNN to produce more representative information.",
            "cite_spans": [
                {
                    "start": 170,
                    "end": 174,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "A. Estimation via Representation-based Classification"
        },
        {
            "text": "The selected pre-trained models for this feature extraction procedure are DenseNet-121 [13] , VGG19 [14] , and ResNet-50 [15] that are trained over the ImageNet dataset with more than one million images:",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 91,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 100,
                    "end": 104,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 121,
                    "end": 125,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "A. Estimation via Representation-based Classification"
        },
        {
            "text": "\u2022 DenseNet-121 is a fully connected convolutional network: an L-layer DenseNet-121 has a total of L(L+1)/2 connections whereas the corresponding traditional version of the convolutional network would have only L connections. \u2022 VGG19 is a deep neural network consisting of convolutional and fully connected (dense) layers (as a generic CNN structure) without any skip-connections. \u2022 ResNet-50 is based on residual learning having skipconnections between every other layer in the network. Overall, DenseNet-121 and ResNet-50 are in the form of convolutional layers consisting of only convolutional layers except for the output layer, whereas VGG19 has multiple fully connected layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Estimation via Representation-based Classification"
        },
        {
            "text": "Accordingly, we compose the features before the last convolutional layers of DenseNet-121 and ResNet-50 and before the fully connected layers of VGG19. Then, the collected multiple feature maps are flattened by applying global maxpooling operation. Consequently, the described feature extraction procedure provides the mapping \u03c6 : R N \u00d7N \u00d73 \u2192 R d to produce a feature vector, s i = \u03c6 (I i ), where I i is the i th object cropped from the observed frame and resized to a predetermined size i.e., N \u00d7 N as demonstrated in Fig.  1 . The feature vector dimension d = 1024, 512, and 2048 for DenseNet-121, VGG19, and ResNet-50, respectively. The composed features for m number of objects are collected column-wise to have the matrix, \u03a6 \u2208 R d\u00d7m . The representative dictionary D is then formed as D = A\u03a6 using the compression matrix A \u2208 R m\u00d7d as PCA. When forming the dictionary, we quantize the distances to interpret the regression problem as a classification problem. For example, let the desired sensitivity is selected as 1m, then there would be 60classes for a distance estimation task for the range of 1 -60 meters. This dictionary formation procedure is illustrated in Fig. 2 : To form the representative dictionary D, samples are collected with the increasing order of the distances. Then, they are resized and fed to the feature extractor. Next, after additional dimensional reduction operation with the matrix A, they are stacked in such a way that the first-class category corresponds to 1m and the C th class to C meters. Fig. 2 . Apparently, the distance information in the extracted features comes from the resolution of the cropped input images since the distant objects tend to have blurry appearances due to the rescaling small-scale distant objects as observed in Fig.  2 . Next, representation-based classification approaches with SRC and CRC can be used to predict the class which will correspond to the quantized distance. As illustrated in Fig. 1 , the aforementioned four-step approach in Section II is used in the framework including the residual finding step.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 520,
                    "end": 527,
                    "text": "Fig.  1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1171,
                    "end": 1177,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 1529,
                    "end": 1535,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 1777,
                    "end": 1784,
                    "text": "Fig.  2",
                    "ref_id": null
                },
                {
                    "start": 1957,
                    "end": 1963,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. Estimation via Representation-based Classification"
        },
        {
            "text": "With the proposed approach, it is possible to produce exact estimates instead of quantized distances during the inference. Hence, to the best of our knowledge, as the first time in the literature, we are introducing the utilization of a representative dictionary for a complete regression task. Accordingly, the proposed approach that will be detailed next is called Representation-based Regression (RbR).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "Since the traditional approaches first fully reconstruct the signal before the actual SE task, the performance of the SE becomes highly dependent on the performance of the signal recovery. As discussed earlier, the signal reconstruction is not guaranteed if the required sparsity of x does not hold due to practical reasons such as the presence of significant noise or high correlation between samples as observed in some classification problems such as face recognition. Nevertheless, it is still possible to recover \u039b fully [28] , [29] , [30] , [31] or partially [31] , [32] , [33] . With this motivation, we aim to learn a direct mapping to the corresponding support set\u039b for a given query sample y.",
            "cite_spans": [
                {
                    "start": 526,
                    "end": 530,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 533,
                    "end": 537,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 540,
                    "end": 544,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 547,
                    "end": 551,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 565,
                    "end": 569,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 572,
                    "end": 576,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 579,
                    "end": 583,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "The proposed SE follows a compact architecture that also maximizes the performance with a minimum number of annotated data. To this end, compact CSENs used in the previous work [16] have been modified to enable regression in the distance estimation task. The proposed modified CSEN inherits the same capabilities and advantages as the previous study in [16] . The network was a fully convolutional network consisting of only convolutional layers. In this study, we keep this strategy for SE as well and use MLP only for the regression over the predicted support sets. One may consider using an MLP-like structure for SE as in [24] which is originally proposed for SR. However, the followed topology in CSENs brings several advantages over MLPs as proven in [16] : low computational complexity, robustness to the noise, and learning capability with a limited amount of training data thanks to the compact structure of CSEN and significantly less number of parameters compared to the MLP.",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 353,
                    "end": 357,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 626,
                    "end": 630,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 757,
                    "end": 761,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "A CSEN network is designed to produce a binary mask v \u2208 {0, 1} n :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "The estimated support set would be\u039b = { i \u2208 { 1, 2, .., n} :v i = 1 }. Thus, in [16] , the CSEN network, which provides P (y, D) : R n \u2192 [0, 1] n mapping, produces a probability vector p of each index to be counted as a support. The final\u039b is then obtained by thresholding p with a fixed threshold. During the training phase, CSEN takesx as the input and producesv as the SE, wherev,x \u2208 R n ; hence the learned transformation would bev \u2190 P (x). Here, the input of CSEN is a rough estimation and it is called proxy. The proxyx can be the Maximum Correlationx = D T y or LMMSE [22] D T D + \u03bbI \u22121 D T y. The input proxyx is then reshaped to a 2-D plane and convolved with the weight kernels {w 1 1 , w 2 1 , ..., w N 1 }. After the addition of biases",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 84,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 575,
                    "end": 579,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": ".., f N 1 } in the first hidden layer with N number of weight kernels is formed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "where S(.) is the down-or up-sampling operation and ReLu(x) = max(0, x). This is illustrated in Fig. 3 . At the layer l, the k th feature can be defined as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 96,
                    "end": 102,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "Accordingly, an L-layer CSEN network would have the following trainable weight and bias {w, b}, parameters:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "In SRC, the dictionary is collected by stacking training samples, for example, by concatenating the same class samples together. Thus, group 1 -minimization can be used instead of (5):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "where x G,i is the group of coefficients from class i. Therefore, the cost function for a CSEN can be expressed as,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "where P \u0398 (x) p and v p are the actual output and binary mask of the sparse code x for p th pixel, respectively. The introduced regularization may bring additional computational complexity; hence, in the previous study [16] , an approximation of (11) is adopted for CSEN by applying average pooling over the output and then performing SoftMax operation to produce the class probabilities directly. However, for the regression problem, which is undertaken in this study, we propose to modify the architecture by replacing the average pooling with the max pooling and inserting an additional convolutional layer and fully connected layer right after the max-pooling as illustrated in Fig. 3 . The included layers form the regression part of the modified CSEN. Then, the loss function of the modified CSEN for the regression can be expressed as L CSEN = i\u2208M smooth 1 (P \u0398 (x i ) \u2212 d i ) over a Fig. 4 : Conventional dictionary design versus the proposed dictionary design for the CSEN. In the conventional dictionary design, samples are collected with the increasing order of the distances. The first, second, third class categories correspond to 1m, 2m, 3m, respectively, and the C th class corresponds to C meters.",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 223,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [
                {
                    "start": 682,
                    "end": 688,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 891,
                    "end": 897,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "batch M , where P \u0398 (x i ), d i are the predicted and real distance values for the i th object and smooth 1 -loss is expressed as,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "Consequently, the proxy is selected asx",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "is obtained for the extracted object feature f i = \u03c6 (I i ), and the input and output pair of the proposed method for the regression is x train , d train for the training. Note the fact that the proposed RbR method can directly map the exact distance values and it is possible to train the model using the exact distance information. The quantized distances are only used when forming the dictionary D with the selected quantized dictionary samples. In Section III-A, we have detailed the distance estimation utilizing representationbased classification with SRC and CRC approaches since they can only estimate the quantized distances that correspond to a classification task, i.e., class c corresponds to objects of c meter away from the camera. Therefore, the grouped features from different objects (e.g., car, person, and truck), but from the same distances (c-meter) as shown in Fig. 2 . In this way, we will have a categorical invariant distance estimator unlike the literature work [2] , [3] .",
            "cite_spans": [
                {
                    "start": 989,
                    "end": 992,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 995,
                    "end": 998,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 884,
                    "end": 890,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "In the traditional approaches with SRC and CRC, one can directly use the collected representative dictionary D having the samples collected in a random order as long as the ordering is known since the recovery of x is obtained from y = Dx. However, in the CSENs, direct mapping from y is performed using 2-D convolutional layers. Hence, in the proposed CSENs, it is important to group samples with the same quantized distances together after reshaping the proxyx since the grouped coefficients are max pooled in the feed-forward phase as discussed. Accordingly, the columns of the dictionary D are re-ordered in such a way that after reshaping the proxy into a 2-D plane, the samples with the same distances in the quantized level are grouped together. This proposed re-ordering topology is illustrated in Fig. 4 where 1-D coefficient vector x is reshaped to a 2-D plane that yields X. Correspondingly, one can directly say that the input size of the CSEN depends on the collected dictionary size and the stride size (also kernel size) of the average pooling depends on the number of samples within the same distance level.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 806,
                    "end": 812,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "B. The Proposed Representation-based Regression (RbR) with CSENs"
        },
        {
            "text": "In the CSEN approach, the input is the reshaped proxy signal,x, which is obtained directly byx = D T D + \u03bbI \u22121 D T y. Ultimately, the performance of the CSEN was therefore limited to this proxy mapping stage i.e., x = By since B is treated as a constant during the training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Compressive Learning CSEN (CL-CSEN) Approach"
        },
        {
            "text": "To overcome this limitation, we propose to fine-tune the denoiser matrix B as follows: we include two additional fullyconnected (dense) layers right before the first convolutional layer of the CSENs. The neurons connecting the input layer to the first hidden dense layer are initialized with B T where B = D T D + \u03bbI \u22121 D T . Next, the output of the first hidden dense layer is reshaped to form the input of the first hidden convolutional layer. The CL-CSEN framework is illustrated in Fig. 5 where the mapping from low-dimensional to high-dimensional space is learned during training. In this way, the proxy mapping layer is jointly optimized with the CSEN part of the CL-CSEN model to maximize the regression performance. Hence, the input and output pair of the proposed method with CL-CSEN will be y train , d train for the training.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 486,
                    "end": 492,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "C. Compressive Learning CSEN (CL-CSEN) Approach"
        },
        {
            "text": "The performance of the proposed approach is evaluated over the KITTI 3D Object Detection [8] dataset. KITTI provides 3D bounding boxes for the detected objects as well as their categories. Besides having 3D object dimensions including length, height, and width, the dataset has the information of the 3D object locations: x,y, and z in camera coordinates. Hence, we use the z location information as the ground truth for the object distance estimation task. The collected frames are captured by a moving platform/vehicle from rural areas, a mid-size city, and highways. One challenge with this dataset is that there are overlapping samples on the observed scene as illustrated in Fig. 6 . ",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 92,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [
                {
                    "start": 680,
                    "end": 686,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "IV. EXPERIMENTAL EVALUATION"
        },
        {
            "text": "The KITTI annotations consist of 7481 images and there are a total of 40 570 objects having the distance information. The majority of them, 38 307 objects are in the range of [0.5, 60.5] meters. In this study, the objects between the given range are selected for the evaluation in order to remove the outlier objects that are significantly far or close to the camera. The selected and cropped objects are then resized to 64 \u00d7 64 images and fed to the different feature extractor networks. We have created two different experimental setups. In the first one, a total of 19 769 samples are randomly selected for the training split and the remaining 18 538 samples are for the testing. In the second, only 4800 samples are used for training while the majority (33 507 samples) are used for the test. Consequently, these scenarios fulfill the aim of this study, i.e., evaluation of the learning capability with the limited amount of data (approximately 50% and less than 13% of the annotated data in the first and latter scenarios, respectively).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Experimental Setup"
        },
        {
            "text": "To form the dictionary D, we allocate 1200 samples from the training split and quantize those samples using 61 partitions in such a way that at the end, there are 20 samples per meter (20\u00d760 = 1200 objects in total) within the selected distance range. Recall the fact that these selected samples for each meter consist of different object categories such as person, car, truck, and trailer. Thus, D consists of 1200 samples in the proposed approaches with the CSEN and CL-CSEN. The compression ratio is set to CR = m/d = 0.5 using the PCA matrix A that is computed using the allocated samples for the dictionary formation. Consequently, the size of the equivalent dictionary D would be m \u00d7 1200 with the proposed compression using PCA where m = 512, 256, and 1024 for DenseNet-121, VGG19, and ResNet, respectively. Consequently, the corresponding denoiser matrix B = D T D + \u03bbI \u22121 D T would be 1200 \u00d7 m. Therefore, the reshaped version of the computed proxy signalx = By,x \u2208 R n=1200 has the size of 80 \u00d7 15 in the 2-D plane. Finally, the remaining training samples are used for the training of CSEN and CL-CSEN.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "The proposed compact CSEN structure given in Fig. 3 consists of only two convolutional (both with 5 \u00d7 5 filter sizes) and one dense layer. The first convolutional layer has 64 weight kernels that is followed by max-pooling with 4 \u00d7 5 pooling size. The second convolutional layer has only one kernel that creates a feature map that is flattened and connected to the single output neuron. In the CL-CSEN, there are additional two fully connected dense layers with the number of neurons corresponding to the size of B T as previously discussed. In this way, the followed compact structure brings the ability to learn from a limited amount of data. All the layers have ReLu as the activation function except the output that has the SoftPlus activation function.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 45,
                    "end": 51,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "The CSEN is trained with 100 epochs and batch size of 16 by Adam optimizer [34] using the proposed default parameter values as a learning rate \u03b1 = 10 \u22123 , \u03b2 1 = 0.9, and \u03b2 2 = 0.999. From the training set, we separate 20% of samples for the validation to select the best network model to be used for testing. The experiments have been performed using Python on a PC with NVidia \u00ae 1080 Ti GPU card, Intel \u00ae i9\u22127900X CPU having 128 GB system memory. The CSEN and CL-CSEN are implemented with the Tensorflow library [35] . The hyper-parameter of \u03bb is first searched in log-scale within the range \u03bb * \u2208 [10 \u221213 , 10 3 ]. Afterwards, the fine-tuned version is set with few more steps by slight adjustment such that \u03bb = \u03bb * \u00b1 10 log(\u03bb * ) .",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 513,
                    "end": 517,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "2) Competing Methods: Since we propose to use RbR by utilizing the regularized least-square sense solution as the coarse estimation of the support sets, the performance analysis will be performed against the base model with CRC [12] , and then, the improvement over CRC by the proposed CSEN and CL-CSEN will be reported. Moreover, we include various different solvers for SRC approach including ADMM [36] , Dalm [37] , OMP [37] , Homotopy [38] , GPSR [39] , L1LS [40] , 1 -magic [41] , Palm [37] . In addition, the performance evaluations are performed against the SVR [7] that has been used by [3] and [7] for distance estimation. Note that compared to [3] and [7] , we use the enhanced features obtained by the feature extraction method explained earlier. The SVR configuration is developed by searching the optimal hyperparameters. Accordingly, the grid-search is applied over the validation set with the following kernel functions: linear, Radial Basis Function (RBF), and polynomial using the following parameters: \u03b3 parameter (kernel coefficients for the RBF and polynomial kernels) in the range [10 \u22123 , 10 3 ] by varying in the log-scale, the degree of the polynomial {2, 3, 4}, the regularization parameter (C parameter) in the range [10 \u22123 , 10 3 ] by varying in the log-scale.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 232,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 400,
                    "end": 404,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 412,
                    "end": 416,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 423,
                    "end": 427,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 439,
                    "end": 443,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 451,
                    "end": 455,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 463,
                    "end": 467,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 479,
                    "end": 483,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 491,
                    "end": 495,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 569,
                    "end": 572,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 595,
                    "end": 598,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 603,
                    "end": 606,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 654,
                    "end": 657,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 662,
                    "end": 665,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "To make a fair comparison with the competing methods, the training set of SVR includes also the dictionary samples in addition to the training samples that are used in the proposed CSEN and CL-CSEN. Similarly, the dictionary samples in SRC and CRC methods include the training samples plus the dictionary samples of CSEN and CL-CSEN. The same feature extraction procedure in the proposed method is used in the SRC, CRC, and SVR (i.e., \u03c6 (I i ) where \u03c6 is the pre-trained network for the cropped and resized object I i ). The same CR is used by the PCA for SRC and CRC. In SVR, it is not TABLE I: The statistical (mean and standard deviations) performance metrics are reported from five different runs to show the object distance estimation performance of the proposed approach against the competing methods over the KITTI dataset and using different feature extractor networks, \u03c6 : R N \u00d7N \u00d73 \u2192 R d . The train:test splits are selected as approximately 1:1 proportion. In the metrics, \u2193:lower is better and \u2191: higher is better.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "DenseNet-121 Support Vector Regressor (SVR) [7] 0.2588 \u00b1 0.003 1.7764 \u00b1 0.041 5.3239 \u00b1 0.013 0.4189 \u00b1 0.006 0.6908 \u00b1 0.002 0.8862 \u00b1 0.003 0.9433 \u00b1 0.003 Base Model (CRC-light) [12] 0.4183 \u00b1 0.008 6.9585 \u00b1 0. feasible to compute the exact solution due to the scale of the data; and hence, we use Nystroem method [42] , [43] for the kernel approximation in order to approximate m = CR \u00d7 d number of feature maps where CR = 0.5. Overall, we keep the same CR value for all the methods in the experimental evaluations.",
            "cite_spans": [
                {
                    "start": 44,
                    "end": 47,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 176,
                    "end": 180,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 311,
                    "end": 315,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 318,
                    "end": 322,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "1) CSEN and CL-CSEN Configurations:"
        },
        {
            "text": "The same performance metrics as used in [1] , [2] , [3] , [4] , [5] , [6] are used to evaluate the distance estimation performance of the proposed approach. Let the actual and predicted distances be d i andd i and N is the number of samples in the test split, then for a given threshold t, the metric Threshold is defined as,",
            "cite_spans": [
                {
                    "start": 40,
                    "end": 43,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 46,
                    "end": 49,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 52,
                    "end": 55,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 58,
                    "end": 61,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 64,
                    "end": 67,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 70,
                    "end": 73,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "B. Experimental Results"
        },
        {
            "text": "Next, the Absolute Relative Distance (ARD) and the Squared Relative Distance (SRD) are defined as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Experimental Results"
        },
        {
            "text": "Finally, the Root of Mean Squared Error (RMSE) and the root of the Mean Squared logarithmic Error (RMSE log ) are,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Experimental Results"
        },
        {
            "text": "The distance estimation performance of the proposed method is presented in Table I . In these results, we report the RbR performance with the proposed CSEN and CL-CSEN models where the quantization is not applied for the training and testing samples, but is only used for the dictionary reconstruction. Correspondingly, the train:test splits are chosen as approximately 1:1 proportion. Note the fact that multiple pre-trained networks are utilized for feature extraction. In this way, we aim to evaluate the performance effect of different network architectures in feature extraction. DenseNet-121 has skip-connections that connect each layer to every other layer so that each layer is densely connected, ResNet-50 only has skip-connections between every second layer, and VGG-19 does not have any such shortcut connection between the layers. Based on Table I , a higher estimation accuracy is achieved by the proposed approach compared to SVR and the performance is highly improved compared to our base CRC model. Moreover, the proposed method outperforms [3] even though they use additional information such as the categorical class information of the objects and the projection matrix for the training. For a more fair comparison, the proposed method is also compared with the base model of [3] without classification; and the performance gap becomes even higher as expected. Additionally, scattering plots are provided in Fig. 7 demonstrating the actual distance versus the predicted distance by all methods. Correspondingly, we expect to see an identity transformation ideally. In the plots, the sample point sizes are purposely selected bigger to better illustrate the misdetections. Thus, considering the number of samples, most of them located at the identity line region and give a constant color view. Hence, it is observed that the CL-CSEN method provides the least scattered samples compared to the other methods especially when ResNet-50 features are used. Even though the reported metrics in Table I show improvements achieved by the proposed method; the performance gain is more visible for distant objects considering that the gap is significant in the squared metrics.",
            "cite_spans": [
                {
                    "start": 1057,
                    "end": 1060,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1294,
                    "end": 1297,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 75,
                    "end": 82,
                    "text": "Table I",
                    "ref_id": null
                },
                {
                    "start": 852,
                    "end": 859,
                    "text": "Table I",
                    "ref_id": null
                },
                {
                    "start": 1426,
                    "end": 1432,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 2006,
                    "end": 2013,
                    "text": "Table I",
                    "ref_id": null
                }
            ],
            "section": "B. Experimental Results"
        },
        {
            "text": "Next, the performance comparison is provided in Table II regarding the proposed method with CSEN and CL-CSEN versus CRC and SRC approaches. In this set of experiments, contrary to Table I Fig. 7 is that expectedly, the samples are located with 1m distances due to the applied quantization. Three sample frames are shown in Fig. 9 with their corresponding true and the estimated object-specific distances by the three best-performing methods: SVR, CSEN, and CL-CSEN. The first frame (first column in Fig. 9 ) represents a typical sample from the KITTI 3D Object Detection dataset in which there are overlapping objects. Moreover, even though the dataset may have some well-separated samples, the illumination conditions make it harder to perform analysis as observed in the third sample frame in Fig. 9 . Visual inspection based on these frames indicates that even though CL-CSEN provides enhanced performance than CSEN according to the quantitative analysis, for the close objects, CSEN seems to provide more accurate results. However, CSEN starts to underperform compared to CL-CSEN when the objects are distant from the camera.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 48,
                    "end": 56,
                    "text": "Table II",
                    "ref_id": null
                },
                {
                    "start": 180,
                    "end": 187,
                    "text": "Table I",
                    "ref_id": null
                },
                {
                    "start": 188,
                    "end": 194,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 323,
                    "end": 329,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 499,
                    "end": 505,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 795,
                    "end": 801,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "B. Experimental Results"
        },
        {
            "text": "The number of trainable parameters is provided in Table IIIa for the proposed CSEN and CL-CSEN models. Accordingly, TABLE II: The statistical (mean and standard deviations) performance metrics are reported from five different runs to show the object distance estimation performance of the proposed approach against the competing methods over the KITTI dataset and using different feature extractor networks, \u03c6 : R N \u00d7N \u00d73 \u2192 R d . The train:test splits are selected as approximately 1:17 proportion and the selected distance sensitivity (with quantization) is 1m. In the metrics, \u2193:lower is better and \u2191: higher is better.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 50,
                    "end": 60,
                    "text": "Table IIIa",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "C. Computational Complexity Analysis"
        },
        {
            "text": "CRC-light [12] 0.4157 \u00b1 0.0. 10 the SVR method. Note the fact that even though the CL-CSEN pipeline has more trainable parameters, the required time for the inference is less than CSEN. Because; the proxy mapping and reshaping stages for the following convolutional layers are implemented on GPU as an end-to-end pipeline that brings the computational efficiency that was lacking in the initial CSEN approach. Note that even though CSEN and CL-CSEN utilize the proxy mapping stage of the CRC approach, they are still ",
            "cite_spans": [
                {
                    "start": 10,
                    "end": 14,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 29,
                    "end": 31,
                    "text": "10",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "C. Computational Complexity Analysis"
        },
        {
            "text": "The presented distance estimation results are obtained using the proposed CSEN and CL-CSEN approaches that contain 2-D convolution operations. One can investigate operating directly over the 1-D proxy signal without further reshaping it as the input of the first convolutional layer. Hence, we present the distance estimation results in Table IV using 1-D convolutional layers in the proposed approaches. Accordingly, the CSEN-1D and CL-CSEN-1D models do not have any reshaping operations contrary to 2-D versions illustrated in Fig. 3 and Fig. 5 . It is observed that using the same number of trainable parameters, i.e., 25 \u00d7 1 filter sizes for each convolutional layer, the comparable results are obtained by performing 1-D inference on the proxy signal.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 337,
                    "end": 345,
                    "text": "Table IV",
                    "ref_id": null
                },
                {
                    "start": 529,
                    "end": 535,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 540,
                    "end": 546,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "D. Discussion: 1-D versus 2-D Proxy Signal Representation"
        },
        {
            "text": "In this study, we first propose a novel CSEN-based distance estimation method using a single camera. CSENs were recently proposed to directly estimate support sets of a signal instead of the traditional approach, i.e., first reconstructing the sparse signal and applying a threshold. Using the modified CSENs for regression, we demonstrate that it is possible to utilize representative dictionaries for a regression task; and to the best of authors' knowledge, this makes the pioneer study in this domain. Hence, we introduce the term Representationbased Regression (RbR) to reflect this fact. Moreover, utilizing the introduced representative dictionary design by collecting the samples with the same distances in the quantization level, the performance of the proposed distance estimators becomes class invariant unlike the several existing studies such as [2] , [3] . IV: The statistical (mean and standard deviations) performance metrics are reported from five different runs using the 1D versions of the proposed approaches (CSEN-1D and CL-CSEN-1D) over the KITTI dataset and using different feature extractor networks, \u03c6 : R N \u00d7N \u00d73 \u2192 R d . In the metrics, \u2193:lower is better and \u2191: higher is better.",
            "cite_spans": [
                {
                    "start": 859,
                    "end": 862,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 865,
                    "end": 868,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "V. CONCLUSION"
        },
        {
            "text": "(a) The train:test splits are selected as approximately 1:1 proportion. Finally, we propose a novel CSEN architecture in the CL-CSEN model by introducing the ability to fine-tune the proxy mapping matrix during the training procedure. Therefore, the proposed CL-CSEN method is a complete, one-to-one support estimator network in which the denoiser matrix B is directly connected to the convolutional layers using fully connected dense layers. Thus, it provides a superior distance estimation performance and efficient single-stage inference. Overall, it is observed that CSEN and CL-CSEN architectures significantly outperform the competing methods, SVR, CRC, and SRC. Finally, with their compact network models, we have shown that both CSEN and CL-CSEN are able to learn with a limited number of annotated data, e.g., with less than 13% annotated data used in the training to demonstrate this competence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Plug-and-play: Improve depth prediction via sparse data propagation",
            "authors": [
                {
                    "first": "T.-H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "F.-E",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J.-T",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Y.-H",
                    "middle": [],
                    "last": "Tsai",
                    "suffix": ""
                },
                {
                    "first": "W.-C",
                    "middle": [],
                    "last": "Chiu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Int. Conf. Robot. Automat",
            "volume": "",
            "issn": "",
            "pages": "5880--5886",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Disnet: a novel method for distance estimation from monocular camera",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Haseeb",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Risti\u0107-Durrant",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gr\u00e4ser",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Workshop Plann., Percept. Navig. Intell. Veh",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Learning object-specific distance from a monocular image",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. IEEE Int. Conf. Comput. Vision",
            "volume": "",
            "issn": "",
            "pages": "3839--3848",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Unsupervised learning of depth and ego-motion from monocular video using 3d geometric constraints",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mahjourian",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wicke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Angelova",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. IEEE Conf. Comput. Vision Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "5667--5675",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Depth prediction without the sensors: Leveraging structure for unsupervised learning from monocular videos",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Casser",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pirk",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mahjourian",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Angelova",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "AAAI Conf. Artif. Intell",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Pyramid stereo matching network",
            "authors": [
                {
                    "first": "J.-R",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "Y.-S",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. IEEE Conf. Comput. Vision Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "5410--5418",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Vision-based detection and distance estimation of micro unmanned aerial vehicles",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "G\u00f6k\u00e7e",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "\u00dc\u00e7oluk",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kalkan",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Sensors",
            "volume": "15",
            "issn": "9",
            "pages": "23--805",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Are we ready for autonomous driving? the kitti vision benchmark suite",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Geiger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Lenz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Urtasun",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proc. IEEE Conf. Comput. Vision Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Imagenet large scale visual recognition challenge",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Russakovsky",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Krause",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Satheesh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karpathy",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bernstein",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. J. Comput. Vision",
            "volume": "115",
            "issn": "3",
            "pages": "211--252",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Robust face recognition via sparse representation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "Y"
                    ],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ganesh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Sastry",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "31",
            "issn": "2",
            "pages": "210--227",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Sparse representation for computer vision and pattern recognition",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mairal",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sapiro",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proc. IEEE",
            "volume": "98",
            "issn": "",
            "pages": "1031--1044",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Sparse representation or collaborative representation: Which helps face recognition",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proc. IEEE Int. Conf. Comput. Vision",
            "volume": "",
            "issn": "",
            "pages": "471--478",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. IEEE Conf. Comput. Vision and Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc. IEEE Conf. Comput. Vision and Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Convolutional sparse support estimator network (csen) from energy efficient support estimation to learning-aided compressive sensing",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yamac",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahishali",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiranyaz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gabbouj",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.00768"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Advance warning methodologies for covid-19 using chest x-ray images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahishali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Degerli",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yamac",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiranyaz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hameed",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Hamid",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mazhar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gabbouj",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Access",
            "volume": "9",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Convolutional sparse support estimator-based covid-19 recognition from x-ray images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yama\u00e7",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahishali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Degerli",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiranyaz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gabbouj",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "volume": "32",
            "issn": "5",
            "pages": "1810--1820",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Optimally sparse representation in general (nonorthogonal) dictionaries via l 1 minimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Donoho",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Elad",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Proc. Nat. Acad. Sci",
            "volume": "100",
            "issn": "5",
            "pages": "2197--2202",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Atomic decomposition by basis pursuit",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Donoho",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Saunders",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Soc. Ind. Appl. Math. Rev",
            "volume": "43",
            "issn": "1",
            "pages": "129--159",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The restricted isometry property and its implications for compressed sensing",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Candes",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Comptes Rendus Math",
            "volume": "346",
            "issn": "9",
            "pages": "589--592",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "The sampling rate-distortion tradeoff for sparsity pattern recovery in compressed sensing",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Reeves",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gastpar",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "58",
            "issn": "5",
            "pages": "3065--3092",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Necessary and sufficient conditions for sparsity pattern recovery",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Fletcher",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rangan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Goyal",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "55",
            "issn": "12",
            "pages": "5758--5772",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Amp-inspired deep networks for sparse linear inverse problems",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Borgerding",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Schniter",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rangan",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Signal Process",
            "volume": "65",
            "issn": "16",
            "pages": "4293--4308",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Learning sparse representations for human action recognition",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Guha",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Ward",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "34",
            "issn": "8",
            "pages": "1576--1588",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A survey on representation-based classification and detection in hyperspectral remote sensing imagery",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Pattern Recognit. Lett",
            "volume": "83",
            "issn": "",
            "pages": "115--123",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "A probabilistic and ripless theory of compressed sensing",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Candes",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Plan",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "57",
            "issn": "11",
            "pages": "7235--7254",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Information-theoretic bounds on sparsity recovery in the high-dimensional and noisy setting",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wainwright",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "IEEE Int. Symp. Inf. Theory",
            "volume": "",
            "issn": "",
            "pages": "961--965",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Informationtheoretic limits on sparse support recovery: Dense versus sparse measurements",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Wainwright",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ramchandran",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE Int. Symp. Inf. Theory",
            "volume": "",
            "issn": "",
            "pages": "2197--2201",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Nearly sharp sufficient conditions on exact sparsity pattern recovery",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Rad",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "57",
            "issn": "7",
            "pages": "4672--4679",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Limits on support recovery with probabilistic models: An information-theoretic framework",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Scarlett",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Cevher",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "63",
            "issn": "1",
            "pages": "593--620",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Sampling bounds for sparse support recovery in the presence of noise",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Reeves",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gastpar",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE Int. Symp. Inf. Theory",
            "volume": "",
            "issn": "",
            "pages": "2187--2191",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Approximate sparsity pattern recovery: Information-theoretic lower bounds",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Reeves",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Gastpar",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Trans. Inf. Theory",
            "volume": "59",
            "issn": "6",
            "pages": "3451--3465",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Adam: A method for stochastic optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Tensorflow: A system for large-scale machine learning",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Abadi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Barham",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Davis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dean",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Devin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ghemawat",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Irving",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Isard",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "USENIX Symp. Operating Syst. Des. Implementation",
            "volume": "",
            "issn": "",
            "pages": "265--283",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Boyd",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Peleato",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Eckstein",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Found. Trends Mach. Learn",
            "volume": "3",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Fast l 1 -minimization algorithms for robust face recognition",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "Y"
                    ],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Balasubramanian",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Sastry",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Trans. Image Process",
            "volume": "22",
            "issn": "8",
            "pages": "3234--3246",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Homotopy continuation for sparse signal representation",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Malioutov",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cetin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Willsky",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proc. IEEE Int. Conf. Acoust., Speech, and Signal Process",
            "volume": "5",
            "issn": "",
            "pages": "733--736",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Gradient projection for sparse reconstruction: Application to compressed sensing and other inverse problems",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Figueiredo",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "D"
                    ],
                    "last": "Nowak",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Wright",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "IEEE J. Sel. Topics Signal Process",
            "volume": "1",
            "issn": "4",
            "pages": "586--597",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "An interior-point method for largescale l 1 -regularized logistic regression",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Koh",
                    "suffix": ""
                },
                {
                    "first": "S.-J",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Boyd",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "J. Mach. Learn. Res",
            "volume": "8",
            "issn": "",
            "pages": "1519--1555",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "l 1 -magic: Recovery of sparse signals via convex programming",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Candes",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Romberg",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Caltech, Tech. Rep",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Using the nystr\u00f6m method to speed up kernel machines",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Seeger",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Proc. 14th Annu. Conf. Neural Inf. Process. Syst",
            "volume": "",
            "issn": "",
            "pages": "682--688",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Nystr\u00f6m method vs random fourier features: A theoretical and empirical comparison",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Y.-F",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mahdavi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "Z.-H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Adv. Neural Inf. Process. Syst",
            "volume": "25",
            "issn": "",
            "pages": "476--484",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "[22],x LM M SE = D T D + \u03bbI n\u00d7n \u22121 D T y and Maximum Correlation (MC) [23],x M C = D T y, and (iii) Deep Neural Networks.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The proposed framework for the object distance estimation is based on representation-based classification methodologies including Sparse Representation-based Classification (SRC) and Collaborative Representation-based Classification (CRC). The output class estimation yields the quantized estimated distance.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The proposed framework for the object distance estimation based on Convolutional Support Estimator Networks (CSEN). The modified CSEN performs regression over the estimated support sets using the reshaped proxy signalx = By where B = D T D + \u03bbI \u22121 D T .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The proposed Compressive Learning CSEN (CL-CSEN) framework that jointly optimizes proxy mapping with support estimation and regression parts during the training.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Two sample frames from KITTI 3D Object Detection showing overlapped samples.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Three sample frames are shown with the object bounding boxes and their corresponding ground-truth distances (GTD) in the first row: (a), (b), and (c). Then, the estimated distances for the objects by the three best-performing methods in this work: SVR, CSEN, and CL-CSEN are illustrated in the second (d -e -f), third (g -h -i), and the last (j -k -l) rows, respectively. The approximate 1:1 ratio is followed in train:test splits.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": ", we have applied quantization to the training and testing samples of the CSEN and CL-CSEN approaches as previously discussed. Even though they can be",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "6823 \u00b1 0.077 12.5880 \u00b1 0.092 1.1247 \u00b1 0.018 0.4641 \u00b1 0.003 0.6432 \u00b1 0.007 0.7166 \u00b1 0.009 the CSEN model has only a few thousand trainable parameters since the denoiser matrix B is not trainable, whereas in the CL-CSEN model, depending on the size of B the trainable parameters vary. Nevertheless, both are still compact architectures only with a few layers. The elapsed times are reported in Table IIIb on the aforementioned PC setup. On the other hand, SRC methods suffer drastic time complexity whereas elapsed times for CSEN and CL-CSEN methods are comparable with",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The number of trainable parameters is given in (a) for the proposed CSEN and CL-CSEN models. The elapsed times using the aforementioned PC setup are given in (b) for the methods.(a) The trainable parameters using different feature extractors \u03c6. \u03c6 : R N \u00d7N \u00d73 \u2192 R d (b) Average elapsed times in milliseconds (ms) for the estimation of a test object sample. The given computational times are obtained in the case of ResNet-50 features.computationally efficient because CRC-light and CRC require additional residual finding step that was explained in Section II-B.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "The train:test splits are selected as approximately 1:17 proportion and the distance sensitivity (with quantization) is 1m.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}