{
    "paper_id": "690017153ba3303033cfac7f4677471f474d9097",
    "metadata": {
        "title": "Atomic model validation using the CCP-EM software suite",
        "authors": [
            {
                "first": "Agnel",
                "middle": [],
                "last": "Praveen",
                "suffix": "",
                "affiliation": {},
                "email": "agnel-praveen.joseph@stfc.ac.uk"
            },
            {
                "first": "Joseph",
                "middle": [],
                "last": "",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Mateusz",
                "middle": [],
                "last": "Olek",
                "suffix": "",
                "affiliation": {
                    "laboratory": "United Kingdom, and c Electron BioImaging Center, Diamond Light Source, Rutherford Appleton Laboratory",
                    "institution": "University of York",
                    "location": {
                        "settlement": "York, Didcot",
                        "country": "United Kingdom. *Correspondence"
                    }
                },
                "email": ""
            },
            {
                "first": "Sony",
                "middle": [],
                "last": "Malhotra",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Peijun",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Kevin",
                "middle": [],
                "last": "Cowtan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "United Kingdom, and c Electron BioImaging Center, Diamond Light Source, Rutherford Appleton Laboratory",
                    "institution": "University of York",
                    "location": {
                        "settlement": "York, Didcot",
                        "country": "United Kingdom. *Correspondence"
                    }
                },
                "email": ""
            },
            {
                "first": "Tom",
                "middle": [],
                "last": "Burnley",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Martyn",
                "middle": [
                    "D"
                ],
                "last": "Winn",
                "suffix": "",
                "affiliation": {},
                "email": "martyn.winn@stfc.ac.uk"
            }
        ]
    },
    "abstract": [
        {
            "text": "Recently, there has been a dramatic improvement in the quality and quantity of data derived using cryogenic electron microscopy (cryo-EM). This is also associated with a large increase in the number of atomic models built. Although the best resolutions that are achievable are improving, often the local resolution is variable, and a significant majority of data are still resolved at resolutions worse than 3 \u00c5 . Model building and refinement is often challenging at these resolutions, and hence atomic model validation becomes even more crucial to identify less reliable regions of the model. Here, a graphical user interface for atomic model validation, implemented in the CCP-EM software suite, is presented. It is aimed to develop this into a platform where users can access multiple complementary validation metrics that work across a range of resolutions and obtain a summary of evaluations. Based on the validation estimates from atomic models associated with cryo-EM structures from SARS-CoV-2, it was observed that models typically favor adopting the most common conformations over fitting the observations when compared with the model agreement with data. At low resolutions, the stereochemical quality may be favored over data fit, but care should be taken to ensure that the model agrees with the data in terms of resolvable features. It is demonstrated that further rerefinement can lead to improvement of the agreement with data without the loss of geometric quality. This also highlights the need for improved resolutiondependent weight optimization in model refinement and an effective test for overfitting that would help to guide the refinement process. research papers Acta Cryst. (2022). D78, 152-161 Agnel Praveen Joseph et al. Validation using CCP-EM 153 research papers Acta Cryst. (2022). D78, 152-161 Agnel Praveen Joseph et al. Validation using CCP-EM 155",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Over the last decade, there has been a rapid increase in the number of structures solved using cryogenic electron microscopy (cryo-EM; Callaway, 2020; Subramaniam, 2019; K\u00fc hlbrandt, 2014) . The resolution of cryo-EM reconstructions has also improved significantly, thanks to technological advances in sample imaging and software for map reconstruction. Currently, the best resolution achieved is 1.15 \u00c5 (Yip et al., 2020) and efforts are ongoing to determine cryo-EM reconstructions at atomic resolutions (Nakane et al., 2020) . Nevertheless, nearly 40% of all reconstructions deposited in the Electron Microscopy Data Bank (EMDB; Patwardhan, 2017) are in the resolution range 3-5 \u00c5 and about 48% are at worse than 5 \u00c5 .",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 150,
                    "text": "Callaway, 2020;",
                    "ref_id": null
                },
                {
                    "start": 151,
                    "end": 169,
                    "text": "Subramaniam, 2019;",
                    "ref_id": null
                },
                {
                    "start": 170,
                    "end": 188,
                    "text": "K\u00fc hlbrandt, 2014)",
                    "ref_id": null
                },
                {
                    "start": 404,
                    "end": 422,
                    "text": "(Yip et al., 2020)",
                    "ref_id": null
                },
                {
                    "start": 506,
                    "end": 527,
                    "text": "(Nakane et al., 2020)",
                    "ref_id": null
                },
                {
                    "start": 632,
                    "end": 649,
                    "text": "Patwardhan, 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The need for cryo-EM map and model validation has been recognized in recent years (Afonine et al., 2018; Rosenthal & Rubinstein, 2015; Lawson et al., 2021) , and the EMDR (EMDataResource) map and model challenges (Lawson et al., 2021; Lawson & Chiu, 2018) have played a very useful role in comparing existing validation metrics, identifying new requirements and providing data sets for further developments. ISSN 2059-7983 EM targets have been included in the CASP (Critical Assessment of Protein Structure Prediction) competition since round 13, and the community is invited to submit atomic models for cryo-EM targets (Kryshtafovych et al., 2019) .",
            "cite_spans": [
                {
                    "start": 82,
                    "end": 104,
                    "text": "(Afonine et al., 2018;",
                    "ref_id": null
                },
                {
                    "start": 105,
                    "end": 134,
                    "text": "Rosenthal & Rubinstein, 2015;",
                    "ref_id": null
                },
                {
                    "start": 135,
                    "end": 155,
                    "text": "Lawson et al., 2021)",
                    "ref_id": null
                },
                {
                    "start": 213,
                    "end": 234,
                    "text": "(Lawson et al., 2021;",
                    "ref_id": null
                },
                {
                    "start": 235,
                    "end": 255,
                    "text": "Lawson & Chiu, 2018)",
                    "ref_id": null
                },
                {
                    "start": 408,
                    "end": 422,
                    "text": "ISSN 2059-7983",
                    "ref_id": null
                },
                {
                    "start": 620,
                    "end": 648,
                    "text": "(Kryshtafovych et al., 2019)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Atomic model assessment and validation span different aspects, including model geometry, fit to data, tests for overfitting and model bias. Approaches that evaluate stereochemical properties of the atomic model, such as MolProbity (Williams, Headd et al., 2018) and CaBLAM (Prisant et al., 2020) , PROCHECK (Laskowski et al., 1993) and WHAT_ CHECK (Hooft et al., 1996) , aim to detect potential issues with the geometry of the model by assessing stereochemical properties and comparison with expected standards. Outliers should ideally be fixed where possible prior to automated model refinement . The Ramachandran Z-score (Sobolev et al., 2020; Hooft et al., 1997 ) is very useful for detecting an 'unusual' '/ dihedral distribution in the model, which is often caused by refinement approaches that overfit the backbone '/ angles to the centroid of allowed Ramachandran space. Another set of methods evaluate each residue in the atomic model based on the local structural neighborhood (Eisenberg et al., 1997; Sippl, 1993) , which is especially useful to detect errors in the sequence register.",
            "cite_spans": [
                {
                    "start": 231,
                    "end": 261,
                    "text": "(Williams, Headd et al., 2018)",
                    "ref_id": null
                },
                {
                    "start": 273,
                    "end": 295,
                    "text": "(Prisant et al., 2020)",
                    "ref_id": null
                },
                {
                    "start": 307,
                    "end": 331,
                    "text": "(Laskowski et al., 1993)",
                    "ref_id": null
                },
                {
                    "start": 348,
                    "end": 368,
                    "text": "(Hooft et al., 1996)",
                    "ref_id": null
                },
                {
                    "start": 623,
                    "end": 645,
                    "text": "(Sobolev et al., 2020;",
                    "ref_id": null
                },
                {
                    "start": 646,
                    "end": 664,
                    "text": "Hooft et al., 1997",
                    "ref_id": null
                },
                {
                    "start": 986,
                    "end": 1010,
                    "text": "(Eisenberg et al., 1997;",
                    "ref_id": null
                },
                {
                    "start": 1011,
                    "end": 1023,
                    "text": "Sippl, 1993)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "It is also crucial to assess the quality of modeled interfaces between subunits in the cryo-EM-derived assemblies, as they often involve inter-subunit steric clashes, loose interface packing etc. . A recently published score, the Protein Interface score (PI-score), is a metric which can help to distinguish 'native-like' interfaces at low-to-intermediate resolution .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The most common metric used to quantify agreement of the atomic model with the cryo-EM map is the cross-correlation coefficient (CCC; Volkmann & Hanein, 1999; Roseman, 2000; Rossmann, 2000) . In Fourier space, the correlation calculated in each resolution shell (Fourier shell correlation; FSC) reflects the agreement of features at each resolution (Brown et al., 2015) . Several other metrics have been tested (Afonine et al., 2018; Joseph et al., 2017; Ram\u00edrez-Aportela et al., 2021) and some were found to perform better than others in different resolution ranges and at different degrees of overlap . With data resolution becoming better, multiple methods have been developed to evaluate the agreement with the map at the residue level. The local agreement is either quantified as the real-space CCC in the Phenix local CCC (Afonine et al., 2018) , the Manders' overlap coefficient in SMOC (Joseph et al., 2016) or a score of atomic resolvability in map Q (Pintilie et al., 2020) . The absolute values of most of these metrics vary with the map resolution (Lawson et al., 2021) . The recently introduced FSC-Q score applies normalization to the local FSC to account for local resolution variation (Ram\u00edrez-Aportela et al., 2021) .",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 158,
                    "text": "Volkmann & Hanein, 1999;",
                    "ref_id": null
                },
                {
                    "start": 159,
                    "end": 173,
                    "text": "Roseman, 2000;",
                    "ref_id": null
                },
                {
                    "start": 174,
                    "end": 189,
                    "text": "Rossmann, 2000)",
                    "ref_id": null
                },
                {
                    "start": 349,
                    "end": 369,
                    "text": "(Brown et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 411,
                    "end": 433,
                    "text": "(Afonine et al., 2018;",
                    "ref_id": null
                },
                {
                    "start": 434,
                    "end": 454,
                    "text": "Joseph et al., 2017;",
                    "ref_id": null
                },
                {
                    "start": 455,
                    "end": 485,
                    "text": "Ram\u00edrez-Aportela et al., 2021)",
                    "ref_id": null
                },
                {
                    "start": 828,
                    "end": 850,
                    "text": "(Afonine et al., 2018)",
                    "ref_id": null
                },
                {
                    "start": 894,
                    "end": 915,
                    "text": "(Joseph et al., 2016)",
                    "ref_id": null
                },
                {
                    "start": 960,
                    "end": 983,
                    "text": "(Pintilie et al., 2020)",
                    "ref_id": null
                },
                {
                    "start": 1060,
                    "end": 1081,
                    "text": "(Lawson et al., 2021)",
                    "ref_id": null
                },
                {
                    "start": 1201,
                    "end": 1232,
                    "text": "(Ram\u00edrez-Aportela et al., 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Another set of metrics evaluate whether atoms in the model are positioned within the molecular contour of the map. The atom-inclusion score (Lagerstedt et al., 2013) implemented as part of the EMDB validation analysis pages identifies residues that are outside the author-recommended contour of the map. More recently, we developed a tool for assessing the backbone atom positions in the map ) based on the false-discovery rate-control approach for segregating background noise from molecular volume at a range of resolutions (Beckers et al., 2019) .",
            "cite_spans": [
                {
                    "start": 140,
                    "end": 165,
                    "text": "(Lagerstedt et al., 2013)",
                    "ref_id": null
                },
                {
                    "start": 526,
                    "end": 548,
                    "text": "(Beckers et al., 2019)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Some of the metrics used for model assessment are intrinsically optimized by automated model-refinement approaches, and hence the use of multiple and/or independent metrics is recommended for validation purposes. Atomic model-building and refinement approaches aim to maximize the agreement with map data while satisfying restraints on geometry (Afonine et al., 2018; Nicholls et al., 2018) . Relative weights for geometry and fit to data are often estimated automatically depending on the data quality. Ideally, the estimated weights are expected to result in an optimal fit to data without overfitting and distorting geometry. Here, we assess the stereochemical quality and fit to data of the deposited models in order to better understand the effect of weights estimated in refinement.",
            "cite_spans": [
                {
                    "start": 345,
                    "end": 367,
                    "text": "(Afonine et al., 2018;",
                    "ref_id": null
                },
                {
                    "start": 368,
                    "end": 390,
                    "text": "Nicholls et al., 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Overfitting is an important factor to consider while trying to optimize the model fit to map. Over the years, several approaches for cross-validation have been proposed to detect overfitting (DiMaio et al., 2013; Falkner & Schr\u00f6 der, 2013; Cossio, 2020; Brown et al., 2015) . However, the requirement for a sufficiently large independent data set has been the primary factor limiting the development of a standardized cross-validation approach, as R free is for X-ray crystallography (Br\u00fc nger, 1992) .",
            "cite_spans": [
                {
                    "start": 191,
                    "end": 212,
                    "text": "(DiMaio et al., 2013;",
                    "ref_id": null
                },
                {
                    "start": 213,
                    "end": 239,
                    "text": "Falkner & Schr\u00f6 der, 2013;",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 240,
                    "end": 253,
                    "text": "Cossio, 2020;",
                    "ref_id": null
                },
                {
                    "start": 254,
                    "end": 273,
                    "text": "Brown et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 484,
                    "end": 500,
                    "text": "(Br\u00fc nger, 1992)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Here, we describe a user-friendly graphical interface which aims to integrate multiple tools for validation that are complementary and/or work on different resolution ranges. The interface is provided as a task within the Collaborative Computational Project for Electron cryo-Microscopy (CCP-EM) software suite (Burnley et al., 2017) . We also discuss trends from the validation of atomic models determined from SARS-CoV-2 and demonstrate the importance of model agreement with data with the help of a few examples.",
            "cite_spans": [
                {
                    "start": 311,
                    "end": 333,
                    "text": "(Burnley et al., 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The CCP-EM software suite incorporates a range of functionalities for structure solution under different user interfaces. The atomic model-validation interface (Validation: model) in CCP-EM currently integrates multiple tools and metrics that evaluate the geometry of the model and the fit to data. The minimal input for the interface is an atomic model(s) in PDB or mmCIF format that needs to be evaluated for geometry. Computation of scores that quantify the fit to data requires a map and its global resolution as additional inputs (Fig. 1a) . Before calculating the fit-to-data scores, ensure that the model coordinates align with the map grid. Tools for assessing the map quality are not included in this task, but can be found elsewhere in the CCP-EM software suite.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 535,
                    "end": 544,
                    "text": "(Fig. 1a)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Atomic model-validation task in CCP-EM"
        },
        {
            "text": "The fit-to-data metrics that are part of the task (see below) are sensitive to one or more of the map-processing techniques, including sharpening, filtering, denoising and masking. For a well fitted model, reducing the noise and artifacts (for example from tight masks or over-sharpening) while preserving the signal should ideally improve the fit-to-data scores. Densitymodification approaches have been shown to help with refinement and to improve the agreement between the model and map (Terwilliger et al., 2020; Sanchez-Garcia et al., 2021; Jakobi et al., 2017) . When using post-processed maps as input, we recommend a careful inspection of the map prior to model validation. Comparison with scores calculated against the raw map might also help to understand any significant effects of post-processing. To compute the FDR-backbone score (see Section 2.2.2), an unmasked input map is required.",
            "cite_spans": [
                {
                    "start": 490,
                    "end": 516,
                    "text": "(Terwilliger et al., 2020;",
                    "ref_id": null
                },
                {
                    "start": 517,
                    "end": 545,
                    "text": "Sanchez-Garcia et al., 2021;",
                    "ref_id": null
                },
                {
                    "start": 546,
                    "end": 566,
                    "text": "Jakobi et al., 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Atomic model-validation task in CCP-EM"
        },
        {
            "text": "The user interface includes graphical tabs allowing access to input parameters, program logs, output files and results. Under the 'Results' tab the results are presented for both global and local assessment of the model (Fig. 1b) . It is important to ensure that the atomic B factors of the model are refined, as the features of the calculated map are affected by the atomic B factors. Hence, the scores may vary significantly depending on whether or not the model B factors are refined. A plot of the atomic B-factor distribution is provided in the output, and a warning message is displayed when multiple peaks are detected in the distribution. Multiple peaks might indicate partial occupancies or large domain motions, but can also point to inconsistencies in the atomic B-factor refinement. The theoretical map calculation from the map is performed using REFMAC5 (Nicholls et al., 2018) by default. If it is turned off, then TEMPy global scores use a more simplistic Gaussian approximation of atoms for map calculation. More systematic approaches for evaluating atomic B-factor distributions have recently been developed (Masmaliyeva et al., 2020) and we plan to integrate such approaches in the future.",
            "cite_spans": [
                {
                    "start": 867,
                    "end": 890,
                    "text": "(Nicholls et al., 2018)",
                    "ref_id": null
                },
                {
                    "start": 1125,
                    "end": 1151,
                    "text": "(Masmaliyeva et al., 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 220,
                    "end": 229,
                    "text": "(Fig. 1b)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Atomic model-validation task in CCP-EM"
        },
        {
            "text": "The validation tools that are currently part of the validation interface are listed in Sections 2.1 and 2.2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Atomic model-validation task in CCP-EM"
        },
        {
            "text": "MolProbity (Williams, Headd et al., 2018) provides statistics on the quality of bonds, angles and dihedrals and serious atomic clashes. Outliers are detected by comparison to standard or expected distributions of geometric parameters. Outlier types include Ramachandran map outliers, rotamer outliers, serious clashes (clashscore), C deviations, cispeptides and bond-length/angle and dihedral outliers. It is important to ensure that the outliers in the model are justified by the data. The outliers, when present, are often very relevant in terms of the structure stabilization and/or function of the protein.",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 41,
                    "text": "(Williams, Headd et al., 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Model geometry"
        },
        {
            "text": "MolProbity reports a single score (MolProbity score) which is a weighted combination of clashscore and the percentage of residues in the favorable region of the Ramachandran plot and rotamer outliers. Lower values of the MolProbity score reflect better geometry. For crystal structures, a score lower than the crystallographic resolution suggests that the model is better than other structures at this resolution (AE0.25 \u00c5 ) on average. Percentiles associated with clashscore and the MolProbity score are also provided to place the model relative to other structures in this resolution range. For a correct interpretation of the percentiles, it is important to ensure that the PDB file header holds the information on data resolution.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Model geometry"
        },
        {
            "text": "CaBLAM (Prisant et al., 2020; Richardson et al., 2018; provides statistics on backbone quality based on pseudo-dihedrals consisting of consecutive C atoms and peptide carbonyls. Outliers are detected based on the position in the pseudo-dihedral space formed by the distribution observed in structures at similar resolutions. In general, a model is expected to have less than 5% CaBLAM outliers. CaBLAM is particularly useful for lower resolutions, and it is less prone to being refined against.",
            "cite_spans": [
                {
                    "start": 7,
                    "end": 29,
                    "text": "(Prisant et al., 2020;",
                    "ref_id": null
                },
                {
                    "start": 30,
                    "end": 54,
                    "text": "Richardson et al., 2018;",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Model geometry"
        },
        {
            "text": "PI-score is a metric that evaluates subunit interfaces in the atomic model and is map-independent. The method computes the PI-score for all of the interfaces present in the input structure and detects potential outliers based on a score cutoff of \u00c00.5 (as recommended by the authors). The chains forming the interfaces identified as outliers are listed in a table under the 'Global' results tab. The residues associated with the interface identified as an outlier are also provided as a table under the 'Local' outlier tab. Implementation of this score is included in the latest CCP-EM nightly release.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Model geometry"
        },
        {
            "text": "Both global and local (outliers) statistics from MolProbity and CaBLAM are included in the Results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Model geometry"
        },
        {
            "text": "An atomic model is expected to provide the best representation of experimental data and any interpretations based on the atomic model are also supported by the data. Hence, it is very important to assess the agreement of the model with the data. The model-validation interface in CCP-EM integrates approaches that provide both global and local evaluation of the structures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fit to map"
        },
        {
            "text": "2.2.1. Global fit to map. REFMAC5 is used to calculate the model-map Fourier shell correlation (FSC) between a theoretical map calculated from the atomic model and the experimental map ( Figs. 1b and 3c ). An FSCavg score is derived from the model-map FSC curve by calculating an average of the FSC weighted by the number of structure factors in each shell (Brown et al., 2015) up to the reported resolution limit. Although higher FSCavg values reflect a better fit, it is necessary to check whether the model starts overfitting to noise. Brown et al. (2015) proposed an approach to estimate model overfitting by comparing modelmap FSCs calculated on half maps. The validation interface supports the input of other independent maps for comparing the fit-to-data scores. This is useful as a test for overfitting if the refinement is carried out in one (half) map and an independent additional map input (for example the other half map) can be used to compare the model-validation scores.",
            "cite_spans": [
                {
                    "start": 357,
                    "end": 377,
                    "text": "(Brown et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 539,
                    "end": 558,
                    "text": "Brown et al. (2015)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 187,
                    "end": 202,
                    "text": "Figs. 1b and 3c",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Fit to map"
        },
        {
            "text": "TEMPy (Cragnolini et al., 2021; Farabella et al., 2015) is used to calculate the extent of model-map overlap (OV), realspace cross-correlation coefficient (CCC) and mutual information (MI) scores Figs. 1b and 3d) . A map contour threshold is applied prior to computation of these scores. Users can provide a threshold for contouring the map, which is recommended. The contour level should ideally cover the molecular volume or mask out the background. The choice of contour level is often subjective and for the maps deposited in the EMDB authors often provide a 'recommended contour level'. The 'Confidence map' tool in the CCP-EM software package can be used to automatically identify voxels covering the molecular volume (Beckers et al., 2019) . By default, a level corresponding to 1.5 from the background peak is used as the contour threshold. When three or more models are supplied as input, combined scores that integrate both CCC and MI with extent of overlap (CCC_OV and MI_OV; described in Joseph et al., 2017) are also calculated. These scores make use of the score distribution to rescale the individual scores before combining them; hence, the calculation requires more than two models.",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 31,
                    "text": "(Cragnolini et al., 2021;",
                    "ref_id": null
                },
                {
                    "start": 32,
                    "end": 55,
                    "text": "Farabella et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 196,
                    "end": 212,
                    "text": "Figs. 1b and 3d)",
                    "ref_id": null
                },
                {
                    "start": 724,
                    "end": 746,
                    "text": "(Beckers et al., 2019)",
                    "ref_id": null
                },
                {
                    "start": 1000,
                    "end": 1020,
                    "text": "Joseph et al., 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Fit to map"
        },
        {
            "text": "2.2.2. Local fit to map. TEMPy is also used to calculate a segment-based Manders' overlap coefficient (SMOC) score that quantifies the per-residue agreement between a theoretical map derived from the atomic model and the experimental map (Joseph et al., 2016) . To identify outliers or potential misfits, we compute a Z-score for each residue relative to the local neighborhood (residues within 12 \u00c5 ). Residues associated with Z-scores of <\u00c01.5 are identified as potential outliers.",
            "cite_spans": [
                {
                    "start": 238,
                    "end": 259,
                    "text": "(Joseph et al., 2016)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Fit to map"
        },
        {
            "text": "The confidence-map tool developed by Beckers et al. (2019) is used to assess the coordinate positions of backbone atoms in the model . The backbone validation score reflects whether the residue backbone is traced in the molecular volume or background noise. An unmasked map is required as input for the successful computation of this score. This score was demonstrated to be complementary to other existing scores that quantify model agreement with maps. Residues associated with scores lower than 0.9 usually require attention and are designated as outliers. Implementation of this score is included in the latest CCP-EM nightly release. Supplementary Fig. S2 shows an example from the EMDB Model Challenge 2019 (Lawson et al., 2021) where the FDRbackbone score detects potential issues with the backbone trace.",
            "cite_spans": [
                {
                    "start": 37,
                    "end": 58,
                    "text": "Beckers et al. (2019)",
                    "ref_id": null
                },
                {
                    "start": 713,
                    "end": 734,
                    "text": "(Lawson et al., 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 639,
                    "end": 660,
                    "text": "Supplementary Fig. S2",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Fit to map"
        },
        {
            "text": "JPred4 is used to predict the secondary structure from the sequence of the protein chain (Drozdetskiy et al., 2015) . The high-confidence predictions for helical and strand conformations are then compared against the secondary-structure type observed in the atomic model as assigned using DSSP (Kabsch & Sander, 1983) . Mismatches are reported as outliers, although it is important to note that the accuracy of the prediction from sequence is only about 80-85% (Buchan & Jones, 2019; Drozdetskiy et al., 2015; Yang et al., 2018) . Hence, we recommend prioritizing cases where there is low agreement with the map (outliers based on fit-to-data metrics) and a mismatch with the secondary-structure prediction from the sequence. In this case, it is possible that the modeled secondary structure is incorrect and needs to be fixed.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 115,
                    "text": "(Drozdetskiy et al., 2015)",
                    "ref_id": null
                },
                {
                    "start": 294,
                    "end": 317,
                    "text": "(Kabsch & Sander, 1983)",
                    "ref_id": null
                },
                {
                    "start": 461,
                    "end": 483,
                    "text": "(Buchan & Jones, 2019;",
                    "ref_id": null
                },
                {
                    "start": 484,
                    "end": 509,
                    "text": "Drozdetskiy et al., 2015;",
                    "ref_id": null
                },
                {
                    "start": 510,
                    "end": 528,
                    "text": "Yang et al., 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Fit to map"
        },
        {
            "text": "In the CCP-EM model-validation interface, per-residue SMOC and FDR-backbone scores are provided as a plot under the local tab, and outliers identified are also highlighted (Fig. 1c) . Table 1 gives a summary of tools currently accessible from the validation task.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 172,
                    "end": 181,
                    "text": "(Fig. 1c)",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 184,
                    "end": 191,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Fit to map"
        },
        {
            "text": "Often, atomic models derived from cryo-EM data are associated with a large number of outliers that arise from different metrics and are distributed across the structure. To highlight specific structural regions with the most serious issues, we cluster outliers with C atoms that are within 7 \u00c5 of each other and provide a summary table with a list of clusters ordered by cluster size (a validation 'to-do' list). Users can proceed with examining the outliers in Coot (Emsley et al., 2010) by clicking the button at the bottom of the Results page (Fig. 2a) . This opens the model and map in Coot along with the list of outlier clusters (Fig. 2b) . The issues can be fixed interactively in Coot and flagged as complete when each residue is fixed.",
            "cite_spans": [
                {
                    "start": 467,
                    "end": 488,
                    "text": "(Emsley et al., 2010)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 546,
                    "end": 555,
                    "text": "(Fig. 2a)",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 635,
                    "end": 644,
                    "text": "(Fig. 2b)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Outlier clusters"
        },
        {
            "text": "Access to MolProbity, CaBLAM and REFMAC5 via the CCP-EM interface currently requires installation of the CCP4 software suite .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Outlier clusters"
        },
        {
            "text": "3.1. Assessment using the CCP-EM model-validation task A set of 298 models derived from cryo-EM structures from SARS-CoV-2 were available in the PDB at the end of March 2021. We filtered out models for which the coordinates do not overlap with the map, reflecting potential issues with the relative positioning of the map (grid origin) and model coordinates in space (20/298). This resulted in a set of 278 models that were assessed using the validation suite.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assessment of cryo-EM structures from SARS-CoV-2"
        },
        {
            "text": "75% of the data set corresponded to models derived from maps resolved at worse than 3.0 \u00c5 resolution. 44% of the models had MolProbity scores better than 1.5 (Fig. 3a) and 36% had no Ramachandran outliers. A MolProbity score of 1.5 reflects that the model is of comparable geometric quality to structures resolved at a crystallographic resolution of 1.5 \u00c5 (Chen et al., 2010) . However, in practice, with refinement approaches becoming better and the addition of new models, this correspondence may not be accurate. Nevertheless, the Table 1 List of tools currently included in the CCP-EM model-validation task. score gives an indication of the quality of the model, which is expected to vary with the data quality. The median of MolProbity scores associated with structures better than 3.0 \u00c5 resolution is 1.53 and the medians of the FSCavg and CCC scores are 0.62 and 0.87, respectively. On the other hand, the median of the MolProbity scores associated with structures worse than 4.0 \u00c5 resolution is 1.54 and the medians of the FSCavg and CCC scores are 0.50 and 0.47, respectively. Clearly, the geometry is heavily restrained by refinement approaches at low resolutions and the (implicit) inclusion of Ramachandran restraints in refinement might have contributed to the absence of Ramachandran outliers in a significant number of models. On the other hand, fit-to-data scores are often poor, particularly for lower resolution structures. To check whether the fit to data can be improved further, we randomly selected 100 models from the data set. The models were then subjected to 20 cycles of local refinement using the REFMAC5 implementation in CCP-EM (Burnley et al., 2017; Nicholls et al., 2018) . In REFMAC5, automated weight estimation (keyword: weight auto) identifies a relative weight (geometry restraints versus fit to data) that maintains the target bond r.m.s.d. within 0.01 and 0.02 \u00c5 . However, as recommended in the REFMAC5 documentation (https:// www2.mrc-lmb.cam.ac.uk/groups/murshudov/content/refmac/ refmac_keywords.html), the relative weight for the data needs to be optimized further for use with cryo-EM maps. New developments in REFMAC (Yamashita et al., 2021) include better weight estimation within the range 0.2-18.0, depending on the resolution and the ratio of model to map volumes.",
            "cite_spans": [
                {
                    "start": 356,
                    "end": 375,
                    "text": "(Chen et al., 2010)",
                    "ref_id": null
                },
                {
                    "start": 1658,
                    "end": 1680,
                    "text": "(Burnley et al., 2017;",
                    "ref_id": null
                },
                {
                    "start": 1681,
                    "end": 1703,
                    "text": "Nicholls et al., 2018)",
                    "ref_id": null
                },
                {
                    "start": 2163,
                    "end": 2187,
                    "text": "(Yamashita et al., 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 158,
                    "end": 167,
                    "text": "(Fig. 3a)",
                    "ref_id": null
                },
                {
                    "start": 534,
                    "end": 541,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Assessment of cryo-EM structures from SARS-CoV-2"
        },
        {
            "text": "From our experience, a relative weight of between 2 and 4 works well at resolutions of 3 \u00c5 or worse. In this study, we used a weight of 3 using the 'weight auto 3' keyword, which sets a relatively lower starting weight of 3. Note that this weight may not be optimal for all maps in the data set and further interactive refinement and error fixes may be required on a case-by-case basis after automated refinement. Nevertheless, we wanted to check whether the automated refinement helps to improve agreement with the data without a significant decline in geometric quality.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assessment of cryo-EM structures from SARS-CoV-2"
        },
        {
            "text": "Using this automated protocol, FSCavg improved in 71% of the re-refined models while 20% had a lower FSCavg score. 34% of the models had both a better FSCavg score and the same or an improved MolProbity score (Fig. 3b) . Where the MolProbity score became worse, the change was not large (less than 0.2 for all but five models), suggesting that the majority of the re-refined models had comparable geometric quality to the respective initial model.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 209,
                    "end": 218,
                    "text": "(Fig. 3b)",
                    "ref_id": null
                }
            ],
            "section": "Assessment of cryo-EM structures from SARS-CoV-2"
        },
        {
            "text": "Hence, the fit to data could be further improved in a significant majority of these cases. Figs. 3(c)-3(e) show an example (PDB entry 7df4) where the FSCavg improved from 0.42 to 0.65, with no significant change in the MolProbity score. The global statistics from the CCP-EM model-validation interface highlight the improvement based on multiple metrics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assessment of cryo-EM structures from SARS-CoV-2"
        },
        {
            "text": "We calculated the FDR-backbone scores for the data set of atomic models associated with cryo-EM structures from SARS-CoV-2. As the confidence-map calculation (Beckers et al., 2019) requires unmasked maps as input, we filtered out maps deposited in EMDB that were post-processed with the application of a mask. The backbone trace of the remaining 199 SARS-CoV-2 models were evaluated using the FDRbackbone score . The FDR-backbone score allows us to easily identify and locate potential issues with backbone tracing in the model. Residues with an FDRbackbone score of lower than 0.9 are potentially misplaced and might require additional refinement. The quality of the model can be represented with an overall FDR-backbone metric, which is calculated as the fraction of residues with a score of higher than 0.9. Fig. 4(a) shows the distribution of the overall FDRbackbone metric. 143 of 199 models have the backbone atoms correctly placed for at least 90% of the residues. 56 models out of 199 had an overall FDR-backbone score of lower than 0.9. Of the 147 models built from maps with reported resolution 3-4 \u00c5 , 37 were associated with an overall FDR-backbone metric of less than 0.9 (Fig. 4b) , reflecting potential issues with the backbone trace. We checked whether further re-refinement could improve the FDR-backbone score. To demonstrate this, we selected a model (PDB entry 7c2l) associated with a low FDR-backbone score of 0.8. A region with several residues with lower FDR-backbone scores (chain C, residues 568-571; Fig. 4c ) was re-refined using the real-space refinement tools in Coot (Sphere and Zone Refine; Emsley et al., 2010; Fig. 4c ). The interactive refinement resulted in an improved fit of the residues in the map, which was also associated with improved Trends of model geometry versus fit to data for 252 deposited SARS-CoV-2 models. In (a) and (b), the points are colored based on the resolution of the map, and the color bar on the right shows the colors with respect to resolution. (a) Distribution of MolProbity scores versus FSCavg. (b) Plot of difference in scores (refined \u00c0 initial) for a random set of 100 models that were re-refined: (c) model-map FSC curves and FSCavg calculated using REFMAC5, (d) table with different scores on fit to data calculated using TEMPy and (e) comparison of MolProbity statistics. FDR-backbone scores, with most residues having a score of 1.0 (Fig. 4d) .",
            "cite_spans": [
                {
                    "start": 158,
                    "end": 169,
                    "text": "(Beckers et",
                    "ref_id": null
                },
                {
                    "start": 1622,
                    "end": 1642,
                    "text": "Emsley et al., 2010;",
                    "ref_id": null
                },
                {
                    "start": 1643,
                    "end": 1650,
                    "text": "Fig. 4c",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 811,
                    "end": 820,
                    "text": "Fig. 4(a)",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 1185,
                    "end": 1194,
                    "text": "(Fig. 4b)",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 1526,
                    "end": 1533,
                    "text": "Fig. 4c",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 2407,
                    "end": 2416,
                    "text": "(Fig. 4d)",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Assessment of backbone tracing"
        },
        {
            "text": "We further assessed the quality of protein interfaces in the fitted models for the SARS-CoV-2 cryo-EM structures. The structures were subjected to quality assessment using the Protein-Interface quality score (PI-score; Malhotra et al., 2021) . PI-score is a machine-learning-based score which uses derived features of the interfaces for training. Here, we have retrained the PI-score machine-learning model without using sequence conservation as one of the derived interface features, as we have previously shown that other features such as shape complementarity were ranked much higher than conservation . The calculation of residue conservation at the interface is a very time-consuming step, as one needs to collect homologs and build a multiple sequence alignment. The model accuracy was not significantly affected when conservation was not used as one of the derived interface features ( Supplementary Fig. S3 ).",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 241,
                    "text": "Malhotra et al., 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 893,
                    "end": 914,
                    "text": "Supplementary Fig. S3",
                    "ref_id": null
                }
            ],
            "section": "Assessment of modeled interfaces"
        },
        {
            "text": "All of the required features to calculate PI-score were successfully calculated for 489 interfaces from 178 SARS-CoV-2 cryo-EMderived structures. These interfaces were then assessed for their interface quality using PI-score. 94% of the interfaces and even those modeled from low-resolution data scored positive, indicating the good-quality interfaces modeled within the cryo-EM structures (Figs. 5a and 5b) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 390,
                    "end": 407,
                    "text": "(Figs. 5a and 5b)",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Assessment of modeled interfaces"
        },
        {
            "text": "We further investigated one of the interfaces which was scored negative (PDB entry 7cac, chains B and E, PI-score = \u00c01.2, resolution 3.55 \u00c5 ). This interface is between the receptor-binding domain of the spike protein (chain B) and the antibody heavy (d) Re-refined structures for chains B and E of PDB entry 7cac, obtained using Coot real-space refinement, show improved shape complementarity of the protein-protein interface. chain (chain E). The interface was scored low on shape complementarity (sc score 0.44; Lawrence & Colman, 1993) and has clashes at the interface (Fig. 5c) . We further re-refined this structure in Coot (Sphere Refine), which helped to resolve some of the clashes and improved the shape-complementarity score (to 0.67; Fig. 5d ). Subsequently, the re-refined structure obtained a positive PI-score of 1.57. In this case, using the CCC and SMOC score calculated on interface residues (iSMOC), one cannot distinguish between the deposited structure (CCC = 0.75 and iSMOC = 0.25) and the re-refined structure (CCC = 0.74 and iSMOC = 0.26), whereas the PI-score can help to locate the errors at the interface. Hence, the PI-score provides complementary validation assessment for protein-protein interfaces which can be very helpful in cases such as these.",
            "cite_spans": [
                {
                    "start": 515,
                    "end": 539,
                    "text": "Lawrence & Colman, 1993)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 573,
                    "end": 582,
                    "text": "(Fig. 5c)",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 746,
                    "end": 753,
                    "text": "Fig. 5d",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Assessment of modeled interfaces"
        },
        {
            "text": "The interface for model validation (Validation:model) is available in the CCP-EM software package, which is downloadable from https://www.ccpem.ac.uk/download.php. Based on the assessment of cryo-EM structures from SARS-CoV-2, we observe a clear bias towards model geometry when compared with agreement with data. Although model geometry may be favored at low resolutions due to the low information content associated with the data, care should be taken to ensure agreement with resolvable features in the map. To this end, there is a need for validation tools that evaluate the quality of low-resolution features of a model and their agreement with the map. This is also relevant for tomogram reconstructions and subtomogram averages from cryo-electron tomography. Currently, there is a lack of a robust test for overfitting that will help with the selection of refinement weights (DiMaio et al., 2013 ) and optimization of model fit to map. In fact, the models currently available from the PDB might benefit from further re-refinement. In this context, efforts such as CERES (Liebschner et al., 2021) and the extension of PDB-REDO (Joosten et al., 2014) to models derived from cryo-EM will be of increasing importance. As most of the cryo-EM reconstructions suffer from variable local resolution, an overall bias towards model geometry will affect fit in the better resolved areas. To address this, local resolutiondependent weight optimization for model refinement would be a good step forward.",
            "cite_spans": [
                {
                    "start": 882,
                    "end": 902,
                    "text": "(DiMaio et al., 2013",
                    "ref_id": null
                },
                {
                    "start": 1077,
                    "end": 1102,
                    "text": "(Liebschner et al., 2021)",
                    "ref_id": null
                },
                {
                    "start": 1133,
                    "end": 1155,
                    "text": "(Joosten et al., 2014)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Availability and future perspectives"
        },
        {
            "text": "The pipeline underlying the validation task has been used to evaluate all cryo-EM structures from SARS-CoV-2 and the results have been deposited in the public repository maintained by the Coronavirus Structure Task Force (Croll et al., 2021) . In this study, we show examples where validation metrics evaluate different features of the model and highlight associated potential issues. These issues were then fixed using interactive refinement in Coot.",
            "cite_spans": [
                {
                    "start": 221,
                    "end": 241,
                    "text": "(Croll et al., 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Availability and future perspectives"
        },
        {
            "text": "The validation task in CCP-EM highlights the crucial areas associated with more serious issues by clustering outliers in space. The interface also provides a way to fix the outlier clusters in Coot. In the future, we plan to expand the validation task with other validation tools including tools for the validation of nucleic acids and carbohydrates. We also aim to include functionality to recalculate these scores from the Coot interface upon fixing the outliers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Availability and future perspectives"
        }
    ],
    "bib_entries": {
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Proc. Natl Acad. Sci. USA",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Falkner",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "F"
                    ],
                    "last": "Schr\u00f6 Der",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "110",
            "issn": "",
            "pages": "8930--8935",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Praveen Joseph et al. Validation using CCP-EM Acta Cryst. (2022). D78, 152-161",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 1",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Model-validation task (Validation:model) interface in the CCP-EM software suite. The task can be accessed from the list of tasks in the main CCP-EM window. The figure shows the 'Setup' and 'Results' tabs of the interface for calculations on the atomic model of hemoglobin (PDB entry 5ni1) derived from a cryo-EM map at 3.2 \u00c5 resolution(Khoshouei et al., 2017).(a) The input setup page lists all input and parameter requirements. Users can choose a selection of assessment tools listed under 'Method Selection'. (b) Global results tab under 'Results' showing a list of sections with global statistics returned by different tools. The atomic B-factor distribution plot is highlighted. (c) Local results tab under 'Results' showing a list of sections with outlier details returned by different tools. A per-residue plot of SMOC and FDR-backbone scores is provided under 'Per-residue scores'. The outlier positions are marked in different colors in this plot.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Praveen Joseph et al. Validation using CCP-EM Acta Cryst. (2022). D78, 152-161",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Joseph et al. Validation using CCP-EM 157",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Summary table with outlier clusters. (a) Local results of the CCP-EM model-validation task, highlighting the table with outliers clustered in space. The clusters are ranked by size and the last row includes all residues that are not part of any cluster. (b) Clicking the orange button at the bottom of the local results page opens the map and the atomic model in Coot and a window with a list of outliers that need fixing, again ordered by clusters.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Praveen Joseph et al. Validation using CCP-EM Acta Cryst. (2022). D78, 152-",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Joseph et al. Validation using CCP-EM 159",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "a) Histogram of the overall FDR-backbone metric from the SARS-CoV-2 data set. (b) Plot of the overall FDR-backbone metric versus resolution. (c) A region of the deposited model (residues 568-571, PDB entry 7c21) colored by the per-residue FDR-backbone scores. (d) The re-refined model colored by the perresidue FDR-backbone scores.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Assessment of modeled interfaces in SARS-CoV2 cryo-EM assemblies. (a) Distribution of PI-score for the SARS-CoV-2 assemblies. (b) Plot of PI-scores (averaged over all interfaces within a structure) against the resolution of the structures. (c) Modeled interface between chain B (spike) and chain E (heavy chain of the antibody) in one of the open-state structures (PDB entry 7cac; 3.55 \u00c5 resolution) which was scored negative.",
            "latex": null,
            "type": "figure"
        }
    },
    "back_matter": [
        {
            "text": "We thank Professor Jane Richardson, Dr Gerard Kleywegt, Professor Maya Topf, Dr Garib Murshudov, Dr Peter Rosenthal, Dr Colin Palmer, Professor Geoff Barton, Dr Jim Procter, Dr Arjen Jakobi, Dr Alan Roseman, Dr Charles Ballard and Professor Elena Orlova for useful discussions on the implementation of the validation task and other aspects of this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements"
        },
        {
            "text": "This work was supported by the Wellcome Trust (research grants 208398/Z/17/Z and 206422/Z/17/Z), MRC Partnership grants (MR/N009614/1 and MR/V000403/1), a BBSRC grant (BB/T012935/1) and a PhD studentship from the University of York and Diamond (eBIC).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Funding information"
        }
    ]
}