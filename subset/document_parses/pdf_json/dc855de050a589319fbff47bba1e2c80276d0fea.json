{
    "paper_id": "dc855de050a589319fbff47bba1e2c80276d0fea",
    "metadata": {
        "title": "A novel social distancing analysis in urban public space: A new online spatio-temporal trajectory approach",
        "authors": [
            {
                "first": "Jie",
                "middle": [],
                "last": "Su",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sichuan University",
                    "location": {
                        "postCode": "610064",
                        "settlement": "Chengdu",
                        "region": "Sichuan",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Xiaohai",
                "middle": [],
                "last": "He",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sichuan University",
                    "location": {
                        "postCode": "610064",
                        "settlement": "Chengdu",
                        "region": "Sichuan",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Linbo",
                "middle": [],
                "last": "Qing",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sichuan University",
                    "location": {
                        "postCode": "610064",
                        "settlement": "Chengdu",
                        "region": "Sichuan",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Tong",
                "middle": [],
                "last": "Niu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sichuan University",
                    "location": {
                        "postCode": "610064",
                        "settlement": "Chengdu",
                        "region": "Sichuan",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Yongqiang",
                "middle": [],
                "last": "Cheng",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Hull",
                    "location": {
                        "postCode": "HU6 7RX",
                        "settlement": "Hull",
                        "country": "United Kingdom"
                    }
                },
                "email": ""
            },
            {
                "first": "Yonghong",
                "middle": [],
                "last": "Peng",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manchester Metropolitan University",
                    "location": {
                        "postCode": "M1 5GD",
                        "settlement": "Manchester",
                        "country": "United Kingdom"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Social distancing in public spaces plays a crucial role in controlling or slowing down the spread of coronavirus during the COVID-19 pandemic. Visual Social Distancing (VSD) offers an opportunity for real-time measuring and analysing the physical distance between pedestrians using surveillance videos in public spaces. It potentially provides new evidence for implementing effective prevention measures of the pandemic. The existing VSD methods developed in the literature are primarily based on frame-by-frame pedestrian detection, addressing the VSD problem from a static and local perspective. In this paper, we propose a new online multi-pedestrian tracking approach for spatio-temporal trajectory and its application to multi-scale social distancing measuring and analysis. Firstly, an online multi-pedestrian tracking method is proposed to obtain the trajectories of pedestrians in public spaces, based on hierarchical data association. Then, a new VSD method based on spatio-temporal trajectories is proposed. The proposed method not only considers the Euclidean distance between tracking objects frame-by-frame but also takes into account the discrete Fr\u00e9chet distance between trajectories, hence forms a comprehensive solution from both static and dynamic, local and holistic perspectives. We evaluated the performance of the proposed tracking method using the public dataset MOT16 benchmark. We also collected our own pedestrian dataset ''SCU-VSD'' and designed a multi-scale VSD analysis scheme for benchmarking the performance of the social distancing monitoring in the crowd. Experiments have demonstrated that the proposed method achieved outstanding performance on the analysis of social distancing. * Corresponding authors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The COVID-19 pandemic is ravaging the world, which has sadly caused a significant loss to human life, and a great negative impact on society and the economy. On 30 January 2020, the World Health Organisation (WHO) declared that the outbreak of COVID-19 constitutes a Public Health Emergency of International Concern (PHEIC) (Statement on the second meeting of the International Health Regulations (2005) Emergency Committee regarding the outbreak of novel coronavirus (2019-nCoV, 2021). On 13 January 2021, it reported that there have been 90,054,813 confirmed cases of COVID-19, including over 1,945,610 deaths globally Dashboard, 2021). The rapid spread of COVID-19 is mainly through close contact from people to people, and asymptomatic carriers can also spread the virus to others (Aguilar, Faust, Westafer, & Gutierrez, 2020) . Due to the high density and mobility of the urban population and the complexity of the urban environment, the spread of the pandemic has been exacerbated to some extent, which brings severe challenges to the construction, governance and sustainable development of cities.",
            "cite_spans": [
                {
                    "start": 385,
                    "end": 403,
                    "text": "Regulations (2005)",
                    "ref_id": null
                },
                {
                    "start": 785,
                    "end": 830,
                    "text": "(Aguilar, Faust, Westafer, & Gutierrez, 2020)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "For the epidemic diseases, measures that are taken to prevent and control infections include vaccination, treatment, quarantine, isolation, and prophylaxis (Dias, Queiroz, & Martins, 2020) . However, the vaccine for has not yet entered the promotion stage, and the more contagious coronavirus variant has been detected. In this scenario, one effective way to control or slow down the spread of coronavirus is to make sure people maintain social distancing in public places. There exists some work in the literature studying the impact of social distancing on the progression of the coronavirus (Cacciapaglia & Sannino, 2020; Dias et al., 2020; Hellewell et al., 2020; Prem et al., 2020; Rahmani & Mirmahaleh, 2020; Sun & Zhai, 2020) . Using Wuhan as a case study, Prem et al. (2020) stated that physical distancing https://doi.org/10.1016/j.scs.2021.102765 Received 22 August 2020; Received in revised form 16 January 2021; Accepted 30 January 2021 based non-pharmacological interventions have a high potential for flattening the peak of COVID-19 and reducing the overall number of cases. Cacciapaglia and Sannino (2020) demonstrated that social distancing measures are more efficient than border control in delaying the epidemic peak. Sun and Zhai (2020) researched the efficacy of social distancing and ventilation effectiveness in preventing transmission. With the current epidemic unlikely to end in the short term, keeping a safe social distancing 1 from others in public spaces and workplaces is one of the key measures for maintaining a low risk of infection.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 188,
                    "text": "(Dias, Queiroz, & Martins, 2020)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 594,
                    "end": 624,
                    "text": "(Cacciapaglia & Sannino, 2020;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 625,
                    "end": 643,
                    "text": "Dias et al., 2020;",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 644,
                    "end": 667,
                    "text": "Hellewell et al., 2020;",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 668,
                    "end": 686,
                    "text": "Prem et al., 2020;",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 687,
                    "end": 714,
                    "text": "Rahmani & Mirmahaleh, 2020;",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 715,
                    "end": 732,
                    "text": "Sun & Zhai, 2020)",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 764,
                    "end": 782,
                    "text": "Prem et al. (2020)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1089,
                    "end": 1120,
                    "text": "Cacciapaglia and Sannino (2020)",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1236,
                    "end": 1255,
                    "text": "Sun and Zhai (2020)",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In recent years, with the deepening of the concept of ''smart sustainable cities'' (Bibri & Krogstie, 2017; Silva, Khan, & Han, 2018) , countries around the world have deeply integrated information technologies with the various needs of urban development. In this context, some research work has explored ways to prevent and respond to the ongoing COVID-19 pandemic by using urban infrastructures and emerging technologies (Bhattacharya et al., 2020; He et al., 2020; Loey, Manogaran, Taha, & Khalifa, 2020; Nguyen et al., 2020; Silva et al., 2020; Zhou et al., 2020) , especially in the aspect of automatic social distancing monitoring in public places (Ahmed, Ahmad, Rodrigues, Jeon, & Din, 2020; Cristani, Del Bue, Murino, Setti, & Vinciarelli, 2020; Khandelwal, Khandelwal, & Agarwal, 2020; Nguyen et al., 2020; Punn, Sonbhadra, & Agarwal, 2020; Sathyamoorthy, Patel, Savle, Paul, & Manocha, 2020; Shorfuzzaman, Hossain, & Alhamid, 2021; Yang, Yurtsever, Renganathan, Redmill, & \u00d6zg\u00fcner, 2020) . This helps to enhance the resilience and sustainability of cities. The construction of smart cities has also resulted in an explosive growth in video data taken from public spaces. Compared with other big data utilised in existing researches, the video data contains wealthy spatial and temporal information about humans. Exploiting video data to study and analyse human trajectories can more precisely mine human activities in various complex scenes, which is an excellent supplement to non-visual big data and has unique advantages. Therefore, during the pandemic, it is of great theoretical significance and research value to measure and analyse the social distancing between pedestrians based on their spatio-temporal trajectories using surveillance videos in public places and take appropriate epidemic prevention measures according to the crowd gathering situations. This research topic is called Visual Social Distancing (VSD), which refers to approaches relying on video cameras and other imaging sensors to analyse the proxemic behaviour of people (Cristani et al., 2020) .",
            "cite_spans": [
                {
                    "start": 83,
                    "end": 107,
                    "text": "(Bibri & Krogstie, 2017;",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 108,
                    "end": 133,
                    "text": "Silva, Khan, & Han, 2018)",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 423,
                    "end": 450,
                    "text": "(Bhattacharya et al., 2020;",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 451,
                    "end": 467,
                    "text": "He et al., 2020;",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 468,
                    "end": 507,
                    "text": "Loey, Manogaran, Taha, & Khalifa, 2020;",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 508,
                    "end": 528,
                    "text": "Nguyen et al., 2020;",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 529,
                    "end": 548,
                    "text": "Silva et al., 2020;",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 549,
                    "end": 567,
                    "text": "Zhou et al., 2020)",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 654,
                    "end": 698,
                    "text": "(Ahmed, Ahmad, Rodrigues, Jeon, & Din, 2020;",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 699,
                    "end": 753,
                    "text": "Cristani, Del Bue, Murino, Setti, & Vinciarelli, 2020;",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 754,
                    "end": 794,
                    "text": "Khandelwal, Khandelwal, & Agarwal, 2020;",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 795,
                    "end": 815,
                    "text": "Nguyen et al., 2020;",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 816,
                    "end": 849,
                    "text": "Punn, Sonbhadra, & Agarwal, 2020;",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 850,
                    "end": 901,
                    "text": "Sathyamoorthy, Patel, Savle, Paul, & Manocha, 2020;",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 902,
                    "end": 941,
                    "text": "Shorfuzzaman, Hossain, & Alhamid, 2021;",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 942,
                    "end": 997,
                    "text": "Yang, Yurtsever, Renganathan, Redmill, & \u00d6zg\u00fcner, 2020)",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 2057,
                    "end": 2080,
                    "text": "(Cristani et al., 2020)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, a new VSD method based on the human spatiotemporal trajectory has been proposed to quantify and analyse the social distancing between pedestrians in public spaces. The contributions of our work are summarised as follows: 1. A new hierarchical association based online and real-time multipedestrian tracking method is proposed to obtain pedestrians' trajectories, which can effectively reduce the number of identity switches while achieving overall competitive performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "proposed, considering both the Euclidean distance between sampling points of trajectories from a local perspective and the Fr\u00e9chet distance between trajectories from a holistic view. 3. A multi-scale social distancing analysis scheme is proposed, including four evaluation metrics, which can evaluate the crowd gathering situations from various time scales respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A new VSD method based on spatio-temporal trajectories is"
        },
        {
            "text": "The rest of the paper is organised as follows. Section 2 gives the related work of VSD and Multiple-Object Tracking. Section 3 provides the detailed contents of the proposed approaches. The related experimental results and discussions are illustrated in Section 4. The conclusion of the given work is presented in Section 5.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A new VSD method based on spatio-temporal trajectories is"
        },
        {
            "text": "Here we introduce the related work of VSD and Multi-Object Tracking respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Some new research work has been conducted to study the VSD problem for COVID-19 (Ahmed et al., 2020; Cristani et al., 2020; Khandelwal et al., 2020; Nguyen et al., 2020; Punn et al., 2020; Sathyamoorthy et al., 2020; Shorfuzzaman et al., 2021; Yang et al., 2020) . For instance, Cristani et al. (2020) proposed a VSD method based on body pose estimation. In each frame, the body pose detector is used to detect visible people. In the corresponding bird's eye view (top view), each detected pedestrian is regarded as the centre of the circle, and the safe distance as the radius. Then the VSD issue is converted to a sphere collision problem. Yang et al. (2020) proposed a VSD and critical social density detection system to avoid overcrowding by modulating inflow to the region-of-interest (ROI). Shorfuzzaman et al. (2021) used deep learning-based object detection models to detect individuals and implement social distancing monitoring. The Landing AI Company 2 developed a social distancing detection tool by detecting pedestrians in real-time video streams and measuring the distance between pedestrians in the corresponding bird's eye view frames. These methods have made some useful contributions to VSD in the pandemic, but most of them are based on frame-by-frame pedestrian detection rather than pedestrian tracking over a period of time. Although there existed some VSD studies leveraging both detection and tracking approaches (Ahmed et al., 2020; Sathyamoorthy et al., 2020) , the tracking algorithms in these methods were employed for tracking detected people and associating them with assigned IDs rather than for trajectory-based social distancing measuring. As a consequence, these frame-by-frame distance metric based VSD methods fall in the category of the detectionbased VSD, while the proposed VSD method based on spatio-temporal trajectories distance metric belongs to the trajectory-based VSD. To the best of our knowledge, this research work is the first attempt to address the VSD issue in a dynamic and spatio-temporal manner.",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 100,
                    "text": "(Ahmed et al., 2020;",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 101,
                    "end": 123,
                    "text": "Cristani et al., 2020;",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 124,
                    "end": 148,
                    "text": "Khandelwal et al., 2020;",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 149,
                    "end": 169,
                    "text": "Nguyen et al., 2020;",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 170,
                    "end": 188,
                    "text": "Punn et al., 2020;",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 189,
                    "end": 216,
                    "text": "Sathyamoorthy et al., 2020;",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 217,
                    "end": 243,
                    "text": "Shorfuzzaman et al., 2021;",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 244,
                    "end": 262,
                    "text": "Yang et al., 2020)",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 279,
                    "end": 301,
                    "text": "Cristani et al. (2020)",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 642,
                    "end": 660,
                    "text": "Yang et al. (2020)",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 797,
                    "end": 823,
                    "text": "Shorfuzzaman et al. (2021)",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 1438,
                    "end": 1458,
                    "text": "(Ahmed et al., 2020;",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1459,
                    "end": 1486,
                    "text": "Sathyamoorthy et al., 2020)",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "VSD problem"
        },
        {
            "text": "The distinction between the detection-based VSD and the trajectorybased VSD is shown in Fig. 1 . The detection-based VSD detects and calibrates the positions of pedestrians, and measures the distance between them frame-by-frame in the bird's eye view. The trajectory-based VSD tracks pedestrians and calibrates trajectories, and measures the distance between corresponding calibrated trajectories in the threedimensional spatio-temporal coordinate (adding a time axis ). The detection-based VSD method is from a static and local perspective, while the trajectory-based VSD method is from a dynamic and spatiotemporal perspective. However, during the pandemic, the issue that should be considered is the continuous measurement and analysis of social distancing rather than a specific moment. Therefore, it is more sensible to investigate the VSD problem based on the spatio-temporal trajectory over a time period.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 88,
                    "end": 94,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "VSD problem"
        },
        {
            "text": "The Multi-Object Tracking (MOT) (Luo, Xing, Zhang, Zhao, & Kim, 2015) task is a fundamental research topic in the field of computer vision, which is widely applied to smart surveillance, autonomous driving, security and other areas. MOT is also an underpinning technique for the trajectory-based VSD. In recent years, with the dramatical improvement of detectors (Redmon & Farhadi, 2017 Ren, He, Girshick, & Sun, 2015) , Tracking-by-Detection (Al-Shakarji, Bunyak, Seetharaman, & Palaniappan, 2018; Bae & Yoon, 2017; Bewley, Ge, Ott, Ramos, & Upcroft, 2016; Chu et al., 2017; Sanchez-Matilla, Poiesi, & Cavallaro, 2016; Wojke, Bewley, & Paulus, 2017) has become the mainstream paradigm of MOT. For Tracking-by-Detection, objects are detected and localised in each frame firstly, and then tracking is J. Su et al. conducted by using data association to link detections into trajectories. Therefore, the tracking performance is highly dependent on the performance of the detector and the data association method. Also, MOT can be divided into online tracking (Al-Shakarji et al., 2018; Bae & Yoon, 2017; Bewley et al., 2016; Chu et al., 2017; Sanchez-Matilla et al., 2016; Wojke et al., 2017) and offline tracking (Brendel, Amer, & Todorovic, 2011; Dehghan, Modiri Assari, & Shah, 2015; Milan, Roth, & Schindler, 2013; Son, Baek, Cho, & Han, 2017) . Online tracking refers to data association based only on the past and the current frames, while offline tracking refers to data processing by exploiting all the frames or batch frames. Because offline tracking methods demand the entire set of videos to be obtained in advance, they are less favoured by real-time tasks compared to their online counterparts.",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 69,
                    "text": "(Luo, Xing, Zhang, Zhao, & Kim, 2015)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 363,
                    "end": 386,
                    "text": "(Redmon & Farhadi, 2017",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 387,
                    "end": 418,
                    "text": "Ren, He, Girshick, & Sun, 2015)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 457,
                    "end": 498,
                    "text": "Bunyak, Seetharaman, & Palaniappan, 2018;",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 499,
                    "end": 516,
                    "text": "Bae & Yoon, 2017;",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 517,
                    "end": 557,
                    "text": "Bewley, Ge, Ott, Ramos, & Upcroft, 2016;",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 558,
                    "end": 575,
                    "text": "Chu et al., 2017;",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 576,
                    "end": 619,
                    "text": "Sanchez-Matilla, Poiesi, & Cavallaro, 2016;",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 620,
                    "end": 650,
                    "text": "Wojke, Bewley, & Paulus, 2017)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 1057,
                    "end": 1083,
                    "text": "(Al-Shakarji et al., 2018;",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1084,
                    "end": 1101,
                    "text": "Bae & Yoon, 2017;",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1102,
                    "end": 1122,
                    "text": "Bewley et al., 2016;",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1123,
                    "end": 1140,
                    "text": "Chu et al., 2017;",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1141,
                    "end": 1170,
                    "text": "Sanchez-Matilla et al., 2016;",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1171,
                    "end": 1190,
                    "text": "Wojke et al., 2017)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 1212,
                    "end": 1246,
                    "text": "(Brendel, Amer, & Todorovic, 2011;",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1247,
                    "end": 1284,
                    "text": "Dehghan, Modiri Assari, & Shah, 2015;",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1285,
                    "end": 1316,
                    "text": "Milan, Roth, & Schindler, 2013;",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1317,
                    "end": 1345,
                    "text": "Son, Baek, Cho, & Han, 2017)",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": "Multi-object tracking"
        },
        {
            "text": "With regard to online Tracking-by-Detection, the traditional methods include the Multiple Hypothesis Tracking (MHT) (Reid, 1979) and the Joint Probabilistic Data Association Filter (JPFAF) (Fortmann, Bar-Shalom, & Scheffe, 1983) . Recently, deep learning based methods enhance the tracking performance in complex scenes drastically. The Person of Interest (POI) (Yu et al., 2016) method introduced the highperformance detection and deep learning based appearance feature into the context of MOT. Depending on Convolutional Neural Network (CNN) based detection, the Simple Online and Realtime Tracking (SORT) (Bewley et al., 2016) method utilised the Kalman filter for frame-by-frame prediction and the Hungarian method for data association, by calculating intersection-over-union (IOU) distance as the assignment cost for the association. The Deep SORT (Wojke et al., 2017) method further introduced deep appearance features and motion features on the basis of SORT for assignment costs calculation. Also, some research work in the literature focuses on researching hierarchical data association to improve the reliability of association. Bae and Yoon (2017) proposed a hierarchical association method based on the tracklet confidence, which built optimal tracklets by sequentially linking tracklets and detections using the high and low confidence association. Al-Shakarji et al. (2018) proposed a three-step cascade scheme for efficient data association.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 128,
                    "text": "(Reid, 1979)",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 189,
                    "end": 228,
                    "text": "(Fortmann, Bar-Shalom, & Scheffe, 1983)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 362,
                    "end": 379,
                    "text": "(Yu et al., 2016)",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 608,
                    "end": 629,
                    "text": "(Bewley et al., 2016)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 853,
                    "end": 873,
                    "text": "(Wojke et al., 2017)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 1139,
                    "end": 1158,
                    "text": "Bae and Yoon (2017)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1362,
                    "end": 1387,
                    "text": "Al-Shakarji et al. (2018)",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Multi-object tracking"
        },
        {
            "text": "The proposed approaches consist of two main steps: (1) a hierarchical association based online multi-pedestrian tracking method to obtain trajectories of pedestrians; (2) a trajectory-based social distancing measurement and analysis method to evaluate social distancing situations between pedestrians in public spaces.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The proposed approaches"
        },
        {
            "text": "Considering the real-time requirement of the trajectory-based VSD task, it is necessary to design a simple and highly real-time tracking method. Inspired by SORT (Bewley et al., 2016) and Deep SORT (Wojke et al., 2017) method, we utilise the Kalman filter and the Hungarian algorithm (Kuhn, 1955) to address the MOT task. Besides, we design a new hierarchical data association scheme to ensure tracking performance and fewer ID switches.",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 183,
                    "text": "(Bewley et al., 2016)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 198,
                    "end": 218,
                    "text": "(Wojke et al., 2017)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 284,
                    "end": 296,
                    "text": "(Kuhn, 1955)",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Hierarchical association based online multi-pedestrian tracking"
        },
        {
            "text": "For online Tracking-by-Detection, the essence is a frame-by-frame data association based on detection responses pre-generated by the detector. The detection responses in the current frame are assigned to the existing tracklets (the tracklet is a part of the trajectory formed during the tracking process) according to the data association method. However, the issues of misdetection, occlusion, the appearance and the disappearance of tracking objects lead to many challenges of the MOT task. To tackle these challenges, we adopt a hierarchical data association method based on the states of the tracklets to address multipedestrian tracking. According to the number of consecutive associated frames, the states of the tracklets are classified into four categories, namely initial, tentative, stable and deleted. The transition mechanism of the four states of the tracklets is shown in Fig. 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 886,
                    "end": 892,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The initial-state: the initial-state is defined for a new detection that cannot be associated with any existing tracklet. In this state, it is regarded as a new tracklet. If it is associated successfully in the next frame, its state will become as tentative. Otherwise, it will be deleted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The tentative-state: the tentative-state is a state when the tracklet in initial-state is successfully associated in the next frame. In this scenario, if the tracklet in tentative-state continues to be successfully associated for over 1 consecutive frames (the threshold 1 is a small positive integer), its state will progress to stable. Otherwise, it will be deleted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The stable-state: the stable-state is defined as a state when the tracklet in tentative-state is successfully associated for over 1 consecutive frames. Once the state of the tracklet becomes stable, it can only be deemed to be finished and deleted when it fails to be associated for over 2 consecutive frames (The threshold 2 is a positive integer significantly greater than 1 ). Besides, the stable-state can be further divided into two stages, the first association stage and the second association stage. These two stages employ different feature metrics for assignment costs calculation during the association (Section 3.1.3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The deleted-state: under the following conditions, the state of the tracklet will be defined as deleted-state: (1) when the tracklet is in initial-state or tentative-state, and it fails to be associated in the next J. Su et al. frame; (2) when the stable-state tracklet fails to be associated for over 2 consecutive frames.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The setting of the initial-state and the tentative-state can effectively address the misdetection issue. This is because the tracklet of the misdetected object in the initial or tentative state will be deleted once the association fails. The stable-state setting takes into account the impact of occlusion during tracking. The tracklet may fail to be associated during the tracking process due to occlusions. Under this situation, the object could not be considered to have disappeared, nor should the tracklet be deleted immediately. The setting of the threshold 2 is beneficial to improve the completeness of tracking. And the two association stages of the stable-state helps to improve the reliability of data association. The deleted-state setting is to reduce unnecessary calculations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The states of the tracklets and the transition mechanism"
        },
        {
            "text": "The distance between appearance features is taken into account in the analysis of data association. Inspired by the Cosine Softmax method (Wojke & Bewley, 2018; Wojke et al., 2017) and the Additive Angular Margin Softmax (AAM-Softmax) method (Deng, Guo, Xue, & Zafeiriou, 2019; Jie, He, Qing, Yu, & Xu, 2019) , an AAM-Softmax appearance feature descriptor network is designed to obtain well-discriminative appearance features of pedestrians. Before being applied in the online tracking task, the network is trained offline by using a large-scale person re-ID dataset Market1501 (Zheng et al., 2015) with 12,936 training images of 751 identities, which facilitates deep metric learning in a pedestrian tracking context.",
            "cite_spans": [
                {
                    "start": 138,
                    "end": 160,
                    "text": "(Wojke & Bewley, 2018;",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 161,
                    "end": 180,
                    "text": "Wojke et al., 2017)",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 242,
                    "end": 277,
                    "text": "(Deng, Guo, Xue, & Zafeiriou, 2019;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 278,
                    "end": 308,
                    "text": "Jie, He, Qing, Yu, & Xu, 2019)",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 578,
                    "end": 598,
                    "text": "(Zheng et al., 2015)",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "We mainly use convolutional layers and residual blocks (He, Zhang, Ren, & Sun, 2016) to construct the architecture of the proposed descriptor network (shown in Fig. 3 ). The pedestrian images with size 128 \u00d7 64 \u00d7 3 are input into the CNN-based architecture, including two convolutional layers (each layer has 32 kernels with size 3 \u00d7 3 and stride 1), a max-pooling layer (pooling size is 3 \u00d7 3 and stride is 2) and six residual blocks with two stacked layers. Through the CNN architecture, the feature maps with size 16 \u00d7 8 \u00d7 128 can be obtained. Then after a Global Average Pooling (GAP) layer, a Batch Normalisation (BN) layer and a 2 Normalisation layer, the descriptor network finally outputs a feature vector with 128 dimensions. In the training phase, the ID of each sample is utilised as a training label, and each embedded feature is input into the fully connected layer followed by the AAM-Softmax classifier, performing supervised learning by the AAM-Softmax loss.",
            "cite_spans": [
                {
                    "start": 55,
                    "end": 84,
                    "text": "(He, Zhang, Ren, & Sun, 2016)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 160,
                    "end": 166,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "The Softmax classifier is widely used in deep classification tasks, with loss function as Eq. (1):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "where \u2208 R is the input feature (due to the 2 Normalisation layer in the descriptor, \u2016 \u2016 \u2016 \u2016 is equal to 1), and is the class label of . is the th column of the weight matrix \u2208 R \u00d7 and \u2208 R is the bias. The target logit term is presented as T + , is the batch size and is the number of classes. Based on the Softmax loss, the improvement can boost the ability to learning discriminative features effectively. Specifically, the bias is set to 0, and 2 normalisation is imposed on",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "where is the angle between and . The 2 -normalised Softmax loss is presented as Eq. (2):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "where cos is the target logit, is the feature scale hyper-parameter. Then by imposing an additive angular margin to the target logit, the AAM-Softmax loss (Deng et al., 2019) formulation can be written as Eq. (3):",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 174,
                    "text": "(Deng et al., 2019)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "The additive angular margin penalty makes the decision boundaries more stringent and separated, enhancing the similarity of intraclass features and the disparity of inter-class features simultaneously, which facilitates to improve the discriminative capability of features effectively. Since the AAM-Softmax loss only imposes an additive angular margin constraint in the angular space, it neither increases the structural complexity of the network nor the number of trainable parameters. When performing the online MOT task, the pre-trained descriptor network is exploited as the feature encoder to obtain discriminative features of pedestrians for the appearance distance metric in the subsequent data association process.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AAM-Softmax appearance feature descriptor"
        },
        {
            "text": "During the data association process, the assignment costs between tracklets and detections are the basis of association. In this paper, based on different states of the tracklets, different metric methods are utilised to calculate the assignment costs and hierarchical associations are conducted. For each tracklet, except the initial-state tracklet, an appearance feature gallery = { ( ) } =1 will be generated, containing the historical appearance features backtracking from the current frame, where ( ) (\u2016 ( ) \u2016 = 1) is the th 2 -normalised historical appearance feature, = 1 denotes the current frame and is the maximum capacity of the gallery. The appearance metric between the tracklet and the detection forms an important part of the distance metric. It can be derived by calculating the minimum cosine distance between all historical appearance features of the tracklet ( ) \u2208 and the appearance feature of the detection, written as Eq. (4):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "where ( ) is the th tracklet (except for the initial-state tracklet), is the th detection and is the appearance feature of . a ( ( ) , ) J. Su et al. represents the appearance metric between ( ) and . Due to the 2 normalisation operation (\u2016 ( ) \u2016 = 1, \u2016 \u2016 = 1), the cosine similarity can be written as the inner product form T ( ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "(1) Assignment costs calculation based on the state. The initial-state: for the initial-state tracklet, since there is no appearance feature gallery, only position information can be used for data association. Firstly, the standard Kalman filter is used to predict its moving state. Then the IOU distance between the prediction bounding box and the detection bounding box is calculated as the motion metric, presented as Eq. (5):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "where ( ) initial denotes the th initial-state tracklet and B ( ) initial is the prediction bounding box of ( ) initial ; denotes the th detection and B",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "is the bounding box of . ( ( ) initial , ), IoU ( ( ) initial , ) and IoU( ( ) initial , ) represent the distance metric, the IOU distance and the IOU value between ( ) initial and respectively. is the minimum constant that makes all the IOU distances are not less than 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "The tentative-state: the tentative-state tracklet already generates an appearance feature gallery , but at this time the features in the gallery are limited. So, at this stage, the IOU distance between the prediction and the detection is still used as the motion metric for association, whilst the appearance metric is only used as a threshold for filtering and discarding infeasible detections. If the appearance metric is greater than the threshold, the candidate detection will be excluded, with no possibility of being associated. The assignment cost is expressed as Eq. (6):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "where ( ) tentative and denote the th tentative-state tracklet and the th detection respectively. ( ( ) tentative , ), IoU ( ( ) tentative , ) and a ( ( ) tentative , ) represent the metric distance, the IOU distance and the appearance metric (obtained by Eq. (4)) between ( ) tentative and respectively. is the appearance threshold.",
            "cite_spans": [
                {
                    "start": 273,
                    "end": 276,
                    "text": "( )",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "The stable-state: for the stable-state tracklet, the data association process contains two stages. In the first association stage, the Mahalanobis distance is utilised as the motion metric, written as Eq. (7):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "where ( ) stable and represent the th stable-state tracklet and the th detection respectively. m ( ( ) stable , ) is the Mahalanobis distance between ( ) stable and , and ( , ) is the measurement space of ( ) stable . In this stage, different metric methods are adopted for different states of the camera (moving or stationary) due to the motion information caused by the camera's movement. For the moving situation, the appearance metric is mainly considered, and the motion metric is only used for filtering. If the motion metric is greater than the threshold, the candidate detection will be discarded. The assignment cost is written as Eq. (8):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "where ( ( ) stable , ), a ( ( ) stable , ) (calculated by Eq. (4)) and m ( ( ) stable , ) (calculated by Eq. (7)) denote the metric distance, the appearance metric and the motion metric between ( ) stable and respectively. m is the Mahalanobis threshold. For the stationary situation, the motion metric and the appearance metric are both taken as the joint metric and integrated into a unified form through the hyper-parameter , presented as Eq. (9):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "Due to occlusions or other reasons, the appearance features of the object may change dramatically, causing the stable-state tracklet to fail to be associated in the first association stage. Hence, the second association stage is added for this situation. Instead of considering the appearance metric, only the motion metric calculated by IOU distance is utilised for data association in the second stage.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "(2) Hierarchical data association and the states' update. The stability of the tracklet determines its confidence. Therefore, according to the order of confidence from high to low, the corresponding states are the stable-state, the tentative state and the initial state, respectively. Based on this confidence order, a hierarchical association method is designed to divide the entire data association stage into three levels. The flow chart of the proposed hierarchical data association is shown in Fig. 4 . Specifically, the first association of the stable-state tracklets is performed. Then, those tracklets that fail to be associated subsequently enter the second association stage. After that, the tracklets in the initial-state or the tentative-state are considered to be associated with the remaining detections. According to the states of the tracklets, the corresponding metrics are calculated, and the associations between the tracklets and the detections are conducted by using the Hungarian algorithm (Kuhn, 1955) . For the tracklet in initial-state or tentativestate, if it fails to be associated, it will be deleted. This way of dealing with unstable objects can facilitate the tracker to filter the incorrectly detected objects to a certain extent thus to improve the performance efficiency. For the tracklet in the stable-state, if it fails to be associated for over consecutive 2 frames, it will be deleted, which can increase the completeness of the trajectory. For unassociated detection, it will be considered as a new tracklet and will be assigned with a new ID.",
            "cite_spans": [
                {
                    "start": 1012,
                    "end": 1024,
                    "text": "(Kuhn, 1955)",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 499,
                    "end": 505,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Assignment problem"
        },
        {
            "text": "The description of a tracklet includes the ID, the position information (the coordinates of the bounding box), the appearance feature and its state. After each association, the tracklets will be updated. For the successfully associated tracklet, the coordinates of the tracking bounding box are updated according to its new position; the new appearance feature in the current frame will be added to the appearance feature gallery. But when occlusion occurs, the confidence of the appearance feature decreases due to the introduced noise. To tackle this issue, the IOU values between the prediction bounding box of the tracklet with all detection bounding boxes are calculated and a threshold IoU is set. If there exists an IOU value greater than IoU , the appearance feature gallery is not updated. Besides, the state of the tracklet should be updated as well according to its current state and the transition mechanism (Section 3.1.1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "As a summary, the entire process of online multi-object tracking based on hierarchical data association is illustrated in Fig. 5 . For the th frame, firstly the detector is used to conduct multi-object detection.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 122,
                    "end": 128,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Assignment problem"
        },
        {
            "text": "Then, according to different states of the tracklets, different assignment cost calculation methods are adopted to associate the tracklets with the detections hierarchically. After data association, it is required to update the appearance feature galleries and the states of the tracklets. Then the updated tracklets will be associated with the candidate detections in the ( + 1)-th frame.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Assignment problem"
        },
        {
            "text": "The surveillance videos are taken from arbitrary perspective views, it is necessary to transform the original perspective video into the bird's eye view to perform distance measurement. This is carried out by utilising the perspective transformation matrix. As the calibration is conducted for the transformation of the ground plane, the bottomcentre point of the tracking bounding box of every trajectory in each frame is transformed into the bird's eye view as the sampling point of the trajectory. Then, the re-parameterisation time information is added to ensure cannot be backtracked, and the spatio-temporal trajectories of pedestrians are represented in the three-dimensional coordinates space ( \u2032 , \u2032 and ). For addressing the VSD problem, the discrete Fr\u00e9chet distance (Eiter & Mannila, 1994) is utilised to measure the distance between each spatio-temporal trajectory pair. Finally, the social distancing between pedestrians in the real world can be estimated by multiplying the metric distance with the scaling factor.",
            "cite_spans": [
                {
                    "start": 778,
                    "end": 801,
                    "text": "(Eiter & Mannila, 1994)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "The essence of calibration is to map the original video into the bird's eye view by performing the perspective transformation. The formula of the perspective transformation is presented as Eq. (10): ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "where ( , ) and ( , , 1) are the Cartesian coordinate and the homogeneous coordinate of the trajectory respectively in each original frame. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "For calibration, we first need to select a rectangular reference area in the shooting scene. Due to the arbitrary angle of the camera, the reference area appears as a quadrilateral in the original perspective view. Since the video is captured by a single camera (monocular camera), the calibration method is to map the quadrilateral in the original video to the bird's eye view to re-form a rectangle with the same aspect ratio. Using the four pairs of vertex coordinates of the quadrilateral and the rectangle, the perspective transformation matrix can be calculated by Eq. (10). Then, the calibrated coordinates in the bird's eye view of each trajectory's sampling points can be calculated through Eq. (11).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "The Fr\u00e9chet distance (Eiter & Mannila, 1994) is to determine the distance between each spatio-temporal trajectory pair and in the calibrated space by taking into account location and time ordering, defined as Eq. (12):",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 44,
                    "text": "(Eiter & Mannila, 1994)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "where is the distance function of the space . ( ( )) and ( ( )) represent the spatial position of and at time respectively. and are continuous and non-decreasing re-parameterisation. The discrete Fr\u00e9chet distance (Eiter & Mannila, 1994) is an approximation of the continuous Fr\u00e9chet distance. Firstly, the two trajectory curves and are discretised and represented as the sequences with and sampling points, presented with ( ) =",
            "cite_spans": [
                {
                    "start": 213,
                    "end": 236,
                    "text": "(Eiter & Mannila, 1994)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "( 1 , \u2026 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": ") respectively. Because the distance metric is performed in the bird's eye view, the corresponding transformed sequences",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "need to be obtained by Eq. (11). A coupling \u2032 between \u2032 and \u2032 is a sequence of distinct pairs from ( \u2032 ) and ( \u2032 ), written as Eq. (13):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "where 1 = 1 and 1 = 1, = and = , and for all = 1, 2, \u2026 , , we have +1 = or +1 = + 1, +1 = or +1 = + 1. The length \u2016 \u2016 \u2032\u2016 \u2016 of the coupling \u2032 is the length of the longest link in \u2032 , presented as Eq. (14):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "We use Euclidean distance to calculate ( \u2032 , \u2032 ) , and the discrete Fr\u00e9chet distance between \u2032 and \u2032 in the bird's eye view is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "By Multiplying the metric distance in the bird's eye view with the scaling factor , the social distancing in the real world can be estimated. On the one hand, the Euclidean distance is used to measure the distance between each sampling point pair of trajectories from a local perspective, presented as Eq. (16):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "On the other hand, from a holistic view, the discrete Fr\u00e9chet distance is exploited to measure the distance between trajectory pairs, presented as Eq. (17):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory transformation and distance measurement"
        },
        {
            "text": "Here we design a multi-scale social distancing analysis scheme to evaluate the social distancing situations in public spaces from multiple time scales. The scheme includes the following four evaluation metrics:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Social distancing analysis"
        },
        {
            "text": "The Average Ratio of Pedestrians with Unsafe Social Distancing (ARP-USD): if the distance between pedestrians, calculated by Eq. (16), is below the minimum acceptable distance, we believe that the pedestrians are at an unsafe distance at this moment. The ARP-USD metric is the mean proportion of the number of pedestrians with an unsafe distance in respect to the total number of people over a period of time in the public space. Given a video with frames, for the th frame, is the total number of tracking persons,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Social distancing analysis"
        },
        {
            "text": "is the position point of the th pedestrian. The set of pedestrians with unsafe social distancing in the th frame is represented as Eq. (18):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Social distancing analysis"
        },
        {
            "text": "where \u2032 , \u2032 ( , = 1, 2, \u2026 , and \u2260 ) are the calibrated points of , in the bird's eye view, (\u22c5) is the Euclidean distance, is the scaling factor, s is the safe distance threshold, and is the number of the elements in . If \u2260 0, the ratio of pedestrians with an unsafe distance in the th frame can be written as , so the ARP-USD is calculated as Eq. (19):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Social distancing analysis"
        },
        {
            "text": "where ( \u2264 ) is the number of the frames with \u2260 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Social distancing analysis"
        },
        {
            "text": "if the distance between the trajectory pair, calculated by Eq. (17), is below the safe distance s , we consider the trajectory pair to be at an unsafe distance. The NTP-USD metric is the number of the stable-state trajectory pairs with unsafe social distancing. Assuming that the number of the stable-state trajectories is ( is dynamically updated) and the th stable-state trajectory is represented as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Trajectory Pairs with Unsafe Social Distancing (NTP-USD):"
        },
        {
            "text": ", the set of the stable-state trajectory pairs with unsafe social distancing can be formulated as Eq. (20):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Trajectory Pairs with Unsafe Social Distancing (NTP-USD):"
        },
        {
            "text": "are the mapped trajectories of stable , stable in the bird's eye view, where (\u22c5) is the discrete Fr\u00e9chet distance and is the scaling factor. is the number of the elements in , indicating the value of the NTP-USD.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Trajectory Pairs with Unsafe Social Distancing (NTP-USD):"
        },
        {
            "text": "If the discrete Fr\u00e9chet distance of the trajectory pair is less than the safe distance threshold, it means that the distance of each sampling point pair of the two trajectories has been less than the safe distance for the entire measurement process. In another word, the two pedestrians have continuously violated social distancing for a period of time. Therefore, based on spatio-temporal trajectories, the NTP-USD metric measures the overall number of trajectory pairs with an unsafe distance in public spaces, which reflects the situation of social distancing violations in the public area over a period of time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Trajectory Pairs with Unsafe Social Distancing (NTP-USD):"
        },
        {
            "text": "Concerning the spread of pandemics, the longer people stay at an unsafe distance, the higher the risk of infection. Therefore, the duration of pedestrians staying within an unsafe distance is an essential factor that should be taken into account. The discrete Fr\u00e9chet distance used in NTP-USD is to measure the similarity of trajectories for a given duration holistically. But for two dissimilar trajectories, for example, two trajectories facing each other with opposite directions, their Fr\u00e9chet distance can be very large. Hence NTP-USD is unable to spot the infection risk when pedestrians are very close for a certain amount of time but facing back to each other. So, for a trajectory pair, if the number of their sampling point pairs with an unsafe distance is more than the threshold , it is considered as the pedestrian pair with continuous unsafe social distancing. The NPPC-USD is designed to count the number of the above pedestrian pairs, which can reflect the concept of the unsafe distance for a period of time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Pedestrian Pairs with Continuous Unsafe Social Distancing (NPPC-USD):"
        },
        {
            "text": "The Average Gathering Degree (AGD): to describe the degree of pedestrians gathering in public spaces, the concept of gathering group is defined. As shown in Fig. 6 , pedestrians in one gathering group have social distancing with one or more people in the same group less than the safe distance. The social distancing between any two people in different gathering groups is larger than the safe distance. According to the number of pedestrians in a group, the gathering degree is divided into six levels, from 0 to 5 (illustrated in Fig. 6 ). In order to facilitate unified grading, a single person is also regarded as a gathering group with gathering degree 0. For each frame, the maximum gathering degree is taken as the gathering degree of this frame . The average gathering degree of a video with frames is formulated as Eq. (21):",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 157,
                    "end": 163,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 532,
                    "end": 538,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "The Number of Pedestrian Pairs with Continuous Unsafe Social Distancing (NPPC-USD):"
        },
        {
            "text": "During the pandemic, the larger the number of people in a gathering group, the higher the risk of cross-infection. Therefore, the AGD can reflect the gathering situation of people in a period of time, which is a useful metric for assessing the risk of infection in public spaces.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Number of Pedestrian Pairs with Continuous Unsafe Social Distancing (NPPC-USD):"
        },
        {
            "text": "Market1501: the AAM-Softmax appearance feature descriptor network is pre-trained using a large-scale person re-ID dataset Market1501 (Zheng et al., 2015) captured by six cameras. It contains 12,936 images of 751 identities for training, 3,368 images of another 750 identities as the query set, and 19,732 images as the gallery set. The input images are resized to 128 \u00d7 64.",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 153,
                    "text": "(Zheng et al., 2015)",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "MOT16: we evaluate the performance of the proposed tracking method on the MOT16 benchmark dataset (Milan, Leal-Taix\u00e9, Reid, Roth, & Schindler, 2016) . It consists of 14 video sequences, where 7 videos are used as training and verification sets, and another 7 are employed as test sets. The input sizes of the MOT16 are 1920 \u00d7 1080 and 640 \u00d7 480. There are front-view scenes taken from moving camera and top-down view scenes captured from surveillance camera. The complex scenes, the large number of pedestrians and the varying illuminations have imposed great challenges in analysing this MOT16 benchmark dataset.",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 148,
                    "text": "(Milan, Leal-Taix\u00e9, Reid, Roth, & Schindler, 2016)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "SCU-VSD: we conduct social distancing measurement and analysis experiments on our own dataset, called as SCU-VSD. It includes 8 pedestrian video sequences, which were taken from a pedestrian street with different scenes and perspective views. For each video sequence, the size is 1920 \u00d7 1080, the duration is 60 s, and the frame rate is 25 fps (each video gives 1500 consecutive frames).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "The detection results of the MOT16 benchmark dataset used in the paper are provided by the POI method (Yu et al., 2016) . The detector in the POI is Faster R-CNN (Ren et al., 2015) fine-tuned by additional training datasets (including ETHZ pedestrian dataset (Ess, Leibe, Schindler, & Van Gool, 2008) , Caltech pedestrian dataset (Doll\u00e1r, Wojek, Schiele, & Perona, 2009 ) and their surveillance dataset (Yu et al., 2016) ). For the AAM-Softmax loss, the hyper-parameters and J. Su et al. a The values in red and blue represent the optimal and the suboptimal results respectively. in Eq.",
            "cite_spans": [
                {
                    "start": 102,
                    "end": 119,
                    "text": "(Yu et al., 2016)",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 162,
                    "end": 180,
                    "text": "(Ren et al., 2015)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 259,
                    "end": 300,
                    "text": "(Ess, Leibe, Schindler, & Van Gool, 2008)",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 330,
                    "end": 369,
                    "text": "(Doll\u00e1r, Wojek, Schiele, & Perona, 2009",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 403,
                    "end": 420,
                    "text": "(Yu et al., 2016)",
                    "ref_id": "BIBREF52"
                }
            ],
            "ref_spans": [],
            "section": "Online hierarchical association based multi-pedestrian tracking"
        },
        {
            "text": "(3) are set to 30 and 0.006 respectively. The Optimiser is Adam and the batch size is 128. During the training, the learning rate is set to 1\u00d710 \u22123 with the first 55,000 interactions, and it decays to 1\u00d710 \u22124 in the last 10,000 interactions. For the transition mechanism of the states, the thresholds 1 and 2 are set to 3 and 30 respectively. For hierarchical data association, the appearance threshold a in Eq. (6) is set to 0.8 and the Mahalanobis threshold m in Eq. (8) is set to 9.49, the hyperparameter in Eq. (9) is set to 0.2. For the states' update, the threshold IoU is set to 0.5. The evaluations of the proposed MOT method are conducted by using following six metrics (Luo et al., 2015) . The results shown in Table 1 are obtained based on MOT16 benchmark dataset. Compared with other online MOT methods, our proposed hierarchical data association based multi-pedestrian tracking method has achieved overall competitive performance. While maintaining high tracking accuracy and precision (MOTA and MOTP are 61.4% and 79.1% respectively), the IDS of our proposed method decreases to 710, which effectively reduces the number of trajectory ID switches and improves the ability to maintain trajectory ID. The reduction of FM (1913) indicates the decrement of the number of trajectory interruptions.",
            "cite_spans": [
                {
                    "start": 679,
                    "end": 697,
                    "text": "(Luo et al., 2015)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1230,
                    "end": 1239,
                    "text": "FM (1913)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 721,
                    "end": 728,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Online hierarchical association based multi-pedestrian tracking"
        },
        {
            "text": "For each scene in the real world, a rectangular reference area on the ground is selected and its actual length and width are measured. Due to the arbitrary angle of the camera, the rectangular reference area is presented as a quadrilateral in the original perspective video. According to the aspect ratio of the reference area, a reference rectangle is drawn with scaling factor = 0.1 in the bird's eye view (with size 500 \u00d7 500), J. Su et al. which corresponds to the calibrated rectangle of the quadrilateral in the original video. Through the coordinates of the four vertex pairs of the quadrilateral and the calibrated rectangle, the perspective transformation matrix of each video can be obtained by using the Eq. (10). By using , the transformed trajectory of each pedestrian in the bird's eye view can be calculated. The detailed information of the selected rectangular reference area of each SCU-VSD video is shown in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 926,
                    "end": 933,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "The comparisons between the original perspective view and the calibrated bird's eye view for SCU-VSD dataset are shown in Fig. 7 . Table 3 . The numerical values of each matrix are expressed using scientific notation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 122,
                    "end": 128,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 131,
                    "end": 138,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "J. Su et al. For social distancing measurement, the safe distance threshold s is set to 2 m, the threshold is set to 250, and the scaling factor is set to 0.1. Based on the varying scales of time, the experiments of multiscale social distancing measurement and analysis in public spaces are performed as follow: (1) for 1/25 s (one frame as a unit), the Euclidean distance between tracking objects in the bird's eye view is measured to calculate the real-time social distancing between pedestrians, the real-time ratio of pedestrians with unsafe social distancing and the real-time gathering degree; (2) for 10 s (250 consecutive frames as a unit), the ARP-USD and AGD are calculated; (3) for 60 s (1500 frames, this is the entire video duration), the ARP-USD and AGD are calcu- tracking object pairs in the bird's eye view are measured frame-byframe to estimate the real-time social distances between the pedestrians. If the social distances are less than the safe distance, the tracking bounding boxes in the left figure will change from blue to red, and the corresponding trajectory points in the right figure will change from green to red, with a red line linking pedestrians. The real-time ratio of pedestrians with unsafe social distancing and the real-time gathering degree are calculated, and the results are displayed in the top-left corner of the right figure.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "Taking 10 s as a unit, each video is divided into 6 periods. For each period, the ARP-USD and AGD metrics are calculated, and the results are drawn using colourmaps. The colourmaps of ARP-USD (on the left) and AGD (on the right) for every 10 s of each video clip are shown in Fig. 9 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 276,
                    "end": 282,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF15"
                }
            ],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "From Fig. 9 , each row of the colourmaps can reflect the changing trend of metrics in different time units of the same video, while each column of the colourmaps can reflect the metrics' changing tendency of different videos in the same time unit. These trends can be displayed intuitively through colour gradients of the corresponding colorbar. We take the first row and the first column of colourmaps as the examples for analysis. The first row of data represents the ARP-USD and AGD metrics of SCU-VSD-01 clip in different time units. It can be seen that the changing trends of the two metrics of SCU-VSD-01 are roughly identical, rising and then falling, reaching their peaks (80.4% and 1.81 respectively) at the second time unit. The first column of the data J. Su et al. represents the comparisons of the two metrics of the 8 video clips in the first time unit. It also can be observed that in this period, the two metric values of SCU-VSD-03 are the minimum (7.07% and 0.06 respectively), while the ARP-USD of SCU-VSD-04 and the AGD of SCU-VSD-01 are the maximum (84.83% and 1.32 respectively). In practical applications, the duration of the time window can be adjusted according to the actual requirement, so that ARP-USD and AGD at different time scales can be obtained.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 5,
                    "end": 11,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF15"
                }
            ],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "From the global perspective, the four metrics ARP-USD, NTP-USD, NPPC-USD and AGD for each entire video are calculated, shown in Table 4 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 128,
                    "end": 135,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "Trajectory-based social distancing measurement and analysis"
        },
        {
            "text": "The four metrics ARP-USD, NTP-USD, NPPC-USD and AGD for each entire video. As shown in Table 4 , the NTP-USD, NPPC-USD and AGD of SCU-VSD-01 achieve the maximum values, which are 32, 11 and 1.2 respectively, while the four metrics of SCU-VSD-03 are the minimum, 47.62%, 3, 2 and 0.57 respectively. Comprehensively, it can be concluded that SCU-VSD-01 video has the largest number of pedestrian pairs with unsafe social distancing and the highest average gathering degree. In contrast, SCU-VSD-03 video has the smallest number of pedestrians with unsafe distancing and the lowest average gathering degree.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 87,
                    "end": 94,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "Table 4"
        },
        {
            "text": "In this paper, in response to the VSD problem in public places during the pandemic, we first proposed a hierarchical association based online multi-pedestrian tracking method to obtain pedestrians' trajectories. We then proposed a spatio-temporal trajectory based multi-scale social distancing measurement and analysis method. The proposed VSD method considers both Euclidean distance from a static perspective and Fr\u00e9chet distance from a spatio-temporal perspective to estimate the social distancing and analyse the crowd gathering situations based on a variety of time scales. The multi-scale metrics obtained by the proposed VSD approach can provide the local authorities with guiding information to help them monitor the real-time and overall situations of the social distancing of crowds in public spaces, so as to formulate and take corresponding prevention measures. In addition, for the areas where the pandemic has outbroken, the proposed VSD and analysis scheme can be used to provide useful supporting data for the subsequent epidemiological investigation, such as locating and search of the infection chain.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Declaration of competing interest"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A model describing COVID-19 community transmission taking into account asymptomatic carriers and risk mitigation",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Aguilar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Faust",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Westafer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "B"
                    ],
                    "last": "Gutierrez",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A deep learningbased social distance monitoring framework for COVID-19",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Rodrigues",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Jeon",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Din",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sustainable Cities and Society",
            "volume": "65",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Multi-object tracking cascade with multi-step data association and occlusion handling",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Al-Shakarji",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Bunyak",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Seetharaman",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Palaniappan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "15th IEEE international conference on advanced video and signal based surveillance",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Confidence-based data association and discriminative deep appearance learning for robust online multi-object tracking",
            "authors": [
                {
                    "first": "S.-H",
                    "middle": [],
                    "last": "Bae",
                    "suffix": ""
                },
                {
                    "first": "K.-J",
                    "middle": [],
                    "last": "Yoon",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "40",
            "issn": "3",
            "pages": "595--610",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Simple online and realtime tracking",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bewley",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ge",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ott",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ramos",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Upcroft",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "2016 IEEE international conference on image processing",
            "volume": "",
            "issn": "",
            "pages": "3464--3468",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Deep learning and medical image processing for coronavirus (COVID-19) pandemic: A survey",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bhattacharya",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "K R"
                    ],
                    "last": "Maddikunta",
                    "suffix": ""
                },
                {
                    "first": "Q.-V",
                    "middle": [],
                    "last": "Pham",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "R"
                    ],
                    "last": "Gadekallu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L"
                    ],
                    "last": "Chowdhary",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alazab",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Smart sustainable cities of the future: An extensive interdisciplinary literature review",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Bibri",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Krogstie",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Sustainable Cities and Society",
            "volume": "31",
            "issn": "",
            "pages": "183--212",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Multiobject tracking as maximum weight independent set",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Brendel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Amer",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Todorovic",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "CVPR 2011",
            "volume": "",
            "issn": "",
            "pages": "1273--1280",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Interplay of social distancing and border restrictions for pandemics (COVID-19) via the epidemic renormalisation group framework",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cacciapaglia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Sannino",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.04956"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Online multi-object tracking using CNN-based single object tracker with spatial-temporal attention mechanism",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ouyang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "4836--4845",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "The visual social distancing problem",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cristani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Del Bue",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Murino",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Setti",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vinciarelli",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.04813"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Gmmcp tracker: Globally optimal generalized maximum multi clique problem for multiple object tracking",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Dehghan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Modiri Assari",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shah",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "4091--4099",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Arcface: Additive angular margin loss for deep face recognition",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zafeiriou",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "4690--4699",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Controlling epidemic diseases based only on social distancing level",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Dias",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "I D M"
                    ],
                    "last": "Queiroz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "D M"
                    ],
                    "last": "Martins",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.08052"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Pedestrian detection: A benchmark",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Doll\u00e1r",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wojek",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Schiele",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Perona",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "304--311",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Computing discrete Fr\u00e9chet distance",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Eiter",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mannila",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "A mobile vision system for robust multi-person tracking",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ess",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Leibe",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Schindler",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Gool",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "2008 IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Sonar tracking of multiple targets using joint probabilistic data association",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Fortmann",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bar-Shalom",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scheffe",
                    "suffix": ""
                }
            ],
            "year": 1983,
            "venue": "IEEE Journal of Oceanic Engineering",
            "volume": "8",
            "issn": "3",
            "pages": "173--184",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Efficient suspected infected crowds detection based on spatio-temporal trajectories",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.06653"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Feasibility of controlling COVID-19 outbreaks by isolation of cases and contacts. The Lancet Global Health",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hellewell",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Abbott",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gimma",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "I"
                    ],
                    "last": "Bosse",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "I"
                    ],
                    "last": "Jarvis",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "Russell",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "A new discriminative feature learning for person re-identification using additive angular margin softmax loss",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jie",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Qing",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 UK/China emerging technologies (UCET)",
            "volume": "",
            "issn": "",
            "pages": "1--4",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Using computer vision to enhance safety of workforce in manufacturing in a post COVID world",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Khandelwal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khandelwal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.05287"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "The hungarian method for the assignment problem",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "W"
                    ],
                    "last": "Kuhn",
                    "suffix": ""
                }
            ],
            "year": 1955,
            "venue": "Naval Research Logistics Quarterly",
            "volume": "2",
            "issn": "1-2",
            "pages": "83--97",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Fighting against COVID-19: A novel deep learning model based on YOLO-v2 with ResNet-50 for medical face mask detection",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Loey",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Manogaran",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H N"
                    ],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Real-time multiple people tracking with deeply learned candidate selection and person re-identification",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Haizhou",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zijie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chong",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "ICME",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Multiple object tracking: A literature review",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "K"
                    ],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "MOT16: A benchmark for multi-object tracking",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Milan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Leal-Taix\u00e9",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Reid",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Schindler",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1603.00831"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Continuous energy minimization for multitarget tracking",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Milan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Schindler",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "volume": "36",
            "issn": "1",
            "pages": "58--72",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Enabling and emerging technologies for social distancing: A comprehensive survey",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "T"
                    ],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Saputra",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Van Huynh",
                    "suffix": ""
                },
                {
                    "first": "N.-T",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "V"
                    ],
                    "last": "Khoa",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Tuan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.02816"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "The effect of control strategies to reduce social mixing on outcomes of the COVID-19 epidemic in wuhan, China: a modelling study",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Prem",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "W"
                    ],
                    "last": "Russell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Kucharski",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Eggo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Davies",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Monitoring COVID-19 social distancing with person detection and tracking via fine-tuned YOLO v3 and deepsort techniques",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "Punn",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Sonbhadra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.01385"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Coronavirus disease (COVID-19) prevention and treatment methods and effective parameters: A systematic literature review",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Rahmani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "Y H"
                    ],
                    "last": "Mirmahaleh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sustainable Cities and Society",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "YOLO9000: better, faster, stronger",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Farhadi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "7263--7271",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Yolov3: An incremental improvement",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Farhadi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1804.02767"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "An algorithm for tracking multiple targets",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Reid",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "IEEE Transactions on Automatic Control",
            "volume": "24",
            "issn": "6",
            "pages": "843--854",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "91--99",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Online multi-target tracking with strong and weak detections",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sanchez-Matilla",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Poiesi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Cavallaro",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "COVID-Robot: Monitoring social distancing constraints in crowded scenarios",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Sathyamoorthy",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Patel",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "A"
                    ],
                    "last": "Savle",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Manocha",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2008.06585"
                ]
            }
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Towards the sustainable development of smart cities through mass video surveillance: A response to the COVID-19 pandemic",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shorfuzzaman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hossain",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "F"
                    ],
                    "last": "Alhamid",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Sustainable Cities and Society",
            "volume": "64",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Towards sustainable smart cities: A review of trends, architectures, components, and open challenges in smart cities",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "N"
                    ],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sustainable Cities and Society",
            "volume": "38",
            "issn": "",
            "pages": "697--713",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "A city cluster risk-based approach for sars-CoV-2 and isolation barriers based on anonymized mobile phone users' location data",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "C S"
                    ],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "F"
                    ],
                    "last": "De Lima Silva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "D S D"
                    ],
                    "last": "Neto",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ferraz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Melo",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "R F"
                    ],
                    "last": "J\u00fanior",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Multi-object tracking with quadruplet convolutional neural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Son",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Baek",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cho",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "5620--5629",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Statement on the second meeting of the international health regulations (2005) emergency committee regarding the outbreak of novel coronavirus (2019-nCoV)",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "secondmeeting-of-the-international-health-regulations-(2005)-emergency-committeeregarding-the-outbreak-of-novel-coronavirus-(2019-ncov)",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "The efficacy of social distance and ventilation effectiveness in preventing COVID-19 transmission",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sustainable Cities and Society",
            "volume": "62",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "COVID-19) dashboard",
            "authors": [],
            "year": 2021,
            "venue": "WHO Coronavirus disease",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Deep cosine metric learning for person re-identification",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wojke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bewley",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 IEEE winter conference on applications of computer vision",
            "volume": "",
            "issn": "",
            "pages": "748--756",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Simple online and realtime tracking with a deep association metric",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Wojke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bewley",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Paulus",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 IEEE international conference on image processing",
            "volume": "",
            "issn": "",
            "pages": "3645--3649",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Spatial-temporal relation networks for multi-object tracking",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "3988--3998",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "A vision-based social distance and critical density detection system for COVID-19",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Yurtsever",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Renganathan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "A"
                    ],
                    "last": "Redmill",
                    "suffix": ""
                },
                {
                    "first": "\u00dc",
                    "middle": [],
                    "last": "\u00d6zg\u00fcner",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2007.03578"
                ]
            }
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Poi: Multiple object tracking with high performance detection and appearance feature",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "European conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "36--42",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Scalable person re-identification: A benchmark",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the IEEE international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "1116--1124",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Detecting suspected epidemic cases using trajectory big data",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "H"
                    ],
                    "last": "Wen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.00908"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The distinction between the detection-based VSD and the trajectory-based VSD.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The transition mechanism of the four states of the tracklets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "The architecture of the AAM-Softmax appearance feature descriptor network.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The flow chart of the proposed hierarchical data association.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "The entire process of online multi-object tracking based on hierarchical data association.is the perspective transformation matrix. ( , , ) is the calibrated homogeneous coordinate in the bird's eye view. Its corresponding Cartesian coordinate ( \u2032 , \u2032 ) can be obtained as Eq.(11):",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The gathering group and the corresponding gathering degree.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Multi-Object Tracking Accuracy (MOTA): it reflects the overall accuracy according to false positives, false negatives and identity switches; (2) Multi-Object Tracking Precision (MOTP): it reveals the overall tracking precision based on the bounding box overlap between the ground-truth and the prediction position; (3) Mostly Tracked (MT): the percentage of ground-truth trajectories that are covered by the tracker output for more than 80% of their length ; (4) Mostly Lost (ML): the percentage of ground-truth trajectories that are covered by the tracker output for less than 20% of their length; (5) Identity Switches (IDS): the number of times the reported identity of a ground-truth trajectory changes; (6) Fragmentation (FM): the number of times a ground-truth trajectory is interrupted in the tracking result.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "The comparisons between the original perspective view and the calibrated bird's eye view for SCU-VSD.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "The rectangular reference area in each video is marked as a purplebox. Due to the different perspective views of the videos, the reference areas in original videos are presented as different quadrilaterals. In the calibration process, we use four corresponding vertex coordinate pairs of the reference area in the original video and the bird's eye view to calculate the perspective transformation matrix of each video by Eq. (10), shown in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "(continued).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "lated; for pedestrians' trajectories, the NTP-USD and the NPPC-USD are calculated. The real-time social distancing measurement and analysis for SCU-VSD dataset are shown in Fig. 8. The figure on the left is the original video, and the one on the right is the corresponding bird's eye view. The tracking pedestrians in the original video are transformed to the trajectory points in the bird's eye view. The Euclidean distance between J. Su et al.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "The real-time social distancing measurement and analysis for SCU-VSD dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "(continued).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "The colourmaps of ARP-USD and AGD for every 10 s.",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Comparisons of different online algorithms on MOT16 benchmark (with private detectors).",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The information of the selected rectangular reference areas for SCU-VSD Dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The coordinates of the four vertex pairs and the perspective transformation matrix for SCU-VSD.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This work was supported by the National Natural Science Foundation of China under Grant 61871278, the Sichuan Science and Technology Program, China (no. 2018HH0143), the Sichuan Science and Technology Program, China (no. 2019YFH0034), the Sichuan Education Department Program, China (no. 18ZB0355).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements"
        }
    ]
}