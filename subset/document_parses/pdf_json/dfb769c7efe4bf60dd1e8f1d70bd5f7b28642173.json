{
    "paper_id": "dfb769c7efe4bf60dd1e8f1d70bd5f7b28642173",
    "metadata": {
        "title": "A note on tools for prediction under uncertainty and identifiability of SIR-like dynamical systems for epidemiology",
        "authors": [
            {
                "first": "Chiara",
                "middle": [],
                "last": "Piazzola",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Consiglio Nazionale delle Ricerche",
                    "location": {
                        "addrLine": "Via Ferrata 5/A",
                        "postCode": "27100",
                        "settlement": "Pavia",
                        "country": "Italy"
                    }
                },
                "email": ""
            },
            {
                "first": "Lorenzo",
                "middle": [],
                "last": "Tamellini",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Consiglio Nazionale delle Ricerche",
                    "location": {
                        "addrLine": "Via Ferrata 5/A",
                        "postCode": "27100",
                        "settlement": "Pavia",
                        "country": "Italy"
                    }
                },
                "email": ""
            },
            {
                "first": "Ra\u00fal",
                "middle": [],
                "last": "Tempone",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Alexander von Humboldt Professor in Mathematics for Uncertainty Quantification",
                    "institution": "RWTH Aachen University",
                    "location": {
                        "addrLine": "Pontdriesch 14-16",
                        "postCode": "52062",
                        "settlement": "Aachen",
                        "country": "Germany"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "We provide an overview of the methods that can be used for prediction under uncertainty and data fitting of dynamical systems, and of the fundamental challenges that arise in this context. The focus is on SIR-like models, that are being commonly used when attempting to predict the trend of the COVID-19 pandemic. In particular, we raise a warning flag about identifiability of the parameters of SIR-like models; often, it might be hard to infer the correct values of the parameters from data, even for very simple models, making it non-trivial to use these models for meaningful predictions. Most of the points that we touch upon are actually generally valid for inverse problems in more general setups.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "This work provides an overview of the methods that can be used for prediction under uncertainty (also known as Uncertainty Quantification) and data fitting of dynamical systems, and of the fundamental challenges that arise in this context. While this work can be easily connected with the usage of SIR-like models for the COVID-19 pandemic, the discussion presented here is actually valid for compartmental models in epidemiology and for dynamical systems in general; most points would actually be valid also in the context of inverse problems with spatial inhomogeneities. We put particular emphasis on the issue of identifiability, whose possible lack might cause serious issues when attempting long-term forecasts. To make our case clearer, in this work we use synthetic data only, which gives us full control on the errors generated by the numerical identifiability procedure.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "For the sake of compactness, we have chosen to not provide many technical details on the topics that we touch, but rather point the reader to the relevant bibliography. For the same reason, most of the bibliography for further reading is provided at the end of each section, rather than during the discussion. We chose, however, to keep a rather concrete register, therefore each section comes with one or two short examples. We use for this purpose simple models, with the understanding that the points raised by the examples will be even more valid for more complicated models. For a more bird's eye view on data-informed modeling and identifiability and their ramifications in the general society, see e.g. [1, 33] . For readers' convenience, we report here the topic of each section and list the examples: Section 2: Short overview of SIR-like models in epidemiology Section 3: Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty Section 4: Sensitivity analysis",
            "cite_spans": [
                {
                    "start": 710,
                    "end": 713,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 714,
                    "end": 717,
                    "text": "33]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The recent COVID-19 pandemic has triggered an unprecedented effort among researchers worldwide 1 . In the field of applied mathematics, a large share of this effort has been focusing on devising tools to forecast the trends of the epidemics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "The most widely used tools to this end are compartmental models, where individuals of a population are categorized in compartments (Infected, Recovered, Dead, etc.) and can transition from one compartment to another according to some \"transition rates\". The origin of these models can be traced back to the work of [38] . The actual model in that paper was a system of integro-differential equations. Some simplifications allow to rewrite those equations as a non-linear system of ordinary differential equations (ODEs), whose simplest form is the SIR model:",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 319,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "which describes the time-evolution of three compartments: individuals (S)usceptible to the disease, individuals (I)nfected with the disease, and finally individuals (R)emoved from the disease dynamics (either because they recovered, assuming immunity after having contracted the disease, or died). The total number of individuals in the population N pop = S + I + R is supposed constant, and individuals transition from one compartment to the next one with certain transition rates \u03b2, r. Besides the ODE, the Kermack and McKendrick integro-differential equations can also be rewritten as a stochastic differential equation whose limit is the ODE equation; see [14] . Of course, a simple SIR model is insufficient to capture the dynamics of the COVID-19 disease, due to its biological peculiarities, such as the incubation time and the presence of asymptomatic carriers of the disease, as well as human interventions such as individuals in quarantine (hence with limited transmissivity) and hospitalized. Therefore, many works in the COVID-19 literature consider more complex variations of the simple SIR model (1) with, for example, more compartments, time-dependent coefficients, or by introducing network models, in an attempt to better describe the dynamics of the pandemic and provide reliable forecasts of its evolution. Of course, one should always keep in mind that while more complex models have potentially a greater predictive power, they are also more complex to analyze and tune, so that one should ideally look for for the model with the optimal trade-off between these two aspects.",
            "cite_spans": [
                {
                    "start": 660,
                    "end": 664,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "Bibliography and further reading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "\u2022 For a survey of SIR-like models \"pre-COVID\" for diseases such as Zika, Dengue, Ebola, H1N1, see [13, 14, 71, 59, 16, 36, 57, 70] .",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "[13,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 103,
                    "end": 106,
                    "text": "14,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 107,
                    "end": 110,
                    "text": "71,",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 111,
                    "end": 114,
                    "text": "59,",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 115,
                    "end": 118,
                    "text": "16,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 119,
                    "end": 122,
                    "text": "36,",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 123,
                    "end": 126,
                    "text": "57,",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 127,
                    "end": 130,
                    "text": "70]",
                    "ref_id": "BIBREF70"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "\u2022 For some examples of SIR-like models for COVID, see e.g. [31, 3, 52, 73, 19, 30, 40] .",
            "cite_spans": [
                {
                    "start": 59,
                    "end": 63,
                    "text": "[31,",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 64,
                    "end": 66,
                    "text": "3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 67,
                    "end": 70,
                    "text": "52,",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 71,
                    "end": 74,
                    "text": "73,",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 75,
                    "end": 78,
                    "text": "19,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 79,
                    "end": 82,
                    "text": "30,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 83,
                    "end": 86,
                    "text": "40]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "\u2022 A somewhat different approach is proposed in [54] , where the underlying model is a simple SIR, with a more complex model for the probability distribution of the delays between infection and the observed events (hospitalization, recovery, death).",
            "cite_spans": [
                {
                    "start": 47,
                    "end": 51,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "\u2022 Control strategies for SIR-like systems are also an important topic, see e.g. [2] .",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 83,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "SIR-like models in epidemiology"
        },
        {
            "text": "In general, SIR-like models can be written as ODE systems for a state vector X with N states components. The evolution of the system depends on N coef coefficients p = [p 1 , . . . , p N coef ] and on the N states initial conditions q = [q 1 , . . . , q Nstates ]. Moreover, we might be interested in monitoring not only the states of the system but also some related quantities Y (Quantities of Interest, say we have N qoi of them), which can be derived from X by an observation operator G, that in turn might depend on some hyper-parameters h (let us denote their number by N hyp ):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "where \u2200t \u2208 [0, T ] we have X \u2208 R Nstates , Y \u2208 R Nqoi , and f (\u00b7, p) : R Nstates \u2192 R Nstates , G(\u00b7, h) :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "We collect coefficients and initial conditions in a vector \u03d1 = [p, q] with N \u03d1 = N coef + N states components. Throughout the manuscript, we refer to \u03d1 as parameters, and we will write X(\u03d1), Y (\u03d1, h) to emphasize the dependence of the states and quantities of interest on parameters and hyper-parameters. For SIR, p = [\u03b2, r], and Y might be for instance:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 the peak-time of number of infected persons: G(X) = arg max t\u2208[0,T ] I(t);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 the cumulative number of infected persons: G(X) = T 0 I(t)dt. This quantity is also called incidence data in epidemiology, as opposed to prevalence data, which are the instantaneous data, G(X(t)) = I(t);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 the peak-time of the new infected persons in a time-window of length \u2206: G(X, \u2206) = arg max t t+\u2206 t \u03b2 Npop S(s)I(s)ds.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "Another important scenario is under-reporting, where we assume that due to insufficient measurements, we observe only a fraction K of the total number of infected, G(X(t), K) = 1 K I(t) (K being possibly unknown). Typically, most of the parameters (and possibly the hyper-parameters as well) are not known exactly and they are either taken from literature or calibrated from data. We can then assume that these parameters are random variables with a certain probability density function (pdf): for instance, uniform random variables over a variability range, or Gaussian random variables centered around a most likely value. 2 Then, a natural question is: how does the variability of the parameters impact the quantities of interest Y of the SIR-like model at hand? Or otherwise, what is the variability range of Y as the parameters range over their values?",
            "cite_spans": [
                {
                    "start": 625,
                    "end": 626,
                    "text": "2",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "This kind of analysis is known as Forward Uncertainty Quantification (UQ) in computational science and engineering. The most straightforward way to accomplish this task is by sampling methods, i.e., by generating M samples of the parameters \u03d1 1 , \u03d1 2 , . . . \u03d1 M according to their probability distribution, solving the SIR-like system for each \u03d1 i , and estimating statistics such as mean, standard deviation, confidence bands, and the probability density function of Y from the corresponding quantities of interest ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "where the parameter samples \u03d1 i and the weights \u03c9 i depend on the specific sampling method used. For instance, Monte Carlo employs random \u03d1 i and \u03c9 i = 1 M . The probability density function of the quantity of interest can be approximated by, for example, histograms or kernel density estimates [60, 51] .",
            "cite_spans": [
                {
                    "start": 295,
                    "end": 299,
                    "text": "[60,",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 300,
                    "end": 303,
                    "text": "51]",
                    "ref_id": "BIBREF51"
                }
            ],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "Example 1 (Forward Uncertainty Quantification of a SIR model). Consider a SIR model with initial conditions S(0) = 0.95, I(0) = 0.05, R(0) = 0. The survey on the literature performed by [19] suggests these ranges for the parameters: \u03b2 \u2208 [0.25, 0.35], r \u2208 [0.06, 0.18]. We assume that a-priori we have no knowledge that any value of \u03b2, r is more plausible than others; therefore, we assume that \u03b2, r are uniform independent random variables. We solve the SIR system with Matlab's ode45 up to final time T = 150. Figure 1 -left shows the SIR dynamics obtained by 100 Monte Carlo samples. The black lines are the average trajectories of SIR obtained by sampling values of \u03b2 and r (65 samples with sparse grids sampling). The remaining panels show pdfs of quantities of interest of SIR: SIR states at T = 30 (after the average peak position) and T = 100 (when the dynamics is over), again computed both with sparse grids (solid line) and Monte Carlo (circle markers); peak time and peak intensity (we only show the pdf obtained by sparse grids). Figure 2 shows the so-called response surface, i.e., a plot showing how the quantity of interest changes as \u03b2 and r vary in their range (we report only those obtained by sparse grids). Response surfaces are useful to derive information on the general trends of the system, and to quickly approximate the value of a quantity of interest without evaluating the full model (i.e., they act as a surrogate model for the dynamical system, where the pdfs of the quantities of interest obtained by sparse grids have actually been obtained by querying these response surfaces rather than the full model).",
            "cite_spans": [
                {
                    "start": 186,
                    "end": 190,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [
                {
                    "start": 511,
                    "end": 519,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1042,
                    "end": 1050,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "Bibliography and further reading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 For random sampling methods (Monte Carlo, Latin Hypercube Sampling, Stratified Sampling), see [12, 48, 45] . Random sampling methods are robust and easy to implement, but have a poor accuracy (typically proportional to M \u22121/2 ).",
            "cite_spans": [
                {
                    "start": 96,
                    "end": 100,
                    "text": "[12,",
                    "ref_id": null
                },
                {
                    "start": 101,
                    "end": 104,
                    "text": "48,",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 105,
                    "end": 108,
                    "text": "45]",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 For sparse grids sampling methods, see [4, 76, 18, 34] . These are deterministic (i.e., non-random) sampling schemes that generalize tensor (cartesian) grid sampling when the parameter space is highdimensional, in which case a cartesian grid sampling scheme would be too expensive. They are less straightforward than random sampling methods, but guarantee greater accuracy, at least for problems up to a few tens of parameters. These tools have been developed in the context of Uncertainty Quantification for models that are expensive to evaluate, whereas evaluating a SIR-like model is typically very fast. Therefore, their use is not as crucial in the context of COVID-19, and random sampling methods might be favored for their straightforwardness. Sparse grids have still an advantage over random sampling for sensitivity analysis, see the next section.",
            "cite_spans": [
                {
                    "start": 41,
                    "end": 44,
                    "text": "[4,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 45,
                    "end": 48,
                    "text": "76,",
                    "ref_id": "BIBREF76"
                },
                {
                    "start": 49,
                    "end": 52,
                    "text": "18,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 53,
                    "end": 56,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": "\u2022 A somewhat intermediate possibility are Quasi Monte Carlo sampling methods, such as Sobol or Halton sequences. These are also deterministic sampling schemes as well, that aim at covering the space of parameters in the \"most uniform way\" (space filling) [12, 48, 66] . They typically have accuracy proportional to M \u22121 .",
            "cite_spans": [
                {
                    "start": 255,
                    "end": 259,
                    "text": "[12,",
                    "ref_id": null
                },
                {
                    "start": 260,
                    "end": 263,
                    "text": "48,",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 264,
                    "end": 267,
                    "text": "66]",
                    "ref_id": "BIBREF66"
                }
            ],
            "ref_spans": [],
            "section": "Forward Uncertainty Quantification (UQ): tools to make predictions under uncertainty"
        },
        {
            "text": ": pinpoint what parameters we need to get right, and preliminary assessment of feasibility of inversion Sensitivity analysis aims at assessing which parameters have the largest impact on the quantities of interest. This information is crucial to determine which parameters should be subjected to further investigations to reduce their variability. The sensitivity analysis can be local or global :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 local sensitivity analysis is usually based on the derivatives of the quantities of interest with respect to \u03d1, upon fixing each \u03d1 i at some representative value (average, median, mode). 3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 global sensitivity analysis considers the total variability of a quantity of interest and decomposes such variability into elementary components, each due to \u03d1 i individually or to mixed effects such as \u03d1 i \u03d1 j , \u03d1 i \u03d1 j \u03d1 k , . . .: the larger the component, the more sensitive the quantity of interest to \u03d1 i is.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "In these short notes we focus on the Sobol indices for global sensitivity analysis, which are variance-based indices, i.e. the variability of the quantity of interest is measured as its variance [67] . The total variance is decomposed as follows: one term due to each \u03d1 i ; one term due to each mixed effect composed of two parameters, \u03d1 i \u03d1 j ; one term for each mixed effect composed of three parameters, and so forth. The sum is then normalized to one, and each quantity thus obtained is called Sobol-index:",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 199,
                    "text": "[67]",
                    "ref_id": "BIBREF67"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "The Sobol index of each parameter \u03d1 i per se, s i , is usually reported as an indicator of the importance of each parameter, and is called the principal Sobol index. Another relevant quantity is the total Sobol index of a parameter, s T i , which is obtained by adding to the principal Sobol index of \u03d1 i all the Sobol indices of mixed effects of which \u03d1 i is part, e.g. for \u03d1 1 :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "This approach bears many similarities with the ANOVA decomposition in statistics. An important observation is that, with an eye to parameter identification, we can expect that if the Sobol index of a parameter is small, it will be hard to recover its value from measurements of the quantity of interest. We also remark that as a general rule of thumb, the larger the range of values of a parameter, the larger its corresponding Sobol indices.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "Example 2 (Computing the Sobol indices for a SIR model). Consider again the SIR example of the previous section. The Sobol decomposition of any quantity of interest Y reads 1 = s \u03b2 + s r + s \u03b2r and the total Sobol indices can be computed as s T \u03b2 = s \u03b2 + s \u03b2r , s T r = s r + s \u03b2r . Figure 3 shows the time-evolution of the Sobol indices (principal and total) for the SIR states: the principal indices are represented by the solid line, while the total indices are represented by the dashed line. The principal and total indices behave very similarly, indicating that the interaction between the two parameters is quite limited. Note that the Sobol indices are not constant in time and behave differently for the different stages. More specifically, the asymptotic regime is mostly dictated by r for all the stages, while \u03b2 impacts more in the transient regime, especially in the case of the stage R. This has an impact on the inversion procedure. In particular, if the data of R are missing or too noisy severe difficulties in the estimation of \u03b2 can be encountered. Moreover, note that the influence of r is larger, in general. Further evidence of this is shown in the right-most panel, where we show the variability of the trajectories if the range of r is reduced to [0.06, 0.1]. The overall variability is greatly reduced, as expected.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 283,
                    "end": 291,
                    "text": "Figure 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Note that in general"
        },
        {
            "text": "Bibliography and further reading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "\u2022 Classical books on sensitivity include [11, 63] .",
            "cite_spans": [
                {
                    "start": 41,
                    "end": 45,
                    "text": "[11,",
                    "ref_id": null
                },
                {
                    "start": 46,
                    "end": 49,
                    "text": "63]",
                    "ref_id": "BIBREF63"
                }
            ],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "\u2022 Sobol indices can be computed either by Monte Carlo sampling, see e.g. [63] , or perhaps more conveniently by polynomial expansions or sparse grids sampling, see e.g. [29] .",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 77,
                    "text": "[63]",
                    "ref_id": "BIBREF63"
                },
                {
                    "start": 169,
                    "end": 173,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "\u2022 Sobol indices analyses for SIR-like problems can be found in [9, 13] .",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 66,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 67,
                    "end": 70,
                    "text": "13]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "\u2022 An alternative to Sobol indices are the Morris indices [47] .",
            "cite_spans": [
                {
                    "start": 57,
                    "end": 61,
                    "text": "[47]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "\u2022 Sobol indices can also be computed with respect to measures of variability other than variance, see e.g. [20] .",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 111,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Note that in general"
        },
        {
            "text": "Inverse UQ (data fitting) as a preliminary step to tune the parameters pdf to the data",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "The sections above discussed some general elementary tools to perform predictions under uncertainty once the pdfs for the parameters have been chosen. This section discusses the preliminary step to the uncertainty quantification process, i.e. how to construct pdfs for the parameters, and in particular how to do so by merging prior information on the parameters and the available data. Upon deriving these data-informed pdfs, we will use them to carry out the uncertainty quantification analysis. In literature, data-informed pdfs are often called posterior pdfs, \u03c1 post , as opposed to prior pdfs, \u03c1 prior , before the data are available.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "Computing the posterior pdfs of the parameters can be done by means of the Bayes theorem on conditional probabilities. This procedure is quite general and includes as a special case the least-squares approach for data fitting (this connection will be made clearer later). For ease of exposition, we exemplify the procedure over a specific example -extension to other problems is relatively straightforward (see e.g. Examples 4, 5 later on). For now we assume that:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 We have at our disposal N meas measurements of the I state and N meas measurements of the R state, at equispaced times t i = i\u2206t, i = 1, 2, 3, . . . N meas . In total we have 2N meas data, D = {\u00ce 1 ,\u00ce 2 , . . . ,R 1 ,R 2 , . . .};",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 These data correspond to some values \u03d1 true of coefficients and initial conditions of the system (2);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 The prior pdfs for \u03d1 are uniform (see Example 4 for an example with Gaussian priors);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 Our measurements are under-reported by a factor K, i.e., we are able to measure only a fraction of the actual compartments;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 Data are noisy, i.e. affected by some random errors I,i , R,i , that are independent random variables with zero mean and standard deviation \u03c3;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 identical \u03c3 for I and R (see Example 5 for the generalization to the case where the two compartments have different \u03c3);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 I,i , R,i are Gaussian random variables N (0, \u03c3 2 ). See discussion at the end of the section for bibliography on more general models;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "\u2022 K, \u03c3 are hyper-parameters constant in time. We assume for the moment that K is known and \u03c3 is unknown (see Examples 6, 7, 8 for a discussion on how to determine K in case it is assumed unknown as well).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "In formulas our data model is the following:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "We also introduce the 2N meas misfits M = {M I,1 , M I,2 , . . . , M R,1 , M R,2 , . . .} between the data and the model predictions, obtained upon fixing the parameters at some estimate \u03d1 guess of \u03d1 true :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "The Bayes theorem provides us with a practical formula to compute the posterior pdf of the parameters \u03d1, i.e., with a means of adjusting the prior pdf to the data at hand. An informal writing of the Bayes formula is pdf(\u03d1 given M) = pdf(M given \u03d1) \u00d7 pdf(\u03d1) \u00d7 1 pdf(M) (7) where \"pdf(\u03d1 given M)\" is the pdf of the parameters when given the misfits, hence given the data (i.e., the posterior pdf that we aim at computing), while \"pdf(\u03d1)\" is the pdf of the parameters based only on a-priori information. The \"pdf(M)\" can be simply considered to be the normalization constant such that the posterior pdf is actually a pdf (i.e., its integral is equal to 1). Therefore, to make the computation of the posterior pdf practical we only need to know the expression of the \"pdf(M given \u03d1)\", which is the so-called likelihood function; we will denote this quantity as L(\u03d1).",
            "cite_spans": [
                {
                    "start": 268,
                    "end": 271,
                    "text": "(7)",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Bayes Theorem and posterior distributions"
        },
        {
            "text": "Deriving an expression for L(\u03d1) is quite straightforward. If \u03d1 guess were the true values, then the probability that the misfits M have certain values is the probability that the measurement errors I,i , R,i have those values (cf. Equations (5) and (6)). By assumption, we know that I,i , R,i are independent Gaussian random variables with zero mean and standard deviation \u03c3, therefore,",
            "cite_spans": [
                {
                    "start": 241,
                    "end": 244,
                    "text": "(5)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Bayes Theorem and posterior distributions"
        },
        {
            "text": "so that the posterior pdf of the parameters reads",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bayes Theorem and posterior distributions"
        },
        {
            "text": "where the \u221d symbol is used to signify that we have omitted the normalization constant.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Bayes Theorem and posterior distributions"
        },
        {
            "text": "Computational challenges of working with the posterior pdf Equipped with (9), we would then only need to proceed as in Section 3 and perform the Uncertainty Quantification analysis. Although conceptually straightforward, this approach can be practically challenging, because it is not easy to obtain samples of the random parameters \u03d1 distributed according to the posterior pdf (9) . The classical computational tool to this end is the so-called Markov-Chain Monte Carlo -MCMC [69] , which generates a sequence of proposed values of \u03d1 that are asymptotically distributed according to \u03c1 post . A nice feature of MCMC algorithms is that they do not require knowledge of the normalization constant. The use of MCMC for forward Uncertainty Quantification has however some drawbacks:",
            "cite_spans": [
                {
                    "start": 378,
                    "end": 381,
                    "text": "(9)",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 477,
                    "end": 481,
                    "text": "[69]",
                    "ref_id": "BIBREF69"
                }
            ],
            "ref_spans": [],
            "section": "5.2."
        },
        {
            "text": "1. the likelihood function has to be evaluated at every proposed \u03d1, which requires evaluating the SIR-like model. Even if evaluating SIR-like models for a single choice of \u03d1 is quite cheap, this procedure can be overall expensive, bearing in mind that until the sequence of generated \u03d1 enters in the asymptotic regime, the values generated have to be discarded because they are not distributed according to \u03c1 post .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5.2."
        },
        {
            "text": "2. most MCMC algorithms proceed by acceptance-rejection criteria, where a new value of \u03d1 is generated and then rejected if doesn't agree with certain criteria; this leads to a further increase in the number of model evaluations;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5.2."
        },
        {
            "text": "3. the forward UQ analysis based on the MCMC samples is a Monte Carlo analysis, which needs many samples of \u03d1 to provide an accurate estimate (the accuracy being proportional to the inverse of the square root of the number of samples as already discussed -or more precisely, the inverse of the square root of the number of accepted samples upon having entered the asymptotic regime).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5.2."
        },
        {
            "text": "4. the design of an efficient MCMC algorithm (effective proposal strategies with low rejection rate, quick to enter the asymptotic regime) might be non-trivial.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5.2."
        },
        {
            "text": "Instead of using an MCMC approach, the strategy we employ here is to approximate \u03c1 post with a multivariate Gaussian distribution with mean \u00b5 G and covariance matrix \u03a3 G ; this is also called Fisher approximation. This approximation, provided that the available data is sufficient to determine the parameters, is in general more and more accurate as more data become available, i.e., as N meas \u2192 \u221e, and it has the advantage that upon doing so, it is much easier to perform the uncertainty quantification analysis, because obtaining samples from Gaussian random variables is a standard task. It has, however, some disadvantages that will be made clearer in the later sections, when discussing identifiability of the system: in a nutshell, we can already reveal that the problem is that the Fisher approximation assumes identifiability of the system, but this is not always true in practice and whether the system is identifiable or not should be checked beforehand. MCMC instead does not assume identifiability, and can in principle be used even when the system is not identifiable: dealing with a non-identifiable system is, however, intrinsically difficult and care needs to be taken also when tackling it using MCMC methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "The Gaussian approximation is centered at the point of maximum of the posterior pdf (maximum aposteriori estimate, MAP). Since we have further made the assumption that the prior pdf for \u03d1 is uniform (see Example 4 for the extension to the case of non-uniform prior), this is equivalent to computing the value \u03d1 where the likelihood function is maximized; this point is generally known as the Maximum Likelihood Estimate (MLE) for \u03d1:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "In practice, it is numerically more convenient to work with the logarithm of the likelihood, and to recast the problem as a minimization problem, i.e., to compute \u00b5 G as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "The function N LL(\u03d1) is called negative log-likelihood, and in the particular case where the noise affecting the data is assumed to be Gaussian random variables (such as in our case), this problem is equivalent the least-squares estimate of \u03d1. Indeed, it is straightforward to combine (8) and (10) to obtain 4",
            "cite_spans": [
                {
                    "start": 285,
                    "end": 288,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "Observe that this formulation does not require prior information on the value of the noise variance \u03c3: if \u03c3 is unknown, it can be recovered as the sample variance of the misfits at \u03d1 M LE",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "The covariance matrix \u03a3 G can be chosen as the inverse of the Hessian of the NLL at the MLE estimate of the parameters \u03d1 M LE , see e.g. [15] :",
            "cite_spans": [
                {
                    "start": 137,
                    "end": 141,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "The matrix H is also called the Fisher information matrix. The diagonal entries of \u03a3 G are the variances of the posterior pdfs of the Gaussian approximations of the parameters, i.e.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "This formula quantifies the intuitive fact that the precision of the MLE estimate is related to how narrow the minimum of the NLL at \u03d1 M LE is. A deep, narrow minimum means that moving even slightly from \u03d1 M LE will change consistently the value of NLL; therefore, we have a significant evidence that the estimate is precise. Conversely, a shallow minimum means that the MLE estimate is not very reliable. At \u03d1 M LE the Hessian is positive definite, with large eigenvalues if the minimum is narrow; therefore, its inverse has small eigenvalues, and in general small diagonal entries, that can be used as variances of the parameters (the opposite is true for a shallow minimum: the Hessian has small eigenvalues, which means that the diagonal entries of its inverse will be large, and consequently the variances of the parameters will be large). As already mentioned, approximating the true posterior with equation (14) is in general more and more valid as more data become available, provided that the system is identifiable, as we will make clear below. 5 Given the expression of the likelihood in equation (8), we can derive an expression for H as follows:",
            "cite_spans": [
                {
                    "start": 1055,
                    "end": 1056,
                    "text": "5",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": ". Usually, the terms involving the second derivatives of I, R are dropped because they are smaller than the other terms: this is because either the misfits at \u03d1 = \u03d1 M LE are small or because of near-linearity of the models I m (\u03d1), R m (\u03d1) close to the solution, i.e., \u2202 \u03d1i,\u03d1j I m (\u03d1 M LE ) and \u2202 \u03d1i,\u03d1j R m (\u03d1 M LE ) are small [49, Chap. 10] . Collecting all the derivatives of the model predictions with respect to the parameters in the Jacobian matrix J IR , we can write in compact form 6",
            "cite_spans": [
                {
                    "start": 327,
                    "end": 331,
                    "text": "[49,",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 332,
                    "end": 341,
                    "text": "Chap. 10]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "Finally, we make an important remark: minimizing the NLL to compute \u03d1 M LE requires repeatedly evaluating the SIR-like model for the various parameters \u03d1 proposed by the optimizer. The minimization procedure should be repeated several times with different starting guesses, to avoid local mimima.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "Example 3 (Inverse and posterior-based Forward Uncertainty Quantification of a SIR model). In this example we show the results of the inversion procedure using artificial/synthetic data, by fixing the values of the parameters to \u03d1 true = [0.29, 0.09], adding numerical Gaussian noise with \u03c3 = 0.025, discount factor to K = 3, considering data collected at t = 1, 2, . . . , 30, and verifying the results of the inversion procedure. We will then perform the Forward Uncertainty Quantification based on the posterior pdf.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "Regarding the results of the inversion procedure, we expect to see that \u03c1 post is centered close to the true value of the parameters with a reasonably small variance, i.e. \u03d1 M LE \u2248 \u03d1 true and [\u03a3 G ] i,i such that the support of \u03c1 post (\u03b8 i ) is smaller than the support of \u03c1 prior (\u03b8 i ). We also expect \u03c3 2 M LE to be a reasonable approximation of \u03c3. Regarding the subsequent forward Uncertainty Quantification, we expect to see that the uncertainty in the prediction should be smaller than what would be obtained by using the prior information only, and the expected values of the quantities of interest should be closer to the true values when using the posterior pdf than when using the prior. The resulting estimates for the parameters obtained from the inverse UQ are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "The estimated covariances computed using the full Hessian (that we can compute directly by centered finite differences in this simple test) and with Equation (16) Figure 4 provides more details on the results. The top row shows on the left the true trajectories from which the data were generated (dotted thick lines), the noisy data (circles with thin line) and the trajectory obtained by fixing the parameters as \u03d1 = \u03d1 M LE . The next panel provides a zoom on the data. We have also rescaled both the true trajectory and the MLE trajectory by K, to emphasize the match with the data. The match between true and MLE trajectories is very good, although not perfect (the distance between the trajectories would further reduce for smaller noises \u03c3). The last two panels of the row compare the prior and (Gaussian approximation of ) the posterior pdfs of the parameters. It can be seen that the posterior are centered close to the true value, and the Gaussian pdf is quite concentrated in comparison to the prior interval. The bottom row provides details about the minimization procedure. More specifically, the leftmost panel shows the contour of the NLL function, the true values of the parameters (yellow dot) and the MLE estimate (red dot). The presence of noise prevents a perfect match between the true values and the MLE estimate, but the match is nonetheless good and the isolines are nicely rounded, which suggest a unique, narrow (hence trustworthy) minimum. The next panel shows the corresponding likelihood function, taken by exponentiating the NLL (remember that since we have assumed uniform prior, the posterior is proportional to the likelihood), which shows a clear Gaussian profile. The next panel shows the Gaussian approximation where the covariance approximation has been computed by inverting the true Hessian of the NLL, while the approximation obtained by using the Jacobian matrix only is shown in the right-most panel, cf. equation (15) and (16) . The three latter plots match well (other than by the rescaling factor), indicating that the approximation steps are not introducing significant errors. The MLE has been computed with the simple fminsearch algorithm in Matlab, which implements the derivative-free Nelder-Mead (simplex) algorithm. Finally, upon calibrating the pdfs of the parameters to the data, the forward UQ analysis can be performed, using the sampling methods discussed in Section 3 to compute the mean of the quantities of interest (S,I,R compartments, location and intensity of the peak), and their pdfs. Results are shown in Figure 5 , where we compare the results obtained with prior and posterior pdfs, to appreciate the improvement in the quality of the predictions if data are provided. The top row compares the true and the expected SIR trajectories after the forward UQ analysis based on prior and posterior pdfs. The thick solid lines are the expected values (we compute these with sparse grids sampling), the thick dotted lines are the true trajectories and the colored lines are Monte Carlo trajectories based on the prior/posterior distribution. The results clearly show that the posterior forward-UQ is more centered around the true trajectories, and the uncertainty in the prediction is smaller. Similar conclusions can be obtained by looking at the pdfs of the quantities of interest computed based on either the prior or the posterior pdfs, where we have marked with vertical dotted lines the true values (mid-row: prior-based, bottom row: posterior based).",
            "cite_spans": [
                {
                    "start": 1955,
                    "end": 1959,
                    "text": "(15)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1964,
                    "end": 1968,
                    "text": "(16)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [
                {
                    "start": 163,
                    "end": 171,
                    "text": "Figure 4",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 2570,
                    "end": 2578,
                    "text": "Figure 5",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Gaussian approximation of the posterior: MLE and Fisher approximation"
        },
        {
            "text": "Suppose that we provide prior information about the parameters \u03d1 true different from the uniform distribution. For instance, we could for simplicity assume that each \u03d1 i is a Gaussian random variable with mean\u03b8 i and standard deviation s i , and these variables are all independent (in this way we are allowing \u03d1 i to assume negative values with a non-zero probability; we will fix this issue later in the example). Then, the posterior distribution (9) becomes ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "The computation of the sample variance estimator \u03c3 2 M LE and of the Hessian H should be of course updated accordingly. Coming back to the non-positivity issue of the Gaussian prior pdf, a possible workaround is e.g. to assume a log-normal prior for the parameters and then work with the log of the parameters in the model. The expression derived in equation (17) for the posterior pdf would still be valid, the change being \"hidden\" in the mappings \u03d1 \u2192 R(\u03d1, t), \u03d1 \u2192 I(\u03d1, t).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "Example 5 (Inverse Uncertainty Quantification when different data types have different noise levels). Let us consider the data model (5) and assume that the noises I,i and R,i are independent Gaussian random variables distributed according to N (0, \u03c3 2 I ) and N (0, \u03c3 2 R ), respectively. The posterior distribution of the parameters can be computed with a slight modification of the procedure explained above to account for the different variances. We detail the new procedure here below, following closely [15, 53] .",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 136,
                    "text": "(5)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 509,
                    "end": 513,
                    "text": "[15,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 514,
                    "end": 517,
                    "text": "53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "We begin by assuming that the ratio \u03bb between the variances of the two sets of data \u03bb :=",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "is known. In this case minimizing the NLL (10) is equivalent to minimizing the following quantity",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "which is obtained combining (8) , opportunely modified to incorporate the different standard deviations, and (10). The parameter \u03bb weighs the sum of squared residuals of I and R, highlighting a different level of trust in the first or second set of data. If \u03bb is small, the residuals of I condition more the quantity T , whereas the data for S are more influential if \u03bb is large. Finally, if \u03bb = 1 the data sets are equally weighted and we recover the least-squares formula (11) . Hence, minimizing the quantity T can be seen as a weighted least-squares criterion.",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 31,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 474,
                    "end": 478,
                    "text": "(11)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "As \u03bb is however unknown in general, we vary iteratively \u03bb within an appropriate range of values, and minimize T for each value of \u03bb to find the corresponding \u03d1 M LE . Among the considered \u03bb, we then select the one that realizes the minimum of N LL. The corresponding value of T is also needed, and we denote it by 1 6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81 T min . Indeed, the values of the empirical variances of the two data sets are then recovered in the following way",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": ". Note that value of \u03bb can be selected also by means of criteria other than the minimum of the NLL. In particular, in [53] the Kayshap Information Criteria has been employed, that penalizes values of \u03bb that result in shallow NLL.",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 122,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "Finally, we illustrate this minimization procedure with the help of an example. We consider the SIR model, and generate 41 equispaced synthetic data in the time interval [0, 20] with \u03d1 true = [0.29, 0.09], adding numerical Gaussian noises with \u03c3 I = 0.2 and \u03c3 R = 0.05, where \u03bb true = 16. We consider integer values of \u03bb in the range [1, 90] , and for each of them we minimize T . In Figure 6 on the left we plot the minimum value of the NLL for each considered \u03bb. We observe that the value of \u03bb resulting in the minimum NLL can be approximately correctly identified (\u03bb min \u2248 21), resulting in the following estimates of the parameters Bibliography and further reading.",
            "cite_spans": [
                {
                    "start": 334,
                    "end": 337,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 338,
                    "end": 341,
                    "text": "90]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 384,
                    "end": 392,
                    "text": "Figure 6",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 MCMC methods for deriving the posterior pdfs of parameters of SIR-like models for COVID-19 have been used in e.g. [40, 30] . \u2022 For further approaches to the Bayesian inversion problem, see Approximate Bayesian Computation (ABC, see e.g. [21] ) and the Integrated Nested Laplace Approximation (INLA, [61] ). ABC is used in cases when it is difficult to evaluate (or even define) the likelihood function. INLA is instead useful when certain conditional posteriors can be reasonably approximated by Gaussian distributions.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 120,
                    "text": "[40,",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 121,
                    "end": 124,
                    "text": "30]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 239,
                    "end": 243,
                    "text": "[21]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 301,
                    "end": 305,
                    "text": "[61]",
                    "ref_id": "BIBREF61"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 In this section we have assumed a simple error model with additive Gaussian errors. See e.g. [71, 13] for more general error models. In particular, the under-reporting can also be modeled by assuming that the errors are negative binomial or quasi-Poisson random variables, see e.g. [72, 41] .",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 99,
                    "text": "[71,",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 100,
                    "end": 103,
                    "text": "13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 284,
                    "end": 288,
                    "text": "[72,",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 289,
                    "end": 292,
                    "text": "41]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 In this section we have assumed that \u03c1 prior are either uniform or Gaussian random variables; other choices with good properties are possible, e.g. the Jeffreys non-informative priors [28] .",
            "cite_spans": [
                {
                    "start": 186,
                    "end": 190,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 Using sparse grids for uncertainty quantification with exact posterior pdf in equation (9) is not straightforward, because the functional shape of \u03c1 post does not fall into classical families of pdfs (e.g. uniform, Gaussian, gamma) for which these methods are developed. A possible remedy would be to compute adhoc polynomials, in the spirit of [75, 50] . Another possibility is to keep sampling according to the prior pdf, see e.g. [64] , but this is possibly suboptimal if the prior and the posterior are significantly different (e.g., a uniform prior and a very peaked posterior).",
            "cite_spans": [
                {
                    "start": 347,
                    "end": 351,
                    "text": "[75,",
                    "ref_id": "BIBREF75"
                },
                {
                    "start": 352,
                    "end": 355,
                    "text": "50]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 435,
                    "end": 439,
                    "text": "[64]",
                    "ref_id": "BIBREF64"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 Conversely, sparse grids sampling for Gaussian random variables has been discussed multiple times in literature, see e.g. [25] ; therefore, sparse grids computation are easy to use upon having performed the Fisher approximation.",
            "cite_spans": [
                {
                    "start": 124,
                    "end": 128,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 Replacing the evaluation of the full-model with a response surface either in the MCMC sampling of posterior pdf or in the minimization of NLL is possible (this operation is routine in computationallyheavy inverse problems, see e.g. [44] ), but in this context this operation does not dramatically speed-up the computational time because SIR-like models are rather cheap to evaluate.",
            "cite_spans": [
                {
                    "start": 234,
                    "end": 238,
                    "text": "[44]",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 We could extend the error model for I , R to account for the various sources of error (model error, response surface error if used, numerical discretization errors), see e.g. [43] .",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "\u2022 Minimizing the NLL function is an example of non-linear least-squares optimization problems, for which ad-hoc algorithms exist, like Gauss-Newton, Levenberg-Marquardt, VarPro, Trust-region reflective, see e.g. [49, 32] .",
            "cite_spans": [
                {
                    "start": 212,
                    "end": 216,
                    "text": "[49,",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 217,
                    "end": 220,
                    "text": "32]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Example 4 (Incorporating prior information on parameters in the Inverse Uncertainty Quantification)."
        },
        {
            "text": "Summarizing the discussion so far, the ideal UQ workflow for a prediction under uncertainty would consist of these steps:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summary: an ideal UQ workflow, from data to prediction"
        },
        {
            "text": "Algorithm 1: Ideal UQ workflow 1 Choose a model and the prior distributions for its parameter (literature, expert opinion); 2 Compute Sobol indices to assess which parameters are more influential and can be inferred from data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summary: an ideal UQ workflow, from data to prediction"
        },
        {
            "text": "Fix the remaining parameters to some reasonable value; 3 Perform the inverse UQ analysis to adjust the prior distribution to the data evidence; 4 Perform the forward UQ analysis based on the posterior distribution to obtain statistical information about the quantities of interest of the model (e.g. expected value, variance, full pdf of the outputs);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summary: an ideal UQ workflow, from data to prediction"
        },
        {
            "text": "This ideal workflow however is missing one step, i.e., the identifiability analysis, which is a crucial preliminary analysis to perform. We discuss it in details in the next sections. The adjusted ideal UQ workflow will then be presented in the final section 9 (discussion and conclusion), see Algorithm 2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summary: an ideal UQ workflow, from data to prediction"
        },
        {
            "text": "The fundamental assumption underlying the inversion approach proposed in Section 5 is that there exists a certain set of parameters and hyper-parameters [\u03d1 true , h true ] that generated the observed data from the system (2), as expressed in Equation (5) . We then embrace the fact that the data are noisy, and that this noise might prevent us from correctly determining the values [\u03d1 true , h true ]; we therefore give up on giving a \"oneshot\" estimate of [\u03d1 true , h true ], and rather content ourselves with computing a posterior pdf, which quantifies our degree of belief on each possible value of [\u03d1 true , h true ]. The Fisher approximation then further assumes that the NLL has a unique, well-shaped minimum, which means that the posterior pdf of the parameters is sufficiently well-approximated by a Gaussian pdf centered at \u03d1 M LE , whose variance gets smaller as we acquire more data. If instead we believe that there exists a certain set [\u03d1 true , h true ] but for some reason we think that our data do not support the assumption that the posterior is Gaussian (for instance, because we have only limited data), we could consider the \"full\" posterior given by equation (9) instead (using e.g. MCMC as computational tool), and ideally three scenarios might then occur:",
            "cite_spans": [
                {
                    "start": 251,
                    "end": 254,
                    "text": "(5)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "1. the posterior pdf is actually close to Gaussian; 2. the posterior pdf is unimodal but it departs from Gaussian in that it might show \"heavy tails\" and/or some degree of skewness. This would indicate that we might be introducing a bias that leads to over/underestimates;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "3. the posterior pdf is multi-modal: this would mean that the inversion procedure is suggesting a few \"likely\" combinations of parameters \u03d1, each corresponding to one peak of the posterior pdf: in this case the heights of the peaks represent our belief on the plausibility that such \u03d1 is the \"true one\".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "In any case, the crucial point that one has to address is: can we guarantee that there is a unique set [\u03d1 true , h true ] that generates the observed outputs? Or, equivalently, is the inverse problem well-posed? If not, the Fisher approximation is bound to fail (for instance, item 3 in the list above) and the MCMC approach also needs to be handled with care. In the field of mathematical epidemiology (and more generally of dynamical systems/systems control), this question falls into the study of the so-called system identifiability, which can be divided in two consecutive steps:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "Structural identifiability: studying from a theoretical point of view the well-posedness of the identifiability (inverse) problem, assuming that perfect information is available, i.e., that infinitely many noise-free observations of the outputs are available. It is an intrinsic property of the system and is the topic of this section. This topic is well-studied in the epidemiological literature: a list of references is available at the end of the section.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "Practical identifiability: addressing the identifiability of the system given limited and noisy observations of the outputs. It depends not only on the properties of the system but also on the quality of the data. In other words, the structural identifiability is a necessary but not sufficient condition for the practical identifiability of the system. The practical identifiability is the topic of the next Section 8.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "Mathematically, a system is structurally identifiable if the model map, i.e. the function [\u03d1, h] \u2192 Y (\u03d1, h) mapping each realization of \u03d1, h to the corresponding values of the outputs / quantities of interest is injective. Of course, numerical estimates of parameters obtained by UQ techniques for structurally non-identifiable systems are not reliable and might lead to very wrong predictions. We will show some results on this in Example 8.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Structural identifiability"
        },
        {
            "text": "The differential algebra approach to the structural identifiability problem is based on deriving a set of differential equations for the model outputs Y of the form P(Y,\u1e8e ,\u0178 , . . . , \u03d1, h) = 0 where P is a monic differential polynomial including only Y , their derivatives and the model parameters/hyperparameters; see e.g. Example 6.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "One approach to obtain such equations is by ad-hoc substitution and differentiation to eliminate the unwanted quantities, starting from the original system (2) . These equations are known as input-output equations and are an implicit form of the model map, as they generate the same output as the original model (of course, one must be careful not to remove/introduce additional solutions e.g. by canceling/multiplying every term by Y ). The coefficients of the input-output equations give indication on the identifiability of the system: if the map from [\u03d1, h] to the coefficients of the input-output equation is injective, the system is structurally identifiable; conversely, if there are multiple values of [\u03d1, h] that generate the same input/output equations, the system if of course structurally non-identifiable.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 159,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "We refer to [23] for the theoretical background underlying this procedure: in particular, in that work it is shown that the identifiability result does not depend on the particular method employed to derive the inputoutput equations, as long as a certain property, called mutual reduction, holds true -see again Example 6. This property is always true in the case of a single output quantity, whereas it needs to be enforced in the case of multiple output quantities. The fact that the identifiability result does not depend on the specific form of the input-output equation stems from the fact that by definition all the input-output equations generate the same output trajectory as the original model. From this, it follows that all forms of such equations contain the same identifiability information of the original system.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 16,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "For systems with many compartments, the manual ad-hoc substitution method might be impractical, and a more algorithmic approach is needed: one possibility consists in generating the input-output equations as part of the so-called characteristic set of the algebraic ideal generated by the polynomials defining the model, see [56] . Finally, note that the calculations required to derive the input-output equations can be done also using symbolic calculus software, e.g. Mathematica and Maple.",
            "cite_spans": [
                {
                    "start": 325,
                    "end": 329,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "Example 6 (Structural identifiability of a SIR model by differential algebra). In this example, we focus on the case of the SIR model (1) with output Y = 1 K I (our argument here is similar to those in [71, 36] ). We consider the following system",
            "cite_spans": [
                {
                    "start": 202,
                    "end": 206,
                    "text": "[71,",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 207,
                    "end": 210,
                    "text": "36]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "Note that we have neglected the equation for R in (1) as it does not influence the dynamics of the system. Combining the differential equation for I and Y yield\u1e61",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "which can be solved for S; from the latter, an expression for\u1e60 can then be derived. Then, replacing these expressions for S and\u1e60 in the differential equation for S of the SIR model, we obtain the following equation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "We then divide all the terms by N pop to obtain the following monic polynomial, i.e. a polynomial with the coefficient of the highest order term equal to 1:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "Assuming N pop and K known, the map [\u03b2, r] \u2192 [K \u03b2 Npop , Kr \u03b2 Npop ] is injective, i.e., the system",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "can be solved for r, \u03b2. This means that it is possible to uniquely identify \u03b2 and r, and the model is structurally identifiable. Conversely, if K is unknown, only r and the combination K\u03b2 can be uniquely estimated, i.e., the model is structurally non-identifiable. If instead we consider the case of having also a second quantity of interest Z = 1 K R, all the parameters of the SIR model result to be structurally identifiable, as we show in the following. This is a realistic scenario, as both prevalence data of infectious and removed are typically known in an outbreak. Since we have data of I and R, we drop the differential equation for the stage S of the SIR model and consider the following equivalent system",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "The practice of eliminating a stage is possible as we assume that N pop = S + I + R for all times, which means that the dynamics of the compartment that we eliminate is completely determined by the remaining ones. In particular, if we let S = N pop \u2212 I \u2212 R, we can immediately see tha\u1e6b",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "i.e., we recover the initial equation for S. In this second example we have two outputs, therefore we have to derive two input-output equations. We rewrite the differential equations for I and R in terms of Y and Z and obtain",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "To make the polynomials monic we have to introduce a ranking among the variables. 7 A common choice for the ranking is Y < Z <\u1e8e <\u017b (any other ranking would lead to the same results as already mentioned, of course after different computations), from which it follows that the leading monomials of the input-output equations are\u1e8e and\u017b, respectively. We then divide all the terms of the equations above by the coefficient of the corresponding leading term and obtain the following monic input-output equation\u1e61",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "Since we have more than one output, before concluding on the identifiability of the system we have to check that the two equations are mutually reduced; if not, the analysis could lead to spurious results, as pointed out in [23] . The concept of reduction is again based on the chosen ranking of the variables: a polynomial P i is reduced with respect to the polynomial P j if it does not contain neither the leading monomial of P j with equal or greater degree nor its derivatives. In our case it can be easily seen that the input-output equations are mutually reduced, and by looking at their coefficients we conclude that \u03b2, r and K can be simultaneously identified. Hence, the SIR model is structurally identifiable from prevalence data of I and R.",
            "cite_spans": [
                {
                    "start": 224,
                    "end": 228,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Differential algebra"
        },
        {
            "text": "This approach is discussed in [26, 27] ; we refer the reader interested to the theoretical background to these two references and only sketch the main idea and the \"practical recipe\" here. Example 7 gives an example of the application of this method to the SIR model. For ease of notation, in this discussion the vector p \u2208 R p collects all the uncertain elements of (2), i.e., not just the coefficients, but also the initial conditions and the hyper-parameters, i.e. p = N coef +N states +N hyp . Moreover, we change the notation in (2) to a more compact form and write f p (X) instead of f (X, p) and similarly for G, and let N states = n, N qoi = m. Summarizing the new notation, (2) becomes",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 34,
                    "text": "[26,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 35,
                    "end": 38,
                    "text": "27]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "We explain the method with the support of Figure 7 . If the system (18) is not identifiable, then there are two different sets of parameters, say p andp, such that the trajectories X(t, p) and X(t,p) are different but the corresponding outputs are identical, Y (t, p) = Y (t,p) \u2200t \u2208 [0, t max ]. If these conditions hold true, then it is possible to rework the equality Y (t, p) = Y (t,p) to explicitly construct a map \u03bb : R n \u2192 R n that maps the trajectories X(t, p) and X(t,p) to one another: \u03bb(X(p)) = X(p) (we will come back to this point with more details later on).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 42,
                    "end": 50,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Mapping approach"
        },
        {
            "text": "Since the map \u03bb has been derived by enforcing equality between the outputs Y (t, p) and Y (t,p), without taking into account the dynamics of the system, one further has to check that \u03bb(X(p)) still solves the X(t,p) Figure 7 : The mapping approach for structural identifiability.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 215,
                    "end": 223,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Mapping approach"
        },
        {
            "text": "dynamical system. Taking time derivatives of both sides of \u03bb(X(p)) = X(p) and using (18) one gets (removing the dependence on t for ease of notation):",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 88,
                    "text": "(18)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Therefore, one has to check that the last equation (19) is valid for the proposed \u03bb. This will result in a set of conditions for the components of p andp: if the resulting conditions are p =p the system is identifiable; otherwise, there will be non-trivial conditions between some of the components of p and some of the components ofp, (see e.g. Example 7), which means that the system is not identifiable. We now come back to the issue of constructing the map \u03bb. As already mentioned, the idea is to construct \u03bb from the conditions Y (p) = Y (p), i.e. from",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Gp(X(p)) = G p (X(p)) = G p (\u03bb(X(p)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "In principle, it would be enough to solve for \u03bb in the latter, i.e. \u03bb(X) = (G p ) \u22121 [Gp(X)], but the system might be underdetermined if we have m < n observables. Then, the idea is to complement the observables with additional equations and to create an \"augmented\" observables vector H p : R n \u2192 R n , as follows, by taking into account the directional derivatives of the outputs Y j along the direction f p (X):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "The next step is to verify that H p is a bijective map (Observability Rank Condition, ORC), i.e. that the Jacobian of H p with respect to X is non-singular in the domain of definition of the trajectories X for every admissible p. Finally, the map \u03bb can be computed by solving for \u03bb the system of equations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Hp(X(p)),p) = H p (\u03bb(X(p)), p), leading to (cf. again Figure 7 )",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 54,
                    "end": 62,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Mapping approach"
        },
        {
            "text": "where the well-posedness of (H p ) \u22121 is guaranteed by the ORC. We close this discussion with a couple of remarks on the construction of H p :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "\u2022 In case the number of observables m < n/2, adding the directional derivatives \u2207 X Y j \u00b7f p (X), j = 1, . . . m will not be enough to reach n observables. In this case, one should add derivatives of higher order.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "\u2022 In the opposite case, in which 2m > n, one can choose among multiple directional derivatives \u2207 X Y j \u00b7 f p (X): after having dropped the choices that make the mapping H p singular in the domain of definition of the trajectories X, one should check all remaining combinations (the fact that one choice results in identifiability in this case does not rule out the possibility that another choice might result in nonidentifiability). If m > n, then there are more observables than states, and the same principle applies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Example 7 (Structural identifiability of a SIR model by mapping approach). Let us consider the SIR model with output y = 1 K I as in Example 6, and rewrite it replacing S, I as X = [x 1 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Our goal is to recover the structural identifiability results already obtained in Example 6 with the differential algebra approach. The first step is to build the two maps H p and \u03bb, where p = [\u03b2, r, K, N pop ]. As for x 2 ) ) T , we need to augment the observable y with a directional derivative:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 219,
                    "end": 224,
                    "text": "x 2 )",
                    "ref_id": null
                }
            ],
            "section": "Mapping approach"
        },
        {
            "text": "The Jacobian of this mapping has non-zero determinant whenever x 2 = 0, which is a value never attained by the trajectories X unless the initial condition is x 2 (0) = 0 (in which case the trajectory is the uninteresting case X = [0, 0] T ). Therefore, we can apply the methodology. The mapping \u03bb = (\u03bb 1 (x 1 , x 2 ), \u03bb 2 (x 1 , x 2 )) T is obtained by solving the equation H p (\u03bb(X)) = Hp(X), i.e.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "whose Jacobian is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "Then, enforcing condition (19) results in the following equations:",
            "cite_spans": [
                {
                    "start": 26,
                    "end": 30,
                    "text": "(19)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "The second equation is identically verified. Conversely, the first one holds true for every",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "i.e. we obtain the same non-trivial condition previously obtained in Example 6: at most one parameter out of K, \u03b2, N pop can be identified. If both observations of I and R are available instead, then we have two observables \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "and the analysis must be repeated. In particular, the map H p can now be constructed without using directional derivatives, as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "This map is linear, therefore it is bijective for every X and we can carry on with the analysis. The mapping \u03bb is obtained by solving the equations H p (\u03bb(X)) = Hp(X), resulting in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "whose Jacobian is K K times the identity matrix. Then, enforcing condition (19) results in the following equations:",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "text": "(19)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "which result in the conditions r =r, K =K, \u03b2 N pop =\u03b2 N pop , i.e., the system is now structurally identifiable if we assume N pop to be known, as already discussed in Example 7.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping approach"
        },
        {
            "text": "As already mentioned in Section 4, if an output / quantity of interest Y is only weakly influenced by a parameter, such parameter might be non-identifiable from Y : therefore, computing the sensitivity of a quantity to a parameter gives an indication about the structural identifiability of the parameter. As explained in Section 4, sensitivity analysis can be local or global. In the first case, a small gradient of the quantity of interest value indicates that the quantity of interest is not very sensible to small variations in the parameter, which might then be non-identifiable. The global sensitivity analysis can be performed by means of Sobol indices: parameters with low Sobol index do not strongly influence the quantity of interest Y , and might be non-identifiable from observations of Y .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "Bibliography and further reading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 The concept of structural identifiability was first introduced in [7] .",
            "cite_spans": [
                {
                    "start": 68,
                    "end": 71,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 Some theoretical background on the differential algebra approach is provided in [46, 23] .",
            "cite_spans": [
                {
                    "start": 82,
                    "end": 86,
                    "text": "[46,",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 87,
                    "end": 90,
                    "text": "23]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 Many methods we have not directly mentioned here (e.g. Taylor series approach, generating series approach, and methods based on the implicit function theorem) are explained in [46] .",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 182,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 See [71] for the detailed discussion of structural identifiability of a SEIR model by differential algebra. [71] also shows that the SIR model is structurally identifiable also in the case of cumulative data (i.e., incidence data).",
            "cite_spans": [
                {
                    "start": 6,
                    "end": 10,
                    "text": "[71]",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 110,
                    "end": 114,
                    "text": "[71]",
                    "ref_id": "BIBREF71"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "\u2022 Sensitivity analysis is discussed in, e.g., [13] and [46] , where several methods based on the Jacobian matrix J and on the Fisher matrix H are discussed, see equations (13) and (16) .",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 50,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 55,
                    "end": 59,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 171,
                    "end": 175,
                    "text": "(13)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 180,
                    "end": 184,
                    "text": "(16)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Sensitivity analysis"
        },
        {
            "text": "Upon having assessed the structural identifiability of a system, it is still not obvious that the system can be identified from limited, noisy data, that possibly cover only a fraction of the time-span of the dynamics (e.g., when one measures the initial part of a trajectory and wants to assess the parameters for long-term forecast). With reference to Figure 7 , if the output trajectories Y (p), Y (p) are distinct but close, they might become indistinguishable from one another if we only have at our disposal a noisy cloud of points around them rather than the entire exact trajectories. The study of this setting is called practical identifiability analysis, and is typically performed on synthetic data to see under which conditions the inversion procedure obtains results \"close enough\" to the true values of the parameters. In the following, we give a short outlook on the main tools; see the bibliography at the end of the section for further readings on each method.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 354,
                    "end": 362,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "Monte Carlo simulations/bootstrap: generate M sets of synthetic data and for each data set k = 1, . . . , M , compute the maximum likelihood estimate \u03d1 (k) . Then, compute dispersion indices for the M MLE estimates of each parameter, such as their sample variance or their average relative error, which is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Repeat the procedure for synthetic data with an increasing level of noise and observe the trend of the dispersion indices as the noise increases. If the ARE of the estimates is e.g. higher than the noise level, the parameters are not-identifiable (other criteria in the same spirit might be used as well).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "The same procedure should be repeated by considering each time a different number of parameters to be jointly estimated, until all the parameters are included. In this way, it is possible to detect the influence of each parameter on the quality of the joint estimate.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Finally, note that the amount and the timespan of the available data might be relevant for practical identifiability, and the analysis should ideally be repeated while varying these settings. For instance, [71] discusses the bootstraps analysis for the SIR model computing the ARE of parameter estimates using data sets of increasing time-span: the results indicate that the model with unknown \u03b2, r is practically identifiable from data on the I compartment only after that the epidemic peak is reached (despite the fact the model is structurally identifiable in such settings, see Example 6).",
            "cite_spans": [
                {
                    "start": 206,
                    "end": 210,
                    "text": "[71]",
                    "ref_id": "BIBREF71"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Fisher information matrix: as already explained in Section 5.3, the Fisher information matrix is the Hessian of the NLL at the maximum log-likelihood estimate (or its approximation in Equation (16)). If the Fisher Information Matrix is positive definite with large eigenvalues, the NLL has a narrow minimum and we can conclude local practical identifiability of the system, i.e. identifiability in a neighborhood of the maximum likelihood estimate; conversely, small eigenvalues are symptom of practical non-identifiability, since the minimum of the NLL occurs in a shallow region. Numerically, the optimization procedure might even end up in a critical point where the Fisher Information Matrix is not even positive definite, e.g. it could be non-definite or it could have rank smaller than the number of parameters. In that case, the rank of Fisher Information Matrix gives an indication on the maximum number of parameters that can be simultaneously inferred, see e.g. [24] .",
            "cite_spans": [
                {
                    "start": 972,
                    "end": 976,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Correlation matrix C: The inverse of the Fisher information matrix H gives an approximation of the covariance matrix of the parameters, \u03a3 G , see Equation (13) . From \u03a3 G , it is possible to compute the correlation matrix of the parameters, rescaling each entry as",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "(13)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "If two parameters have correlation close to 1, they are linearly dependent, and cannot be estimated separately. Hence, they are practically non-identifiable.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Optimization with multiple restart: As already mentioned in Section 5.3, one should repeat several times the optimization to determine the MLE for different initial guesses and check where the minimization ends. If the algorithm ends always at the same point, there is empirical evidence that the NLL has a unique minimum and the system is globally practically identifiable (the minimum might be different from the nominal value of the parameter, i.e. the noise might introduce a bias in the estimate, see e.g. Example 3). If several local minima or a manifold of minima are detected we conclude that the system is not practically identifiable: in particular, in the case of a manifold of minima there are many sets of parameters that fit equally well the data, denoting a possible case of structural non-identifiability. For instance, in Example 6 when only data of I are considered, we expect that the region K\u03b2 = const will be a manifold of minimum points for the NLL.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Profile log-likelihood for each parameter: The previous discussion, pointing to the possibility that the NLL might have a manifold of minima, allows us to introduce the last tool to assess practical identifiability, i.e., the profile log-likelihood; this tool is actually \"in between\", and could also be used for structural identifiability, as it will be made clearer later on.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Whenever \u03d1 are practically identifiable, the NLL should have a global minimum at \u03d1 = \u03d1 true . Therefore, a visual inspection of the NLL can immediately tell whether the system is identifiable or not. Of course, this is not a viable solution for problems with more than two parameters. In this case, one can resort to the profile likelihood, which is a mono-dimensional slice of the log-likelihood function in the direction of the considered parameter \u03d1 i . The profile likelihood can be obtained by changing the parameter \u03d1 i iteratively in a certain range of values around its MLE value \u03d1 M LE,i , while reoptimizing all other parameters. Thus, the profile log-likelihood is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "If the profile log-likelihood has a unique minimum, the parameter is practically identifiable, whereas more complex shapes, with shallow regions and multiple minima indicate that the parameter is practically non-identifiable. In particular, a flat profile means that the NLL has a manifold of minima that fit the data equally well and we can again conclude that the system is structurally non-identifiable. For a schematic illustration we refer to Figure 8 . Crucially, if the NLL has a manifold of minima, the Fisher approximation of the posterior will be completely wrong, since it is based on the assumption that NLL has a unique minimum; the case of finitely many local minima could instead be fixed by acquiring more data, which should hopefully make the \"spurious peaks\" become smaller and smaller.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 448,
                    "end": 456,
                    "text": "Figure 8",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "In summary, the analysis of the profile log-likelihood is based on checking the \"flatness\"/\"shallowness\" of such function. To make this criterion more quantitative and discriminate between different levels of shallowness one can provide confidence thresholds of the profile log-likelihood CI PL using a \u03c7 2 1 test:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "where \u2206 \u03b1 \u03c7 2 1 is the \u03b1 quantile of the \u03c7 2 1 distribution. If the likelihood profile of a parameter exceeds the confidence threshold \u2206 \u03b1 \u03c7 2 1 on both sides of \u03d1 M LE,i the parameter is practically identifiable (the threshold is indicated by the black dotted lines in Figure 8 ). This is an alternative approach to determine a posterior pdf for the MLE estimates, consisting of a uniform pdf instead of the Gaussian Fisher approximation discussed in Section 5.3. Such uniform estimate might be more robust for limited datasets [55] .",
            "cite_spans": [
                {
                    "start": 529,
                    "end": 533,
                    "text": "[55]",
                    "ref_id": "BIBREF55"
                }
            ],
            "ref_spans": [
                {
                    "start": 270,
                    "end": 278,
                    "text": "Figure 8",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "Finally, observe that if the data are generated in a noise-less way by sampling the trajectories of \u03d1 = \u03d1 true , and they are sufficiently many, we end up in the scenario of structural identifiability. The profile log-likelihood can still be constructed and evaluated also in this case, as the NLL is just the sum of square misfits (without the 1 \u03c3 2 factor), and therefore it can be used as a computational tool to verify structural identifiability, i.e., for the existence of a manifold of minima. In case the system is structurally or practically non-identifiable, a possible workaround is to learn some of the parameters from independent studies, thus reducing the number of parameters to be simultaneously identified. Sometimes even a hierarchical optimization approach might be effective: in this approach, one does a first round of optimization to obtain the values of the entire set of parameters but retains the values obtained for the identifiable parameters only. Upon fixing these parameters to the values just obtained, the optimization of the remaining parameters can be repeated. An alternative is to reparametrize the model, replacing the original parameters with the combination that can be identified, see e.g. [70] . Finally, one could resort to so-called marginalization techniques, see e.g. [35, 39, 62] . Example 8 (Practical non-identifiability of a SIR model with unknown under-reporting factor). In the scenario of COVID-19, it has been often pointed out that data of infected and dead persons have been underreported (even significantly), but the exact value of the under-reporting factor K is not known. Some discussion on this aspect is provided in [3, 30] . In this example, we consider a SIR model, generate synthetic data and investigate the practical identifiability of \u03b2, r, K when measurements of I and R are considered, by computing the profile likelihood for K; we already know from Example 6 that in this scenario the parameters are structurally identifiable. We repeat practical identifiability analysis in three settings, that differ by the timespan covered by the data: until past the peak of I, up to the peak of I, and before the peak of I.",
            "cite_spans": [
                {
                    "start": 1229,
                    "end": 1233,
                    "text": "[70]",
                    "ref_id": "BIBREF70"
                },
                {
                    "start": 1312,
                    "end": 1316,
                    "text": "[35,",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 1317,
                    "end": 1320,
                    "text": "39,",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 1321,
                    "end": 1324,
                    "text": "62]",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 1677,
                    "end": 1680,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1681,
                    "end": 1684,
                    "text": "30]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "We fix \u03d1 = [0.28, 0.11], \u03c3 = 0.025, and the discount factor to K = 3. Data for I and R are collected up to T = 20, 30, 40 for the three scenarios. The results are reported in Figure 9 and suggest that for data before peak the profile likelihood of K is shallow (look at the scale on the vertical axis) and even has a minimum at the wrong value K = 2, denoting practical non-identifiability of K. For longer collection times instead, the profile likelihood shows an increasingly deep minimum around the correct value K = 3. The fact that time might be important in determining whether a system is practically identifiable was already discussed in [13, 16, 71] . Fixing K to the wrong value to perform the Forward Uncertainty Quantification analysis of course leads to predictions that are far from the true behavior of the system, see Figure 10 -top-left. An important disclaimer to do here is that it would be hard to say that the set of parameters obtained for K = 2 fits the data worse than those obtained for K = 3, see would actually tell that the fitting of the case K = 2 is slightly better than the case K = 3 (numbers not reported for brevity). The scatterplots of predictions vs data are qualitatively identical, and reasonably aligned with the bisector, see Figure 10 -top and bottom third and fourth panel. The empirical distribution of the misfits in both cases are qualitatively identical and close to a Gaussian (see the quantile-quantile plots in Figure 10 -top and bottom-right panels). In summary, all of these diagnostic tools give little-to-no evidence that K = 2 is the wrong choice of the under-reporting parameter. We close this example with some remarks:",
            "cite_spans": [
                {
                    "start": 646,
                    "end": 650,
                    "text": "[13,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 651,
                    "end": 654,
                    "text": "16,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 655,
                    "end": 658,
                    "text": "71]",
                    "ref_id": "BIBREF71"
                }
            ],
            "ref_spans": [
                {
                    "start": 175,
                    "end": 183,
                    "text": "Figure 9",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 834,
                    "end": 843,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1268,
                    "end": 1277,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1462,
                    "end": 1471,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 the quality of the fitting of the cases K = 2, K = 3 cannot be assessed by the R 2 coefficient, which is not well-defined for non-linear least-squares problems [68] .",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 166,
                    "text": "[68]",
                    "ref_id": "BIBREF68"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 if instead K is known, the SIR system is practically identifiable regardless of time, since the NLL in the \u03b2 \u2212 r plan has always a unique minimum which is always close to the true value, in all of the three scenarios, see Figure 11 -top. Of course, the time span of data collection still has an impact on the quality of the results. Indeed, if time increases the minimum of the NLL is less and less shallow, which implies that the uncertainty on the parameters is smaller and smaller. This is visible in Figure 11 bottom, where we show the Gaussian approximation of the posterior pdfs of \u03b2, r. As the data time-span increases, the posterior pdfs are more and more concentrated and, equivalently, that the system is more and more practically identifiable (cf. Fisher information matrix criterion for practical identifiability).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 224,
                    "end": 233,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 506,
                    "end": 515,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "Example 9 (Structural and practical non-identifiability of a SEIRD model). In this example, we discuss the identifiability of a slightly more complicated model with incubation period (stage \"E\", exposed), where we distinguish between recovered and dead persons (stages \"R\" and \"D\", respectively). We also assume that at T = T lock the parameter \u03b2 changes, due to some restriction measure being enforced (lockdown). 8 We call this model SEIRDz:",
            "cite_spans": [
                {
                    "start": 415,
                    "end": 416,
                    "text": "8",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "where \u03b2(t) = \u03b2 1 for t \u2264 T lock and \u03b2(t) = \u03b2 1 \u2212 z for t > T lock . We consider these ranges for the parameters (that we consider as uniform random variables): In this setting the rate r is the recovery rate (inverse of the average days of sickness), the rate d is the mortality rate and the rate i is the inverse of the incubation time. With these intervals we are assuming that the average number of days of sickness is roughly between 5 and 16, while the average incubation time is roughly between 3 and 7 days. We consider T lock = 15 and run the simulation until T = 100. We set the initial conditions to S(0) = 0.95, E(0) = 0.04, I(0) = 0.01, R(0) = 0, D(0) = 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "If we assume that \u03b2 is constant in time, we can show that the system is structurally identifiable, by means of the differential algebra approach. The computations are shown in details in Appendix Appendix A. Since we have assumed that we know the time T lock where the change in \u03b2 happens, we can apply the structural analysis results to both the time intervals t \u2264 T lock and t > T lock separately, and conclude that the model SEIRDz is structurally identifiable. Figure 12 shows some results for the preliminary prior-based forward UQ analysis. The left-most panel shows 100 Monte Carlo trajectories, and the expected value of the compartments, computed with a sparse grid (2433 model evaluations 9 ). It is clearly visible that the trajectories are significantly scattered, and that the asymptotic values of the compartments vary considerably. The remaining panels show the time-evolution of the Sobol indices, from which we can derive some information about the identifiability of the model. We can see that not all parameters impact equally the variability of the solution, and we expect in particular that it will be difficult to recover by the inversion procedure the value of those parameters that have the smallest impact (i, z, \u03b2). Even more so given that we only measure the compartments I, R, D (while \u03b2 would be best recovered from the S compartment), and that we will only measure them up to a certain time, and the Sobol indices are not constant in time (for instance, \u03b2 has a significant impact on R but only at late times, say T \u2265 30, while we measure essentially early times). Thus, while the system is structurally identifiable, it might be practically non-identifiable. Next, we perform the inversion and check for practical identifiability. We fix and measure data until T = 40 (after peak). We repeat the minimization procedure 20 times with different initial guesses for the parameters, to investigate the presence of local minima of the NLL, and select as MLE estimate the results that led to the smallest NLL. The results of this procedure are shown in Figure 13 -top, where we report the initial and final values of the NLL, as well as the initial and final values of the parameters. We can conclude that while the final values of the NLL are all close (yet not identical), the values of the parameters show a significant variability, denoting the fact that the NLL has a multiple minima with similar NLL value. Moreover, most of the parameters are not correctly identified. This further suggests that the model might be practically non-identifiable, at least for the value of \u03c3 tested here. Therefore, the trajectories corresponding to the computed values of the parameters are quite far from the true one, see Figure 13 -bottom.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 465,
                    "end": 474,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2078,
                    "end": 2087,
                    "text": "Figure 13",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2738,
                    "end": 2747,
                    "text": "Figure 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "To confirm our diagnosis of non-identifiability, we compute the profile likelihood of the problem. Results are shown in Figure 14 . The only parameter with a deep, narrow minimum is r (compare the vertical scales) while the other ones are in rather shallow regions. Moreover, the profile likelihoods for i, \u03b2 and z are very noisy (as expected, due to the fact that their Sobol indices are rather small). This confirms that the only parameter that can be easily identified are r and to a certain extent d (given that the shape of the profile likelihood is not noisy, although shallow), and overall the system is practically non-identifiable.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 120,
                    "end": 129,
                    "text": "Figure 14",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "As mentioned, a possible workaround which might help in this situation is to learn some of the parameters from independent studies, and thus reduce the number of parameters to be simultaneously identified. For instance, medical studies might give us estimates of the incubation time, recovery time and death rate, so that we are left to identify only the contact probabilities \u03b2 1 and z. One has to pay attention to the fact that setting the influential parameters to the wrong values can be however detrimental to the procedure. Here, we fix the values of i, r, and d to their exact values and repeat the identification procedure. This is of course an over-optimistic scenario. Another possibility would be to use, for example, r, d obtained from the inversion procedure (whose profile likelihood is \"well-shaped\", even though the one for d is quite shallow; we named this Figure 14 : Profile likelihood for the SEIRDz identifiability problem, centered around the MLE estimates of the parameters (red circle markers). Observe that the red markers do not always coincide with the profile likelihood. This is because the optimization for the remaining parameters might land at different local optima (despite running the optimizer multiple times with random initial points). procedure as \"hierarchical optimization\" in the previous discussion). The results obtained by fixing i, r, and d to their exact values are reported in Figure 15 , which shows the same information of Figure 13 , i.e. initial and final values of NLL and parameters, and trajectories of the model. The presence of local minima in the NLL is greatly reduced, and the identification of \u03b2 1 and z is more robust and closer to the true values (this might not always be the case though, depending on the noise level and the quality of the data). As a result, the trajectories corresponding to this new set of parameters are closer to the true ones than the previous results, as shown in the right-most panel.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 874,
                    "end": 883,
                    "text": "Figure 14",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1425,
                    "end": 1434,
                    "text": "Figure 15",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1473,
                    "end": 1482,
                    "text": "Figure 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Practical identifiability"
        },
        {
            "text": "Bibliography and further reading.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 For a general survey on practical identifiability, we refer the reader to [46, 71, 59] .",
            "cite_spans": [
                {
                    "start": 76,
                    "end": 80,
                    "text": "[46,",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 81,
                    "end": 84,
                    "text": "71,",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 85,
                    "end": 88,
                    "text": "59]",
                    "ref_id": "BIBREF59"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 Bootstrap approaches in the context of epidemiological models are considered e.g. in [71, 59] . The analysis in [71] considers a criterion based on ARE to conclude on identifiability, whereas in [59] a combination of the size of the confidence interval and mean squared error of the parameters is employed.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 91,
                    "text": "[71,",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 92,
                    "end": 95,
                    "text": "59]",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 114,
                    "end": 118,
                    "text": "[71]",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 197,
                    "end": 201,
                    "text": "[59]",
                    "ref_id": "BIBREF59"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 An extensive explanation on the use of the likelihood profiles is given in [55] and further references are [36, 70] .",
            "cite_spans": [
                {
                    "start": 77,
                    "end": 81,
                    "text": "[55]",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 109,
                    "end": 113,
                    "text": "[36,",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 114,
                    "end": 117,
                    "text": "70]",
                    "ref_id": "BIBREF70"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 [16] provides a quite comprehensive step-by-step guide on fitting compartmental models for epidemiology, with an eye to identifiability.",
            "cite_spans": [
                {
                    "start": 2,
                    "end": 6,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 In the context of COVID-19, some discussion about identifiability is provided by [58] .",
            "cite_spans": [
                {
                    "start": 83,
                    "end": 87,
                    "text": "[58]",
                    "ref_id": "BIBREF58"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 [36] provide an interesting example of the consequences of identifiability in the context of a SEIRbased model for a Dengue outbreak: the system is practically non-identifiable, resulting in two sets of parameters that show an excellent fit of the data but provide dramatically different predictions when used to test a possible non-medical remediation strategy (removal of mosquitos).",
            "cite_spans": [
                {
                    "start": 2,
                    "end": 6,
                    "text": "[36]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "\u2022 Optimal design of experiments can be used to improve the quality of the data to minimize the impact of practical identifiability issues, see e.g. [42] .",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 152,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "9. Discussion and conclusions: a revisited UQ workflow",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "In these notes we have reviewed some computational tools for prediction under uncertainty and model identification for dynamical systems, which we referred to as forward and inverse Uncertainty Quantification analyses, respectively. Combined together, these tools provide a powerful framework for reliable predictions of the outputs of a dynamical system, and complement the punctual predictions with confidence estimates with solid ground in probability/statistics theory. However, investigators should always carefully check whether their model is actually identifiable, both structurally and practically. Dynamical systems might indeed be not fully identifiable, and blindly using the prediction tools in this case can be harmful, see e.g. Example 8 or the above-mentioned case study on Dengue reported in [36] .",
            "cite_spans": [
                {
                    "start": 809,
                    "end": 813,
                    "text": "[36]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "If the system is not identifiable, the Fisher approach to the inversion problem is bound to fail, because it intrinsically assumes identifiablity of the system, or in other words because it assumes that the NLL has a unique minimum where the Gaussian approximation of the posterior should be centered, whereas in case of structural non-identifiability the NLL has a manifold of minima. The case of NLL with a finite number of local minima (symptom of practical non-identifiability, see Section 8) could instead hopefully be fixed by acquiring more data of the right kind, that should hopefully rule out the \"wrong minima\".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Conversely, MCMC methods make no assumptions on the shape of the NLL and therefore might be a partially safer technique, However, MCMC algorithms come with a much larger computational cost and are not entirely safe either, since they typically implement some sort of adaptive sampling, where most of the samples are collected in regions of large likelihood, i.e., they cannot entirely escape the problem of computing the maxima of the likelihood. Therefore, unless they are properly designed and tuned, they could fail to realize that there might be an entire manifold of minima. A compromise solution could be to use the Fisher approximation not plainly as the posterior pdf of the parameters, but only in the context of an importance sampling strategy, where one still generates samples from the Fisher approximation of the posterior but then rescales them suitably to remove any bias [5, 6] .",
            "cite_spans": [
                {
                    "start": 887,
                    "end": 890,
                    "text": "[5,",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 891,
                    "end": 893,
                    "text": "6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "In summary, we can modify the ideal UQ workflow sketched in Section 6 (cf. Algorithm 1) as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Our theoretical discussion has been complemented with a number of small examples. None of these consider the initial conditions of the system as unknown, but doing so would not pose any conceptual challenge from a numerical point of view. As already mentioned in Section 7, the most appropriate theoretical tool to investigate the structural identifiability of parameters connected to the initial conditions is the mapping approach.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "An important point that we did not discuss is the issue of model-selection. In the case when multiple models are available (quite common in the case of epidemics modeling and, in particular, of COVID), is there any way to tell which one has the largest statistical evidence? A large body of work is available on this topic in the statistical literature, where several criteria have been developed to select the \"best model\". The underlying principle is that adding more parameters might lead to a better fit of the data, but the more parameters, the larger the chances that the model is overfitted, i.e., that it adjusts to the noise and gets limited predicting power. Thus, one should restrain from blindly adding more parameters. 10 Criteria that try to identify the optimal model among a pool of possible ones include, for example, the Akaike Information Criterion (AIC), the Bayes Information Criterion (BIC), and the Kayshap Information Criterion (KIC). We refer the interested reader e.g. to [65, 17, 10] for a more thorough discussion, as well as to e.g. [22] for a discussion on a model selection strategy in the case when some models are not identifiable.",
            "cite_spans": [
                {
                    "start": 732,
                    "end": 734,
                    "text": "10",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 998,
                    "end": 1002,
                    "text": "[65,",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 1003,
                    "end": 1006,
                    "text": "17,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1007,
                    "end": 1010,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1062,
                    "end": 1066,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "Let us consider the following system",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "where we have removed the equation for the stage E, as it holds that N pop = S + E + I + R + D (the same argument was used in Example 6, when we removed the equation for S while discussing identifiability of SIR with data of I and R). We then rewrite the differential equations in terms of the observed variables. In particular, we derive the following explicit expression for S from the second equation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "From this, we compute\u1e60, insert both formulas in the first differential equation above, and obtain the first input-output equation:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "The other two input-output equations follow from the third and fourth differential equation above and are:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "K\u017b \u2212 rKY = 0 and K\u1e86 \u2212 dKY = 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "The set of these three input-output equations is not mutually reduced with respect to the ranking Y < Z < W <\u1e8e <\u017b <\u1e86 <\u0178 <Z <\u1e84 (other ranking would lead to the same results). The third equation is not reduced with respect to the first one, as its leader monomial\u1e86 appears also in the first one. Similarly, the second equation is not reduced with respect to the first one. By doing some further substitutions to eliminat\u0117 Z and\u1e86 in the first equation we finally get a set of mutually reduced equations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        },
        {
            "text": "The last step is to make the polynomials monic with respect to their leaders, which are\u0178 ,\u017b, and\u1e86 , respectively. It then follows that all the coefficients can be uniquely determined; hence, the SEIRD model is structurally identifiable from data of I, R, and D.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Practical identifiability"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Influencing public health policy with data-informed mathematical models of infectious diseases: Recent developments and new challenges",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Alahmadi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Belet",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Black",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cromer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Flegg",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "House",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Jayasundara",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Keith",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mccaw",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ross",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shearer",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Thein Than Tun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "White",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Whyte",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zarebski",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Epidemics",
            "volume": "32",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Control with uncertain data of socially structured compartmental epidemic models",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Albi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Pareschi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zanella",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Data-based analysis, modelling and forecasting of the COVID-19 outbreak",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Anastassopoulou",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Russo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tsakris",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Siettos",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "PLOS ONE",
            "volume": "15",
            "issn": "3",
            "pages": "1--21",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A stochastic collocation method for elliptic partial differential equations with random input data",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Babu\u0161ka",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Nobile",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "SIAM Review",
            "volume": "52",
            "issn": "2",
            "pages": "317--355",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Fast bayesian experimental design: Laplace-based importance sampling for the expected information gain",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Beck",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Dia",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "F"
                    ],
                    "last": "Espath",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Computer Methods in Applied Mechanics and Engineering",
            "volume": "334",
            "issn": "",
            "pages": "523--553",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Multilevel double loop Monte Carlo and stochastic collocation methods with importance sampling for bayesian optimal experimental design",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Beck",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Mansour Dia",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Espath",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Journal for Numerical Methods in Engineering",
            "volume": "121",
            "issn": "15",
            "pages": "3482--3503",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "On structural identifiability",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bellman",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "And\u00e5str\u00f6m",
                    "suffix": ""
                }
            ],
            "year": 1970,
            "venue": "Mathematical Biosciences",
            "volume": "7",
            "issn": "3",
            "pages": "329--339",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Statistical Decision Theory and Bayesian Analysis",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Berger",
                    "suffix": ""
                }
            ],
            "year": 1985,
            "venue": "Springer Series in Statistics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Is Time to Intervention in the COVID-19 Outbreak Really Important? A Global Sensitivity Analysis Approach. arXiv preprints",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Borgonovo",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Model selection and inference: a practical informationtheoretical approach",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "P"
                    ],
                    "last": "Burnham",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "R"
                    ],
                    "last": "Anderson",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Monte Carlo and quasi-Monte Carlo methods",
            "authors": [],
            "year": 1998,
            "venue": "Acta numerica",
            "volume": "7",
            "issn": "",
            "pages": "1--49",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Parameter estimation and uncertainty quantification for an epidemic model",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Capaldi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Behrend",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Berman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "L"
                    ],
                    "last": "Lloyd",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Mathematical Biosciences and Engineering",
            "volume": "9",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Towards uncertainty quantification and inference in the stochastic SIR epidemic model",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Capistr\u00e1n",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Christen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "X"
                    ],
                    "last": "Velasco-Hern\u00e1ndez",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Mathematical Biosciences",
            "volume": "240",
            "issn": "2",
            "pages": "250--259",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Estimation of aquifer parameters under transient and steady state conditions: 1. maximum likelihood method incorporating prior information",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Carrera",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Neuman",
                    "suffix": ""
                }
            ],
            "year": 1986,
            "venue": "Water Resources Research",
            "volume": "22",
            "issn": "2",
            "pages": "199--210",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Fitting dynamic models to epidemic outbreaks with quantified uncertainty: A primer for parameter uncertainty, identifiability, and forecasts",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chowell",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Infectious Disease Modelling",
            "volume": "2",
            "issn": "3",
            "pages": "379--398",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Model Selection and Model Averaging. Number 9780521852258 in Cambridge Books",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Claeskens",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "L"
                    ],
                    "last": "Hjort",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Approximation of high-dimensional parametric PDEs",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Devore",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Acta Numerica",
            "volume": "24",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Intermittent yet coordinated regional strategies can alleviate the COVID-19 epidemic",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Della Rossa",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Salzano",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Di Meglio",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "De Lellis",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Coraggio",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Calabrese",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Guarino",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cardona",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Delellis",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Liuzza",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Lo Iudice",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Russo",
                    "suffix": ""
                },
                {
                    "first": "Di",
                    "middle": [],
                    "last": "Bernardo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Moment-based metrics for global sensitivity analysis of hydrological systems",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Dell&apos;oca",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Riva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Guadagnini",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Hydrology and Earth System Sciences",
            "volume": "21",
            "issn": "12",
            "pages": "6219--6234",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Approximate Bayesian Computation",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Drovandi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "A bayesian information criterion for singular models",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Drton",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Plummer",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
            "volume": "79",
            "issn": "2",
            "pages": "323--380",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Input-output equivalence and identifiability: some simple generalizations of the differential algebra approach",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Eisenberg",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1302.5484v2"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Determining identifiable parameter combinations using subset profiling",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Eisenberg",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Hayashi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Mathematical Biosciences",
            "volume": "256",
            "issn": "",
            "pages": "116--126",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "On Expansions and Nodes for Sparse Grid Collocation of Lognormal Elliptic PDEs",
            "authors": [
                {
                    "first": "O",
                    "middle": [
                        "G"
                    ],
                    "last": "Ernst",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Sprungk",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tamellini",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Also available as IMATI report",
            "volume": "",
            "issn": "",
            "pages": "19--21",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "The structural identifiability of a general epidemic (SIR) model with seasonal forcing",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Evans",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chapman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chappell",
                    "suffix": ""
                },
                {
                    "first": "Godfrey",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IFAC Proceedings Volumes",
            "volume": "35",
            "issn": "",
            "pages": "109--114",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "The structural identifiability of the susceptible infected recovered model with seasonal forcing",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "D"
                    ],
                    "last": "Evans",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "J"
                    ],
                    "last": "White",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Chapman",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Godfrey",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Chappell",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Mathematical Biosciences",
            "volume": "194",
            "issn": "2",
            "pages": "175--197",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Bias reduction of maximum likelihood estimates",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Firth",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Biometrika",
            "volume": "80",
            "issn": "1",
            "pages": "27--38",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Global sensitivity analysis through polynomial chaos expansion of a basin-scale geochemical compaction model",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Formaggia",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Guadagnini",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Imperiali",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Lever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Porta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Riva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Scotti",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tamellini",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Computational Geosciences",
            "volume": "17",
            "issn": "1",
            "pages": "25--42",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Spread and dynamics of the COVID-19 epidemic in Italy: Effects of emergency containment measures",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gatto",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bertuzzo",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Mari",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Miccoli",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Carraro",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Casagrandi",
                    "suffix": ""
                },
                {
                    "first": "Rinaldo",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the National Academy of Sciences",
            "volume": "117",
            "issn": "19",
            "pages": "10484--10491",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Modelling the COVID-19 epidemic and implementation of population-wide interventions in Italy",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Giordano",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Blanchini",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bruno",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Colaneri",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Di Filippo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Di Matteo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Colaneri",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Nature Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Separable nonlinear least squares: the variable projection method and its applications",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Golub",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Pereyra",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Inverse Problems",
            "volume": "19",
            "issn": "2",
            "pages": "1--26",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Introductory overview of identifiability analysis: A guide to evaluating whether you have the right type of data for your modeling purpose",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Guillaume",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "D"
                    ],
                    "last": "Jakeman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Marsili-Libelli",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Asher",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Brunner",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Croke",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Hill",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Jakeman",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "J"
                    ],
                    "last": "Keesman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Razavi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "D"
                    ],
                    "last": "Stigter",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Environmental Modelling & Software",
            "volume": "119",
            "issn": "",
            "pages": "418--432",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Stochastic finite element methods for partial differential equations with random input data",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Gunzburger",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "G"
                    ],
                    "last": "Webster",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Acta Numerica",
            "volume": "23",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Bayesian inferences of the thermal properties of a wall using temperature and heat flux measurements",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Iglesias",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sawlan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scavino",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wood",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "International Journal of Heat and Mass Transfer",
            "volume": "116",
            "issn": "",
            "pages": "417--431",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Practical unidentifiability of a simple vector-borne disease model: Implications for parameter estimation and intervention assessment",
            "authors": [
                {
                    "first": "Y.-H",
                    "middle": [],
                    "last": "Kao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Eisenberg",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Epidemics",
            "volume": "25",
            "issn": "",
            "pages": "89--100",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Fundamentals of statistical signal processing",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Kay",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "A contribution to the mathematical theory of epidemics",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "O"
                    ],
                    "last": "Kermack",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Mckendrick",
                    "suffix": ""
                }
            ],
            "year": 1927,
            "venue": "Proceedings of the Royal Society A",
            "volume": "115",
            "issn": "772",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Marginalization of uninteresting distributed parameters in inverse problems-application to diffuse optical tomography",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kolehmainen",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Tarvainen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Arridge",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kaipio",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "International Journal for Uncertainty Quantification",
            "volume": "1",
            "issn": "1",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Suppression of COVID-19 outbreak in the municipality of",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Lavezzo",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Franchin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ciavarella",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cuomo-Dannenburg",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Barzon",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Del Vecchio",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Rossi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Manganelli",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Loregian",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navarin",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Abate",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sciro",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Merigliano",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Decanale",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "C"
                    ],
                    "last": "Vanuzzo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Saluzzo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Onelia",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pacenti",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Parisi",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Carretta",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Donato",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Flor",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Cocchio",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Masi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sperduti",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Cattarino",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Salvador",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "A"
                    ],
                    "last": "Gaythorpe",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "R"
                    ],
                    "last": "Brazzale",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Toppo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Trevisan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Baldo",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Donnelly",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Ferguson",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Dorigatti",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Crisanti",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Using the negative binomial distribution to model overdispersion in ecological count data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lind\u00e9n",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "M\u00e4ntyniemi",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Ecology",
            "volume": "92",
            "issn": "7",
            "pages": "1414--1421",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "A Laplace method for under-determined bayesian optimal experimental designs",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scavino",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                },
                {
                    "first": "Wang",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Computer Methods in Applied Mechanics and Engineering",
            "volume": "285",
            "issn": "",
            "pages": "849--876",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Accurate solution of bayesian inverse uncertainty quantification problems combining reduced basis methods and reduction error models",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Manzoni",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pagani",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Lassila",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "SIAM/ASA Journal on Uncertainty Quantification",
            "volume": "4",
            "issn": "1",
            "pages": "380--412",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "A stochastic collocation approach to bayesian inference in inverse problems",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Marzouk",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Xiu",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Communications in computational physics 6",
            "volume": "",
            "issn": "",
            "pages": "826--847",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Comparison of three methods for selecting values of input variables in the analysis of output from a computer code",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Mckay",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "J"
                    ],
                    "last": "Beckman",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Conover",
                    "suffix": ""
                }
            ],
            "year": 1979,
            "venue": "Technometrics",
            "volume": "21",
            "issn": "2",
            "pages": "239--245",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "On identifiability of nonlinear ODE models and applications in viral dynamics",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Perelson",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "SIAM Review",
            "volume": "53",
            "issn": "1",
            "pages": "3--39",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Factorial sampling plans for preliminary computational experiments",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Morris",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "",
            "volume": "33",
            "issn": "",
            "pages": "161--174",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Random number generation and quasi-Monte Carlo methods. CBMS-NSF regional conference series in applied mathematics",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Niederreiter",
                    "suffix": ""
                }
            ],
            "year": 1992,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Numerical Optimization",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Nocedal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Data-driven uncertainty quantification using the arbitrary polynomial chaos expansion. Reliability Engineering and System Safety",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Oladyshkin",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Nowak",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "106",
            "issn": "",
            "pages": "179--190",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "On estimation of a probability density function and mode",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Parzen",
                    "suffix": ""
                }
            ],
            "year": 1962,
            "venue": "The Annals of Mathematical Statistics",
            "volume": "33",
            "issn": "3",
            "pages": "1065--1076",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Epidemic analysis of COVID-19 in China by dynamical modeling",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhuge",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Hong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Inverse modeling of geochemical and mechanical compaction in sedimentary basins through polynomial chaos expansion",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Porta",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tamellini",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Lever",
                    "suffix": ""
                },
                {
                    "first": "Riva",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Water Resources Research",
            "volume": "",
            "issn": "12",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Inferring the COVID-19 infection curve in Italy",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pugliese",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sottile",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Raue",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kreutz",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Maiwald",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bachmann",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schilling",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Klingmller",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Timmer",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Bioinformatics",
            "volume": "25",
            "issn": "15",
            "pages": "1923--1929",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Differential Algebra. Colloquium publications",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ritt",
                    "suffix": ""
                }
            ],
            "year": 1950,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Epidemic models with uncertainty in the reproduction number",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "G"
                    ],
                    "last": "Roberts",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Journal of Mathematical Biology",
            "volume": "66",
            "issn": "7",
            "pages": "1463--1474",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Why is it difficult to accurately predict the COVID-19 epidemic?",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "C"
                    ],
                    "last": "Roda",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "B"
                    ],
                    "last": "Varughese",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "Y"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Infectious Disease Modelling",
            "volume": "5",
            "issn": "",
            "pages": "271--281",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Assessing parameter identifiability in compartmental dynamic models using a computational approach: application to infectious disease transmission models",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roosa",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chowell",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Theoretical Biology and Medical Modelling",
            "volume": "",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Remarks on some nonparametric estimates of a density function",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rosenblatt",
                    "suffix": ""
                }
            ],
            "year": 1956,
            "venue": "The Annals of Mathematical Statistics",
            "volume": "27",
            "issn": "3",
            "pages": "832--837",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Approximate bayesian inference for latent gaussian models by using integrated nested Laplace approximations",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rue",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Martino",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Chopin",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
            "volume": "71",
            "issn": "2",
            "pages": "319--392",
            "other_ids": {}
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "A hierarchical bayesian setting for an inverse problem in linear parabolic pdes with noisy boundary conditions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ruggeri",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sawlan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Scavino",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tempone",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Bayesian Anal",
            "volume": "12",
            "issn": "2",
            "pages": "407--433",
            "other_ids": {}
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "Global Sensitivity Analysis: The Primer",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saltelli",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ratto",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Andres",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Campolongo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cariboni",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gatelli",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Saisana",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tarantola",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF64": {
            "ref_id": "b64",
            "title": "Sparse, adaptive Smolyak quadratures for Bayesian inverse problems",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Schillings",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Schwab",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Inverse Problems",
            "volume": "",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF65": {
            "ref_id": "b65",
            "title": "Model selection on solid ground: Rigorous comparison of nine ways to evaluate bayesian model evidence",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Schniger",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Whling",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Samaniego",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Nowak",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Water Resources Research",
            "volume": "50",
            "issn": "12",
            "pages": "9484--9513",
            "other_ids": {}
        },
        "BIBREF66": {
            "ref_id": "b66",
            "title": "When are quasi-Monte Carlo algorithms efficient for highdimensional integrals?",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "H"
                    ],
                    "last": "Sloan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wo\u017aniakowski",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "J. Complexity",
            "volume": "14",
            "issn": "1",
            "pages": "1--33",
            "other_ids": {}
        },
        "BIBREF67": {
            "ref_id": "b67",
            "title": "Sensitivity estimates for nonlinear mathematical models",
            "authors": [
                {
                    "first": "&apos;",
                    "middle": [],
                    "last": "Sobol",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "M"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Math. Modeling Comput. Experiment",
            "volume": "1",
            "issn": "4",
            "pages": "407--414",
            "other_ids": {}
        },
        "BIBREF68": {
            "ref_id": "b68",
            "title": "An evaluation of R2 as an inadequate measure for nonlinear models in pharmacological and biochemical research: a Monte Carlo approach",
            "authors": [
                {
                    "first": "A.-N",
                    "middle": [],
                    "last": "Spiess",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Neumeyer",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "BMC Pharmacology",
            "volume": "",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF69": {
            "ref_id": "b69",
            "title": "Inverse problems: A bayesian perspective",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Stuart",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Acta Numerica",
            "volume": "19",
            "issn": "",
            "pages": "451--559",
            "other_ids": {}
        },
        "BIBREF70": {
            "ref_id": "b70",
            "title": "Profile likelihood-based analyses of infectious disease models",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "T\u00f6nsing",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Timmer",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kreutz",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Statistical Methods in Medical Research",
            "volume": "27",
            "issn": "7",
            "pages": "1979--1998",
            "other_ids": {}
        },
        "BIBREF71": {
            "ref_id": "b71",
            "title": "Structural and practical identifiability analysis of outbreak models",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tuncer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "T"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Mathematical Biosciences",
            "volume": "299",
            "issn": "",
            "pages": "1--18",
            "other_ids": {}
        },
        "BIBREF72": {
            "ref_id": "b72",
            "title": "Quasi-poisson vs. negative binomial regression: How should we model overdispersed count data?",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Ver Hoef",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "L"
                    ],
                    "last": "Boveng",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Ecology",
            "volume": "88",
            "issn": "11",
            "pages": "2766--2772",
            "other_ids": {}
        },
        "BIBREF73": {
            "ref_id": "b73",
            "title": "Phase-adjusted estimation of the number of Coronavirus Disease",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Tsamlag",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF74": {
            "ref_id": "b74",
            "title": "Explicit cost bounds of algorithms for multivariate tensor product problems",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wasilkowski",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wozniakowski",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Journal of Complexity",
            "volume": "11",
            "issn": "1",
            "pages": "1--56",
            "other_ids": {}
        },
        "BIBREF75": {
            "ref_id": "b75",
            "title": "Modeling physical uncertainties in dynamic stall induced fluidstructure interaction of turbine blades using arbitrary polynomial chaos",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Witteveen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarkar",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Computers and Structures",
            "volume": "85",
            "issn": "",
            "pages": "866--878",
            "other_ids": {}
        },
        "BIBREF76": {
            "ref_id": "b76",
            "title": "High-order collocation methods for differential equations with random inputs",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Xiu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Hesthaven",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "SIAM J. Sci. Comput",
            "volume": "27",
            "issn": "3",
            "pages": "1118--1139",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Left: SIR dynamics.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Time-evolution of Sobol indices for the SIR compartments, and SIR trajectories obtained by reducing the range of variability of r. The principal indices are represented by the solid line, while the total indices are represented by the dashed line.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "(where the Jacobian entries are also computed by centered finite differences) are respectively \u03a3 G,Jac = 10",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Result of the inverse UQ analysis for SIR. Top row, from left to right: trajectories corresponding to \u03d1 = \u03d1true and \u03d1 = \u03d1 M LE , and synthetic data obtained dividing the trajectories for \u03d1 = \u03d1true by the under-reporting factor K and adding the Gaussian noise; zoom on the data, and trajectories for \u03d1 = \u03d1true and \u03d1 = \u03d1 M LE rescaled by K; prior and posterior pdfs for \u03b2 and r, as well as the true and MLE values of the parameters. Bottom row, from left to right: isolines of N LL; surface-plot of the full likelihood; surface-plot of the likelihood after the Fisher approximation, cf. equation(15); surface-plot of the likelihood after having further dropped the second derivatives of I, R in the definition of H, cf. equation(16).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "17) and the Fisher approximation should now be centered at the maximum of the posterior pdf (we referred to this value as MAP) \u00b5 M AP = arg min \u03d1 [\u22122 log(L D (\u03d1)\u03c1 prior )] , which in practice recovers a form of Tikhonov regularization of the least-squares problem, with penalization",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Forward UQ analysis for SIR based on either the prior or the posterior pdfs of the parameters.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Left: values of N LL across the range of tested values of \u03bb for the test in which the data for I and R have different standard deviations. The smallest NLL is reached for \u03bb min close to the exact one \u03bbtrue; middle: posterior distribution of \u03b2 and r for \u03bb min , \u03bb = 1, and \u03bb = 90; right: Monte Carlo trajectories based on the posterior distribution of the parameters, for \u03bb min , \u03bb = 1, and \u03bb = 90, respectively. The black lines are the true trajectories.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "\u03d1 M LE = [0.2917, 0.0950], \u03c3 I = 0.2330 \u03c3 R = 0.0508. The figure in the middle displays the posterior distribution of the parameters corresponding to \u03bb min and to the two extremes of the considered range of \u03bb. The figures on the right show 200 Monte Carlo trajectories based on the posterior distribution of the parameters. The value \u03bb = \u03bb min (left-most panel) gives a narrow bundle of trajectories matching the true ones. The other bundles (\u03bb = 1, 90 i.e., the smallest and largest values of \u03bb tested) are more spread and in the case of \u03bb = 90 they are also far from being centered around the true trajectories.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Several variations of Gaussian approximation of the posterior pdfs can be conceived, depending on the choice of the mean (e.g., MLE, MAP, expected value of the posterior) and of the covariance matrix, see e.g. [8, Result 8, p.224].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Three cases of profile likelihood (blue line), with nominal value of the parameter (red star), and confidence threshold \u2206\u03b1\u03c7 2 1 (dashed line ). Left: the parameter is practically identifiable; middle: the parameter is not structurally identifiable; right: the parameter is practically non-identifiable.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "top and bottom-second figure. Even using quantitative criteria to evaluate the goodness of fit of the two fittings, such as Root Mean Square Error (RMSE) :",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "|F m (\u03d1 M LE ) \u2212F m |, for F = I, R Mean Absolute Percentage Error (MAPE) : 1 Nmeas Nmeas m=1 F m (\u03d1 M LE ) \u2212F m /F m , for F = I, R.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Profile Likelihood for K for the three different scenarios, i.e. data collection ending: before peak of I (left), around the peak of I (center), after the peak of I (right).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Comparison of quality of predictions and data fitting obtained for K = 2 (top) and K = 3 (bottom) in the scenario of data available only before the peak. From left to right: forward Uncertainty Quantification based on the posterior pdf; the fitting of the data in the two cases; scatterplot of data vs predictions; qqplot of misfits.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Results of inversion for the three cases T = 20, 30, 40 for K = 3. Top row: contours of the NLL in the three cases (left to right); the true value of the parameters is the yellow dot, the MLE estimate is the red dot. The NLL contour lines suggest that the NLL has a unique minimum at the MLE estimate, which is always close to the true value of the parameters. Bottom rows: Gaussian approximation of the posterior pdfs of \u03b2, r for the three cases T = 20, 30, 40 for K = 3.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Prior-based forward UQ for the SEIRDz model. Left-most panel: Monte Carlo realizations and expected value of the compartments. Remaining panels: time-evolution of the Sobol indices.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Results for inversion of SEIRDz. Top row, from left to right: the initial and final value of NLL for the 20 trials (blue and red line, respectively) and a zoom on the final values (the value with the smallest NLL is marked with a black square); the initial and final values of the parameters for the 20 trial (blue and red line, respectively), the correct values (black dash lines), and the values of the parameters that yield the smallest NLL (black square marker). Bottom row: the trajectories of the 20 MLE estimates and a zoom on the E, I, D compartments. The colored trajectories are those obtained by the values of the parameters obtained by the 20 optimization trials. The MLE trajectories are reported in full black line, while the true ones in dashed black lines. the parameters as \u03b2 true = 0.28, r true = 0.11, d true = 0.018, i true = 0.18, z true = 0.18, K = 3, \u03c3 = 0.01;",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Results for inversion of SEIRDz upon blocking the parameters r, d, i. Left panel: the initial and final value of NLL for the 20 trials (blue and red line, respectively) and a zoom on the final values (the value with the smallest NLL is marked with a black square). Mid panel: the initial and final values of \u03b2, z for the 20 trial (blue and red line, respectively), the correct values (black dash lines), and the values of the parameters that yield the smallest NLL (black square marker). Right panel: the true trajectories (black lines), the MLE estimate when trying to identify all parameters (colored dotted lines) and the MLE estimates when trying to identify \u03b2, z only (full colored lines).",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "The colored lines represent the SIR dynamics obtained by Monte Carlo samples of \u03b2, r, and the thick black lines represent the average computed by sparse grids. The other panels represent pdfs of quantities of interest: SIR states at T = 30, 100 (by Monte Carlo and sparse grids), peak-time for I and peak-value for I (sparse grids only).Figure 2: Sparse grids response surfaces for the SIR quantities of interest. From left to right: S at T = 30, I at T = 30, R at T = 30, peak time, and peak value.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "). The easiest sampling scheme is Monte Carlo, but more advanced sampling techniques can be used (Latin Hypercube Sampling, Stratified Sampling, Quasi-Monte-Carlo, Sparse grids, among others; see the bibliography for discussion). Within sampling schemes, quantities such as mean, standard deviations and higher moments with respect to the parameters can be computed by averaging over the M samples of the model results:",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "\u03b2 \u2208 [0.25, 0.35] r \u2208 [0.06, 0.18] d \u2208 [0.01, 0.02] i \u2208 [0.14, 0.33] z \u2208 [0.1, 0.2].",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors acknowledge the many fruitful discussions with several colleagues, and in particular the colleagues at CNR-IMATI that participated in the COVID-19 modeling study group.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        },
        {
            "text": "None. Appendix A. Structural identifiability of a SEIRD model by differential algebraIn this section we consider the SEIRD model, which is a simplified version of the SEIRDz model considered in Example 9 with \u03b2 constant in time. We show by means of the differential algebra technique explained in Section 7 that it is structurally identifiable from prevalence data of I, R and D.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Declarations of interest"
        },
        {
            "text": "Algorithm 2: Ideal UQ workflow 1 Choose a model and the prior distributions for its parameter (literature, expert opinion); 2 Determine whether the system is structurally identifiable (Sobol indices, profile likelihood, differential algebra, mapping approach, etc.); 3 if the model is structurally identifiable then 4 while the model is not practically identifiable (bootstrap, profile likelihood, multiple restart, etc.) do 5 Acquire more data / get information on some parameters from independent studies / perform a hierarchical optimization; ",
            "cite_spans": [
                {
                    "start": 425,
                    "end": 426,
                    "text": "5",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "annex"
        }
    ]
}