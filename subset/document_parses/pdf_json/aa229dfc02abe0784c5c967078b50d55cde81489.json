{
    "paper_id": "aa229dfc02abe0784c5c967078b50d55cde81489",
    "metadata": {
        "title": "Comparing acoustic analyses of speech data collected remotely",
        "authors": [
            {
                "first": "Cong",
                "middle": [],
                "last": "Zhang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Radboud University",
                    "location": {
                        "postCode": "6500 HD",
                        "settlement": "Nijmegen",
                        "region": "GLD",
                        "country": "Netherlands"
                    }
                },
                "email": ""
            },
            {
                "first": "Kathleen",
                "middle": [],
                "last": "Jepson",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Radboud University",
                    "location": {
                        "postCode": "6500 HD",
                        "settlement": "Nijmegen",
                        "region": "GLD",
                        "country": "Netherlands"
                    }
                },
                "email": ""
            },
            {
                "first": "Georg",
                "middle": [],
                "last": "Lohfink",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Kent",
                    "location": {
                        "postCode": "CT2 7NF",
                        "settlement": "Canterbury, Kent",
                        "country": "UK"
                    }
                },
                "email": ""
            },
            {
                "first": "Amalia",
                "middle": [],
                "last": "Arvaniti",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Radboud University",
                    "location": {
                        "postCode": "6500 HD",
                        "settlement": "Nijmegen",
                        "region": "GLD",
                        "country": "Netherlands"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Face-to-face speech data collection has been next to impossible globally due to restrictions. To address this problem, simultaneous recordings of three repetitions of the cardinal vowels were made using a Zoom H6 Handy Recorder with external microphone (henceforth H6) and compared with two alternatives accessible to potential participants at home: the Zoom meeting application (henceforth Zoom) and two lossless mobile phone applications (Awesome Voice Recorder, and Recorder; henceforth Phone). F0 was tracked accurately by all devices; however, for formant analysis (F1, F2, F3) Phone performed better than Zoom, i.e. more similarly to H6, though data extraction method (VoiceSauce, Praat) also resulted in differences.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "In addition, Zoom recordings exhibited unexpected drops in intensity. The results suggest that lossless format phone recordings present a viable option for at least some phonetic studies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Speech production studies have been significantly impacted by restrictions related to COVID-19, as both access to laboratories and face-to-face interaction with study participants have been restricted. In order to adapt to the situation, we set out to test whether alternatives easily accessible to participants recorded remotely can produce recordings suitable for acoustic analysis. We note that these findings are of interest to phoneticians working on speech production even if COVID-19 related restrictions are completely lifted in some countries, as researchers may continue to have limited access to speech communities in some countries. More generally, researchers may have to conduct recordings remotely for other reasons, for instance because of ethical, political, or financial restrictions that make travel difficult or impossible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Research has already examined the performance of several devices that can be used for recordings, such as iPads (De Decker, 2016; Maryn et al., 2017) , computers (De Decker and Nycz, 2011; Kojima et al., 2019; Vogel et al., 2014) , and smart phones (Grillo et al., 2016; Kojima et al., 2019; Manfredi et al., 2017; Uloza et al., 2015; Vogel et al., 2014; see Jannetts et al., 2019, for a review) . Other studies have examined the effects of different file formats, such as lossless Apple .m4a files (De Decker and Nycz, 2011) , lossy compressed .mp3 files (Bulgin et al., 2010) , and audio extracted from compressed video files (De Decker and Nycz, 2011) .",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 129,
                    "text": "(De Decker, 2016;",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 130,
                    "end": 149,
                    "text": "Maryn et al., 2017)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 162,
                    "end": 188,
                    "text": "(De Decker and Nycz, 2011;",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 189,
                    "end": 209,
                    "text": "Kojima et al., 2019;",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 210,
                    "end": 229,
                    "text": "Vogel et al., 2014)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 249,
                    "end": 270,
                    "text": "(Grillo et al., 2016;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 271,
                    "end": 291,
                    "text": "Kojima et al., 2019;",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 292,
                    "end": 314,
                    "text": "Manfredi et al., 2017;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 315,
                    "end": 334,
                    "text": "Uloza et al., 2015;",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 335,
                    "end": 354,
                    "text": "Vogel et al., 2014;",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 355,
                    "end": 395,
                    "text": "see Jannetts et al., 2019, for a review)",
                    "ref_id": null
                },
                {
                    "start": 499,
                    "end": 525,
                    "text": "(De Decker and Nycz, 2011)",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 556,
                    "end": 577,
                    "text": "(Bulgin et al., 2010)",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 628,
                    "end": 654,
                    "text": "(De Decker and Nycz, 2011)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Two key findings emerge from these studies. First, F0 is often unaffected by recording device and file format (Bulgin et al., 2010; Fuchs and Maxwell, 2016; Jannetts et al., 2019; Maryn et al., 2017) , though it is unclear whether this applies equally well to F0 that exhibits significant dynamic changes, as it does to steady F0 (which is what is typically tested). Second, lossy formats distort the F1-F2 vowel space in unpredictable ways; both expansion and compression (i.e., changes in both F1 and F2 simultaneously) are observed inconsistently across speakers (Bulgin et al., 2010) , with women's speech showing greater distortion in lossy files recorded in quiet conditions (De Decker and Nycz, 2011) . Noise, on the other hand, can lead to greater vowel space distortion in male voices instead (De Decker, 2016) .",
            "cite_spans": [
                {
                    "start": 110,
                    "end": 131,
                    "text": "(Bulgin et al., 2010;",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 132,
                    "end": 156,
                    "text": "Fuchs and Maxwell, 2016;",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 157,
                    "end": 179,
                    "text": "Jannetts et al., 2019;",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 180,
                    "end": 199,
                    "text": "Maryn et al., 2017)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 566,
                    "end": 587,
                    "text": "(Bulgin et al., 2010)",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 681,
                    "end": 707,
                    "text": "(De Decker and Nycz, 2011)",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 802,
                    "end": 819,
                    "text": "(De Decker, 2016)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "We add to this line of research, by comparing recordings made with a high-quality digital recorder, Zoom H6 Handy Recorder (henceforth H6) with recordings made using two \"remote\" options: the Zoom cloud meeting application (henceforth Zoom) and mobile phone applications that produce sound files in lossless formats (henceforth Phone). We investigated these two options because they are convenient, free, readily available, and allow for local file storage.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Phone-based options have the benefit of only requiring a smartphone to use, which most people have ready access to. They are a convenient way to record lossless format files which are recorded by H6, and are used as standard in acoustic research. Zoom has been successfully used for supervised online data collection (Leemann et al., 2020) and so may be a convenient recording tool already in use in remote data collection. Zoom was also selected as 1) participants do not need to have a personal account to join a Zoom meeting, which may be relevant for data protection obligations; 2) the built-in recording function in Zoom allows local recording without relying on internet connection. It is noted that Zoom does require internet connection to start a meeting session. Local recording, however, does not rely on the internet connection quality.",
            "cite_spans": [
                {
                    "start": 317,
                    "end": 339,
                    "text": "(Leemann et al., 2020)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Other computer-based options may need a paid subscription, are browser-based, or require fast, stable internet connection. These features pose two problems: use requires suitable infrastructure in the locations where the data are collected, and this may not always be available; further, data saved in proprietary applications could create issues with data storage and personal data protection regulations. Zoom recordings may be comparable to those made using other conferencing software such as Skype and Microsoft Teams (Freeman & De Decker, 2021) ; However, further investigation is needed to generalise the findings of this study to different applications.",
            "cite_spans": [
                {
                    "start": 523,
                    "end": 550,
                    "text": "(Freeman & De Decker, 2021)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "INTRODUCTION"
        },
        {
            "text": "Four females (PF1-4) and three males (PM1-3), aged 30-52 (mean 37) took part in the study. linguistic backgrounds of the participants are not a problem for the present study which focuses on differences between devices and thus on within-speaker comparisons. All participants were aware of the purpose of the study. Though this is a small sample size, it is hoped the results will be of help to speech researchers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Participants"
        },
        {
            "text": "The materials consisted of pure tones and elicitation of sustained versions of the primary cardinal vowels, [i, e, \u025b, a, \u0251, \u0254, o, u] . Here we report only on the results from the vowel recordings. We used sustained vowels to make our findings comparable to those of previous studies (e.g., Grillo et al., 2016; Manfredi et al., 2017; Maryn et al., 2017; Uloza et al., 2015; Vogel et al., 2014) , which in turn used sustained vowels because they \"feature simple acoustic structure and allow reliable detection and computation of acoustic features\" (Uloza et al., 2015) .",
            "cite_spans": [
                {
                    "start": 108,
                    "end": 132,
                    "text": "[i, e, \u025b, a, \u0251, \u0254, o, u]",
                    "ref_id": null
                },
                {
                    "start": 290,
                    "end": 310,
                    "text": "Grillo et al., 2016;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 311,
                    "end": 333,
                    "text": "Manfredi et al., 2017;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 334,
                    "end": 353,
                    "text": "Maryn et al., 2017;",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 354,
                    "end": 373,
                    "text": "Uloza et al., 2015;",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 374,
                    "end": 393,
                    "text": "Vogel et al., 2014)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 547,
                    "end": 567,
                    "text": "(Uloza et al., 2015)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "B. Materials"
        },
        {
            "text": "Participants made simultaneous recordings of the vowels using an H6 with an external microphone, a Phone running a recording application using the built-in microphone, and a laptop running Zoom using the built-in microphone of the laptop; see Table I for details. The range of mobile phones and computers used simulates real-world scenarios where participants in a remote speech production study would use different devices. Following previous studies (e.g., Grillo et al., 2016; Manfredi et al., 2017; Maryn et al., 2017; Uloza et al., 2015; Vogel et al., 2014) , we instructed participants to produce and sustain each vowel for 3-5 s, and repeat them three times",
            "cite_spans": [
                {
                    "start": 459,
                    "end": 479,
                    "text": "Grillo et al., 2016;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 480,
                    "end": 502,
                    "text": "Manfredi et al., 2017;",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 503,
                    "end": 522,
                    "text": "Maryn et al., 2017;",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 523,
                    "end": 542,
                    "text": "Uloza et al., 2015;",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 543,
                    "end": 562,
                    "text": "Vogel et al., 2014)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 243,
                    "end": 250,
                    "text": "Table I",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "C. Recording devices and applications"
        },
        {
            "text": "The devices were placed as follows: the Zoom computer was placed on a table directly in front of the participant, approximately 40-50 cm away, resembling a Zoom meeting set up; the participant held the Phone approximately 10-20 cm from their mouth; the H6 was used with either a head-mounted microphone or a microphone with pop filter on a stand 15 cm in front of the participant. Participants were asked to turn all devices to silent mode. Participants were not asked to restart their devices, or turn off all other processes and background applications before recording. This was done because we aimed to simulate a real-life scenario that applies both in the lab and in remote online data collection: in speech production studies, participants are regularly asked to view documents that present text for reading or images to describe etc, and thus it is not possible to stop all processes on a device other than the recording application. For the same reasons, participants were not asked to use an external microphone for either Phone or Zoom, as this is equipment that may not always be available. Thus, the present study provides an acoustic analysis of data acquired using the simplest application settings and readily available equipment.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Recording devices and applications"
        },
        {
            "text": "The recordings provided us with a corpus of 504 tokens [7 participants \u00d7 8 vowels \u00d7 3",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "repetitions \u00d7 3 devices]. These vowel tokens were manually segmented in Praat (Boersma and Weenink, 2019) . F0, F1, F2, and F3 were extracted using both VoiceSauce (Shue, 2010) and",
            "cite_spans": [
                {
                    "start": 78,
                    "end": 105,
                    "text": "(Boersma and Weenink, 2019)",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 164,
                    "end": 176,
                    "text": "(Shue, 2010)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "Praat. Praat was chosen because it is commonly used for data extraction in speech analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "VoiceSauce is an alternative tool which implements different algorithms and has a finer step for data extraction (see below). For F0, the range for extraction was 40-500 Hz in both VoiceSauce and Praat. For vowel formants, default VoiceSauce settings were used (covariance method, preemphasis of 0.96). In Praat, the maximum number of formants was set at five, and the formant extraction ranges were specified for males as 0-5000 Hz and for females as 0-5500 Hz. Mean F0, F1, F2, and F3 of all 3 tokens per vowel were calculated. For the VoiceSauce-extracted data, token means were calculated from values extracted every 1 ms throughout each token with a moving window length of 25 ms. In Praat, means were extracted with the built-in \"Get mean\" function.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "Linear mixed effect models (Bates et al., 2015) were built in R (R Core Team, 2020) to investigate how much variation in the dependent variables (F0, F1, F2, and F3) can be ascribed to the recording devices. Data extracted using VoiceSauce and Praat were analysed separately.",
            "cite_spans": [
                {
                    "start": 27,
                    "end": 47,
                    "text": "(Bates et al., 2015)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "For each dependent variable, full models were constructed with a fixed effect of DEVICE (H6, Phone, Zoom). SPEAKER (seven speakers), VOWEL (eight vowels), PHONE_EQUIPMENT (phone models used for phone recording), and COMPUTER_EQUIPMENT (computer models used for Zoom recording) were treated as random intercepts, accounting for interspeaker differences and the use of different phone and computer models (see Table 1 ). Random slopes for DEVICE, PHONE_EQUIPMENT, and COMPUTER_EQUIPMENT were also fitted for SPEAKER in the full model.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 408,
                    "end": 415,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "The random slopes and intercepts were reduced when the full models failed to converge or resulted in singular fit. Final models were the same for VoiceSauce-and Praat-extracted data, and are reported together with the results in Tables II-V. These tables present estimated difference (estimate), standard error (SE), degrees of freedom (df), t value (t), which reflects how extreme the observed difference is relative to the intercept, and p-value (significance) from the ttest (Pr(>|t|)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "Illustrative boxplots, separately for data extracted using Praat and VoiceSauce, can be found in Fig. 1 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 97,
                    "end": 103,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "E. Measurements and Statistical Analysis"
        },
        {
            "text": "Statistical models and results are shown in Tables II-V. Note that for all analyses, COMPUTER_EQUIPMENT and PHONE_EQUIPMENT were not retained in the final models due to singular fits (see section II E). Fig. 1a -d illustrates the difference between devices for F0, F1, F2, and F3 in the data extracted using VoiceSauce (left) and Praat (right).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 203,
                    "end": 210,
                    "text": "Fig. 1a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "Regarding F0, there was no statistically significant effect of DEVICE (see Table II ) for data extracted using either VoiceSauce or Praat. Nevertheless, the data contain some outliers. For instance, the positive outliers for the F0 of /e/ in the VoiceSauce-extracted data (circled in Fig.   1a ) were both from the same repetition simultaneously recorded by the three devices. Such 9 outliers suggest that on occasion both devices failed to capture F0 accurately in a way that could be extracted successfully by VoiceSauce.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 75,
                    "end": 83,
                    "text": "Table II",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 284,
                    "end": 293,
                    "text": "Fig.   1a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "For F1, the effect of DEVICE was significant (see Table III ). While Phone recordings did not present any significant differences from the H6 recordings, Zoom recordings had significantly lower F1 than H6 both for VoiceSauce-and Praat-extracted data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 50,
                    "end": 59,
                    "text": "Table III",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "The effect of DEVICE was also significant for F2 (see Tables IV ). The F2 of VoiceSauceextracted Phone data was significantly lower than that of H6. However, the F2 difference between H6 and Praat-extracted Phone data was not statistically significant. For Zoom, both",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 54,
                    "end": 63,
                    "text": "Tables IV",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "VoiceSauce-and Praat-extracted values were significantly lower than those of H6. Fig. 1c shows that the F2 of front vowels is most affected in both VoiceSauce-and Praat-extracted data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 81,
                    "end": 88,
                    "text": "Fig. 1c",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "For F3 (see Table V ), neither Phone nor Zoom showed statistical differences from H6 in the VoiceSauce-extracted data. However, in the Praat-extracted data, Zoom F3 values were lower than H6. Fig. 1d (right) reflects that Praat had difficulty in extracting F3 data from Zoom recordings across all vowels. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 19,
                    "text": "Table V",
                    "ref_id": null
                },
                {
                    "start": 192,
                    "end": 199,
                    "text": "Fig. 1d",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "III. RESULTS"
        },
        {
            "text": "Audio files recorded by the AVR application using Android devices produced a warning when opened in Praat: \"File too small (1-channel 16-bit). Missing samples were set to zero.\"",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. AVR missing samples"
        },
        {
            "text": "However, there were no audible glitches and files could be opened. Sample dropping in these files was investigated to understand its possible effects on measurement extraction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. AVR missing samples"
        },
        {
            "text": "A small number of zero sequences were found in the recordings, confirming AVR was dropping samples. This occurred across a range of smartphones, when using different recording options (i.e., sample rate and bitrate). To address this issue, we first investigated if sample dropping was due to phones running other applications in conjunction with AVR but this turned out not to be the case: samples were dropped whether all other applications were disabled or other applications were running at the same time as AVR. Following this finding, we proceeded with the analysis of sample dropping when both AVR and other applications were running.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. AVR missing samples"
        },
        {
            "text": "Analysis showed that the vast majority of zero sequences found within the recordings consisted of only 2 samples, while none exceeded 20 samples. Sequences of more than 20 zero samples were found only at the very beginning of recordings and had a maximum of 150 zeros (= 4.7 ms). Considering that the sampling rate was 44.1 kHz, these dropped samples formed a minute fraction of the duration of each recording and thus are unlikely to pose problems for analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. AVR missing samples"
        },
        {
            "text": "In order to completely rule out the possibility that these inconsistencies can negatively affect acoustic measurements, a simulation was run. Audio files containing artificial vowels with a duration of over 1 s were created using Praat's VowelEditor. These were compared to artificially corrupted versions of the same files, such that the latter included sequences of up to 20 zero samples. Over 4,800 such pairs were generated in Praat using ten different vowels with a variety 14 of F0 slopes. Measurements of intensity, F0, F1 and F2 in both versions showed correlations above 0.99. This suggests that the missing samples in recordings from the AVR application do not present an issue in extracting these acoustic measures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. AVR missing samples"
        },
        {
            "text": "In Zoom recordings, intensity was not reliably tracked, at least with the default setting with noise-cancelling processing. Periods of extremely reduced intensity occurred at random, as shown in Fig. 2 . Further investigation is needed into the effects over more varied speech data. In our view, such random, extreme errors make Zoom unsuitable for phonetic research, at least in relation to any intensity-related measurements. However, in the more recent versions of Zoom, an extra setting of \"enable original sound\" is present, which may have the potential of recording audio with higher fidelity. Note that Sanker et al. (2021) found no significant difference in using the \"enable original sound\" setting and the default setting. Further examination is still needed for",
            "cite_spans": [
                {
                    "start": 610,
                    "end": 630,
                    "text": "Sanker et al. (2021)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [
                {
                    "start": 195,
                    "end": 201,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "B. Zoom intensity drop"
        },
        {
            "text": "investigating the recording quality of audio recorded with the new option. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Zoom intensity drop"
        },
        {
            "text": "In summary, Phone and Zoom recordings produced similar F0 values to the H6, a result consistent with previous studies which also showed that F0 is robust to lossy compression and unaffected by device choice (cf. Grillo et al., 2016; Uloza et al., 2015; Vogel et al., 2014) .",
            "cite_spans": [
                {
                    "start": 212,
                    "end": 232,
                    "text": "Grillo et al., 2016;",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 233,
                    "end": 252,
                    "text": "Uloza et al., 2015;",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 253,
                    "end": 272,
                    "text": "Vogel et al., 2014)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "V. DISCUSSION AND CONCLUSIONS"
        },
        {
            "text": "Formant tracking presented some issues for the test devices, and these differed by extraction method. For the Zoom recordings, Praat-extracted data showed differences for all three formants relative to H6. For the Phone recordings, however, there were no differences. VoiceSauceextracted data, on the other hand, showed differences in F1 and F2 values of Zoom recordings, as well as F2 values of Phone recordings. The differences between these extraction methods could be led by the different formant range settings in Praat and VoiceSauce: in Praat, the formant ranges can be set differently by gender, while formant ranges cannot be changed in VoiceSauce.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION AND CONCLUSIONS"
        },
        {
            "text": "These results also showed that Praat may not be able to track F2 and F3 reliably for Zoom recordings. This poses serious issues when using Zoom to record and Praat for data extraction if formant frequencies are measured. Similarly, the intensity drops observed in the Zoom recordings, while not statistically modelled in this paper, could pose serious issues for intensity analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION AND CONCLUSIONS"
        },
        {
            "text": "Close inspection of the data illustrated in Fig. 1 Fig. 3 , which depicts the vowel space of each participant by DEVICE. Fig. 3 illustrates the unpredictable nature of the values recorded by the devices and the distortions they can bring. Based on these finding, we concur with De Decker and Nycz (2011) that researchers should not use different devices (e.g., Zoom and Phone) to record data for the same study, nor should they compare data obtained using different devices or extracted using different extraction methods. Finally, we note that overall, more tracking errors occurred with the female data (PF1-4) than the male data (PM1-3), across all devices. This is in line with previous reports, such as De Decker and Nycz (2011 ",
            "cite_spans": [
                {
                    "start": 711,
                    "end": 732,
                    "text": "Decker and Nycz (2011",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [
                {
                    "start": 44,
                    "end": 50,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 51,
                    "end": 57,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 121,
                    "end": 127,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "V. DISCUSSION AND CONCLUSIONS"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Fitting linear mixed-effects models using lme4",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bates",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "M\u00e4 Chler",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Bolker",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Walker",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Stat. Software1",
            "volume": "1",
            "issn": "",
            "pages": "1--48",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Praat: doing phonetics by computer",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Boersma",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Weenink",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Reliability of formant measurements from lossy compressed audio,\" poster presentation at British Association of Academic Phoneticians",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bulgin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "De Decker",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Nycz",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "An evaluation of noise on LPC-based vowel formant estimates: Implications for sociolinguistic data collection",
            "authors": [
                {
                    "first": "De",
                    "middle": [],
                    "last": "Decker",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Linguist. Vanguard",
            "volume": "2",
            "issn": "",
            "pages": "1--19",
            "other_ids": {
                "DOI": [
                    "10.1515/lingvan-2015-0010"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "For the record: Which digital media can be used for sociophonetic analysis?",
            "authors": [
                {
                    "first": "De",
                    "middle": [],
                    "last": "Decker",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Nycz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Univ. Pennsylvania Work. Pap. Linguist",
            "volume": "17",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "The effects of mp3 compression on acoustic measurements of fundamental frequency and pitch range",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Fuchs",
                    "suffix": ""
                },
                {
                    "first": "Maxwell",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proc. Int. Conf. Speech Prosody",
            "volume": "",
            "issn": "",
            "pages": "523--527",
            "other_ids": {
                "DOI": [
                    "10.21437/speechprosody.2016-107"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Remote sociophonetic data collection: Vowels and nasalization over video conferencing apps",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Freeman",
                    "suffix": ""
                },
                {
                    "first": "De",
                    "middle": [],
                    "last": "Decker",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "J. Acoust. Soc. Am",
            "volume": "149",
            "issn": "",
            "pages": "1211--1223",
            "other_ids": {
                "DOI": [
                    "10.1121/10.0003529"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Influence of smartphones and software on acoustic voice measures",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "U"
                    ],
                    "last": "Grillo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "N"
                    ],
                    "last": "Brosious",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Sorrell",
                    "suffix": ""
                },
                {
                    "first": "Anand",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Int. J. Telerehabilitation",
            "volume": "8",
            "issn": "",
            "pages": "9--14",
            "other_ids": {
                "DOI": [
                    "10.5195/ijt.2016.6202"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Assessing voice health using smartphones: Bias and random error of acoustic voice parameters captured by different smartphone types",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jannetts",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Schaeffler",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Beck",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Cowen",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Int. J. Lang. Commun. Disord",
            "volume": "54",
            "issn": "",
            "pages": "292--305",
            "other_ids": {
                "DOI": [
                    "10.1111/1460-6984.12457"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "An innovative voice analyzer 'VA' smart phone program for quantitative analysis of voice quality",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kojima",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Fujimura",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hori",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Okanoue",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shoji",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Voice",
            "volume": "33",
            "issn": "",
            "pages": "642--648",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jvoice.2018.01.026"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Linguistic fieldwork in a pandemic: Supervised data collection combining smartphone recordings and videoconferencing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Leemann",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Jeszenszky",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Steiner",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Studerus",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Messerli",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Linguist. Vanguard",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1515/lingvan-2020-0061"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Smartphones offer new opportunities in clinical voice research",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Manfredi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lebacq",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cantarella",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schoentgen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Orlandi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bandini",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "H"
                    ],
                    "last": "Dejonckere",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Voice",
            "volume": "31",
            "issn": "",
            "pages": "1--111",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jvoice.2015.12.020"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Mobile Communication Devices, Ambient Noise, and Acoustic Voice Measures",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Maryn",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ysenbaert",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zarowski",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vanspauwen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "31",
            "issn": "",
            "pages": "11--248",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jvoice.2016.07.023"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Awesome Voice Recorder, version 1.1.2 [Android smartphone application",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Newkline",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "R: A language and environment for statistical computing",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "R Core Team",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Don't) try this at home! The effects of recording devices and software on phonetic analysis Lingbuzz Prepr",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sanker",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Babinski",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Burns",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Evans",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Weber",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "The voice source in speech production: Data, analysis and models",
            "authors": [
                {
                    "first": "Y.-L",
                    "middle": [],
                    "last": "Shue",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Exploring the feasibility of smart phone microphone for measurement of acoustic voice parameters and voice pathology screening",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Uloza",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Padervinskis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vegiene",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Pribuisiene",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Saferis",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Vaiciukynas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gelzinis",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Verikas",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Eur. Arch. Oto-Rhino-Laryngology",
            "volume": "272",
            "issn": "",
            "pages": "3391--3399",
            "other_ids": {
                "DOI": [
                    "10.1007/s00405-015-3708-4"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "VLC media player",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Videolan",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Comparability of modern recording devices for speech analysis: Smartphone, landline, laptop, and hard disc recorder",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "P"
                    ],
                    "last": "Vogel",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Rosen",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "T"
                    ],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "Reilly",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Folia Phoniatr. Logop",
            "volume": "66",
            "issn": "",
            "pages": "244--250",
            "other_ids": {
                "DOI": [
                    "10.1159/000368227"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Boxplots of differences in frequency between H6 and Phone and H6 and Zoom for F0 (panel a), F1 (panel b), F2 (panel c) and F3 (panel d) for VoiceSauce-extracted data (left) andPraat-extracted data (right). The middle line represents the median, upper and lower edges of the the first and third quartiles, and the whiskers indicate the range, up to 1.5 times the inter-quartile range away from the median.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "One repetition of vowel [o] from PF3's Zoom recording; spectrogram with intensity curve at top, waveform, below.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "The number of participants was limited due to health safety concerns and COVID-19 restrictions",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Recording equipment and application information for each participant.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": ". The boxplots show differences between devices, calculated by subtracting H6 values from the Phone values and the Zoom values for the same token across the three devices. In other words, each value plotted represents the difference between matching paired tokens from the devices.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Results from the final statistical models for F2 (intercept: H6);",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "While this study serves as a starting point to compare the differences between recording devices and provides researchers with some insight about remote data collection methods, the quality differences between recording methods is a complex, multifaceted issue that requires further investigation. While we tested whether running other applications caused sample dropping in Phone recordings using AVR (it did not), there are further questions that could be addressed regarding specific recording conditions. For instance, whether Zoom audio quality could be improved by closing other applications, clearing device memory, or using a headset microphone. Further tests of what causes the unreliability of Zoom recordings could include investigating the effects of compression, and post-processing of the data files. Future studies are also necessary to look at running speechIn conclusion, our findings indicate that lossless recordings from phones can be a viable method for recording vowel data for acoustic analysis, at least with respect to F0, F1 and F2. On the other hand, caution is needed if conditions limit a researcher's choice to the use of lossy Zoom recordings, as these can lead to erratic outcomes.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Recording equipment and application information for each participant. Recorder b Lenovo Thinkpad T495 Zoom H6 Sennheiser ME64 & K6P Awesome Voice Recorder (Newkline, 2020) b Recorder (DawnDIY, 2016) is an app available on Linux phones; see section II D. for details.TABLE II. Results from the final statistical models for F0 (intercept: H6); formula: F0 ~ device + (1 | speaker) + (1 | vowel). Results from the final statistical models for F1 (intercept: H6); formula: F1 ~ device + (1 | speaker) + (1 | vowel). Results from the final statistical models for F2 (intercept: H6); formula: F2 ~ device + (1 | speaker) + (1 | vowel). Results from the final statistical models for F3 (intercept: H6); formula: F3 ~ device + (1 | speaker) + (1 | vowel).FIG. 1. Boxplots of differences in frequency between H6 and Phone and H6 and Zoom for F0 (panel a), F1 (panel b), F2 (panel c) and F3 (panel d) for VoiceSauce-extracted data (left) and Praat-extracted data (right). The middle line represents the median, upper and lower edges of the box represent the first and third quartiles, and the whiskers indicate the range, up to 1.5 times the inter-quartile range away from the median. FIG. 2. One repetition of vowel [o] from PF3's Zoom recording; spectrogram with intensity curve at top, waveform, below. FIG. 3: Vowel space by device for each speaker, for VoiceSauce-extracted data (top) and Praatextracted data (bottom).",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This research was conducted with support from grant ERC-ADG-835263 titled \"Speech Prosody in Interaction: The form and function of intonation in human communication\" awarded to Amalia Arvaniti.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGEMENTS"
        }
    ]
}