{
    "paper_id": "76c51e9f9ed698e6c76201742f91f6102fc515c4",
    "metadata": {
        "title": "Cross-Site Severity Assessment of COVID-19 From CT Images via Domain Adaptation",
        "authors": [
            {
                "first": "Geng-Xin",
                "middle": [],
                "last": "Xu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Chen",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Jun",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Zhongxiang",
                "middle": [],
                "last": "Ding",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Feng",
                "middle": [],
                "last": "Shi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Man",
                "middle": [],
                "last": "Guo",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Wei",
                "middle": [],
                "last": "Zhao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Xiaoming",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Ying",
                "middle": [],
                "last": "Wei",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Yaozong",
                "middle": [],
                "last": "Gao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Chuan-Xian",
                "middle": [],
                "last": "Ren",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Dinggang",
                "middle": [],
                "last": "Shen",
                "suffix": "",
                "affiliation": {},
                "email": "dinggang.shen@gmail.com."
            }
        ]
    },
    "abstract": [
        {
            "text": "Manuscript treatment planning. To augment the labeled data and improve the generalization ability of the classification model, it is necessary to aggregate data from multiple sites. This task faces several challenges including class imbalance between mild and severe infections, domain distribution discrepancy between sites, and presence of heterogeneous features. In this paper, we propose a novel domain adaptation (DA) method with two components to address these problems. The first component is a stochastic class-balanced boosting sampling strategy that overcomes the imbalanced learning problem and improves the classification performance on poorly-predicted classes. The second component is a representation learning that guarantees three properties: 1) domain-transferability by prototype triplet loss, 2) discriminant by conditional maximum mean discrepancy loss, and 3) completeness by multi-view reconstruction loss. Particularly, we propose a domain translator and align the heterogeneous data to the estimated class prototypes (i.e., class centers) in a hyper-sphere manifold. Experiments on cross-site severity assessment of COVID-19 from CT images show that the proposed method can effectively tackle the imbalanced learning problem and outperform recent DA approaches.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Index Terms-COVID-19 severity assessment, domain adaptation, multi-site data heterogeneity, imbalanced learning, chest computed tomography (CT).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "S INCE the end of 2019, Coronavirus disease 2019 caused by the SARS-CoV-2 virus, has been widely spread around the world. The common manifestations of most infected patients are fever, dry cough, and malaise [1] . Some of these patients progress rapidly with acute respiratory distress syndrome, septic shock, and multiple organ failure, etc., resulting in permanent damage or even death [2] - [4] . Therefore, early and accurate severity assessment of COVID-19 is of crucial importance for the estimation of intensive care unit admission, oxygen therapy, and timely treatment.",
            "cite_spans": [
                {
                    "start": 208,
                    "end": 211,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 388,
                    "end": 391,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 394,
                    "end": 397,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Since most COVID-19 patients have some typical radiographic features in chest computed tomography (CT), e.g., ground-glass opacity and pulmonary consolidation, chest CT plays a key role in the diagnosis and quantification of COVID-19 [5] - [13] . For instance, Song et al. [5] propose a deep learning-based CT diagnosis system, which aims at assisting doctors to detect the patients with COVID-19 and automatically localizing the ground-glass opacity in CT images. In [6] , Yazdani et al. propose a deep learning severe. It can be observed that visual discrepancies (on the appearance and contrast) exist between sites because of the difference in imaging conditions (e.g., imaging protocols and scanner vendors).",
            "cite_spans": [
                {
                    "start": 234,
                    "end": 237,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 240,
                    "end": 244,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 273,
                    "end": 276,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 468,
                    "end": 471,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "framework based on the attentional convolutional network and reach an accuracy of 92% for COVID-19 prediction from chest CT images. Chassagnon et al. [10] design a deep learning-based pipeline for COVID-19 disease quantification. Moreover, Tang et al. [14] extract a series of quantitative features from chest CT images and train a random forest model to assess the severity.",
            "cite_spans": [
                {
                    "start": 150,
                    "end": 154,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 252,
                    "end": 256,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Under the regime of limited CT imaging data with single site (hospital) coverage, the aforementioned models may learn underdetermined parameters and generalize poorly. To alleviate this problem, introducing more data from other sites is an alternative strategy. Such a cross-site data transfer strategy has been verified in other medical image analyses, e.g., prostate segmentation [15] , [16] , pneumonia detection [17] , and COVID-19 CT diagnosis [18] . However, to the best of our knowledge, no previous study has proposed a method for the cross-site severity assessment of COVID-19. There may be several complicated challenges in this task. Firstly, the number of training samples for each class is imbalanced. For example, according to the report from the WHO-China Joint Mission on COVID-19, around 20% developed severe to critical disease (referred to as severe in this work) and the rest remained mild to moderate (referred to as mild in this work) out of 55,924 patients [19] . Secondly, as is shown in Fig. 1 , due to the difference in imaging conditions, the CT images from different cites show discrepancies on appearance and contrast. Directly aggregating the data may contribute little to downstream tasks and lead to negative transfer. Thirdly, most recent works adopt deep learning methods based on original medical images. This manner may have difficulty in exploiting the expert knowledge, which offers a great deal of severityrelated features.",
            "cite_spans": [
                {
                    "start": 382,
                    "end": 386,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 389,
                    "end": 393,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 416,
                    "end": 420,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 449,
                    "end": 453,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 980,
                    "end": 984,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [
                {
                    "start": 1012,
                    "end": 1018,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this paper, we propose a novel perspective with domain adaptation (DA) method for the cross-site severity assessment of COVID-19 from CT images. It aims to transfer discriminant knowledge from a clinical site (source domain) to another site (target domain), where the source domain contains much labeled data whereas the target domain contains a little labeled data. Our method consists of two key components: a stochastic class-balanced boosting sampling (SCBS) phase and a representation learning phase. In SCBS, we stochastically update the training dataset according to sample imbalance rate and classification difficulty (defined as the self-information of prediction in Section II-C) of classes, which aims at fair classification across major versus minor classes, and easy versus hard (i.e., well-predicted versus poorly-predicted by the model) classes. Then, we propose a domain translator to project the source domain data into a latent space while preserving the local structure, which is optimized by a well-designed prototype triplet loss. To strengthen the discriminant and guarantee the completeness of the latent space, we adopt a conditional maximum mean discrepancy (CMMD) loss and a multi-view reconstruction loss on the representation. We refer to our method as Fair cross-domain adaptation with LAtent REpresentations (FLARE).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "We summarize the contributions of this paper as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "\u2022 We propose a DA method, FLARE, for the cross-site diagnosis of COVID-19 severity from CT images. FLARE can deal with the class-imbalance problem in tandem with the domain shift problem between multi-site datasets. \u2022 We propose a domain translator to alleviate the negative transfer problem. In addition, we learn a latent space possessing three properties: domain-transferability, discriminant, and completeness. \u2022 We extend the FLARE method to the multi-source DA scenario. In particular, we design multiple domain translators and weighted classifiers to promote the performance of the DA method. \u2022 To evaluate the effectiveness of FLARE, we collect CT images from multiple clinical sites and assess COVID-19 severity. Extensive experiment results show that FLARE outperforms recent DA and imbalanced learning methods. The rest of this paper is organized as follows. In Section II, related works on COVID-19 diagnosis and quantification, DA method, and imbalanced learning strategy are briefly reviewed. In Section III, the proposed FLARE is presented. Experimental validation against recent methods is conducted in Section IV. Analysis and discussion on our work are described in Section V. Conclusions are given in Section VI.",
            "cite_spans": [
                {
                    "start": 216,
                    "end": 217,
                    "text": "\u2022",
                    "ref_id": null
                },
                {
                    "start": 415,
                    "end": 416,
                    "text": "\u2022",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In the past few months, numerous methods have been proposed for the diagnosis and quantification of COVID-19 [5] - [9] , [11] , [20] . In particular, Ko et al. [7] develop a deep learning framework to diagnose COVID-19 pneumonia, and obtain 99.87% accuracy in detecting COVID-19 from institutional data and 96.97% accuracy in detecting COVID-19 from external validation data. In [8] , Saeedizadeh et al. present a deep learning framework for COVID-19 segmentation from CT images, where a novel connectivity-promoting regularization term is employed to impose desired connectivity requirements. Moreover, Kang et al. [9] extract a series of features from CT images and propose a structured latent multi-view representation learning for COVID-19 diagnosis. Ouyang et al. [11] develop a dual-sampling strategy and online attention module for COVID-19 diagnosis. In addition, Zhu et al. [21] predict the probability and the time of COVID-19 developing severe symptoms using a joint classification and regression method based on chest CT scan data. To effectively combine CT data from different sites, Wang et al. [18] use a contrastive learning method to enhance domain-invariance of representations. Li et al. [20] use a convolutional Siamese neural network-based method to predict the radiographic pulmonary disease severity from chest radiographs. These approaches may learn underdetermined parameters when there is little labeled data in a single site. We address this problem via a cross-site data transfer strategy in this paper.",
            "cite_spans": [
                {
                    "start": 109,
                    "end": 112,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 115,
                    "end": 118,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 121,
                    "end": 125,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 128,
                    "end": 132,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 160,
                    "end": 163,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 379,
                    "end": 382,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 616,
                    "end": 619,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 769,
                    "end": 773,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 883,
                    "end": 887,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1109,
                    "end": 1113,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1207,
                    "end": 1211,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "A. COVID-19 Diagnosis and Quantification"
        },
        {
            "text": "DA methods aim to find a latent space for source and target domains, so that the discrimination information in the source domain can be efficiently transferred to the recognition task in the target domain [22] - [25] . Generally, DA methods can be divided into three categories: unsupervised DA methods, weakly-supervised DA methods, and semi-supervised DA methods. Classical unsupervised DA methods achieve domain alignment by moment matching [26] or adversarial training strategies [27] , [28] . In addition, optimal experimental design [29] and manifold propagation [30] make a prominent breakthrough in adaptive feature learning. Weaklysupervised DA methods aim to tackle the problem where the target domain has some weakly-labeled data. For example, Dong et al. [23] assume that there are some image-level labels but pixel-level ones on the target domain, and propose a quantified transferability mechanism for endoscopic lesions segmentation. Semi-supervised DA methods assume that there is a little labeled data on the target domain. When the domain shift is large, semi-supervised DA methods can obtain better results compared with unsupervised DA methods, due to the use of partial supervision information in the target domain [31] , [32] . For instance, the domain adaptation by covariance matching (DACoM) method [31] matches the distributions by minimizing the covariance in two domains. However, these methods lack consideration of variation in the target domain. Recently, Saito et al. [33] propose a novel minimax entropy (MME) approach, which gradually moves the prototypes closer to unlabeled target data. Tseng et al. [34] design a transformation layer on the top of the feature extractor to simulate various domain feature distributions. Motivated by these works, we propose a domain translator to project the source data around the target prototypes. This manner simulates the target data that are difficult to classify, and enables the model to learn discriminative class boundaries on the target domain.",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 209,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 212,
                    "end": 216,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 444,
                    "end": 448,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 484,
                    "end": 488,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 491,
                    "end": 495,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 539,
                    "end": 543,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 569,
                    "end": 573,
                    "text": "[30]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 767,
                    "end": 771,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1236,
                    "end": 1240,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1243,
                    "end": 1247,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1324,
                    "end": 1328,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1500,
                    "end": 1504,
                    "text": "[33]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1636,
                    "end": 1640,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "B. Domain Adaptation Method"
        },
        {
            "text": "Imbalanced data is fairly common in the real world, especially in the field of medical imaging. There are two widely used strategies to tackle this problem, i.e., sampling strategy and cost-sensitive learning strategy. The sampling strategy tries to construct a balanced sample set or feature space [35] - [39] , and the cost-sensitive learning strategy weights the loss function using the well-designed cost [40] . Most aforementioned approaches aim to learn the classifier jointly with the feature extractor. However, the mechanism of imbalanced learning is unclear. Recently, Zhou et al. [41] discover that the key to achieving a satisfactory long-tailed recognition ability is the classifier learning. Similarly, a new approach named classifier re-training (cRT) [42] first jointly learns the feature extractor and the classifier based on the raw dataset, and then fine-tunes the classifier on a balanced sample set. In addition to the class imbalance, the classification difficulty of the minor class also attracts increasing attention. For instance, Lin et al. [40] modify the cross-entropy loss to a focal loss by down-weighting the loss for well-classified sample, which significantly improves the speed and accuracy of the object detector. Yang et al. [43] use class size and recognition difficulty to define the complexity level of a class, and then propose a corresponding curriculum reconstruction (CR) strategy for clinical skin disease recognition.",
            "cite_spans": [
                {
                    "start": 299,
                    "end": 303,
                    "text": "[35]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 306,
                    "end": 310,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 409,
                    "end": 413,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 591,
                    "end": 595,
                    "text": "[41]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 767,
                    "end": 771,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 1067,
                    "end": 1071,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 1261,
                    "end": 1265,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": "C. Imbalanced Learning Strategy"
        },
        {
            "text": "More recently, some works [12] , [44] - [46] investigate the transfer learning methods and achieve favorable performance for COVID-19 diagnosis. The differences between these studies and our work are three-fold: 1) The task. Most recent methods address the problems in discriminating between COVID-19 and other community-acquired pneumonia or normal. However, we propose a pipeline for the severity assessment of COVID-19, which is by its nature heavily imbalanced; 2) The manner of using transfer learning framework. Some previous works adopt the popular convolutional neural networks pre-trained on a large-scale image dataset (e.g., ImageNet), and fine-tune them for COVID-19 recognition task. In this paper, we focus on learning domain-transferable and discriminative features from one site to another one. This goal helps us to introduce more labeled data from other sites and achieve data-augmentation; 3) The type of used features. Some related works train models based on a single type of feature, whereas we exploit multiple types of heterogeneous features. This helps us to take more effective information into account, especially the features extracted with expert knowledge.",
            "cite_spans": [
                {
                    "start": 26,
                    "end": 30,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 33,
                    "end": 37,
                    "text": "[44]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 40,
                    "end": 44,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "C. Imbalanced Learning Strategy"
        },
        {
            "text": "An overview of the proposed FLARE method is shown in Fig. 2 . It concentrates on imbalanced learning and representation learning simultaneously. With regard to imbalanced learning, an SCBS strategy is designed to generate a balanced data distribution. To reduce the domain distribution discrepancy, we propose a domain translator on the source domain. Subsequently, FLARE learns a latent space possessing three properties: 1) domain-invariance by the prototype triplet loss, 2) discriminant by the CMMD loss, and 3) completeness by the multi-view reconstruction loss. We formulate the framework of FLARE as follows. It includes a domain translator D(\u00b7), a feature extractor F(\u00b7), a classifier L(\u00b7), and V parallel reconstruction networks",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 53,
                    "end": 59,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "III. METHODS"
        },
        {
            "text": ". All these modules adopt fully connected neural networks (FCNs), and share weights between domains, except that the domain translator D(\u00b7) is applied only to the source domain. Thus, F \u2022 D(\u00b7) projects source data onto the latent space, and F(\u00b7) projects target data onto the same space. In this latent space, features from two domains are aligned in a hyper-sphere manifold. Finally, the extracted features will be fed into two pipelines. One is the classifier L(\u00b7) for the classification task. Another pipeline is the parallel networks {R v (\u00b7)} V i=1 for reconstructing multi-view features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. METHODS"
        },
        {
            "text": "We propose an SCBS strategy to overcome the imbalanced learning problem and improve the classification performance on poorly-predicted classes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "Consider a given training dataset with C classes S = \u222a C j =1 S j , where S j denotes the j -th class data subset, |S 1 | \u2265 |S 2 | \u2265 \u00b7 \u00b7 \u00b7 \u2265 |S C |, and \u2229 C j =1 S j = \u2205. In most sampling strategies, the probability of sampling a sample from class j is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "where q \u2208 [0, 1]. When q = 1, samples generated by (1) are subject to the class distribution as the original dataset. When q = 0, (1) is the popular class-balanced sampling strategy, for example, random oversampling (by generating |S 1 | samples from the minor class subset S k (k = 2, . . . , C)).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "We define the classification difficulty for class j , i.e.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "where I [ p(y i |x i )] = \u2212 log [ p(y i |x i )] is the self-information to measure the classification difficulty of an instance x i with label y i . The denominator in (2) is a normalization constant. Let T be the total number of epochs. At the t-th epoch, the probability of sampling a sample from class j in our SCBS is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "where r SC B S 0 ( j ) = r 1 ( j ), \u03b5 t is a random sample from a uniform distribution, and w t is a trade-off parameter that controls the relative importance of poorly-predicted classes mining. Threshold \u03b4 \u2208 (0, 1] reflects the frequency of updating class distribution in SCBS, and it is set to be 0.3 in the experiments. At the beginning of the training process, the predictions of some samples are unreliable, and the classification difficulty defined by (2) cannot detect the poorly-predicted classes well. Hence, we let w t be a relatively small value and focus on addressing the imbalanced learning problem when t is small. Along with the optimization process (the decrease of the objective function), the predictions of most training samples become reliable. Then, we use a larger value for w t and focus on addressing the poorly-predicted classes mining problem. With the above analysis, w t can be calculated as a cosine-based function w t = [1 \u2212 cos(t\u03c0/T )] /2. In our experiments, we randomly generate a sample \u03b5 t from a uniform distribution at the end of each epoch. If \u03b5 t is larger than \u03b4, r SC B S t ( j ) remains unchanged; otherwise, we compute the expectation in (2) by averaging over all training samples with class j , and then update r SC B S t ( j ) by (3). Our SCBS has two advantages as follows. Firstly, since the minor class has few samples, a single oversampling operation may possess a single data distribution, and thus the model will over-fit the corresponding distribution. Instead, SCBS stochastically implements the sampling strategy during the training phase. This manner simulates the data variation and prevents model over-fitting. Secondly, at the beginning of the training phase, SCBS focuses on the imbalanced learning problem. Along with the increase of w t , it pays more attention to the poorly-predicted classes mining problem and further boosts the recognition performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Stochastic Class-Balanced Boosting Sampling (SCBS) Strategy"
        },
        {
            "text": "The COVID-19 CT images present two characteristics as follows. On one hand, within a single site, the samples are usually with large variations. For example, lung deterioration varies considerably between patients because of coexisting diseases. Thus, when single-site data is insufficient, it is difficult for a model only optimized on few label samples to achieve excellent generalization ability. On the other hand, the domain shift is large as shown in Fig. 1 . Directly introducing medical images from other sites may lead to negative transfer. Hence, learning domain-adaptive features is important for the task of cross-site COVID-19 severity assessment.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 457,
                    "end": 463,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "For a semi-supervised DA task, we have a source",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "Our goal is to train a model on D s , D t , and D u , and then evaluate on D u . Particularly, attributed to the transferred discrimination knowledge from D s , the learned model is expected to outperform the target-only model which is trained only on D t .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "To transfer discriminant information from the source domain to the target domain, we design a prototype triplet loss as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "where the prototype",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "is the class center, x s j, p is a source sample with class j , x s j,n is a source sample with class different from j , d (\u00b7, \u00b7) is the cosine similarity measure, and \u03b1 \u2208 [0, 2]. To construct a separable space, we normalize all features into a hyper-sphere manifold. In this hyper-sphere, we estimate the prototype p j for each class on the target domain and update p j by averaging the normalized features of all target labeled samples with class j at the end of each training epoch. Then, we project the source samples near their corresponding prototypes in the latent space, which preserves the discriminative local structure of the source domain. Moreover, in (4), we mainly focus on the data that is difficult to classify, i.e., the hard positive and negative examples. Specifically, for a target prototype p j , we push the closest negative example x s j,n farther to it and pull the farthest positive example x s j, p closer to it. In this process, the local structure (or the relationship of data) in the source domain is preserved, i.e., the intra-class similarity of latent features is larger than the inter-class one. Thus, minimizing (4) helps to transfer discriminant knowledge between domains.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "Different from those DA methods via moment matching or adversarial training manner, the proposed prototype triplet loss guarantees domain alignment as well as data-augmentation. As the hyper-sphere in Fig. 2 shows, the source samples are projected around the estimated target prototypes. This manner of data transformation can simulate various data distributions in the target domain, especially those samples that are far away from the prototypes with the same class, but close to the prototypes with different classes. Thus, FLARE has stronger generalization ability and superior performance for successfully classifying the unlabeled target data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 201,
                    "end": 207,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "With regard to the triplet loss in (4), there are many other ranking loss functions for the task of metric learning. One of the typical works is the contrastive loss [47] , which aims to maximize all positive similarities (between intra-class samples) and minimize all negative ones (between inter-class samples). Compared with the contrastive loss, the advantages of the prototype triplet loss are two-fold. 1) The contrastive loss maximizes all positive similarities and minimizes all negative similarities separately, whereas the prototype triplet loss maximizes the difference between positive similarity and negative similarity with margin \u03b1. Since the relationship of two similarities is taken into account, the feature learned via the prototype triplet loss has better class-separating ability, as shown in Section IV-F. 2) The contrastive loss encourages all intra-class distances to approach 0. However, the prototype triplet loss merely tries to keep all intra-class distances smaller than any inter-class one above a certain threshold. This is a less restrictive objective and can lead to better performance on the target data, as shown in Section IV-D.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 170,
                    "text": "[47]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "B. Domain Adaptation via the Prototype Triplet Loss"
        },
        {
            "text": "Due to the difference in imaging conditions and patient demographics, the COVID-19 CT images show large appearance discrepancies. These discrepancies (in the original input space) will hold up the training process and affect the prediction results. Thus, learning discriminative and compact features is important for the severity classification task.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "Kernel-based pattern analysis has been validated in improving classification performance [48] . To make use of the kernel method for classification, one can directly map the input data onto a reproducing kernel Hilbert space (RKHS) and establish a classifier followed by a cross-entropy (CE) loss. However, this manner relies on the selection of a suitable kernel function, which is expected to effectively capture the difference between intra-class similarity and inter-class one. To address this problem, Ren et al. [48] propose a new kernel learning method for CMMD-based image classification. Motivated by its effectiveness in learning a representative kernel function through placing the CMMD loss in the representation learning phase, we design a CMMD loss in FLARE as follows.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 93,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 518,
                    "end": 522,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "Suppose F and G are the RKHS corresponding to an input X and its true label Y , respectively. CMMD intuitively characterizes the discrepancy between two conditional distributions P(Y |X) and P(\u0176 |X), where\u0176 represents the predicted label. 1 Given two batches of samples D a",
            "cite_spans": [
                {
                    "start": 239,
                    "end": 240,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "and P(\u0176 |X), respectively. The empirical estimation of CMMD is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "where denotes the tensor product operating, [49] . Other variables with subscript b are similarly defined on D b X\u0176 . By minimizing (5), the difference between P(Y |X) and P(\u0176 |X) is reduced and then a predictive model is obtained.",
            "cite_spans": [
                {
                    "start": 44,
                    "end": 48,
                    "text": "[49]",
                    "ref_id": "BIBREF49"
                }
            ],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "The CMMD loss in FLARE consists of two terms on source and target domains respectively. As for the first term, we randomly sample two batches,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": ". . , y s,a n s ]. Variables X b s and\u0176 b s are defined in a similar way on the dataset D b s . As [48] , we apply the kernel functions on the latent features (Z a s and Z b s ) but the raw data (X a s and X b s ). The CMMD loss on the source domain is",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 103,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "As for the second term, we first construct a complete target domain, i.e., D tu = D t \u222a D u . Then, we randomly sample two batches,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": ", from D t and D tu , respectively. Correspondingly, we can define X a t , Y a t , X b tu , and\u0176 b tu in a similar way as X a s , Y a s , X b s , and\u0176 b s . The CMMD loss on the target domain is formulated as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": ". Equation (7) presents a semi-supervised training manner on the target domain. Specifically, it simultaneously uses labeled and unlabeled data. As there may not be sufficient labeled data in each hospital in practice, making full use of the unlabeled data helps to learn more discriminative kernel functions, which is further verified by the experiment in Section IV-E.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "The differences between our FLARE and some related works are as follows. 1) In [48] , the CMMD loss is used on traditional classification tasks where training and testing data is subject to the same distribution, whereas we design a CMDD loss on the DA task. In addition, compared with [48] , we consider both supervised and semi-supervised learning scenarios in a framework. 2) Compared with some popular 1 Note that the core task in a classification problem is to train a predictive model so that P(Y |X) = P(\u0176 |X) holds or approximately holds. Thus, CMMD is capable of solving the classification task. training manners (e.g., using a CE loss), FLARE places a CMMD loss on the latent space to learn more discriminative features. Specifically, in (6) and (7), we adopt F(\u00b7) as the way of improved kernel learning on the source and target domains. This enables the learned kernel values to have better separating ability. Hence, the latent space in FLARE possesses well discriminant for the COVID-19 severity assessment.",
            "cite_spans": [
                {
                    "start": 79,
                    "end": 83,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 286,
                    "end": 290,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "C. Discriminant Learning via the CMMD Loss"
        },
        {
            "text": "In this work, we extract multi-view features from each CT image and expect that they provide complementary information for the severity assessment of COVID-19. To flexibly integrate them into a latent space and effectively exploit the heterogeneous information, we propose a multi-view representation learning framework here.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "As for the input data in our method, each instance is a multi-view sample, i.e.,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "where V is the number of feature types (V = 7 in our experiments). From the reconstruction perspective, a multi-view representation z i is complete if any view x (v) i in an observation x i can be well reconstructed by a mapping R v (\u00b7), i.e., x [50] .",
            "cite_spans": [
                {
                    "start": 246,
                    "end": 250,
                    "text": "[50]",
                    "ref_id": "BIBREF50"
                }
            ],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "To guarantee the completeness of information, we adopt a multi-view reconstruction loss as follows. It consists of two terms. The first one is placed on the source domain as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "where \u00b7 F is the Frobenius norm,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "is v-th type of feature in X s , and the multi-view reconstruction networks {R v (\u00b7)} V i=1 are utilized in parallel as shown in Fig. 2 . The second term is a reconstruction loss on the target domain as",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 129,
                    "end": 135,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "t and X (v) u are the v-th type of features in X t and X u , respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "The advantages of multi-view learning are two-fold. Firstly, such a reconstruction ensures that the feature extractor F(\u00b7) is injective or approximately injective as the autoencoder module designed in [48] . Secondly, it ensures completeness of the latent space, resulting in full use of the extracted heterogeneous features.",
            "cite_spans": [
                {
                    "start": 201,
                    "end": 205,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "D. Multi-View Representation Learning via the Reconstruction Loss"
        },
        {
            "text": "The final loss in the FLARE method is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "E. Total Objective Function"
        },
        {
            "text": "where \u03bb 1 , \u03bb 2 , and \u03bb 3 are the trade-off parameters. FLARE learns a desirable space with domain-transferability, discriminant, and completeness in an end-to-end manner. The backpropagation algorithm is used to optimize the loss function (10) , which can be implemented effectively by Tensor-Flow or PyTorch, etc. Therefore, we omit the derivation details here.",
            "cite_spans": [
                {
                    "start": 240,
                    "end": 244,
                    "text": "(10)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "E. Total Objective Function"
        },
        {
            "text": "In practical scenarios, it is likely that we have labeled data from multiple sites. Owing to the complementary knowledge among these sites, transferring discriminant information from multiple source domains to a target domain is expected to improve the performance of single-source models. However, the multiple source domains contain possible domain shifts with each other. Directly applying single-source DA methods on the combination of all source domain data may lead to negative transfer. To tackle this challenge, we extend the FLARE method to the multi-source adaptation scenario and denote it as M-FLARE for abbreviation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Extension to Multi-Source Domain Adaptation"
        },
        {
            "text": "Suppose {D s,e } E e=1 are multiple distinct source domains, where E is the number of source domains. Domain shifts may exist not only between D s,e and D t , but also between the source domains. Hence, we assign each source domain D s,e a different domain translator D e (\u00b7) and a classifier L e (\u00b7), whereas the feature extractor F(\u00b7) is shared across all domains to learn domain-invariant features as [51] - [53] . For the target domain, data X u is forwarded into F(\u00b7) to extract feature Z u , which is then fed into the multiple classifiers {L e (\u00b7)}. Finally, we combine the E predictions by a weighted rule:",
            "cite_spans": [
                {
                    "start": 404,
                    "end": 408,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "F. Extension to Multi-Source Domain Adaptation"
        },
        {
            "text": "where w e is the weight of the e-th source domain and is defined hereinafter. On the basis of the above framework, the overall objective function of M-FLARE is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "F. Extension to Multi-Source Domain Adaptation"
        },
        {
            "text": "where \u03bb 1 , \u03bb 2 , and \u03bb 3 are the trade-off parameters; L t c and L t r are calculated by (7) and (9) (11) and (12) . In our experiments, we initialize w e using 1/E and update it at the (t + 1)-th epoch based on the values of L s,e c at the t-th epoch.",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 115,
                    "text": "(12)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "F. Extension to Multi-Source Domain Adaptation"
        },
        {
            "text": "We perform extensive experiments on both private and public datasets. In terms of private datasets, 5,358 CT images are collected from three clinical sites, i.e., the Second Xiangya Hospital of Central South University, Hangzhou First People's Hospital of Zhejiang University, and Southwest Hospital of Third Military Medical University (Army Medical University). We denote these sites as Site-1, Site-2, and Site-3, respectively. As [14] , the clinical status of patients is divided into two groups: mild group (mild or common case) and severe group (severe, critical, or dead case). In addition, we evaluate our method on a publicly available dataset MosMedData [54] , which is collected by Moscow City Health Care and denoted as Site-4. The original MosMedData contains 1,110 CT scans with five categories. To perform the same classification task, we divide 856 symptomatic cases into two groups according to the lung lesion grading and routing rules in [54] : mild group (mild or moderate case) and severe group (severe or critical case). Following the previous protocols [9] , [55] , we extract 237-dimensional multi-view heterogeneous features from each CT image which contains seven groups: gray features, texture features, histogram features, number features, intensity features, surface features, and volume features. A standardization preprocessing is adopted before using these multi-view features.",
            "cite_spans": [
                {
                    "start": 434,
                    "end": 438,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 664,
                    "end": 668,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 957,
                    "end": 961,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 1076,
                    "end": 1079,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1082,
                    "end": 1086,
                    "text": "[55]",
                    "ref_id": "BIBREF55"
                }
            ],
            "ref_spans": [],
            "section": "A. Datasets"
        },
        {
            "text": "Since the clinical status groups (mild and severe groups) are usually imbalanced, directly evaluating a model on the data may lead to the failure of metrics, e.g., a misleading high accuracy score. Here, we conduct experiments under both balanced and imbalanced settings. As regards the balanced setting, we first randomly divide the severe group into 30% and 70% for the training and testing set. Then, we randomly select the same number of mild group samples for forming a balanced testing set. The rest of the mild group samples are used as training data. As regards the imbalanced setting, we randomly divide all data into 30% and 70% for the training and testing set. We summarize the datasets in Table I .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 702,
                    "end": 709,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "A. Datasets"
        },
        {
            "text": "We evaluate FLARE on three transfer tasks between the private datasets: (S1,S2)\u2192S1, (S2,S1)\u2192S2, and (S3,S1)\u2192S3. Let us take the task (S1,S2)\u2192S1 as an example. The three domains are: a labeled target domain containing the training set of Site-1, a source domain comprised of all labeled data in Site-2, and an unlabeled target domain consisting of the testing set of Site-1. In addition, we implement transfer task from private dataset to public dataset: (S4,S1)\u2192S4. Note that a different dataset partition setting may result in different classification performance. We adopt random partition ten times and report the average evaluation metrics and the corresponding standard errors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Datasets"
        },
        {
            "text": "B. Experimental Setup 1) Implementation Details: With regard to the domain translator, feature extractor, classifier, and reconstruction networks, we use FCNs with 2, 1, 1, and 1 hidden layers, respectively. [56] optimizer with learning rate lr = 2e-4, \u03b2 1 = 0.5, \u03b2 2 = 0.999, and batch size of 100 is applied over 300 epochs. Since the data flow is different between source and target domains (the domain translator is employed only for the former), the optimization process is implemented alternately on the two domains. Specifically, in each epoch, we randomly divide both source and target data into several batches. Based on each mini-batch, we optimize the objective function on the target domain and source domain in turn. Moreover, we fix \u03bb 1 = 1 and tune the other three hyper-parameters using grid search: \u03bb 2 \u2208 {1e1, 5e1, 1e2, 5e2, 1e3}, \u03bb 3 \u2208 {2e-4, 1e-3, 2e-3, 5e-3, 2e-2}, \u03b1 \u2208 {0, 0.4, 0.8, 1.2, 1.6}. We select the hyper-parameters based on 5-fold cross-validation on the target labeled data.",
            "cite_spans": [
                {
                    "start": 208,
                    "end": 212,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "A. Datasets"
        },
        {
            "text": "The severe infection case is denoted as the positive class. The default value of the operating point is set as 0.5. For evaluating the severity assessment performance of COVID-19, four standard metrics including SEN (sensitivity), SPE (specificity), F1 (harmonic mean of sensitivity and precision), and G-mean (geometric mean of sensitivity and specificity) are used.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2) Evaluation Metrics:"
        },
        {
            "text": "We present extensive comparisons between FLARE and several other methods under both balanced and imbalanced settings. These methods are divided into three groups. The first group consists of five target-only supervised learning methods, i.e., logistic regression (LR), support vector machine (SVM), Gaussian-naive-Bayes (GNB), k-nearest-neighbors (KNN), and FCN. To relieve the class-imbalance problem, we adopt random oversampling (RanOver for short) and SCBS strategies for them. The second group has an approach directly trained on source data (Source-only for short) and some recent unsupervised DA methods: deep adaptation network (DAN) [26] , domain-adversarial neural network (DANN) [27] , and conditional domain adversarial network (CDAN) [28] . The last group includes an algorithm trained jointly using source and labeled target data (JointDomain for short), and some semi-supervised DA methods, i.e., DACoM [31] , cross-domain few-shot baseline (CDFSB) method [32] , CDFSB++ [32] , MME [33] , learned feature-wise transformation (LFT) based classification algorithm [34] , and contrastive cross-site learning (CCSL) method [18] . For fair comparisons, we adopt the same imbalanced learning strategy and network architecture, and place a multi-view reconstruction loss in the representation learning phase for FCN and all DA methods, since the features used in these experiments include heterogeneous types.",
            "cite_spans": [
                {
                    "start": 642,
                    "end": 646,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 690,
                    "end": 694,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 747,
                    "end": 751,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 918,
                    "end": 922,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 971,
                    "end": 975,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 986,
                    "end": 990,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 997,
                    "end": 1001,
                    "text": "[33]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1077,
                    "end": 1081,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 1134,
                    "end": 1138,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "C. Comparison With the State-of-the-Art Methods"
        },
        {
            "text": "1) Transfer Tasks Between the Private Datasets: Table II reports the results on transfer tasks between the private datasets. FLARE yields compelling results on all three DA tasks. On the task (S1,S2)\u2192S1 with balanced setting, DAN [26] and LR obtain better sensitivity and specificity measures, respectively, whereas FLARE outperforms all approaches when assessed by the overall performance metrics, F1 and G-mean. On the task (S1,S2)\u2192S1 with imbalanced setting, LR obtains a better specificity measure, whereas FLARE is best for all the other metrics. Interestingly, the FCN equipping our SCBS strategy outperforms all other target-only learning methods and even the unsupervised DA methods. This demonstrates that the cross-site discrepancy is indeed large, and the supervision information in the target domain is important for classification. FLARE takes the supervision information in both domains into full consideration and achieves excellent results.",
            "cite_spans": [
                {
                    "start": 230,
                    "end": 234,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 48,
                    "end": 56,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "C. Comparison With the State-of-the-Art Methods"
        },
        {
            "text": "On the task (S2,S1)\u2192S2, KNN exhibits better performance by the specificity measure under both balanced and imbalanced settings, but our FLARE is the best for all others performance metrics. Although all semi-supervised DA methods use the supervision information in source and target domains, FLARE outperforms the others in terms of all metrics (except 1.4% below the specificity of CCSL [18] under balanced setting). This effectiveness can be attributed to the prototype triplet loss, where the estimated prototypes are robust to the class-imbalance scenario and the source data is encouraged to be around these prototypes for transferring the discriminant information.",
            "cite_spans": [
                {
                    "start": 388,
                    "end": 392,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "C. Comparison With the State-of-the-Art Methods"
        },
        {
            "text": "Similarly, FLARE outperforms others for sensitivity, F1, and G-mean measures on the task (S3,S1)\u2192S3. Although GNB and GNB+RanOver obtain better results in terms of specificity, they exhibit extremely poor performance by the other measures because of the impact of class-imbalance problem. Compared with the results in the first two DA tasks (i.e., Site-1 or Site-2 as the target domain), all methods achieve slightly poorer performance in the last task (i.e., Site-3 as the target domain). We attribute this to the difficulty of the task itself. Particularly, over 30% of severe patients on the Site-3 encounter critical severe diseases or even deaths, whose lung deteriorations vary owing to the presence of coexisting conditions [3] , [57] . This causes large within-class heterogeneity, as also visualized in Section IV-F.",
            "cite_spans": [
                {
                    "start": 731,
                    "end": 734,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 737,
                    "end": 741,
                    "text": "[57]",
                    "ref_id": "BIBREF57"
                }
            ],
            "ref_spans": [],
            "section": "C. Comparison With the State-of-the-Art Methods"
        },
        {
            "text": "Table III reports the results on transfer task (S4,S1)\u2192S4. Again, to demonstrate the effect of knowledge transfer, ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2) Transfer Task From Private Dataset to Public Dataset:"
        },
        {
            "text": "In this section, we evaluate the effectiveness of each component in the FLARE method. Specifically, we implement our FLARE method on task (S1,S2)\u2192S1 under balanced setting by removing each proposed piece and replacing it with related components. In addition, we show the impact of varying each hyper-parameter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Ablation Study"
        },
        {
            "text": "1) Effectiveness of the SCBS Strategy: To validate the effectiveness of the SCBS strategy, we remove it from the training regime, and optimize the model based on the raw class-imbalanced data or other imbalanced learning strategies, e.g., random oversampling, synthetic minority oversampling technique (SMOTE) [36] , adaptive synthetic sampling approach (ADASYN) [38] , integrations of SMOTE with edited nearest neighbor (SMOTE+ENN) [39] , SMOTE with Tomek links (SMOTE+Tomek) [39] , cRT [42] , focal loss [40] , and CR [43] . The classification results in Table IV show that all strategies boost the performance of the baseline. It can be observed that the simple random oversampling strategy improves the FLARE method by a large margin in F1 and G-mean (compared with baseline strategy). However, the improvement by the recently proposed focal loss [40] is smaller than the sampling strategies. We think the reason is that there is large intra-class heterogeneity among the CT images. Thus, it is difficult for an imbalanced learning strategy which only focuses on poorly-predicted class mining to achieve comparable performance. In the SCBS strategy, we first construct a class-balanced dataset and learn discriminant knowledge progressively from easy to hard classes. Hence the SCBS obtains an overall improvement.",
            "cite_spans": [
                {
                    "start": 310,
                    "end": 314,
                    "text": "[36]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 363,
                    "end": 367,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 433,
                    "end": 437,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 477,
                    "end": 481,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 488,
                    "end": 492,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 506,
                    "end": 510,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 520,
                    "end": 524,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 851,
                    "end": 855,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [
                {
                    "start": 557,
                    "end": 565,
                    "text": "Table IV",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "D. Ablation Study"
        },
        {
            "text": "To check whether the SCBS strategy has statistically significant performance improvement compared with the referred strategies, we conduct paired Student's t-test with a 0.05 significance level between these results. In each pair, we adopt the same dataset partition setting for two strategies to eliminate the possible impacts. According to Table IV, most p-values are smaller than 0.05, demonstrating that SCBS has statistically significant performance improvement compared with most referred strategies. In addition, we report the confusion matrices for some strategies in Fig. 3 . We observe that the Fig. 3 . Confusion matrices of using various imbalanced learning strategies (None, random oversampling, cRT [42] , Focal loss [40] , CR [43] , and SCBS) for the FLARE method. classification accuracy of the severe infection case improves by a large margin when using our SCBS strategy.",
            "cite_spans": [
                {
                    "start": 713,
                    "end": 717,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 731,
                    "end": 735,
                    "text": "[40]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 741,
                    "end": 745,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [
                {
                    "start": 576,
                    "end": 582,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 605,
                    "end": 611,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "D. Ablation Study"
        },
        {
            "text": "Triplet Loss: We abbreviate the model without the domain translator, the prototype triplet loss, and their combination to FLARE (noD), FLARE (noP), and FLARE (noDP), respectively. We also replace the prototype triplet loss with the contrastive loss. The corresponding results are shown in Table V . Comparing with these special cases, the improvement of FLARE (with selected hyper-parameter combination \u03bb 2 = 100, \u03b1 = 0) verifies the contributions of the domain translator and the prototype triplet loss in our method. In addition, we vary the value of the weight \u03bb 2 and the margin \u03b1. It can be observed that the performance of FLARE slightly fluctuates around the selected hyper-parameter combination.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 289,
                    "end": 296,
                    "text": "Table V",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "2) Effectiveness of the Domain Translator and the Prototype"
        },
        {
            "text": "3) Effectiveness of the CMMD Loss: To explore the contribution of the CMMD loss in discriminant learning, we replace it with a standard cross-entropy loss. Comparing the results of FLARE (noC)+CE loss and FLARE (with default hyperparameter \u03bb 1 = 1) in Table VI , we observe that equipping the CMMD loss increases the overall performance by a large margin. This suggests that the CMMD loss successfully improves the discrimination power of the latent space. In addition, 4 . Stability of FLARE versus other methods on the task (S1,S2)\u2192S1 with different ratios of (a) target labeled data, (b) target unlabeled data, and (c) target data in the training phase.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 252,
                    "end": 260,
                    "text": "Table VI",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 470,
                    "end": 471,
                    "text": "4",
                    "ref_id": null
                }
            ],
            "section": "2) Effectiveness of the Domain Translator and the Prototype"
        },
        {
            "text": "the experimental results of varying the weight of the CMMD loss \u03bb 1 show that FLARE obtains slightly poorer performance around the selected hyper-parameter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2) Effectiveness of the Domain Translator and the Prototype"
        },
        {
            "text": "We investigate the importance of the multi-view reconstruction loss. The model without the reconstruction loss is abbreviated as FLARE (noR). We also replace the multi-view decoder with a naive decoder (i.e., a fully connected layer from the latent feature to the input layer). As can be observed from Table VII , FLARE (with selected hyper-parameter \u03bb 3 = 0.002) consistently outperforms FLARE (noR) and its variant with a naive decoder in terms of all metrics. This demonstrates that the completeness enables the latent space to make full use of multi-view features, and thus improves the classification effect. Similarly, we vary the value of the weight \u03bb 3 and observe that the performance of FLARE fluctuates around the selected hyper-parameter.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 302,
                    "end": 311,
                    "text": "Table VII",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "4) Effectiveness of the Multi-View Reconstruction Loss:"
        },
        {
            "text": "To verify the robustness of our FLARE to reduced training data in the target domain, we train all the semi-supervised DA methods with three scenarios: 1) partial target labeled data, 2) partial target unlabeled data, and 3) partial target data. The plots of G-mean scores on task (S1,S2)\u2192S1 under balanced setting are shown in Fig. 4 . As illustrated in Fig. 4(a) and Fig. 4(c) , along with a decrease in the ratio of the target (labeled) data, FLARE exhibits a graceful degradation and consistently outperforms other methods by a significant margin. Furthermore, when 60% of the target (labeled) data is used, FLARE achieves comparable performance, which is even better than other methods with the entire target (labeled) dataset. We attribute this robustness to the prototype triplet loss specially designed for domain alignment. Specifically, when supervision information in the target domain is reduced, FLARE can still estimate the prototypes for all classes and project the data from the source domain around them for transferring discrimination knowledge. In addition, as shown in Fig. 4(b) , our FLARE method is insensitive to the ratio of target unlabeled data. However, this does not mean that we can ignore the contribution of the unlabeled data. In particular, when 20% of target unlabeled data is used, FLARE obtains a G-mean below 80% (the far left of Fig. 4(c) ); after introducing more target unlabeled data (i.e., all target unlabeled data is used), FLARE boosts the G-mean to 82% (the far left of Fig. 4(a) ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 327,
                    "end": 333,
                    "text": "Fig. 4",
                    "ref_id": null
                },
                {
                    "start": 354,
                    "end": 363,
                    "text": "Fig. 4(a)",
                    "ref_id": null
                },
                {
                    "start": 368,
                    "end": 377,
                    "text": "Fig. 4(c)",
                    "ref_id": null
                },
                {
                    "start": 1088,
                    "end": 1097,
                    "text": "Fig. 4(b)",
                    "ref_id": null
                },
                {
                    "start": 1366,
                    "end": 1375,
                    "text": "Fig. 4(c)",
                    "ref_id": null
                },
                {
                    "start": 1515,
                    "end": 1524,
                    "text": "Fig. 4(a)",
                    "ref_id": null
                }
            ],
            "section": "E. Performance Under Various Training Regimes"
        },
        {
            "text": "We visualize the feature representations by t-SNE [58] in Fig. 5 . for tasks (S1,S2)\u2192S1, (S2,S1)\u2192S2, and (S3,S1)\u2192S3 under balanced setting. Two domains are aligned with CCSL [18] , but the classes are not well-discriminated. As for LFT [34] and FLARE, they both adopt a domain transformation. LFT [34] inserts the feature-wise transformation layers into the feature extractor to obtain various feature distributions. This operation improves the prediction ability of the model on target unlabeled samples to a certain extent, but lacks consideration of category information, as is shown in Fig. 5 . Different from LFT [34] , FLARE uses a domain translator before the shared feature extractor, and then aligns two domains on the latent space via a prototype triplet loss. Fig. 5 . illustrates that FLARE successfully projects the source data around the target data with the same category, and transfers the discrimination information simultaneously. Therefore, FLARE obtains larger class separability than LFT.",
            "cite_spans": [
                {
                    "start": 50,
                    "end": 54,
                    "text": "[58]",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 174,
                    "end": 178,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 236,
                    "end": 240,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 297,
                    "end": 301,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 618,
                    "end": 622,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [
                {
                    "start": 58,
                    "end": 64,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 590,
                    "end": 596,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 771,
                    "end": 777,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "F. Feature Visualization"
        },
        {
            "text": "To further investigate the discriminant of features, we compare the similarities of features with the same class and different classes in Fig. 6 . In the top line of Fig. 6 , we display the histograms of kernel values for the raw input features. Results on three DA tasks show that the similarities between all samples are relatively low, and two distributions (orange and blue) have no significant difference. Thus, a general kernel function on the raw samples cannot effectively reflect similarity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 138,
                    "end": 144,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 166,
                    "end": 172,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "F. Feature Visualization"
        },
        {
            "text": "In the bottom line of Fig. 6 , we plot the histograms of kernel values for the representations learned by FLARE. On the DA task (S1,S2)\u2192S1, the similarities of samples with different classes mainly concentrate below 0.4, whereas those with the same class concentrate between 0.4 and 0.8. In addition, on the task (S2,S1)\u2192S2, the kernel values of samples with different classes mainly concentrate below 0.6, whereas those with the same class are concentrated in the range of 0.5 to 0.9. On these two DA tasks, a clear distinction between two distributions means that the representations learned by FLARE have better discriminant. On the last DA task, (S3,S1)\u2192S3, the distinction between the two distributions is small. We infer the reason is that there is large within-class heterogeneity in the CT images. In particular, we find that many samples on Site-3 are critical severe or even dead cases. The presence of coexisting illnesses is common among these patients (also observed in [57] ), which results in small within-class similarities. Table VIII shows the comparisons of M-FLARE with some recent methods on the multi-source DA task (S1,S2,S3)\u2192S1. Following [51] - [53] , we introduce two standards: 1) singlebest domain adaptation, which reports the single-source adaptation result best-performing in the test set, and 2) source combine domain adaptation, which reports the single-source adaptation result by transferring the combination of multiple source domains to a target domain. The first standard ",
            "cite_spans": [
                {
                    "start": 983,
                    "end": 987,
                    "text": "[57]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 1163,
                    "end": 1167,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 1170,
                    "end": 1174,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [
                {
                    "start": 22,
                    "end": 28,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1041,
                    "end": 1051,
                    "text": "Table VIII",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "F. Feature Visualization"
        },
        {
            "text": "To quantitatively investigate the importance and the complementarity of different types of features for assessing COVID-19 severity, we conduct experiments on each type of feature and concatenated features with our FLARE method. Fig. 7 presents the corresponding results on task (S1,S2)\u2192S1 under balanced setting. We can observe that the severity assessment performance varies considerably between different types of features. For instance, number features (NF) and intensity features (IF) have poor discrimination ability. One reason may be that the number of lesions and the intensity in lung are not quite different between patients with various degrees of COVID-19 infections. In addition, among the seven types of features, volume features (VF) have significant discrimination ability. This conforms to the clinical diagnosis. For example, pulmonary parenchyma lesion volume in chest CT plays a key role in COVID-19 disease grading and decision of treatment planning [54] . Although different types of features have different discrimination power, there is complementarity among them. As shown in Fig. 7 , FLARE based on concatenated features (i.e., G-1, G-2, and All) obtains larger G-mean than those on a single type of feature, which sufficiently supports the need for jointly using multiple types of features. Fig. 7 . Performance of FLARE method using different types of features. GF, TF, HF, NF, IF, SF, and VF denote gray features, texture features, histogram features, number features, intensity features, surface features, and volume features, respectively. These features are further divided into two groups: G-1 (including GF and TF) and G-2 (including the rest). \"All\" represents all types of features.",
            "cite_spans": [
                {
                    "start": 972,
                    "end": 976,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [
                {
                    "start": 229,
                    "end": 235,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 1102,
                    "end": 1108,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 1319,
                    "end": 1325,
                    "text": "Fig. 7",
                    "ref_id": null
                }
            ],
            "section": "H. Discrimination Power and Complementarity of Different Types of Features"
        },
        {
            "text": "In this section, we discuss about the robustness and the time complexity of our FALRE method, and some future works.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "A. Robustness 1) Robustness to the Sample Size: The proposed FLARE method is effective for transferring discriminant information from a clinical site (source domain) to another site (target domain). This is verified in extensive experiments on transfer tasks between different datasets. Let us take the DA task (S1,S2)\u2192S1 with imbalanced setting as an example. The source domain (Site-2) and the target domain (Site-1) contain respectively 1,245 and 818 samples. From the results in Table II , we observe that the best target-only supervised learning method obtains 79.6% in terms of G-mean, whereas the best semi-supervised DA method boosts the performance to 86.3%. We contribute this to the transfer learning in the semi-supervised DA method. Note that different sites have different amounts of labeled samples, and thus the DA tasks between these sites (e.g., (S1,S2)\u2192S1 and (S2,S1)\u2192S2) have different ratios of source to target sample sizes. For full comparisons, we report the results on all DA tasks between private datasets in Table II (Section IV-C) and Table II (supplementary materials). In addition, to further investigate the effects of sample sizes, we implement experiments on two additional scenarios: 1) multi-source domain adaptation where there are multiple source domains (Section IV-G), and 2) various training regimes where partial target labeled data is used (Section IV-E). The corresponding experimental results confirm that our FLARE is robust to the sample size. In addition, introducing more discriminant knowledge and adopting appropriate DA methods are beneficial for the improvement of classification performance on the target domain.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 483,
                    "end": 491,
                    "text": "Table II",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1035,
                    "end": 1071,
                    "text": "Table II (Section IV-C) and Table II",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "V. DISCUSSION"
        },
        {
            "text": "2) Robustness to the Image Quality and Resolution: In this study, the CT images are collected from several CT scanners, including uCT 780 from UIH, Optima CT520, Discovery CT750, LightSpeed 16 from GE, Aquilion ONE from Toshiba, SOMATOMForce from Siemens, and SCENARIA from Hitachi. Hence the image qualities of these CT samples are varied. In clinical practice, due to the consideration of radiation doses and the difference in the capacity of CT scanners, CT slice thickness is various within and between hospitals. For instance, in the collected private datasets, reconstructed CT thickness ranges from 0.625 to 2 mm; in the public MosMed-Data, the thickness is 8 mm. For normalization processing, we resample all CT images into 1.5 mm isotropic resolution as [55] . Although the image quality and CT thickness are varied, extensive experiments on different sites show that our FLARE method obtains compelling results compared with the competitors. This demonstrates the robustness of the proposed framework to the image quality and resolution.",
            "cite_spans": [
                {
                    "start": 763,
                    "end": 767,
                    "text": "[55]",
                    "ref_id": "BIBREF55"
                }
            ],
            "ref_spans": [],
            "section": "V. DISCUSSION"
        },
        {
            "text": "The FLARE method contains three major stages: 1) multiview feature extraction; 2) parameter optimization of the FCN; 3) calculation of the objective function. In the first stage, we use a pre-trained VB-Net [59] to segment the infected lesions and lung fields, and then extract handcrafted features for all images. We conduct this feature extraction operation only once and fix the multi-view features during the algorithm training phase. In the second stage, the domain translator, the feature extractor, and the classifier form an FCN at a cost of O( x ), respectively, where n b is the batch size (n b = 100 in the experiments when adopting the mini-batch training strategy), w z and w (v) x are the dimensions of latent feature and the v-th view of input data. In our experiments, it takes an average of 40.0 seconds to segment the infections and lung fields and extract handcrafted features for a CT image on two Nvidia Quadro RTX 4000 graphics cards. In the algorithm training phase, it takes 1.6 seconds per iteration. During the testing phase, it only takes 0.6 milliseconds to assess the severity for a sample on an Nvidia GeForce GTX 1080 Ti graphics card.",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 211,
                    "text": "[59]",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 689,
                    "end": 692,
                    "text": "(v)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "B. Time Complexity"
        },
        {
            "text": "With regard to probable improvement of efficiency, we can implement multi-threading and extract features for multiple CT images. When using a large batch size in the algorithm training phase, we can use the memory efficient kernel approximation [60] , which reduces the complexity of the CMMD loss from O(n 3 b ) to O(n b k 2 + k 3 ) with rank k n b .",
            "cite_spans": [
                {
                    "start": 245,
                    "end": 249,
                    "text": "[60]",
                    "ref_id": "BIBREF60"
                }
            ],
            "ref_spans": [],
            "section": "B. Time Complexity"
        },
        {
            "text": "Recently, many deep learning methods based on original medical images have made great progress in the performance of medical image analysis. Nevertheless, we explore the COVID-19 severity assessment problem using multi-view features in this paper. One of the main reasons why we adopt handcrafted features is the particularity of the task. For instance, when detecting COVID-19 from non-COVID-19 pneumonia or non-pneumonia diseases, deep learning systems are proposed to detect some typical signs of infection (e.g., ground-glass opacity (GGO) and consolidation) in a qualitative evaluation way [5] - [7] . However, when assessing COVID-19 severity, the quantitative indicators (e.g., the number and size of GGOs, the volume of infection) are very important [2] , [54] . Hence, we extract multi-view features based on the lesion region and subsequently propose a DA method. However, it is undeniable that handcrafted features even with expert knowledge may miss some discriminative information. An interesting research direction is to take both original medical images and multi-view features into account. More rigorous analysis on this direction will be our future work.",
            "cite_spans": [
                {
                    "start": 595,
                    "end": 598,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 601,
                    "end": 604,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 758,
                    "end": 761,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 764,
                    "end": 768,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [],
            "section": "C. Future Works"
        },
        {
            "text": "Imbalanced learning is an important and challenging problem in many classification tasks, especially in the field of medicine. To learn a fair prediction for all classes, we propose an imbalanced learning strategy, named SCBS. In fact, generative model is also powerful and widely-explored to handle data imbalance issues. For example, in a pioneering work [35] , the feature space of minor class in the source domain is augmented by synthesizing fake data through a conditional generative adversarial network; experimental results show that this method achieves significant improvement in both minor and overall classification accuracy compared with some baselines. Inspired by this work, a promising direction is to augment the sample sizes of minor and hard classes by generating new data instead of oversampling data in the SCBS strategy. Meanwhile, the complexity of the synthetic sampling algorithm will be studied.",
            "cite_spans": [
                {
                    "start": 357,
                    "end": 361,
                    "text": "[35]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "C. Future Works"
        },
        {
            "text": "In this paper, we propose a novel DA method, named FLARE, for the severity assessment of COVID-19. In particular, it tackles the class-imbalance problem and domain discrepancy among cross-site transfer learning. The key components in FLARE include an SCBS strategy and a desirable representation learning framework. The SCBS is specially designed for relieving the class-imbalance problem and improves the classification performance on poorly-predicted classes. In the representation learning, we pursue a latent space containing three properties, domain-transferability, discriminant, and completeness. For domain-transferability, we propose a domain translator and align the heterogeneous data via a prototype triplet loss in a hyper-sphere manifold. For discriminant and completeness, we adopt the CMMD loss and the multi-view reconstruction loss on the representations, respectively. Extensive experiments show that FLARE significantly outperforms some state-of-the-art methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VI. CONCLUSION"
        },
        {
            "text": "The way to combine the dynamic changes of CT images during COVID-19 development to further improve the performance of the classification method will be our future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VI. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A novel coronavirus outbreak of global health concern",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "W"
                    ],
                    "last": "Horby",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "G"
                    ],
                    "last": "Hayden",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "F"
                    ],
                    "last": "Gao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "10233",
            "pages": "470--473",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "",
            "pages": "497--506",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Early transmission dynamics in Wuhan, China, of novel coronavirus-infected pneumonia",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "New England J. Med",
            "volume": "382",
            "issn": "13",
            "pages": "1199--1207",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: A descriptive study",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet",
            "volume": "395",
            "issn": "10223",
            "pages": "507--513",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Deep learning enables accurate diagnosis of novel coronavirus (COVID-19) with CT images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE/ACM Trans. Comput. Biol. Bioinf., early access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TCBB.2021.3065361"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "COVID CT-Net: Predicting COVID-19 from chest CT images using attentional convolutional network",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yazdani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Minaee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kafieh",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Saeedizadeh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sonka",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2009.05096"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "COVID-19 pneumonia diagnosis using a simple 2D deep learning framework with a single chest CT image: Model development and validation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ko",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Med. Internet Res",
            "volume": "22",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "COVID TV-UNet: Segmenting COVID-19 chest CT images using connectivity imposed UNet",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Saeedizadeh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Minaee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kafieh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yazdani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sonka",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput. Methods Programs Biomed. Update",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cmpbup.2021.100007"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Diagnosis of coronavirus disease 2019 (COVID-19) with structured latent multi-view representation learning",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imag",
            "volume": "39",
            "issn": "8",
            "pages": "2606--2614",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "AI-driven quantification, staging and outcome prediction of COVID-19 pneumonia",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chassagnon",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Med. Image Anal",
            "volume": "67",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Dual-sampling attention network for diagnosis of COVID-19 from community acquired pneumonia",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ouyang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imag",
            "volume": "39",
            "issn": "8",
            "pages": "2595--2605",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Minaee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kafieh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sonka",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yazdani",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "Jamalipour"
                    ],
                    "last": "Soufi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med. Image Anal",
            "volume": "65",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Automated quantification of CT patterns associated with COVID-19 from chest CT",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chaganti",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artif. Intell",
            "volume": "2",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Severity assessment of COVID-19 using CT image features and laboratory indices",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Phys. Med. Biol",
            "volume": "66",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Inter-site variability in prostate segmentation accuracy using deep learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Gibson",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical Image Computing and Computer Assisted Intervention-MICCAI",
            "volume": "",
            "issn": "",
            "pages": "506--514",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "MS-Net: Multi-site network for improving prostate segmentation with heterogeneous MRI data",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Heng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imag",
            "volume": "39",
            "issn": "9",
            "pages": "2713--2724",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "R"
                    ],
                    "last": "Zech",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Badgeley",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "B"
                    ],
                    "last": "Costa",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Titano",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "K"
                    ],
                    "last": "Oermann",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PLoS Med",
            "volume": "15",
            "issn": "11",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Contrastive cross-site learning with redesigned net for COVID-19 CT classification",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Dou",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE J. Biomed. Health Informat",
            "volume": "24",
            "issn": "10",
            "pages": "2806--2813",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Estimates of the severity of coronavirus disease 2019: A model-based analysis",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Verity",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet Infect. Dis",
            "volume": "20",
            "issn": "6",
            "pages": "669--677",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Automated assessment of COVID-19 pulmonary disease severity on chest radiographs using convolutional Siamese neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "D"
                    ],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiol. Artif. Intell",
            "volume": "2",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Joint prediction and time estimation of COVID-19 developing severe symptoms using chest CT scan",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Med. Image Anal",
            "volume": "67",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "A survey on transfer learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "22",
            "issn": "10",
            "pages": "1345--1359",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Weaklysupervised cross-domain adaptation for endoscopic lesions segmentation",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cong",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Trans. Circuits Syst. Video Technol",
            "volume": "31",
            "issn": "5",
            "pages": "2020--2033",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Enhanced transport distance for unsupervised domain adaptation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y.-M",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                },
                {
                    "first": "Y.-W",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "P.-F",
                    "middle": [],
                    "last": "Ge",
                    "suffix": ""
                },
                {
                    "first": "C.-X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Comput. Vis. Pattern Recognit. (CVPR)",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Ieee/Cvf",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Conf",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "13936--13944",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Learning target-domain-specific classifier for partial domain adaptation",
            "authors": [
                {
                    "first": "C.-X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Ge",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "volume": "32",
            "issn": "5",
            "pages": "1989--2001",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Learning transferable features with deep adaptation networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jordan",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of Machine Learning Research",
            "volume": "37",
            "issn": "",
            "pages": "97--105",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Domain-adversarial training of neural networks",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ganin",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "J. Mach. Learn. Res",
            "volume": "17",
            "issn": "1",
            "pages": "2030--2096",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Conditional adversarial domain adaptation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "I"
                    ],
                    "last": "Jordan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. NeurIPS",
            "volume": "",
            "issn": "",
            "pages": "1640--1650",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Heterogeneous domain adaptation via covariance structured feature translators",
            "authors": [
                {
                    "first": "C.-X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "D.-Q",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Trans. Cybern",
            "volume": "51",
            "issn": "4",
            "pages": "2166--2177",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Unsupervised domain adaptation via discriminative manifold propagation",
            "authors": [
                {
                    "first": "Y.-W",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "C.-X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "D.-Q",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., early access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2020.3014218"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Semi-supervised domain adaptation by covariance matching",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "41",
            "issn": "11",
            "pages": "2724--2739",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "A closer look at few-shot classification",
            "authors": [
                {
                    "first": "W.-Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y.-C",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Kira",
                    "suffix": ""
                },
                {
                    "first": "Y.-C",
                    "middle": [
                        "F"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J.-B",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. ICLR",
            "volume": "",
            "issn": "",
            "pages": "1--24",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Semisupervised domain adaptation via minimax entropy",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Saito",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sclaroff",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Darrell",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Saenko",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV)",
            "volume": "",
            "issn": "",
            "pages": "8050--8058",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Cross-domain few-shot classification via learned feature-wise transformation",
            "authors": [
                {
                    "first": "H.-Y",
                    "middle": [],
                    "last": "Tseng",
                    "suffix": ""
                },
                {
                    "first": "H.-Y",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J.-B",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "M.-H",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ICLR, 2020",
            "volume": "",
            "issn": "",
            "pages": "1--16",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Towards fair cross-domain adaptation via generative learning",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV)",
            "volume": "",
            "issn": "",
            "pages": "454--463",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "SMOTE: Synthetic minority over-sampling technique",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "V"
                    ],
                    "last": "Chawla",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "W"
                    ],
                    "last": "Bowyer",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "P"
                    ],
                    "last": "Kegelmeyer",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "J. Artif. Intell. Res",
            "volume": "16",
            "issn": "1",
            "pages": "321--357",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Borderline-smote: A new oversampling method in imbalanced data sets learning",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "W.-Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B.-H",
                    "middle": [],
                    "last": "Mao",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Proc. ICIC",
            "volume": "",
            "issn": "",
            "pages": "878--887",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "ADASYN: Adaptive synthetic sampling approach for imbalanced learning",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Garcia",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Proc. IEEE Int. Joint Conf. Neural Netw",
            "volume": "",
            "issn": "",
            "pages": "1322--1328",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "A study of the behavior of several methods for balancing machine learning training data",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Batista",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "C"
                    ],
                    "last": "Prati",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Monard",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "ACM SIGKDD Explor. Newslett",
            "volume": "6",
            "issn": "1",
            "pages": "20--29",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Focal loss for dense object detection",
            "authors": [
                {
                    "first": "T.-Y",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Girshick",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Dollar",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc. IEEE Int. Conf. Comput. Vis. (ICCV)",
            "volume": "",
            "issn": "",
            "pages": "2980--2988",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "BBN: Bilateral-branch network with cumulative learning for long-tailed visual recognition",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "X.-S",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "Z.-M",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "9719--9728",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Decoupling representation and classifier for long-tailed recognition",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proc. ICLR, 2020",
            "volume": "",
            "issn": "",
            "pages": "1--16",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Self-paced balance learning for clinical skin disease recognition",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "volume": "31",
            "issn": "8",
            "pages": "2832--2846",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Detection of coronavirus (COVID-19) associated pneumonia based on generative adversarial networks and a finetuned deep transfer learning model using chest X-ray dataset",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Eldeen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khalifa",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hamed",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Taha",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Elghamrawy",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.01184"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "COVID-19: Automatic detection from X-ray images utilizing transfer learning with convolutional neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Apostolopoulos",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Mpesiana",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Phys. Eng. Sci. Med",
            "volume": "43",
            "issn": "2",
            "pages": "635--640",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Diagnosing COVID-19 pneumonia from X-ray and CT images using deep learning and transfer learning algorithms",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Maghdid",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "T"
                    ],
                    "last": "Asaad",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Z"
                    ],
                    "last": "Ghafoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Sadiq",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Khan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proc. SPIE",
            "volume": "11734",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Dimensionality reduction by learning an invariant mapping",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Hadsell",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chopra",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lecun",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit",
            "volume": "2",
            "issn": "",
            "pages": "1735--1742",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Learning kernel for conditional moment-matching discrepancy-based image classification",
            "authors": [
                {
                    "first": "C.-X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Ge",
                    "suffix": ""
                },
                {
                    "first": "D.-Q",
                    "middle": [],
                    "last": "Dai",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "IEEE Trans. Cybern",
            "volume": "51",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Joint measures and cross-covariance operators",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Baker",
                    "suffix": ""
                }
            ],
            "year": 1973,
            "venue": "Trans. Amer. Math. Soc",
            "volume": "186",
            "issn": "",
            "pages": "273--289",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "CPM-Nets: Cross partial multi-view networks",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cui",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. NeurIPS",
            "volume": "32",
            "issn": "",
            "pages": "559--569",
            "other_ids": {}
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Deep cocktail network: Multi-source unsupervised domain adaptation with category shift",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zuo",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit",
            "volume": "",
            "issn": "",
            "pages": "3964--3973",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Moment matching for multi-source domain adaptation",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Saenko",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV)",
            "volume": "",
            "issn": "",
            "pages": "1406--1415",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Contrastive adaptation network for single-and multi-source domain adaptation",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Hauptmann",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., early access",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TPAMI.2020.3029948"
                ]
            }
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "MosMedData: Data set of 1110 chest CT scans performed during the COVID-19 epidemic",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Morozov",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Digit. Diag",
            "volume": "1",
            "issn": "1",
            "pages": "49--59",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Large-scale screening to distinguish between COVID-19 and community-acquired pneumonia using infection size-aware classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Phys. Med. Biol",
            "volume": "66",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "On the convergence of Adam and beyond",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Reddi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kale",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proc. ICLR",
            "volume": "",
            "issn": "",
            "pages": "1--23",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Clinical characteristics of coronavirus disease 2019 in China",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "New England J. Med",
            "volume": "382",
            "issn": "",
            "pages": "1708--1720",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Visualizing data using t-SNE",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Mach. Learn. Res",
            "volume": "9",
            "issn": "",
            "pages": "2579--2605",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Abnormal lung quantification in chest CT images of COVID-19 patients with deep learning and its application to severity prediction",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Med. Phys",
            "volume": "48",
            "issn": "4",
            "pages": "1633--1645",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Memory efficient kernel approximation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Si",
                    "suffix": ""
                },
                {
                    "first": "C.-J",
                    "middle": [],
                    "last": "Hsieh",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhillon",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Mach. Learn. Res",
            "volume": "18",
            "issn": "1",
            "pages": "682--713",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Examples of chest CT images with infection of COVID-19 from different clinical sites. Top to bottom: three sites. Left: mild; Right:",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Flowchart of the FLARE method. It updates the class distribution of the samples in the source domain and target domain by an SCBS strategy. After optimizing a specially designed domain translator on the source data, FLARE learns a latent space with three properties: (a) domain-invariance by the prototype triplet loss L p , (b) discriminant by the conditional maximum mean discrepancy (CMMD) loss (L s c + L t c ), and (c) completeness by the multi-view reconstruction loss (L s r + L t r ).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": ", respectively; L s,e c , L e p , and L s,e r are calculated by (6), (4), and (8), respectively, for the e-th source domain. At the training phase, the value of the CMMD loss L s,e c can represent how well the model fits into data in the e-th source domain. Further, when some source domain is fitted well, we expect to assign a larger weight for the alignment between this source domain and the target domain. With the above analysis, we define w e = (L s,e c ) \u22121 / E j =1 (L s, j c ) \u22121 and place it in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Visualization of extracted features using t-SNE[58]. Left to right: three DA tasks for classifying COVID-19 disease severity. Top to bottom: LFT[34], CCSL[18], and our FLARE. FLARE is successful in projecting the source data around the target data and learning discriminant features. (Best viewed in color).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Similarity distribution of features. Left to right: three DA tasks for COVID-19 severity assessment. Top: original features of the target domain. Bottom: discriminative features extracted by our FLARE for the target domain. In each figure, we draw two batches of data with the same and different classes. Compared with the original features, the intraclass similarity of the features learned by FLARE becomes larger and the inter-class one becomes smaller. (Best viewed in color).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "l\u22121 w l ) where d f is the number of layers, and w l is the dimension of the l-th layer. The third stage contains the calculations of the CMMD loss, the prototype triplet loss, and the reconstruction loss. These loss terms have time complexity O(n 3 b ), O(n b C), and O( V v=1 w z w (v)",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "INFORMATION OF DATASETS. SITE-1, SITE-2, AND SITE-3 ARE PRIVATE. SITE-4 IS PUBLICLY AVAILABLE[54]",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "AGAINST COMPETING METHODS ON DA TASKS BETWEEN PRIVATE DATASETS. LEFT TO RIGHT: THREE DA TASKS (S1,S2)\u2192S1, (S2,S1)\u2192S2, AND (S3,S1)\u2192S3. OUR FLARE OUTPERFORMS ALL THE THREE GROUPS OF METHODS IN THE OVERALL PERFORMANCE METRICS, i.e., F1, AND G-MEAN",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "AGAINST COMPETING METHODS ON DA TASKS FROM PRIVATE TO PUBLIC DATASETS, i.e., TASK (S4,S1)\u2192S4",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "OF FLARE USING VARIOUS IMBALANCED LEARNING STRATEGIES. * MEANS A STATISTICALLY SIGNIFICANT DIFFERENCE BETWEEN THE PERFORMANCES OF THE SCBS AND THOSE OF THE REFERRED STRATEGIES",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "RESULTS OF FLARE METHOD IN TERMS OF ADAPTIVE REPRESENTATION LEARNING",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "RESULTS OF FLARE METHOD IN TERMS OF DISCRIMINANT LEARNING",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "AGAINST COMPETING METHODS ON MULTIPLE SOURCE DOMAIN ADAPTATION TASK testifies the need of exploiting a multi-source DA method. From the experimental results inTable VIII, we have three observations. Firstly, the single-best FLARE method obtains much better classification performance than other single-source methods and most multi-source methods. This validates the effectiveness of FLARE. Secondly, compared with single-best DA methods, most source combine DA methods obtain poorer results, demonstrating that domain shifts between source domains should not be neglected. Thirdly, M-FLARE boosts the performance of single-best and source combine FLARE to 87.3% in terms of G-mean, which validates that introducing additional source domains and adopting appropriate transfer method can improve the performance on the target domain.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}