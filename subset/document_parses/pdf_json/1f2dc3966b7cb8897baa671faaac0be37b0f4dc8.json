{
    "paper_id": "1f2dc3966b7cb8897baa671faaac0be37b0f4dc8",
    "metadata": {
        "title": "Novel ensemble of optimized CNN and dynamic selection techniques for accurate Covid-19 screening using chest CT images",
        "authors": [
            {
                "first": "Sameena",
                "middle": [],
                "last": "Pathan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "P",
                "middle": [
                    "C"
                ],
                "last": "Siddalingaswamy",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Preetham",
                "middle": [],
                "last": "Kumar",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Manohara",
                "middle": [],
                "last": "Pai",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "M",
                "middle": [],
                "last": "",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Tanweer",
                "middle": [],
                "last": "Ali",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "U",
                "middle": [],
                "last": "Rajendra Acharya",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Ngee Ann Polytechnic",
                    "location": {
                        "country": "Singapore"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The world is significantly affected by infectious coronavirus disease (covid-19). Timely prognosis and treatment are important to control the spread of this infection. Unreliable screening systems and limited number of clinical facilities are the major hurdles in controlling the spread of covid-19. Nowadays, many automated detection systems based on deep learning techniques using computed tomography (CT) images have been proposed to detect covid-19. However, these systems have the following drawbacks: (i) limited data problem poses a major hindrance to train the deep neural network model to provide accurate diagnosis, (ii) random choice of hyperparameters of Convolutional Neural Network (CNN) significantly affects the classification performance, since the hyperparameters have to be application dependent and, (iii) the generalization ability using CNN classification is usually not validated. To address the aforementioned issues, we propose two models: (i) based on a transfer learning approach, and (ii) using novel strategy to optimize the CNN hyperparameters using Whale optimizationbased BAT algorithm + AdaBoost classifier built using dynamic ensemble selection techniques. According to our second method depending on the characteristics of test sample, the classifier is chosen, thereby reducing the risk of overfitting and simultaneously produced promising results. Our proposed methodologies are developed using 746 CT images. Our method obtained a sensitivity, specificity, accuracy, F-1 score, and precision of 0.98, 0.97, 0.98, 0.98, and 0.98, respectively with five-fold cross-validation strategy. Our developed prototype is ready to be tested with huge chest CT images database before its real-world application.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Covid-19, the disease caused by the SARS-CoV-2 was officially declared as a pandemic by World Health Organization (WHO), if not detected early, can be fatal and evolve as Acute Respiratory Disease Syndrome (ARDS). Thus, early prediction of risk factors and screening of patients is crucial to curb the spread in society thereby preventing mortality [1] . Limited access to health monitoring facilities hinders the development of sustainable cities. With the global pandemic swaying its way in the lives of people in a capricious manner, causing unprecedential damage to health, economy. It is necessary to combat the spread of covid-19 in early stages and provide proper treatment. Currently, RT-PCR is the most common screening method for the detection of covid-19. However, the method is laborious and also has low detection sensitivity in the initial stages. At the onset of covid-19, few changes are observed in the CT-scans of patients [2] . For instance, consolidation and dilation were observed by Zhao et al. [3] , in covid affected patients.",
            "cite_spans": [
                {
                    "start": 349,
                    "end": 352,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 941,
                    "end": 944,
                    "text": "[2]",
                    "ref_id": null
                },
                {
                    "start": 1017,
                    "end": 1020,
                    "text": "[3]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A CT scan provides information regarding the size, shape, texture, and density of various anatomical regions of the body. Fig. 1 illustrates the sample CT images of covid affected and non-covid affected images. In contrast, to the conventional X-Rays, much information is embedded in a CT scan image. This information is usually analyzed by clinicians to provide the diagnosis. However, due to the subjectivity involved and also due to the scarcity of clinicians in fighting this global pandemic, it is necessary to develop an objective diagnostic mechanism, that could speed up the diagnosis and aid in the early detection.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 122,
                    "end": 128,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Off late, deep learning tools have been used to automate and speed up the diagnosis [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] . A self-trans approach using transfer learning and feature extraction methods was proposed by He et al. [5] , achieving an F1-score of 0.85. A precision of 0.84, recall of 0.95, was obtained by Mobiny et al. [6] , using a detailed oriented capsule network. Polsinelli et al. [7] , achieved an accuracy of 0.83 by using SqueezeNet Convolution Neural Networks (CNN) architecture. A voting-based scheme using certain deep learning models was proposed by Silva et al. [4] , achieving an accuracy of 0.87. A weakly-supervised method using deep learning was utilized by Hu et al. [8] , achieving covid classification accuracy of Fig. 1 . Sample chest CT images: covid-19 affected patients (first row images), and normal subjects (second row) [4] .",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 87,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 88,
                    "end": 91,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 92,
                    "end": 95,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 96,
                    "end": 99,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 100,
                    "end": 103,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 104,
                    "end": 107,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 108,
                    "end": 112,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 113,
                    "end": 117,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 118,
                    "end": 122,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 123,
                    "end": 127,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 128,
                    "end": 132,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 133,
                    "end": 137,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 243,
                    "end": 246,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 347,
                    "end": 350,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 414,
                    "end": 417,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 603,
                    "end": 606,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 713,
                    "end": 716,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 875,
                    "end": 878,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [
                {
                    "start": 762,
                    "end": 768,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Overview of the studies conducted on automated detection of covid-19 using chest CT images. Ref 0.89. An accuracy of 0.9 and sensitivity of 0.8 was obtained by Wang et al. [9] , by employing U-net architecture on 3D CT volumes. However, the method was trained on imperfect ground truth masks thereby resulting in misleading results [9] . Ardakani et al. [10] , developed a CAD tool termed as CovidDiag by extracting a set of twenty radiological features using CT images and further classifying into covid and non-covid classes using five different supervised classifiers. Ozakya et al. [11] , achieved a sensitivity of 92% using a convolutional support vector machine. Further few other pre-trained models were also evaluated for the CT covid images. A sensitivity of 68% was obtained by Ozturk et al. [12] , using a set of 495 shrunken features obtained by employing stacked auto encoder and principal component analysis. Maghdid et al. [13] , obtained an accuracy of 94% using pre-trained AlexNet architecture, additionally, a dataset of images was also created [13] . A detailed review of methods for detection of covid19 using deep learning techniques and lung segmentation is given in Ref. [14] . A set of ten prominent CNN's were investigated by Ardakani et al. [15] , for distinguishing covid and non-covid CT images, it was observed that ResNet 101 and Xception resulted in good classification performance [15] . Table 1 provides a summary of the studies pertaining to CT image based covid-19 detection techniques. In the proposed work, two covid-19 classification architectures are proposed, the first architecture is built using features extracted from five standard CNN architectures and classified using AdaBoost of decision stump trees created using ensemble selection techniques. The second architecture is a novel concept, which is built by optimizing the hyperparameters of a CNN using Whale Optimization and Bat (WOA-BAT) swarm heuristics algorithm, to obtain features from CT images, and the extracted features are further classified using a robust classification set-up. A CNN hyperparameter optimization methodology is proposed by Pathan et al. [16] , however, the proposed method is different from the method in Ref. [16] , in the following ways, (i) An optimized CNN is used for extraction of features and further dynamic ensemble of classifiers are used to classify CT images, into covid-19 and non covid-19, whereas in Ref. [16] , a GWO optimized CNN is used for three class classification of images, (ii) The proposed method addressed the limited dataset and overfitting problem, since a dynamic and robust classifier set-up is used for classification, rather than a complex CNN, which requires a larger dataset for achieving good classification accuracy.",
            "cite_spans": [
                {
                    "start": 92,
                    "end": 95,
                    "text": "Ref",
                    "ref_id": null
                },
                {
                    "start": 172,
                    "end": 175,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 332,
                    "end": 335,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 354,
                    "end": 358,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 586,
                    "end": 590,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 802,
                    "end": 806,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 938,
                    "end": 942,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1064,
                    "end": 1068,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1195,
                    "end": 1199,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1268,
                    "end": 1272,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1414,
                    "end": 1418,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 2165,
                    "end": 2169,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 2238,
                    "end": 2242,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 2448,
                    "end": 2452,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [
                {
                    "start": 1421,
                    "end": 1428,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Table 1"
        },
        {
            "text": "CNNs possess excellent capability to analyze the images with very high level of semantics by learning from abstract representations. The filter bank approach adopted in a CNN aids in exploiting the texture content in the images, in contrast to the handcrafted filter bank approaches. One of the major bottlenecks associated with the studies reported in the literature (Table 1) is the availability of huge data. Since deep learning models perform better with larger datasets, the application of the above-reported methods in clinical scenario lacks reliability. Also, these methods have employed standard parameters to develop the models. The classification performance of a CNN is mainly influenced by the hyperparameters chosen and dataset [26] . Since the choice of hyperparameters is application dependent and may lead to low-performance metrics. Rather than randomly choosing the hyperparameter values, application specific values derived from an optimization methodology is adopted. In this regard, the WOA-BAT optimization algorithm is adopted, in contrast to other swarm meta heuristic optimization algorithms. Also, the WOA avoids local optima and reaches a global optimum solution without any structural reformation [28, 29] . Additionally, we aim to improve the classification performance of covid-19 images, thus we created an ensemble of classifiers, and based on the test sample characteristics, a classifier is chosen in a dynamic fashion using ensemble selection techniques. This not only addresses the limited data problem without increasing the computation time and cost, but also improves the classification accuracy, which are needed in the current scenario.",
            "cite_spans": [
                {
                    "start": 742,
                    "end": 746,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1226,
                    "end": 1230,
                    "text": "[28,",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1231,
                    "end": 1234,
                    "text": "29]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 368,
                    "end": 377,
                    "text": "(Table 1)",
                    "ref_id": null
                }
            ],
            "section": "Motivation"
        },
        {
            "text": "The novelty of the methodology is the application of WOA-BAT algorithm to determine the hyperparameter values of optimized CNN architecture. This will help to obtain reduced and efficient feature set for image classification. The major contributions of the paper are given below:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Novelty and contributions"
        },
        {
            "text": "1. Presented a compact deep learning-based dynamic ensemble classifier for prediction of covid-19 using chest CT images. 2. Developed an optimized CNN using WOA-BAT algorithm to extract features. These features are classified using robust ensemble of dynamic classifiers built using decision stump trees. Appropriate choice of hyperparameters determine the accuracy of the classification. In most of the CNN based classification algorithms, the hyperparameters are selected randomly, irrespective of the application, thereby yielding poor classification performance. In the proposed design, hyperparameters are selected based the features extricated from the chest CT images. To the best of our knowledge, the proposed optimized set-up is the first of its kind in the literature to date for the prediction of covid-19 using chest CT images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Novelty and contributions"
        },
        {
            "text": "The proposed classification architectures are briefed as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "1. The first classification model deploys an ensemble of five standard CNN architectures for feature extraction and features are further selected using Binary Grey Wolf Optimizer (BGWO). 2. In the second classification model, the CNN hyperparameters are optimized through WOA-BAT algorithm, for the extraction of features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "In both the classification models, the same classifier set-up is used for determining the class of the CT images using the features extracted from the respective CNN architectures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "The overview of the model 1 is given in Fig. 2 . The first step includes the extraction of features from the CT images. Transfer learning is useful when the dataset is small. In this study, five standard CNN architectures namely ResNet-50, AlexNet, VGG19, Densenet, and Inception V3 are used to extract the features.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 40,
                    "end": 46,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Deep learning ensembles for feature extraction"
        },
        {
            "text": "\u2022 AlexNet-This architecture can classify more than 1000 different classes and built using 60 million parameters [17] . It comprises of 5 Convolutional Layers (CL) with three pooling, with two fully connected layers, and softmax layer. The first convolution layer has 96 kernels of size 11x11x3 and takes an input image of dimension 227x227x3. The two CL layers are followed by overlapping max-pooling layers. The Rectified Linear Unit (ReLu) is applied as the activation function. In this work, from the last layer, a set of 1000 features are extracted. \u2022 ResNet-It is introduced to solve the vanishing gradient and degradation problem in CNN's [18] . Depending on the number of layers, it has different versions like ResNet 18, 50, and 101. During training, it learns from the residual features. In our work, we have used ResNet-50 architecture and generated 1000 features. \u2022 VGG19-It is a 19 layer deep CNN similar to AlexNet from the visual geometry group and can classify images into 1000 classes [19] . The input dimensions are 224x224x3 and VGG19 consists of 16 CL with 3 fully connected layers. We have extracted 1000 features from the last fully connected layer (fc8). \u2022 DenseNet-It is an extension of ResNet, it exploits the potential of network through feature reuse [20] . Dense nets are divided into dense blocks, wherein feature map dimensions remain constant within a block, with variations in the number of filters.",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 116,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 645,
                    "end": 649,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1001,
                    "end": 1005,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1277,
                    "end": 1281,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Deep learning ensembles for feature extraction"
        },
        {
            "text": "\u2022 Inception V3-It is a 48 layer deep CNN that takes an input image of size 299x299x3 [21] . The model consists of techniques such as factorized convolutions, regularizations, dimension reduction, and parallelized computations to obtain optimum network performance. Thus from the five standard architectures, 5000 features are extracted.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 89,
                    "text": "[21]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Deep learning ensembles for feature extraction"
        },
        {
            "text": "In this work, we have obtained large number of features, hence redundant features are to be eliminated. Thus, a swarm-based binary grey wolf optimization algorithm is applied to each of the individual feature vectors from each architecture, leading to 3320 feature vectors. The feature vectors are then concatenated and subjected to the feature selection process, resulting in final set of 2185 features. The procedure for feature selection is described below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Deep learning ensembles for feature extraction"
        },
        {
            "text": "Over the recent years swarm based optimization methods have been used for several applications [22] [23] [24] . Mirajalili et al. [25] , proposed a GWO optimization algorithm that mimics the hunting mechanism of wolves. The wolves are named as alpha (\u221d), beta (\u03b2), delta (\u03b4), and omega (\u03c9). The initial three wolves are the fittest wolves and \u03c9 wolves are considered as subordinates. The nature of prey-hunt is given in (1-2).",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 99,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 100,
                    "end": 104,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 105,
                    "end": 109,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 130,
                    "end": 134,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "where, t indicates the iteration, the distance is given as D, C and A are the coefficients computed as given in (3). The prey's position is denoted as Xp, X is the current location of wolf.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "r1 and r2 are assigned random values in the range [0-1], and 'a' varies from 2 to 0. The initial solutions are stored as alpha, beta and delta, the subordinate wolf position (\u03c9) is iterated as given in (4-7).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "Here, X 1 \u0305\u2192 , X 2 \u0305\u2192 and X 3 \u0305\u2192 are approximate distances as given in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "Ref. [25] . Random candidate solutions are initially created and updated over the iterations considering probable positions of the prey. The value of A \u2192 >1 and A \u2192 <1 describe the divergence and convergence of solutions. Upon reaching the maximum iterations, optimum solution is obtained using GWO.",
            "cite_spans": [
                {
                    "start": 5,
                    "end": 9,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "For the selection of the features, the binary version of GWO termed BGWO is used [25, 27] . Considering a feature vector of size N, 2 N , feature sets are searched exhaustively, such that the best feature combination is obtained. In this work, best feature combination refers to the feature set which gives the best classification performance. The objective function is the minimization of fitness function as given in (8) .",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 85,
                    "text": "[25,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 86,
                    "end": 89,
                    "text": "27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 419,
                    "end": 422,
                    "text": "(8)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "where, E R (D) is the classifier error rate. R is the feature subset length selected. C is the sum of all the features. The constants \u03b1 \u2208 [0, 1], \u03b2 = 1 \u2212 \u03b1, control the accuracy of classification and feature reduction. After applying BGWO to the entire deep learning-based features, a set of 2185 features are obtained for the corresponding class.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection using Binary Grey Wolf Optimizer (GWO)"
        },
        {
            "text": "The images are initially divided into a ratio of 80:20, such that each set consists of images from both the classes. The first step includes feature extraction using 80% of the image data from ResNet-50 architecture, and second step involves determining the hyperparameters of CNN using WOA-BAT optimization methodologies. As illustrated in Fig. 3 , a fully connected, soft-max layer, and classification layer form the last three layers of ResNet-50 architecture. The transfer learning approach is used to extract the features, by replacing last three layers of pre-trained ResNet-50 without freezing. The WOA algorithm [28] , mimics the humpback whales hunting pattern. The prey is initially chased and a bubble net strategy is simulated. Prey encircling and exploitation are the two main phases in the algorithm. In the proposed work, the weights and bias of the MLP are randomly initialized. For a set of features, appropriate choice of bias and weight results in achieving good performance of the MLP. Thus MLP parameters are optimized to tune the CNN hyperparameters. At each iteration stage, the search agents are randomly chosen, or the current best solution at the preceding iteration is retained. The hunting nature for the best solution is given as (9-10)",
            "cite_spans": [
                {
                    "start": 620,
                    "end": 624,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 341,
                    "end": 347,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "is the preceding prey position, X \u2192 (t +1) is the present position of the whale. Similar to (3), D \u2192 , C \u2192 and A \u2192 are computed as (11) .",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 135,
                    "text": "(11)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "The convergence speed is increased by incorporating few modifications in the nature of bats mechanism. Initially, there is 50% of chance to employ either simulating model or spiral mechanism to update the current position [28, 29] . The present iteration is given in (12) .",
            "cite_spans": [
                {
                    "start": 222,
                    "end": 226,
                    "text": "[28,",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 227,
                    "end": 230,
                    "text": "29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 267,
                    "end": 271,
                    "text": "(12)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "For simplicity we consider, b = k = 1, hence,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "If p < 0.5, then the value of the present iteration is updated as given in (14) (15) (16) .",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "text": "(14)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 80,
                    "end": 84,
                    "text": "(15)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 85,
                    "end": 89,
                    "text": "(16)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "Here, x i is position of bat, and v i is bats velocity. Lower and upper bound the algorithm corresponds to the frequency of waves. The bats position is updated using the computed velocity, because as per the law of nature when bat detects the food or prey, the rate of loudness is inversely proportional to instinct direction [30] .",
            "cite_spans": [
                {
                    "start": 326,
                    "end": 330,
                    "text": "[30]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "Based on the new velocity, the bat location is changed. The loudness rate and emission rate are inversely related. The best positions which minimize the MSE objective function are chosen as the hyperparameters of CNN. The graphical illustration of parameter space and objective space pertaining to the average MSE is depicted in Fig. 4 . The steps followed to compute the best values of parameters are described in Algorithm I.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 329,
                    "end": 335,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Feature extraction from CNN optimized using ensemble of WOA-BAT algorithm"
        },
        {
            "text": "Our proposed CNN model is illustrated in Fig. 5 . At each offset, the CNN extracts the image features. Using the hyperparameter values obtained during WOA-BAT optimization, CNN is trained. The extracted features are mapped into the feature space using ReLu. The normalization of gradients and activations is performed using batch normalization. The most relevant information from the image is retained by the max-pooling layer. The image is classified using fully connected and softmax layers. The details of filter sizes are given in Fig. 5 . Adam solver or stochastic gradient is used to tune the hyperparameters. However, the rate of convergence and performance of CNN, mainly rely on the appropriate choice of hyperparameters. If the learning rate is very small, the training time increases. The CNN model is updated at every epoch depending on the error, and the change is decided by the learning rate hyperparameter. Similarly, L2 regularization prevents the model from overfitting. These hyperparameters are computed by best positions obtained using WOA-BAT optimization. The hyperparameters obtained by optimization are given in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 41,
                    "end": 47,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 535,
                    "end": 541,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 1137,
                    "end": 1144,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "ALGORITHM 1."
        },
        {
            "text": "Once the values of hyperparameters are obtained, the CT images are fed to CNN to extract the features. A set of 2 features are obtained from the proposed model 2. Further, the feature sets obtained from two models are subjected to classification using AdaBoost in conjunction with dynamic ensemble selection techniques. To depict the separability between the two classes of data (covid & non-covid), the scatter plot distribution of features is shown in Fig. 6 . A high degree of separability can be observed in two features extracted from proposed method 2, compared to the features extracted from model 1.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 454,
                    "end": 460,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "ALGORITHM 1."
        },
        {
            "text": "The last step in computer-aided detection of any disease is classification [31] . Usually, in an ensemble approach to test the samples, several classifiers are used, and most suitable classifier is chosen.",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 79,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "AdaBoost of stump trees built from dynamic ensemble selection techniques"
        },
        {
            "text": "However, in dynamic ensemble selection technique, depending on the characteristics of test sample, a different classifier is dynamically chosen. We created a dynamic ensemble of stump trees and by adopting dynamic classifier selection technique, we chose a classifier for every test pattern. For every test sample, a set of training samples are created, and the most accurate classifier is chosen. Intuitively, depending on the diversity of classifier ensemble better performance is obtained. The major advantage of this method is that the risk of overfitting and generalization is reduced.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "AdaBoost of stump trees built from dynamic ensemble selection techniques"
        },
        {
            "text": "The classifier is constructed by ensemble of AdaBoost of stump trees, and applying the dynamic classification selection techniques namely, Static Ensemble (EN), Local Class Accuracy (LCA), Overall Local Accuracy (OLA), A-Posterior (A-Po), A-Priori (A-Pr), KNORA-U(K-U), KNORA-E (K-E), Ensemble refers to a set of stump trees are formed by boosting with a maximum tree depth chosen as 2. Initially, five neighbors of a particular test sample are selected using the training data to identify the most appropriate classifier among the classifier pool to predict the test sample. Further, the classifiers are tested on the K-NN samples from the training set and the corresponding accuracy is computed. Whereas for OLA, the K nearest training samples may not belong to the similar group, compared to OLA, the LCA, takes into account the class of K nearest samples (similar to the test sample). Further, the classifier that achieved the maximum good accuracy during classification of training samples is selected. If two classifiers have the same accuracy then K is increased, the detailed explanation can be found in Refs. [32, 37, 38] . KNORA-techniques in contrast to the above mentioned dynamic ensemble selection techniques create an ensemble using the pool of classifiers to decide the test label, using the majority voting scheme, and the nearest training samples are selected in a similar fashion.",
            "cite_spans": [
                {
                    "start": 1118,
                    "end": 1122,
                    "text": "[32,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1123,
                    "end": 1126,
                    "text": "37,",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1127,
                    "end": 1130,
                    "text": "38]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "AdaBoost of stump trees built from dynamic ensemble selection techniques"
        },
        {
            "text": "The study is carried out using a publicly available dataset [33] , containing 347 COVID-19 and 397 normal (non-COVID) images associated with various kinds of pathologies. The images are in portable network graphics format.",
            "cite_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "text": "[33]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "The proposed methodology was designed and tested in MATLAB 2020a. For model 1, the features are extracted from the entire dataset. For model 2, initially, the features are extracted using 80% of the data for obtaining the optimized hyperparameters. Once, the hyperparameter values are obtained, then the features are obtained from the entire dataset. The images are subjected to resizing to reduce the processing time. The average difference between the height and width of the images is small (approximately \u00b187), hence irrespective of the aspect ratio, the images were resized to 448x448x1. The optimized CNN is proposed for extracting features from the two categories (covid -19, no-covid-19) . Further, five-fold cross-validation (CV) is carried for validating the proposed methodologies. The performance is computed as given in (17) (18) (19) (20) (21) . ",
            "cite_spans": [
                {
                    "start": 678,
                    "end": 695,
                    "text": "-19, no-covid-19)",
                    "ref_id": null
                },
                {
                    "start": 833,
                    "end": 837,
                    "text": "(17)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 838,
                    "end": 842,
                    "text": "(18)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 843,
                    "end": 847,
                    "text": "(19)",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 848,
                    "end": 852,
                    "text": "(20)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 853,
                    "end": 857,
                    "text": "(21)",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Training and testing"
        },
        {
            "text": "Precision (PR) = TP/(TP + FP) (20)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training and testing"
        },
        {
            "text": "Accuracy quantifies the average predictive ability into the covid and non-covid classes. Sensitivity indicates the rate of correctly identified positive instances into two classes, whereas the rate of correctly identified negative instances is quantified using specificity. Precision determines the rate of accurately identified true cases. Similarly, precision and recall are combined using F-1 score. The following subsections provide the quantitative results of the proposed methodologies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training and testing"
        },
        {
            "text": "The features extracted from the standard CNN architectures are divided into five distinct groups, with one set used for testing, and four sets used for training at each iteration. Table 3 shows the average results of classification obtained using model 1, and the ROC corresponding to the best results using KNORA-U dynamic ensemble is given in Fig. 7 . The confusion matrices for each of the five folds obtained using various dynamic ensemble selection techniques with deep learning based features and dynamic AdaBoost classification ensemble is illustrated in Fig. 8 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 180,
                    "end": 187,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 345,
                    "end": 351,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 562,
                    "end": 568,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Results of classification using deep learning based features and dynamic AdaBoost classification ensemble"
        },
        {
            "text": "The features extracted from the standard CNN architectures are divided into five distinct groups, with one set used for testing, and four sets used for training at each iteration. Table 4 presents the classification results in the form of mean\u00b1standard deviation using model 2, and the ROC corresponding to the best results using KNORA-U dynamic ensemble is given in Fig. 9 . The confusion matrices obtained for each of the five folds, for various dynamic ensemble selection techniques using WOA-CNN and dynamic AdaBoost classification ensemble is shown in Fig. 10 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 180,
                    "end": 187,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 367,
                    "end": 373,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 557,
                    "end": 564,
                    "text": "Fig. 10",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Results obtained using WOA-CNN and dynamic AdaBoost classification ensemble"
        },
        {
            "text": "A pairwise statistical test has been performed for the 21 combinations to check the statistical significance of each of the dynamic selection method with respect to the other. It was observed that the p-values for OLA and A-priori with respect to the other dynamic selection techniques were lesser than 0.05 (significance level) [35, 36] . Hence these methods (OLA and A-priori) are statistically different from the other methods. But, Ensemble, A-posterior, LCA, KNORA-E and KNORA-U are found to be statistically equivalent. Similarly, for method 2, (results reported in Table 4 ), statistical equivalence is observed. Since, the sensitivity of covid-19 detection using KNORA-U is higher, as compared to the other dynamic selection techniques, the ROC for the same is given in Figs. 7 and 9 for the two methods, respectively.",
            "cite_spans": [
                {
                    "start": 329,
                    "end": 333,
                    "text": "[35,",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 334,
                    "end": 337,
                    "text": "36]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [
                {
                    "start": 572,
                    "end": 579,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Results obtained using WOA-CNN and dynamic AdaBoost classification ensemble"
        },
        {
            "text": "Unoptimized CNN architecture refers to the standard hyperparameter values. The comparison is performed to provide an insight regarding the proposed classification set-up and the normal layered CNN with standard values of hyperparameters. Fig. 11 , provides the graphical illustration of performance of optimized and unoptimized CNNs. It can be observed from Fig. 11 that, classification performance using proposed optimized CNN outperformed the standard CNN performance using all the evaluation metrics.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 238,
                    "end": 245,
                    "text": "Fig. 11",
                    "ref_id": null
                },
                {
                    "start": 358,
                    "end": 365,
                    "text": "Fig. 11",
                    "ref_id": null
                }
            ],
            "section": "Comparison between the proposed optimized classification methodology and the unoptimized CNN architecture"
        },
        {
            "text": "A student's t-test was also performed to compare the means of the two population. The first population consists of performance parameters obtained using unoptimized CNN and the second population consists of performance parameters obtained using optimized CNN. The t-test assumes normal distribution of population for testing the hypothesis which states that, \"Optimized CNN improves the accuracy of covid-19 detection\". The significance value considered was \u03b1 = 0.05. The statistical test resulted in with a p-value of 0.0012, which is lesser than 0.05. Hence the hypothesis is accepted, which proves that optimized CNN significantly performs better in contrast to unoptimized CNN.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison between the proposed optimized classification methodology and the unoptimized CNN architecture"
        },
        {
            "text": "Summary of comparison with literature based approaches developed for covid-19 detection obtained from the same dataset is shown in Table 5 . He et al. [5] , used 25% of the images for testing. The self-trans approach was based on ResNet-50 and Densenet architecture with Adam optimizer default hyperparameter values, resulting in classification accuracy of 86%. Mobiny et al. [6] , proposed the detailed oriented capsule network derived from ResNet with three residual blocks with Adam optimizer default hyperparameter values, 20% data was used for testing. In Ref. [7] , the values for the learning rate, momentum and L2 regularization were tuned experimentally, depending on the performance of SqueezeNet model. Cruz et al. [35] , proposed an ensemble of deep learning methods, 27% of the image data was used for testing the model, and data augmentation was also performed to enlarge the dataset using rotation and vertical flips. Inspite of the data augmentation and robust ensemble, an accuracy of 86.7% was obtained, with an inference time of 14s. The methods reported in the comparative analysis were based on the same dataset, with variation in train and test ratio with standard values for hyperparameters. The comparative analysis performed is fair, since in the proposed work a five-fold cross validation is performed, which indicates that each sample in the dataset has been a part of the test set in either of the five iterations, and moreover the average performance of the five iterations is reported. It can be observed from the comparative study that, the proposed design comparatively performed better. It can be inferred from Table 5 , that the method proposed overcomes the approaches reported in literature in terms of all the evaluation parameters. ",
            "cite_spans": [
                {
                    "start": 151,
                    "end": 154,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 376,
                    "end": 379,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 566,
                    "end": 569,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 726,
                    "end": 730,
                    "text": "[35]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [
                {
                    "start": 131,
                    "end": 138,
                    "text": "Table 5",
                    "ref_id": null
                },
                {
                    "start": 1644,
                    "end": 1651,
                    "text": "Table 5",
                    "ref_id": null
                }
            ],
            "section": "Comparative analysis"
        },
        {
            "text": "The major objective of the proposed study is the classification of covid-19 and non-covid-19 classes using chest CT images with higher classification performance. To avoid problems pertaining to overfitting and under fitting, a computer-aided diagnostic experts need to address three major issues: (i) sufficient data is required to prevent under fitting, (ii) achieving a balance between sensitivity and specificity, and (iii) hyperparameters used to use build the CNN architecture should be carefully chosen to avoid overfitting. The proposed study aims to address the aforementioned limitations. At present, the number of publicly available covid-19 CT images is limited. Hence, to improve the classification performance, a robust set of AdaBoost of stump trees are built using dynamic selection techniques. Additionally, to avoid overfitting the training parameters are chosen until the best values obtained from a WOA-BAT optimizer with MSE of the MLP as objective function. To prove the robustness and reliability of the proposed design, the features extracted from the standard CNN architectures and the features extracted from the optimized CNN architectures are compared. As it can be seen from Fig. 6 , the separability between the two classes of the data is quite high using WOA-BAT optimized CNN as compared to the features extracted from the standard CNN architectures (AlexNet, ResNet, VGG-19, Densenet, and Inception). Also, the classification performance of covid-19 images improved to 98% using the proposed method compared to the standard CNN architecture. The salient features of the proposed study are as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1204,
                    "end": 1210,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Discussion and remarks"
        },
        {
            "text": "1. Hyperparameters of the classifier play a major role in classification.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and remarks"
        },
        {
            "text": "Thus, an appropriate choice of hyperparameters is crucial in improving the classifier performance. 2. The features extracted from the optimized CNN, although few in number (2), exhibit a great degree of separability between the two classes. 3. AdaBoost of ensemble classifiers built using dynamic ensemble selection techniques produced considerably better performance in the classifying covid-19 and non-covid-19 CT images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and remarks"
        },
        {
            "text": "The proposed system was implemented on a 64-bit CPU based system with 8 GB RAM, and processor speed of 2.3 GHz. Hence the processing time required to test a single image was 30s, which is a limitation of the proposed system, However, a higher end GPU based system can reduce the processing time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion and remarks"
        },
        {
            "text": "In this study, an optimized CNN-based architecture is proposed for detection of covid-19 cases from non-covid CT images accurately. The hyperparameters of CNN are application dependent and play a major role in the performance of the classifier. Hence, we have incorporated an ensemble of WOA-BAT technique to optimize CNN parameters. The optimized CNN is used for feature extraction. In this work, we have observed that, in contrast to the features extracted from five standard CNN architectures (2185), the features extracted from the optimized CNN (2 features), showed better discriminative ability. Although a BGWO technique is used to eliminate the redundant features, from the original 5000 features obtained from the well-known CNN designs, the two features extracted from optimized CNN outperformed, and significantly improved the classification accuracy. We have obtained the highest classification accuracy of 96% for predicting covid-19. Further, the optimized CNN is also compared with performance obtained from the unoptimized CNN built using standard values of hyperparameters. Our proposed method yielded better performance with standard CNN architecture irrespective of the limited dataset. The summary of comparison with the state-of-the-art techniques developed for automated detection of covid-19 using chest CT images obtained from the same dataset given in Table 5 proves the superiority of the proposed method [5, 6, 34] . Our developed prototype can be used as a pre-screening software for covid-19, especially in remote villages with limited access to health monitoring facilities. The proposed diagnosis method also eliminates the need for the CNN model to be trained using large datasets. The developed system can also be used for the automated detection of various pathologies using medical images of followed by the optimization methodology, however with a variation in the hyperparameter values based on the type of dataset.",
            "cite_spans": [
                {
                    "start": 1431,
                    "end": 1434,
                    "text": "[5,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1435,
                    "end": 1437,
                    "text": "6,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1438,
                    "end": 1441,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [
                {
                    "start": 1377,
                    "end": 1384,
                    "text": "Table 5",
                    "ref_id": null
                }
            ],
            "section": "Conclusion"
        },
        {
            "text": "In the future, we intend to evaluate the robustness of our developed design using more chest covid-19 CT images collected from local hospitals and polyclinics. This generated economical user-friendly system can be accessed by clinicians to obtain a second opinion about their manual diagnosis. Also, we intend to extend this work with more classes like pneumonia in addition to covid-19 and normal classes. Fig. 11 . Graphical illustration of performance parameters obtained using optimized and unoptimized CNNs.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 407,
                    "end": 414,
                    "text": "Fig. 11",
                    "ref_id": null
                }
            ],
            "section": "Conclusion"
        },
        {
            "text": "Summary of comparison with state-of-the-art approaches developed for automated prediction of Covid-19 using CT images obtained from the same dataset. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Table 5"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Risk factors prediction, clinical outcomes, and mortality in COVID-19 patients",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Behjati",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Roshanzamir",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Abedini",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M S"
                    ],
                    "last": "Islam",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "J. Med. Virol",
            "volume": "93",
            "issn": "4",
            "pages": "2307--2320",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Chest CT in COVID-19: what the radiologist needs to know",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "C"
                    ],
                    "last": "Kwee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Kwee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "40",
            "issn": "",
            "pages": "1848--1865",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Relation between chest CT findings and clinical conditions of coronavirus disease (COVID-19) pneumonia: a multicenter study",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Am. J. Roentgenol",
            "volume": "214",
            "issn": "5",
            "pages": "1072--1077",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "COVID-19 detection in CT images with deep learning: a voting-based scheme and crossdatasets analysis",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Luz",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Moreira",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lucio",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Menotti",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Informatics in Medicine Unlocked",
            "volume": "20",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Sample-Efficient Deep Learning for COVID-19 Diagnosis Based on CT Scans, medRxiv",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Radiologist-Level COVID-19 Detection Using CT Scans with Detail-Oriented Capsule Networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mobiny",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Cicalese",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zare",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Abavisani",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Van Nguyen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.07407"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A Light CNN for Detecting COVID-19 from CT Scans of the Chest",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Polsinelli",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Cinque",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Placidi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.12837"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Weakly supervised deep learning for covid-19 infection detection and classification from ct images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Niu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "118869--118883",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "A weakly-supervised framework for COVID-19 classification and lesion localization from chest CT",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans. Med. Imag",
            "volume": "39",
            "issn": "8",
            "pages": "2615--2625",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "COVIDiag: a clinical CAD system to diagnose COVID-19 pneumonia based on CT findings",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Ardakani",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Habibollahi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Eur. Radiol",
            "volume": "31",
            "issn": "1",
            "pages": "121--130",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Classification of COVID-19 in Chest CT Images Using Convolutional Support Vector Machines",
            "authors": [
                {
                    "first": "U",
                    "middle": [],
                    "last": "Zkaya",
                    "suffix": ""
                },
                {
                    "first": "\u015e",
                    "middle": [],
                    "last": "Zt\u00fcrk",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Budak",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Melgani",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Polat",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2011.05746"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Classification of Coronavirus (COVID-19) from X-ray and CT images using shrunken features",
            "authors": [
                {
                    "first": "\u015e",
                    "middle": [],
                    "last": "Zt\u00fcrk",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Zkaya",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Barstugan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Int. J. Imag. Syst. Technol",
            "volume": "31",
            "issn": "",
            "pages": "5--15",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Diagnosing COVID-19 Pneumonia from X-Ray and CT Images Using Deep Learning and Transfer Learning Algorithms",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Maghdid",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "T"
                    ],
                    "last": "Asaad",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Z"
                    ],
                    "last": "Ghafoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Sadiq",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Khan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.00038"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Automated Detection and Forecasting of Covid-19 Using Deep Learning Techniques: A Review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shoeibi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khodatars",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jafari",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moridian",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Srinivasan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2007.10785"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: results of 10 convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Ardakani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "R"
                    ],
                    "last": "Kanafi",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Khadem",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput. Biol. Med",
            "volume": "121",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Automated Detection of Covid-19 from Chest X-ray scans using an optimized CNN architecture",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pathan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "C"
                    ],
                    "last": "Siddalingaswamy",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Appl. Soft Comput",
            "volume": "104",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Rethinking the inception architecture for computer vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "2818--2826",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Commun. ACM",
            "volume": "60",
            "issn": "6",
            "pages": "84--90",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "A new optimizer using particle swarm theory",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Eberhart",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kennedy",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science",
            "volume": "",
            "issn": "",
            "pages": "39--43",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Ant colony optimization",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Dorigo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Birattari",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Stutzle",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "IEEE Comput. Intell. Mag",
            "volume": "1",
            "issn": "4",
            "pages": "28--39",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Optimization by simulated annealing: quantitative studies",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kirkpatrick",
                    "suffix": ""
                }
            ],
            "year": 1984,
            "venue": "J. Stat. Phys",
            "volume": "34",
            "issn": "5-6",
            "pages": "975--986",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "How effective is the Grey Wolf optimizer in training multi-layer perceptrons",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Appl. Intell",
            "volume": "43",
            "issn": "1",
            "pages": "150--161",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Handbook of Deep Learning in Biomedical Engineering and Health Informatics",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "G"
                    ],
                    "last": "Julie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "H"
                    ],
                    "last": "Robinson",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Binary grey wolf optimization approaches for feature selection",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Emary",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "M"
                    ],
                    "last": "Zawbaa",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Neurocomputing",
            "volume": "172",
            "issn": "",
            "pages": "371--381",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "The whale optimization algorithm",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lewis",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Adv. Eng. Software",
            "volume": "95",
            "issn": "",
            "pages": "51--67",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A Systematic and Meta-Analysis Survey of Whale Optimization Algorithm",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "M"
                    ],
                    "last": "Mohammed",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "U"
                    ],
                    "last": "Umar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Rashid",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Computational intelligence and neuroscience",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Bat algorithm for multi-objective optimisation",
            "authors": [
                {
                    "first": "X",
                    "middle": [
                        "S"
                    ],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Int. J. Bio-Inspired Comput",
            "volume": "3",
            "issn": "5",
            "pages": "267--274",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Dynamic selection of classifiers-a comprehensive review",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Britto",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sabourin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "E"
                    ],
                    "last": "Oliveira",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Pattern Recogn",
            "volume": "47",
            "issn": "11",
            "pages": "3665--3680",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Analyzing dynamic ensemble selection techniques using dissimilarity analysis",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Cruz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sabourin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Cavalcanti",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "IAPR Workshop on Artificial Neural Networks in Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "59--70",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Covid-ct-dataset: A Ct Scan Dataset about Covid19",
            "authors": [
                {
                    "first": "Jinyu",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Yichen",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Xuehai",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Pengtao",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.13865"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Multi-task Deep Learning Based CT Imaging Analysis for COVID-19: Classification and Segmentation, medRxiv",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Amyar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Modzelewski",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ruan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "An ensemble approach for multi-stage transfer learning models for COVID-19 detection from chest CT scans",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "F H"
                    ],
                    "last": "Cruz",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Intelligence-Based Medicine",
            "volume": "5",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: experimental analysis of power",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Garc\u00eda",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Fern\u00e1ndez",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Luengo",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Herrera",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Inf. Sci",
            "volume": "180",
            "issn": "10",
            "pages": "2044--2064",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "An extension on\" statistical comparisons of classifiers over multiple data sets\" for all pairwise comparisons",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Garcia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Herrera",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "J. Mach. Learn. Res",
            "volume": "9",
            "issn": "12",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Dynamic classifier selection: recent advances and perspectives",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Cruz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sabourin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "D"
                    ],
                    "last": "Cavalcanti",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Inf. Fusion",
            "volume": "41",
            "issn": "",
            "pages": "195--216",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "From dynamic classifier selection to dynamic ensemble selection",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Ko",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sabourin",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Britto",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Pattern Recogn",
            "volume": "41",
            "issn": "5",
            "pages": "1718--1731",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Overview of the proposed model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Proposed Covid-19 detection system using hyperparameter optimization with WOA-BAT.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Graphical illustration of parameter and objective space using WOA-BAT.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Illustration of CNN architecture.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Accuracy (ACC) = (TP + TN ) TP + TN + FP + FN(17)Sensitivity (SE) = TP/(TP + FN)(18)Specificity (SP) = TN/(TN + FP)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Distribution of features obtained for the two class problem: (a) Features extracted from optimized CNN (model 2), (b-d) Features obtained after applying BGWO to the features extracted using model 1.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "ROC obtained for model 1 using five-fold CV.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Confusion matrices obtained for each fold for model-1 using various ensemble techniques: (a) Ensemble, (b) OLA, (c) LCA, (d) A-Pr, (e)A-Po, (f) K-E, (g) K-U [Column 1: First fold, Column 2: Second fold, Column 3: Third fold, Column 4: Fourth fold, Column 5: Fifth fold]. * N-C refers to non covid samples, and C refers to covid samples.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "ROC obtained for model 2 using five-fold CV.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Confusion matrices obtained for each fold for model-2 using various ensemble techniques: (a) Ensemble, (b) OLA, (c) LCA, (d) A-Pr, (e)A-Po, (f) K-E, (g) K-U [Column 1: First fold, Column 2: Second fold, Column 3: Third fold, Column 4: Fourth fold, Column 5: Fifth fold].",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Note: GLCM-Grey Level Co-occurrence Matrix, LBGLCM-Local Binary Grey Level Co-occurrence Matrix, GLRLM-Grey Level Run Length Matrix, SFTA-Seg-Based Fractal texture analysis, SAE-Stacked Encoder, PCA-Principal Component Analysis.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Hyperparameters obtained from WOA-BAT.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Results of classification obtained using five-fold cross-validation for Model 1.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Results of classification obtained using five-fold cross-validation for model 2.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        }
    ]
}