{
    "paper_id": "4f9ee68781b7416c2cab626fab784a153ed39187",
    "metadata": {
        "title": "Randomly Initialized Convolutional Neural Network for the Recognition of COVID-19 using X-ray Images",
        "authors": [
            {
                "first": "Henda",
                "middle": [
                    "Ben"
                ],
                "last": "Gh\u00e9zala",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Wadii",
                "middle": [],
                "last": "Boulila",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Maha",
                "middle": [],
                "last": "Driss",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Safa",
                "middle": [
                    "Ben"
                ],
                "last": "Atitallah",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "By the start of 2020, the novel coronavirus disease (COVID-19) has been declared a worldwide pandemic. Because of the severity of this infectious disease, several kinds of research have focused on combatting its ongoing spread. One potential solution to detect COVID-19 is by analyzing the chest Xray images using Deep Learning (DL) models. In this context, Convolutional Neural Networks (CNNs) are presented as efficient techniques for early diagnosis. In this study, we propose a novel randomly initialized CNN architecture for the recognition of COVID-19. This network consists of a set of differentsized hidden layers created from scratch. The performance of this network is evaluated through two public datasets, which are the COVIDx and the enhanced COVID-19 datasets. Both of these datasets consist of 3 different classes of images: COVID19, pneumonia, and normal chest X-ray images. The proposed CNN model yields encouraging results with 94% and 99% of accuracy for COVIDx and enhanced COVID-19 dataset, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The novel coronavirus (COVID-19) appeared in Wuhan, China at the end of 2019, and by 11 March 2020, the World Health Organization (WHO) 1 categorized this virus as a pandemic. COVID-19 has spread rapidly in different parts of the world and to date has resulted in almost three million deaths. As demonstrated in Figure 1 , the number of confirmed cases increases day by day and had reached about 725,275 cases on May 13, 2021. In the United States alone, the number of deaths caused by COVID-19 surpassed 575,000 cases by May 4, 2021. Figure 2 illustrates the total number of COVID-19 deaths in the most impacted countries worldwide. Patients infected with COVID-19 exhibit some similar symptoms compared to those infected with the general flu, such as fever, cough, headaches, and loss of taste or smell. Additionally, more serious symptoms include difficulty or shortness of breath, pain in the chest, and the inability to speak or move normally. Although COVID-19 causes only mild illness for most, it can be fatal for others, especially for older people and those with preexisting medical conditions such as heart problems and high blood pressure. About 15% of COVID-19 cases progress to grave diseases, and 5% become critical cases. The early diagnosis of COVID-positive patients is crucial for avoiding further spread and minimizing the cases of critical illness.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 312,
                    "end": 320,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 535,
                    "end": 543,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Because of the fast spread of the virus, many types of interdisciplinary research have focused on finding ways of combatting it. Detecting In this study, we propose a RaNDomly initialized Convolutional Neural Network (RND-CNN) to classify chest X-ray images and recognize the patient's condition as one of three classes: pneumonia,  or normal state. Randomized Neural Networks (RNN) are defined as neural networks with multi-layered architecture, where the connections between these layers are untrained before the initialization [17] . Recent works show an acceptable performance of the randomly weighted neural networks for feature extraction and classification that is correlated with the results of pre-trained models [18] [19] .",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 138,
                    "text": "Detecting",
                    "ref_id": null
                },
                {
                    "start": 332,
                    "end": 332,
                    "text": "",
                    "ref_id": null
                },
                {
                    "start": 530,
                    "end": 534,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 727,
                    "end": 731,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The following objectives outline our specific goals in this work: 1. Propose a classification CNN model for the automatic recognition of COVID-19, where the connection between layers is randomly initialized; 2. Study the impact of data pre-processing and balancing as a means of enhancing the performance of the proposed model; 3. Apply different techniques of data augmentation on the dataset samples, such as rotation, flips, and scaling; 4. Testing the proposed method using different datasets, including the COVIDx dataset with more than 15000 chest X-ray images, and the enhanced COVID-19 dataset that consists of more than 1000 enhanced images; 5. Compare the performance of the proposed model with other models that use different weight initialization techniques as well as methods proposed in previous works.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 68,
                    "text": "1.",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This paper is structured as follows. Section 2 presents an overview of the basic concepts of CNN and initialization methods. Section 3 provides details about the architecture of our proposed model. In Section 4, we describe the considered datasets and how we have prepared the data to be used in our own model. Section 5 deals with the experiments carried out and the obtained results. Section 6 discusses some comparisons conducted between our proposed model and other existing models using different weight initialization techniques. Finally, Section 7 draws out concluding remarks and future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this section, we present basic knowledge related to CNN and weight initialization methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Background and Basic Concepts"
        },
        {
            "text": "Healthcare services have been improved by the rapid development of DL techniques [20] . Different applications have been proposed and developed for different healthcare services, including elderly care and disease prediction [21] [22] [23] . CNN, for instance, has been presented as a deep neural network that consists of a sequence of layers, wherein different filter operations are performed [24] [25] . This type of DL model is suitable for processing images and/or videos. Because CNN employs supervised learning, it is classified as a discriminative DL architecture [26] .",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 85,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 225,
                    "end": 229,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 230,
                    "end": 234,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 235,
                    "end": 239,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 394,
                    "end": 398,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 399,
                    "end": 403,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 571,
                    "end": 575,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "This network has a set of layers that starts with an input layer, then includes a set of hidden layers, and finally ends with an output layer. It consists of a sequence of convolutional and pooling layers followed by a fully connected layer. In each of these convolutional layers, several filters are embedded. These filters produce different analyses on the input data to produce feature maps.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "Three essential layers build up the CNN network: the convolutional layer, the pooling layer, and the fully connected layer [27] . A brief definition of these layers is presented in the following points:",
            "cite_spans": [
                {
                    "start": 123,
                    "end": 127,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "\uf0b7 Convolutional layer: the CNN model begins with this layer. Here, a filter is applied over the input image that is converted into a matrix. A feature map is the output of the convolutional layer that includes the learned features. Briefly, a filter is presented as a simple matrix with a predefined size smaller than the input data as well as randomly chosen values. This filter goes through the input data from left to right, and then goes down with a step size specified by the stride until it covers the completely input matrix. Equation (1) represents the convolutional layer process:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "where x is the input image, is the jth convolutional layer output, is the activation function, presents the convolutional kernel multiplied by the ith input , and denotes the bias. We illustrate convolutional operations in Figure 3 . \uf0b7 Pooling layer: this layer is applied to lower the complexity of the CNN model. The pooling layer captures the most relevant parts of the generated feature maps by applying an average or max-pooling operation. The pooling operation applies a kernel, or a predefined window, on the feature map. This kernel is responsible for gathering the average or maximum value of the matrix elements according to the method being used, and it slides across the whole feature map with a predefined stride. Figure 4 depicts the pooling layer using the maxpooling operation. In the illustrated example, four slide positions are performed on the feature map, as presented in Figure 4 with the different colors. The resultant pooling values demonstrate how the complexity of the model computations will be reduced. \uf0b7 Fully connected layer: this layer performs the last step in this network, reconnecting the processed portions in order to obtain the full image. The two-dimensional array is converted into a single list. Using different activation functions, which are Sigmoid, Tanh, and ReLu, this layer is converted to probability values, which indicate the probability that the processed image will be in a specific class. Based on the highest probability value, the output layer assigns the image to its output class.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 223,
                    "end": 231,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 727,
                    "end": 735,
                    "text": "Figure 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 893,
                    "end": 901,
                    "text": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "Generally, the convolutional and pooling layers are stacked together at the head of the architecture. Unlike the convolutional and pooling layers, the fully connected layers are stacked with each other at the end of the network architecture.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Architecture of Convolutional Neural Network"
        },
        {
            "text": "CNNs have demonstrated effective performance in many different areas, including image classification and recognition. One of the greatest advantages of CNN is its ability to extract and learn hidden features from big datasets and raw data. CNN goes through a set of steps, as explained in the following paragraph [26] [27] .",
            "cite_spans": [
                {
                    "start": 313,
                    "end": 317,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 318,
                    "end": 322,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "How Do CNNs Work?"
        },
        {
            "text": "Once the training phase starts, the input layer assigns the weights to the input data to be passed to the next layer. According to the type of initializer, the weights are determined to have either constant values or random values. The following layers get the input weights, perform the filter operations, and determine the output that is passed as an input to the next layer. In the last layer, the final output is defined. Within the training process, a loss function is used to examine the prediction's performance. This function calculates the error rate by examining and comparing both predicted and actual results. Various loss functions are designed for different purposes. For example, the binary cross-entropy function is used to deal with classification problems that distinguish between only two classes, categorical cross-entropy is used for classification problems with more than two classes, and mean-squared error is used for regression problems. In order to check the neuron's weights, different optimization algorithms can be utilized, such as Adam and Stochastic Gradient Descent. These algorithms examine the gradient of the loss function and then attempt to change and update the network weights or learning rates to minimize the losses. This set of steps are repeated throughout the training phase until the weights become balanced for each layer's neuron and the error rate value falls. Once the training has finished, the model is ready for use.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "How Do CNNs Work?"
        },
        {
            "text": "Tuning the right parameters of a CNN model helps to improve its performance. These parameters include the internal values of the model configuration, which are estimated from data such as the weights between neural network layers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "How Do CNNs Work?"
        },
        {
            "text": "In order to understand the importance of weight initialization, it is first crucial to understand the neurons or the units that make up each layer of the CNN. These neurons take the input data and operate calculations upon it in order to achieve a weighted summation, and then produce an output through an activation function [28] . Every neuron consists of weights and a bias. In the first layer, the weights are initialized and assigned according to input size, while the bias is optimized throughout the training process. The structure of a neuron is depicted in Figure 5 . Weight initializers are meant to regulate the initial weight values of neural network layers [29] . The process of weight initialization is intended to keep the layer activation outputs away from the common problem of gradient vanishing and exploding. In particular, the vanishing gradients occur due to back-propagation during the training phase [30] . Propagating a feedback signal from the output loss to the earlier layers may affect it, and signals may then become weak or get lost, making the network untrainable. Therefore, a careful weight setting is required in order to achieve better results and higher performance.",
            "cite_spans": [
                {
                    "start": 326,
                    "end": 330,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 670,
                    "end": 674,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 924,
                    "end": 928,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 566,
                    "end": 574,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Weight Initialization"
        },
        {
            "text": "There are three categories of initialization methods [31] . The first category includes the constant methods that employ the same set of weights for the network connections' initialization, such as the zero and the one initializers. However, when using these initialization methods, the equations of the learning algorithm often become incapable of changing or updating the network weights, which leads the model to become locked. For all iterations, then, all layers have the same weights and perform the same calculations. The second category presents the distribution methods for initialization, wherein the Gaussian or the uniform distribution is used, and input matrix numbers are assigned with random values. However, assigning the appropriate parameters for the network-including the mean and the standard deviation of the distribution-may be done incorrectly, which affects the performance of the model training and may lead to the problem of vanishing gradients. The third category is the random initialization based on previous knowledge. To initialize layer weights, heuristics are used in addition to the nonlinear activation functions. \"Heuristics\" is a term used to define the approach of solving a problem without using a method that ensures an optimal solution. Using this type of randomization, the normal distribution variance is assigned based on the number of inputs. Heuristics largely mitigate the issue of exploding or vanishing gradients, but they cannot prevent this issue entirely. Table 1 compares the different types of neural networks initialization.",
            "cite_spans": [
                {
                    "start": 53,
                    "end": 57,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [
                {
                    "start": 1508,
                    "end": 1515,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Weight Initialization"
        },
        {
            "text": "Randomized initialization methods with previous knowledge serve as a good starting point for weight initialization. The main advantages of this means of initialization are its ability to:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Weight Initialization"
        },
        {
            "text": "\uf0b7 initialize the layer weights randomly but more intelligently; \uf0b7 reduce the chances of falling in gradients vanishing and exploding; \uf0b7 help avoid slow speeds of convergence; \uf0b7 mitigate the oscillating of minima. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Weight Initialization"
        },
        {
            "text": "In this section, we will detail the architectural design of the proposed RND-CNN, as well as the techniques used for data preprocessing. Our motivation here is to develop a deep CNN for automatically learning the features and recognizing COVID-19 using two different datasets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Method"
        },
        {
            "text": "The proposed RND-CNN consists of an input layer and four hidden blocks for features learning and extracting, followed by two fully connected layers and a SoftMax layer for case classification (classes: COVID-19/Pneumonia/Normal). Figure 6 presents the proposed RND-CNN architecture. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 230,
                    "end": 238,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Proposed Method"
        },
        {
            "text": "The Xavier initializer is a form of randomly based knowledge initialization. To solve the problem of selecting correct parameters, this initializer is used to automatically determine the scale of initialization according to the number of input and output neurons [32] . This method helps keep the signal within a reasonable range of values between layers.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 267,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "Let y denotes the output of a layer; its value is computed according to equation (2):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "where i presents the input image matrix, w is the weight, and is a bias.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "Using the Xavier initializer, the weights are initialized in such a way that the variance of the input and output remains the same. The values of these weights are calculated using equation (3).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "where n signifies the number of layer neurons.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "Thus, the network weights are initialized in such a way that the neuron activation functions are neither too small nor too large within a reasonable range. The values of the weights that connect two successive layers are usually initialized within the following range:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Random Initialization: Xavier Initializer"
        },
        {
            "text": "In this section, we introduce the design of the proposed RND-CNN. As previously mentioned, this network consists of an input layer, four hidden blocks, and a classification layer. The input images of the network are sized as (150, 150, 3), while the output can be one of three different classes: normal, pneumonia, and COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Network Architecture"
        },
        {
            "text": "This network model consists of four different-sized hidden blocks. Each block consists of a set of convolutional and pooling layers. As we go deeper within the model architecture, the number of convolutional layers increases. Consequently, this difference in layer blocks gives the model a high ability for covering different features through the set of convolutions. The model comes with a significant reduction in the number of parameters and has the ability to achieve high performance within a reasonable execution time compared to other existing CNNs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Network Architecture"
        },
        {
            "text": "Before the model training, we have to assign its initial parameters. We adopt the Xavier initializer to define the weights of the network. This method is proposed by Glorot and is based on the assumption that the activation function is linear.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Network Architecture"
        },
        {
            "text": "The proposed model consists of 10 convolutional layers and 4 pooling layers. For each convolutional layer, filters with size (3 \u00d7 3) are applied with padding, and every pooling layer implements a max-pooling window of size (2 \u00d7 2). In the following, \"Conv2D'', \"MaxPool2D\", and \"FC\" refer to the convolution, the pooling, and the fully connected layers, respectively. Table 2 illustrates the architecture of our proposed CNN and defines the used learning parameters. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 368,
                    "end": 375,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Network Architecture"
        },
        {
            "text": "Input layer Images input layer Input shape= (150, 150, 3)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Layer Description Values"
        },
        {
            "text": "Hidden block 1",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Layer Description Values"
        },
        {
            "text": "Hidden block 2",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Layer Description Values"
        },
        {
            "text": "Hidden block 3 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Layer Description Values"
        },
        {
            "text": "In order to validate the proposed approach, we have used two different datasets for model evaluation. A description of these datasets and how we preprocess them are provided in the following subsections.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "In this work, we used the COVIDx dataset recently created and published by COVID-Net researchers [11] . COVIDx is an open-access benchmark dataset that is continuously updated and enriched with the addition of more images from different sources [33] . The version of the dataset that we used consists of more than 15,000 chest X-ray images, created as a combination and a modification of five open access data repositories. It includes three different types of images, namely: 1) Normal (no infection), 2) Pneumonia, and 3) COVID-19. The dataset consists of two image folders: one for training and one for testing. The distribution of these images is depicted in Table 3 . COVIDx collects its data from five different datasets. As a result, the images in this dataset are of all different sizes and shapes. These differences affect the classification effectiveness, so in order to enhance the classification performance, image preprocessing is first applied to all images across the dataset. All input images for the proposed method are resized to a standard size, which is defined with height: 150 and width: 150.",
            "cite_spans": [
                {
                    "start": 97,
                    "end": 101,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 245,
                    "end": 249,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [
                {
                    "start": 663,
                    "end": 670,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "COVIDx Dataset"
        },
        {
            "text": "It is also worth noting that the dataset is imbalanced. The number of COVID-19 X-ray images is fewer compared to the images available for the other classes (Pneumonia and Normal). However, it is important to work with balanced data to get better results [34] . Imbalanced datasets return inaccurate results because they bias the model towards the predictions of the majority class. Different techniques have been proposed to handle this problem, including random oversampling, random undersampling, Synthetic Minority Oversampling Technique (SMOTE), and classes' reweight [35] . Undersampling consists of randomly sampling from the majority class and reducing its number of instances to be equilibrated with the other classes.",
            "cite_spans": [
                {
                    "start": 254,
                    "end": 258,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 572,
                    "end": 576,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "On the other hand, oversampling treats the minority class by replicating its samples to be balanced with other classes. SMOTE is a type of oversampling method that generates new instances from the samples of the minority class. However, SMOTE is not effective for high dimensional data and may lead the model to be overfitted. The class reweight method is to directly consider the asymmetry of cost errors within the model training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "Due to the severe imbalance between the classes in the COVIDx dataset, resampling methods are not suitable for our problem. Our goal is to detect COVID-19 from X-ray images, but as mentioned above, we did not have as many samples of those images to work with. Because of the high dimensionality of the used dataset, we choose to apply the class reweight as a balancing method which penalized the model if a positive sample is misclassified [36] . To do this, we calculate the weight for each class and assign these to the classifier model. The heaviest weight is applied for the COVID-19 class, which allows the model to pay more attention to the COVID-19 samples:",
            "cite_spans": [
                {
                    "start": 440,
                    "end": 444,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "\u2022 Weight for COVID-19 class: 9.57 \u2022 Weight for Normal class: 0.57 \u2022 Weight for Pneumonia class: 0.83",
            "cite_spans": [],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "The weight of each class is computed using equation (5):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "Where represents the weight for the class, n is the total number of samples, k is the number of classes, and is the number of samples in class i.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "COVIDx Dataset"
        },
        {
            "text": "The second dataset 2 used to test our model was merged and enhanced by Canayas [37] . The dataset consists of more than 1000 images and includes three balanced classes: COVID-19, pneumonia, and normal chest X-ray images. The images of the dataset are gathered from two different sources. The first part contains 145 images of labelled COVID-19 X-ray images available on GitHub 3 . The second part is collected by Chowdhury et al. [38] , publicly available on Kaggle, and contains 219 images for COVID-19 infected chests. The distribution of chest X-ray images in the enhanced COVID-19 dataset is depicted in table 4. In [37] , the author made some changes to the dataset by applying a contrast enhancement on each image of the original dataset. Using the Image Contrast Enhancement Algorithm (ICEA) [39] , the best contrast was applied on the dataset images and the noise was eliminated. Figure  8 plots some samples of X-ray images from this enhanced dataset. ",
            "cite_spans": [
                {
                    "start": 79,
                    "end": 83,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 430,
                    "end": 434,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 620,
                    "end": 624,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 799,
                    "end": 803,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [
                {
                    "start": 888,
                    "end": 897,
                    "text": "Figure  8",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Enhanced COVID-19 Dataset"
        },
        {
            "text": "While CNNs offer several benefits and can make great strides in solving important problems, these networks rely heavily on big data to learn properly. Unfortunately, many different use cases, especially in the healthcare field, do not have the types of big data needed for these purposes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data Augmentation"
        },
        {
            "text": "Data augmentation is the approach of providing the learning model with more training data to avoid overfitting [40] . Overfitting occurs when a model learns a function with high variance, which means that it models the training data well but does not perform properly with new data, leading to a poor generalization [41] . With data augmentation, more images are generated through different random transformations applied to the existing dataset images [42] . As the size of input data increases, this helps to improve the training model's generalization abilities.",
            "cite_spans": [
                {
                    "start": 111,
                    "end": 115,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 316,
                    "end": 320,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 453,
                    "end": 457,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Data Augmentation"
        },
        {
            "text": "In this work, we choose to apply six augmentation strategies for data augmentation and transformations, including scaling, horizontal flip, random rotation (10 degrees), zoom, intensity shift, and lighting conditions. The images of the datasets are flipped horizontally; we do not apply vertical flips since they do not reflect the images in their normal form. Thus, data augmentation was employed to enlarge the training dataset, while valid and test data were not augmented. Figure 9 illustrates some samples of X-ray images resulting from the data augmentation process. Figure 9 : Samples of training X-ray images resulting from the data augmentation process.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 477,
                    "end": 485,
                    "text": "Figure 9",
                    "ref_id": null
                },
                {
                    "start": 573,
                    "end": 581,
                    "text": "Figure 9",
                    "ref_id": null
                }
            ],
            "section": "Data Augmentation"
        },
        {
            "text": "In this section, we present the experimental setup, workflow, and parameters. Then, we describe the used metrics for the evaluation of the model performance. After that, we discuss the obtained results and examine the impact of data augmentation and balancing on the proposed model performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments"
        },
        {
            "text": "In this study, Jupyter notebook was used to encode the whole process in Python 3.8. Both the Keras library [43] and the TensorFlow backend [44] were also used to program neural networks. Keras is a high-level library that works on top of TensorFlow and Theano frameworks and is suitable for convolutional networks as it delivers high performance when conducting multiple experiments. TensorFlow is a flexible DL framework developed using C++, and it helps to run experiments with low latency and high performance. In addition to these Keras and TensorFlow, OpenCV was used for data loading and pre-processing, while Sci-Kit Learn was used to generate the classification reports.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 111,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 139,
                    "end": 143,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                }
            ],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "For faster computation, we used the Nvidia GeForce MX 250 GPU with CUDA and cuDNN library. cuDNN is a GPU-accelerated library designed to optimize different DL frameworks. The infrastructure used to conduct our experiments was a PC with the following configuration: an x64-based processor; an Intel Core i7-8565U CPU @ 1.80GHz 1.99GHz; and a 16 GB RAM running on Windows 10 with NVIDIA GeForce MX.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup"
        },
        {
            "text": "The experimentation workflow consists of a set of steps, including: (1) data preprocessing, (2) data augmentation, (3) model training, (4) model evaluation using the validation data, (5) final evaluation of the model with the best weights using the test data, and (6) calculation of the performance metrics. These steps are detailed and illustrated in Figure 10 . ",
            "cite_spans": [
                {
                    "start": 183,
                    "end": 186,
                    "text": "(5)",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [
                {
                    "start": 352,
                    "end": 361,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Experimentation Workflow Overview"
        },
        {
            "text": "The model configuration was set up as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Parameters Tuning"
        },
        {
            "text": "1. Initializer: before starting the training process, we initialize the layers with proper weights to ensure accurate functions. In this context, we have used the Xavier initializer with a learning rate value of (1e-4). This initializer is capable of determining the scale of initialization randomly according to the input and output nodes number. 2. Optimizer: the Adam optimizer [45] , which was proposed recently as an extension to the stochastic gradient descent [46] , is used for its ability to reach good performance in a short time. 3. Loss function: categorical cross-entropy function was used to measure the network's performance on the training data. 4. Activator: rectified linear unit (ReLu) [47] has been used as an activation function.",
            "cite_spans": [
                {
                    "start": 381,
                    "end": 385,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 467,
                    "end": 471,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 705,
                    "end": 709,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Parameters Tuning"
        },
        {
            "text": "ReLu is known as a faster training function compared to other functions such as sigmoid, tanh, etc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Parameters Tuning"
        },
        {
            "text": "Precision, accuracy, sensitivity, specificity, loss, and f1-score measures are used to evaluate this work. These terms are defined as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Performance Metrics"
        },
        {
            "text": "\u2022 Precision: is used to assess the number of true classes classified by the model, which means the model's ability to not classify a negative sample as positive. Therefore, a high precision indicates that the errors in classification are low. \u2022 Accuracy: is the ratio of the number of correct predictions to the total number of input samples. High accuracy requires high precision. \u2022 Sensitivity: used to assess the overall number of correctly predicted labels according to the total number of labels that are predicted. This factor describes the model's ability to classify the samples correctly. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Performance Metrics"
        },
        {
            "text": "In this section, we present the experimental results obtained by applying the proposed RND-CNN on two different datasets, which are COVIDx and enhanced COVID-19 datasets. We demonstrate also the effectiveness of the proposed model by showing the impact of data augmentation and balancing through several performance measures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "In this subsection, we illustrate the details and the results obtained by implemented the proposed approach described in Section 3 using the COVIDx dataset. For model building, we have to start with three sets of data: training, validation, and test. The training data are used to train the model, while the validation data are utilized for evaluating it during the training process. Once the model completes training, the test data are employed to test its performance. Following this distribution, we randomly split the training folder of the COVIDx dataset into 80% and 20% for training and validation, respectively. Figure 11 represents the distribution of images of each class into training, validation, and test sets. The proposed RND-CNN was trained using the COVIDx dataset over 100 epochs. Figure 12 visualizes the accuracy and loss of the RND-CNN during the training and validation phases. During the training, the model achieved 95% accuracy, while the value of loss continued to decrease until it has reached its minimum by the end of training. After that, the overall performance of our proposed RND-CNN was tested using more than 1500 new chest X-ray images. According to Table 5 , our proposed model achieved an accuracy of 95% in training, 92% in validation, and 94% in testing. Figure 13 shows that we obtained a high area under the ROC curve for COVID-19, pneumonia, and normal classes, which demonstrates that our approach achieved good performance. Examples of features extracted from chest X-ray images across the first, the second, and the last convolution layers are presented in Figure 14 . Additional interesting observations are discovered in feature maps as we dive into layers. In the first convolutional layer, the edges of the image are detected and most of its information are scanned. Going deeper into the CNN, the filters focus further on specific features. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 620,
                    "end": 629,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 799,
                    "end": 808,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1186,
                    "end": 1193,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 1295,
                    "end": 1304,
                    "text": "Figure 13",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1603,
                    "end": 1612,
                    "text": "Figure 14",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Experiments using COVIDx Dataset"
        },
        {
            "text": "In order to examine the effectiveness of the proposed RND-CNN, we implemented it using another dataset collected and enhanced for the purpose of COVID-19 detection [37] . Unlike the COVIDx, this dataset is balanced and consists of the same number of images in each class with a contrast enhancement. Figure 15 illustrates the distribution of the enhanced dataset images of each class into training, validation, and test sets. The proposed RND-CNN was trained using the enhanced COVID-19 dataset over 100 epochs. Figure 16 visualizes the accuracy and loss of the RND-CNN during the training and validation phases. During the training, the model achieved an accuracy of 98% and a very small value of loss of 0.0822. Using the test data, we evaluated the overall performance of the trained model. According to Table 6 , our proposed model achieved an accuracy of 99% in training, 98% in validation, and 99% in testing. Figure 17 plots the ROC curves for COVID-19, pneumonia, and normal classes.",
            "cite_spans": [
                {
                    "start": 164,
                    "end": 168,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [
                {
                    "start": 300,
                    "end": 309,
                    "text": "Figure 15",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 512,
                    "end": 521,
                    "text": "Figure 16",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 807,
                    "end": 814,
                    "text": "Table 6",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 916,
                    "end": 925,
                    "text": "Figure 17",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Experiments Using the Enhanced COVID-19 Dataset"
        },
        {
            "text": "High results of AUC are achieved, with 99%, 100%, and 98%, for COVID-19, normal, and pneumonia, respectively. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiments Using the Enhanced COVID-19 Dataset"
        },
        {
            "text": "Our results reveal that using different data augmentation techniques on dataset images has a significant impact on the efficiency of the model, especially for imbalanced datasets. To examine the results obtained, we trained the same proposed CNN architecture without augmentation for the dataset images, and when we did so, the results show a significant drop in accuracy. The results depicted in Table 7 demonstrate the critical role of data augmentation in improving the model's performance by increasing its accuracy and reducing the rate of loss. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 397,
                    "end": 404,
                    "text": "Table 7",
                    "ref_id": "TABREF8"
                }
            ],
            "section": "Impact of Data Augmentation"
        },
        {
            "text": "To deal with the imbalanced distribution of data of COVIDx, we employed the class weight method to re-balance the whole dataset. Then, we checked the model's performance both before and after this change. Balancing the dataset was particularly important in order to ensure better results for COVID-19 recognition. As depicted in Table 8 , the accuracy of the model when using the data balancing is higher than its accuracy without data balancing. It is noticeable also that the performance of the second dataset was much better than COVIDx due to its balance in the number of images in each class.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 329,
                    "end": 336,
                    "text": "Table 8",
                    "ref_id": "TABREF9"
                }
            ],
            "section": "Impact of Data Balancing"
        },
        {
            "text": "From the results obtained, we conclude that correcting the imbalance of the dataset is a very important step to consider before starting the training of the model. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Impact of Data Balancing"
        },
        {
            "text": "In order to validate the performance of our proposed RND-CNN model, we compare the results we obtained by using the COVIDx dataset with the results obtained by employing other models and different types of weight initialization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparisons and Discussion"
        },
        {
            "text": "As explained previously, a zero initializer will result in poor model performance. To prove this fact and for sake of comparison, we trained the same CNN architecture using the zero initializer for layers' weight. We refer to this architecture as CNN-0. The results of performance metrics were with the same values in each training epoch, ending with an accuracy of 56%. Typically, with the backpropagation algorithm, the weights of layers are updated in each iteration. When the initial weight value of the first layer is 0, the operation of multiplying it by any value in the backpropagation delta does not change the weight. Therefore, the weights of the layers are still with the same value for each iteration without being optimized. All neurons in every layer network perform the same calculation, giving the same output. Thus, we also employed the random uniform initializer to train the proposed CNN architecture. We refer to this architecture as RU-CNN. The accuracy obtained using RU-CNN network was 90%, which was acceptable but still lower than the accuracy of our proposed RND-CNN. Accordingly, we can conclude that the choice of the Xavier initializer will help provide better results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison with Other Deep Neural Networks"
        },
        {
            "text": "Besides changing network's weight initialization, we also examine the results of two other DL models that use transfer learning. Transfer learning is the approach of learning based on previous knowledge and then transferring the knowledge gained to address new problems [27] . The networks developed using this approach are based on VGG16 [48] and Xception [49] pretrained models. VGG16 is a deep CNN proposed by the Visual Geometry Group at Oxford University. VGG16 consists of 16 layers and as a network, has demonstrated strong generalization on many large benchmarking datasets for different tasks. Meanwhile, Xception is a CNN composed of 71 layers. We loaded pre-trained versions of these two models, which were performed on the ImageNet dataset including more than one million images. For sake of comparison, the same parameter values were used across the developed models: optimizer: Adam, learning rate: 1e-4, and loss function: categorical-cross-entropy. Table 9 shows that our proposed model outperforms all the other DL models in terms of accuracy, precision, sensitivity, specificity, and F1-score. It also provides the minimum loss rate compared to the other considered DL models. These results indicate that the architecture of a DL network and the choice of its parameters will have a direct impact on its performance. In addition, the choice of the right method of initialization will help obtain better results for the tasks of classification and recognition. As we can see with the results illustrated in Table 9 , using the randomized method of initialization provides better results for all performance metrics compared to the constant and distributed methods. In addition, compared to the high-performing VGG16 and Xception models, the obtained results demonstrate the excellent effectiveness of our proposed RND-CNN. These indicate that the proposed architecture with its different sets of layers could extract several features, although with random weights.",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 274,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 339,
                    "end": 343,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 357,
                    "end": 361,
                    "text": "[49]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [
                {
                    "start": 965,
                    "end": 972,
                    "text": "Table 9",
                    "ref_id": "TABREF10"
                },
                {
                    "start": 1524,
                    "end": 1531,
                    "text": "Table 9",
                    "ref_id": "TABREF10"
                }
            ],
            "section": "Comparison with Other Deep Neural Networks"
        },
        {
            "text": "In order to fight the novel COVID-19 virus, substantial research works have been conducted. However, most of them are based on transfer learning approaches. In our work, instead of using trained weights, we created a DL model from scratch for the detection of the COVID-19 virus using chest X-ray images. We obtained excellent results that demonstrate the effectiveness of the proposed model. Table 10 shows the accuracy and the F1-score results of different existing models used for the recognition of COVID-19. It demonstrates that our proposed approach produces excellent results for both COVIDx and enhanced COVID-19 datasets. We have obtained similar results as the models presented in [37] , however the later was only applied on one small dataset, which is the enhanced COVID-19 dataset. Also, [13] provides a higher F1score when using COVIDx dataset compared to our model, but it needs to conduct more exhaustive experiments to measure additional performance metrics such as accuracy, precision, sensitivity, and specificity. ",
            "cite_spans": [
                {
                    "start": 691,
                    "end": 695,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 801,
                    "end": 805,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 393,
                    "end": 401,
                    "text": "Table 10",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Comparison with Existing Works"
        },
        {
            "text": "In this study, we developed a novel CNN model to detect and classify chest X-ray images. The model was tested using two different datasets, a large dataset with a high imbalance of classes (COVIDx dataset) and a small dataset with balanced classes and enhanced images (enhanced COVID-19 dataset). The experimental results show the excellent performance of the proposed model for both datasets. However, better results are reached using the enhanced COVID-19 dataset. We observe that the enhancement of contrast for chest X-ray images helps the model to learn more features, therefore accurately detect the COVID-19 disease. In addition, using a dataset that has balanced classes help to achieve better outcomes than an unbalanced dataset, even while correcting the imbalance. Besides, we demonstrate that using different techniques of data augmentation for the training images helps to enhance the final model's predictions. The experiments that did not apply data augmentation achieved a significantly reduced classification accuracy compared to the experiments that adopt augmentation. Results show that a randomly initialized CNN can be used for analyzing chest X-ray images and could reach high accuracy rates instead of using pre-trained networks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Summary"
        },
        {
            "text": "In this paper, an efficient and low computational approach is proposed to detect COVID-19 patients from chest X-ray images. This approach is based on a novel randomly initialized CNN architecture named RND-CNN. The proposed architecture is used to classify three different classes: normal, pneumonia, and COVID-19. We have used two datasets for the model evaluation: a large dataset with a high imbalance of classes (COVIDx dataset) and a small dataset with balanced classes and enhanced images (enhanced COVID-19 dataset). We analyzed the performance of our model through six performance metrics, which are precision, accuracy, sensitivity, specificity, loss, and F1-score. The conducted experiments recorded insightful results for both COVIDx and enhanced COVID-19 datasets. Based on the obtained results, we demonstrated the high rates of recognition made by our RND-CNN model compared to other models and other types of weight initialization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        },
        {
            "text": "Possible extension of our work is to apply the RND-CNN model to analyze different types of images such as CT and MRI images and expand its ability to classify them according to additional labels, such as Pneumothorax, Emphysema, and Fibrosis, among others.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion and Future Work"
        },
        {
            "text": "Data will be available upon request to the corresponding author.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Availability of data and material"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "COVID-19 new cases worldwide by day",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Statista",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "COVID-19 cases and deaths statistics by country",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Statista",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Big data and IoTbased applications in smart environments: A systematic review",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hajjaji",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Boulila",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [
                        "R"
                    ],
                    "last": "Farah",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Romdhani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computer Science Review",
            "volume": "",
            "issn": "39",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Deep learning-based rumor detection on microblogging platforms: a systematic review",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Sarem",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Boulila",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Harby",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Qadir",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Alsaeedi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "152788--152812",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Deep learning for healthcare applications based on physiological signals: A review",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Faust",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hagiwara",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "J"
                    ],
                    "last": "Hong",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lih",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Computer methods and programs in biomedicine",
            "volume": "161",
            "issn": "",
            "pages": "1--13",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Detecting cardiovascular disease from mammograms with deep learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Bidgoli",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Iribarren",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Molloi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Baldi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE transactions on medical imaging",
            "volume": "36",
            "issn": "",
            "pages": "1172--1181",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Future Forecasting of COVID-19: A Supervised Learning Approach",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ur Rehman",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shafique",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Khalid",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Driss",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rubaiee",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Sensors",
            "volume": "21",
            "issn": "10",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bertolini",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Teixeira",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "N"
                    ],
                    "last": "Silla",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Costa",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computer Methods and Programs in Biomedicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Automated detection of COVID-19 cases using deep neural networks with X-ray images",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "B"
                    ],
                    "last": "Baloglu",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computers in Biology and Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Apostolopoulos",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Mpesiana",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Physical and Engineering Sciences in Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-Ray Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zhong Qiu Lin",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09871"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Imagenet: A large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L.-J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "248--255",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Deepcovidexplainer: Explainable covid-19 predictions based on chest x-ray images",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Karim",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rebholz-Schuhmann",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Decker",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cochez",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Beyan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.04582"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Towards an Effective and Efficient Deep Learning Model for COVID-19 Patterns Detection in X-ray Images",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Luz",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Corr",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.05717"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Implementation of convolutional neural network approach for COVID-19 disease detection",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Irmak",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Physiol Genomics",
            "volume": "52",
            "issn": "",
            "pages": "590--601",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "COVID-19 disease severity assessment using CNN model",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Irmak",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IET Image Processing",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep Randomized Neural Networks",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Gallicchio",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Scardapane",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Recent Trends in Learning from Data",
            "volume": "896",
            "issn": "",
            "pages": "43--68",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Deep Image Prior",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ulyanov",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vedaldi",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Lempitsky",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "9446--9454",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Randomly weighted CNNs for (music) audio classification",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pons",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Serra",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "ICASSP 2019-2019 IEEE international conference on acoustics, speech and signal processing (ICASSP)",
            "volume": "",
            "issn": "",
            "pages": "336--340",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Deep learning for health informatics",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rav\u00ec",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Deligianni",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Berthelot",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Andreu-Perez",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "Z"
                    ],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE journal of biomedical and health informatics",
            "volume": "21",
            "issn": "",
            "pages": "4--21",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Cognitive healthcare system and its application in pill-rolling assessment",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "H"
                    ],
                    "last": "Abbasi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "International Journal of Numerical Modelling: Electronic Networks, Devices and Fields",
            "volume": "32",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Privacy-Preserving Wandering Behavior Sensing in Dementia Patients Using Modified Logistic and Dynamic Newton Leipnik Maps",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Masood",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "Y"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Pervaiz",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Taylor",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Imran",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "H"
                    ],
                    "last": "Abbasi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Sensors Journal",
            "volume": "21",
            "issn": "",
            "pages": "3669--3679",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Privacy-preserving non-wearable occupancy monitoring system exploiting Wi-Fi imaging for next-generation body centric communication",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tahir",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Russel",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "Y"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Buchanan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "H"
                    ],
                    "last": "Abbasi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "11",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "RS-DCNN: A novel distributed convolutional-neural-networks based-approach for big remote-sensing image classification",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Boulila",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sellami",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Driss",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Sarem",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Safaei",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "A"
                    ],
                    "last": "Ghaleb",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Computers and Electronics in Agriculture",
            "volume": "182",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "A Novel CNN-LSTM-based Approach to Predict Urban Expansion",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Boulila",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ghandorh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2103.01695"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Recent Advances in Convolutional Neural Networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kuen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shahroudy",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shuai",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "354--377",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Leveraging Deep Learning and IoT big data analytics to support the smart cities development: Review and future directions",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ben Atitallah",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Driss",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Boulila",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ben Gh\u00e9zala",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computer Science Review",
            "volume": "",
            "issn": "35",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Deep Learning for IoT Big Data and Streaming Analytics: A Survey",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mohammadi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Al-Fuqaha",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sorour",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Guizani",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Communications Surveys & Tutorials",
            "volume": "20",
            "issn": "4",
            "pages": "2923--2960",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A Comparison of Weight Initializers in Deep Learningbased Side-channel Analysis",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kr\u010dek",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Perin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Conference on Applied Cryptography and Network Security",
            "volume": "",
            "issn": "",
            "pages": "126--143",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hochreiter",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems",
            "volume": "6",
            "issn": "2",
            "pages": "107--116",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Evolving Deep Convolutional Neural Networks for Image Classification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "G"
                    ],
                    "last": "Yen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Evolutionary Computation",
            "volume": "24",
            "issn": "2",
            "pages": "394--407",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Glorot",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yoshua",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the thirteenth international conference on artificial intelligence and statistics",
            "volume": "",
            "issn": "",
            "pages": "249--256",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "COVIDx Dataset",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Survey on deep learning with class imbalance",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Big Data",
            "volume": "6",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "A survey on addressing high-class imbalance in big data",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Leevy",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Bauder",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Seliya",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Big Data",
            "volume": "5",
            "issn": "1",
            "pages": "1--30",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Classification on imbalanced data",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Tensorflow",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "MH-COVIDNet: Diagnosis of COVID-19 using deep neural networks and meta-heuristic-based feature selection on X-ray images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Canayaz",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Biomedical Signal Processing and Control",
            "volume": "64",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Can AI Help in Screening Viral and COVID-19 Pneumonia?",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khandakar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mazhar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Kadir",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "B"
                    ],
                    "last": "Mahbub",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Islam",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Iqbal",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Emadi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "B I"
                    ],
                    "last": "Reaz",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "132665--132676",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "A New Image Contrast Enhancement Algorithm Using Exposure Fusion Framework",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ying",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "International Conference on Computer Analysis of Images and Patterns",
            "volume": "10425",
            "issn": "",
            "pages": "36--46",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Data augmentation for improving deep learning in image classification problem",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Miko\u0142ajczyk",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Grochowski",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 international interdisciplinary PhD workshop (IIPhDW)",
            "volume": "",
            "issn": "",
            "pages": "117--122",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "The Problem of Overfitting",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Hawkins",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Journal of Chemical Information and Computer Sciences",
            "volume": "44",
            "issn": "1",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "A survey on Image Data Augmentation for Deep Learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shorten",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Big Data",
            "volume": "6",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Deep learning with Python",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Francois",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "361",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "TensorFlow",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Semi-supervised Learning with Deep Generative Models",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Rezende",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mohamed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Welling",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "3581--3589",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Stochastic Gradient Descent Tricks",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bottou",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Neural networks: Tricks of the trade",
            "volume": "",
            "issn": "",
            "pages": "421--436",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Improving deep neural networks for LVCSR using rectified linear units and dropout",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Dahl",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "N"
                    ],
                    "last": "Sainath",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "2013 IEEE international conference on acoustics, speech and signal processing",
            "volume": "",
            "issn": "",
            "pages": "8609--8613",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Xception: Deep Learning with Depthwise Separable Convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1251--1258",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Worldwide confirmed cases of COVID-19 from January 23, 2020 to May 13, 2021[1].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Number of COVID-19 deaths among the most impacted countries worldwide as of May 4, 202[2].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Illustration of the operations done within the convolutional layer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Illustration of the operations done within the pooling layer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Neuron structure.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Proposed RND-CNN architecture.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "presents some samples of patient chest X-ray images presenting different classes (COVID-19/normal/pneumonia).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Samples of chest X-ray images illustrating different classes and belonging to the COVIDx dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Samples of chest X-ray images illustrating different classes and belonging to the enhanced COVID-19 dataset",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "The experimentation workflow.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Specificity: used to measure the model's effectiveness in the recognition of negative samples. \u2022 Loss: is used to calculate the error value and determine how well the model treats the data. A lower value for loss indicates that the model is making fewer errors. \u2022 F1-score: is computed using precision and recall in order to achieve a balanced average result. These measures are computed according to the following equations: True Positive (TP): the predicted case is positive (pneumonia/COVID-19), and the result is true. \u25aa True Negative (TN): the predicted case is negative (normal), and the result is true. \u25aa False Positive (FP): the predicted case is positive (pneumonia/COVID-19), and the result is false. \u25aa False Negative (FN): the predicted case is negative (normal), and the result is false.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Distribution of COVIDx's images of each class into training, validation, and test sets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Accuracy and loss achieved during training and validation phases of the RND-CNN model using COVIDx dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Obtained ROC curves for COVID -19, normal, and pneumonia classes using COVIDx dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Learned features from the first, second, and last convolution layers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Distribution of the enhanced Dataset images of each class into training, validation, and test sets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Accuracy and loss achieved during training and validation phases of the RND-CNN model using the enhanced COVID-19 dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Obtained ROC curves for COVID-19, normal, and pneumonia classes using the enhanced COVID-19 dataset.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "those who have been infected quickly and in an based approach is proposed for the classification of COVID-19 disease severity. The developed CNN divides and categorizes the COVID-19 patients into four severity groups (mild/ moderate/ severe/critical). This study employs also grid search optimization to select the CNN parameters. The experimental results demonstrate the effectiveness of the proposed CNN model, which achieves an accuracy of 95.5%.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Comparison between the different types of initialization.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The proposed randomly initialized CNN and its learning parameters.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Distribution of chest X-ray images from the COVIDx dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Distribution of chest X-ray images belonging to the enhanced COVID-19 dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "RND-CNN accuracy results using the COVIDx dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "RND-CNN accuracy results using the enhanced COVID-19 dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Impact of data augmentation on the model performance.",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "The impact of data balancing on the model performance.",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Comparison of performance results between RND-CNN and other DL models using the COVIDx dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Comparison between our work and existing works.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors declare that they have no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interests"
        }
    ]
}