{
    "paper_id": "2f0cf2256240328d38692bc66b66665522491330",
    "metadata": {
        "title": "A Covid-19's integrated herd immunity (CIHI) based on classifying people vulnerability",
        "authors": [
            {
                "first": "Asmaa",
                "middle": [
                    "H"
                ],
                "last": "Rabie",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Mansoura University",
                    "location": {
                        "settlement": "Mansoura",
                        "country": "Egypt"
                    }
                },
                "email": ""
            },
            {
                "first": "Ahmed",
                "middle": [
                    "I"
                ],
                "last": "Saleh",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Mansoura University",
                    "location": {
                        "settlement": "Mansoura",
                        "country": "Egypt"
                    }
                },
                "email": ""
            },
            {
                "first": "Nehal",
                "middle": [
                    "A"
                ],
                "last": "Mansour",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Artificial Intelligence Lab",
                    "institution": "Nile Higher Institute for Engineering and Technology",
                    "location": {
                        "settlement": "Mansoura",
                        "country": "Egypt"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [],
    "body_text": [
        {
            "text": "Covid-19, this strange virus and its rapidly spreading deadly mutations have affected the daily life of the entire world population [1] [2] [3] . Moreover, its impact is expected to continue in the future. Before a vaccine is fully available, scientist's best hope of combating Covid-19 lies in preventing its spread. Unfortunately, till now, the nature and behaviors of Covid-19 are not completely clear. The clinical and epidemiological characteristics of the virus must continue to be investigated as the virus is highly transmissible through humans [1, 2, 4] . Generally, disease diagnosis depends on clinical symptoms and signs [5] . However, there is definite evidence that many patients infected with Covid-19 are asymptomatic or have too few symptoms to be recognized. The known prevalence of asymptomatic patients is about 19.2% [6, 7] . Unfortunately, asymptomatic transmission acts as a silent harbor for the virus infection [6] . As there are difficulties in screening for asymptomatic infection, it is difficult to prevent and control this epidemic at the national level unless it is dealt with appropriately. Before that, it is necessary to know the detailed picture and characteristics of the asymptomatic Covid-19 patients.",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 135,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 136,
                    "end": 139,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 140,
                    "end": 143,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 553,
                    "end": 556,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 557,
                    "end": 559,
                    "text": "2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 560,
                    "end": 562,
                    "text": "4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 633,
                    "end": 636,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 838,
                    "end": 841,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 842,
                    "end": 844,
                    "text": "7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 936,
                    "end": 939,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Detecting asymptomatic patients is a task that may seem impossible to achieve because this needs continuous scanning of all people to discover the presence of the virus. Therefore, there is an urgent need for new mechanisms to discover or anticipate who may be infected with the virus without showing symptoms, as their bodies contain mechanisms that may not be known to resist the virus. Hence, the virus does not affect them, but they remain infectious to others throughout the recovery period during which no symptoms appear. Herd immunity takes place when the virus cannot spread as it continues to encounter people who are protected from infection. There is no need for every member of the population to be immune, just enough people need to be immune. Only when a sufficient part of the population is not susceptible to infection, the potential for an epidemic to spread is minimal. Herd immunity works to control and avoid the spread of a disease in a population only when a specific amount of that population, called Immunity Threshold (IT), becomes immune to the disease either through vaccination or infection and recovery. Hence, when IT is reached, susceptible individuals become protected from infection because the ongoing spread of disease is limited. However, in the case of Covid-19, applying traditional herd immunity gives a false promise to minimize the spread of infection. Accordingly, much attention should be given to introduce a new herd immunity model that has the ability to; (i) accurately predict the asymptomatic Covid-19 cases to reduce the virus transmission as their potential to spread the virus cannot be ignored, (ii) reduce the virus clustered transmission for community and family, and (iii) protect those who are expected to be severely affected by the virus before actually infection occurs, hence, suitable precautionary measures can be taken.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Many machine learning and artificial intelligence methods have been successfully applied to predict and diagnose Covid-19 cases using the clinical and healthcare data [1] [2] [3] [4] . However, early prediction frameworks for the impact of Covid-19 on people before actual infection occurs have not yet been implemented. Such frameworks can be helpful in taking proactive measures to combat the spread of the virus as well as to protect individuals from any predicted harmful impact of the virus. They can also be used to implement a new herd immunity model for Covid-19. Data mining (DM) is the process of extracting useful information from large amount of databases [8] [9] [10] [11] [12] [13] . DM techniques have been successfully implemented in healthcare domain [4] . Medicinal data mining can utilize the veiled patterns presented in huge medical data. Several DM techniques are useful to medical data such as; association rule mining for finding frequent patterns, classification, and clustering. These techniques are useful in predicting heart diseases, breast cancer, lung cancer, diabetes, and recently Covid-19 [1] [2] [3] [4] .",
            "cite_spans": [
                {
                    "start": 167,
                    "end": 170,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 171,
                    "end": 174,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 175,
                    "end": 178,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 179,
                    "end": 182,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 668,
                    "end": 671,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 672,
                    "end": 675,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 676,
                    "end": 680,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 681,
                    "end": 685,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 686,
                    "end": 690,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 691,
                    "end": 695,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 768,
                    "end": 771,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1123,
                    "end": 1126,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1127,
                    "end": 1130,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1131,
                    "end": 1134,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1135,
                    "end": 1138,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The main contribution of this paper is to introduce a suggested plan that will allow society to stay normal as possible even with the existence of Covid-19, while taking some procedures to protect those who are most at risk. This can be accomplished by replacing the traditional herd immunity with a new specialized immunity model for Covid-19, which is called CIHI. The proposed CIHI would essentially allow the coronavirus to run its course with minimal losses. It has the ability to detect people who will be asymptomatic if they were infected by Covid-19. These people are categorized as less dangerous because their bodies can resist the virus, hence, they can be allowed to return to their normal life with continuous follow. On the other hand, people at high risk could be protected through strict measures even if they have not been infected yet. The proposed CIHI is realized using a new classification strategy called DBCS, which aims to classify people into six classes based on their vulnerability by Covid-19. Hence, special procedures and precautionary measures are applied for each type. DBCS has the ability to discover the people expected to be asymptomatic if they were infected with the virus. It can also identify those people who will be badly influenced by the virus.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "DBCS consists of three sequential phases, which are; ORP, FSP, and CP. In this work, there are three main contributions represented by the proposed methods presented in ORP, FSP, and CP:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 During ORP, the task is to reject those data items with features that are very different from expectation, which are called outliers. Thus, a new technique called HOR has been introduced for rejecting outliers based on a hybrid method that combines standard division as a statistical method and Improved Binary Particle Swarm Optimization (IBPSO) as a machine learning method. \u2022 On the other hand, the main objective of FSP is to select the best set of features that allows to build a useful classification model. HFS method is applied in FSP to select the most appropriate set of features based on a hybrid method that includes Chi-square as a filter method and Improved Binary Gray Wolf Optimization (IBGWO) as a wrapper method. \u2022 Finally, the proposed AKNN method has been used in CP as a classification model. During CP, a new test case can be classified into one of six classes based on the expected resistance of his body against the Corona virus if he is infected with it, which is an indication of the extent of the damage that the virus may cause if the person is actually infected.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This definitely allows specific precautionary measures to be taken for each class before the occurrence of infection, which can achieve the principle of herd immunity. Hence, some people are allowed to be presented in human gatherings with constant observation and followup, others are prevented from the existence in crowded groups, while some people are forced to being at home. DBCS has been compared with modern techniques used to diagnose Covid-19 patients. Experimental results have proven the efficiency and applicability of the proposed strategy because it introduces the best evaluation values in term of accuracy, error, precision, recall, and run time. And accordingly, this guarantees the availability of achieving heard immunity. The remainder of the paper is organized as follows; section 2 provides the required background and basic concepts. Section 3 presents the problem definition and the suggested solution. Section 4 discusses the previous effort about Covid-19 classification models. Section 5 introduces the proposed integrated herd immunity. Next, section 6 presents the experimental setup and results while section 7 discusses the DBCS pros and cons. Finally, section 8 concludes the study and section 9 outlines the main directions for future work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This section aims to present the basic knowledge and emerging ideas on topics relevant to the subject of the paper. Initially, a brief discussion about the infection spread of Covid-19 is presented. Then, traditional herd immunity principles are introduced.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Background and basic concepts"
        },
        {
            "text": "Unfortunately, unusually for disease management, the Covid-19 virus has many exceptions that have yet to be explained. To clarify, a positive test result is not the only criterion for the presence of Covid-19 infection [1] [2] [3] . On the other hand, the test is usually a support for a clinical diagnosis, not a substitute. However, there is a lack of clinical supervision, and thus health care professionals know very little about the proportions of people who have positive results and who do not actually show symptoms throughout the course of the infection. In other words, health care professionals know very little about proportions of people who have symptom scarcity (e.g., subclinical) or asymptomatic (e.g., persistence of symptoms later) or after infection (e.g., with fragments of viral Ribonucleic Acid (RNA) that remain detectable from a previous infection). One of the strong reasons for the rapid spread of Covid-19 is that some people infected with it do not develop symptoms and are nonetheless contagious [14, 15] . Surprisingly, these people do not appear and do not feel sick, but they transmit the virus without realizing it.",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 222,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 223,
                    "end": 226,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 227,
                    "end": 230,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1026,
                    "end": 1030,
                    "text": "[14,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1031,
                    "end": 1034,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Hidden demons behind Covid-19 infection spread"
        },
        {
            "text": "Generally, spread of a disease without illness appearance is called asymptomatic (ASM) transmission. On the other hand, a person with signs of disease is called a symptomatic (SYM) case. However, there is another term that may cause confusion, which is; presymptomatic (PSYM). Although a PSYM case can be understood as a person who has not yet developed any symptoms, PSYM can also mean ASM. Symptomatic, asymptomatic, and pre-symptomatic stages are illustrated in Fig. 1 . As illustrated in such figure, in the pre-symptomatic stage, many people are contagious. Thus, transmission of the virus is still possible even though the disease is not externally manifested. This is why governments require entire families to isolate when one of their members gets sick. Hence, asymptomatic or pre-symptomatic cases have been called \"silent diffusers\". Hence, a critical task for limiting the fast spread of Covid-19 is the early identification of people who will be asymptomatic cases if they were infected by the virus before the actual infection takes place.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 465,
                    "end": 471,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Hidden demons behind Covid-19 infection spread"
        },
        {
            "text": "Herd immunity (HI), also called \"population immunity\", is the indirect protection from infectious diseases by making a population immune either through vaccination or through immunity developed from a previous infection. However, attempts to achieve HI by exposing people to the virus are not only scientifically problematic but also unethical. The World Health Organization (WHO) supports access to HI through vaccination, not by allowing a disease to spread through the population, as this would lead to unnecessary infections, suffering, and death. Fig. 2 illustrates herd immunity types, which are; no Immunization and with immunization.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 552,
                    "end": 558,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Covid-19 and herd immunity"
        },
        {
            "text": "However, in the case of Covid-19, the use of traditional HI may give a false promise to minimize the infection spread for the following reasons; (i) achieving HI through community spread of a pathogen is based on the unproven assumption that individuals who survive infection will become immune, (ii) recently, it has been noticed that people get reinfected with Covid-19 after the initial infection, but how frequently these reinfections take place and whether they lead to less serious illnesses remain open questions, (iii) yet, there is no foolproof way to measure the immunity to Covid-19. Laboratories can test whether individuals have Covid-19-specific antibodies, But they still don't know how long any immunity can last, (iv) after recovery, if infected persons become susceptible to infection again, the community may never reach HI through natural transmission. Vaccination is the only ethical path to HI, however, how many people will need to be vaccinated and how often will depend on many factors, including how effective the vaccine is and how long it continues to protect, (v) the several hidden sources of infections named pre-asymptotic and asymptotic individuals, and (vi) viruses mutate all the time. Several new variants of Covid-19 strain have been discovered recently. For illustration, a new strain has swept across the United Kingdom and has been detected in the United States, Canada, and elsewhere which could be the reason behind the sharp rise in cases there. Researchers and scientists say the new strains have much higher transmissibility than the previous type. This means that more people will be taken to hospital, resulting in overcrowding of hospitals. Once hospitals are full, the quality of care for the sickest patients drops, resulting in higher than expected death rates. For the pre-mentioned reasons, Covid-19 needs special treatments to achieve HI.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Covid-19 and herd immunity"
        },
        {
            "text": "Despite the similarity in the physiological structure, humans differ from each other in the extent to which they respond to diseases. Generally, a person's response to diseases is closely related to his level of immunity, however, there are many other factors that may significantly affect the susceptibility of the human body to a particular disease compared to others. For example, at the beginning of the Corona pandemic, it was believed that the extent of a person's infection with Covid-19 was closely related to his age and his affliction with chronic diseases such as diabetes pressure [1] [2] [3] [4] . However, over time, it is noticed that elderly people suffering from these diseases have been recovered with little effect. On the contrary, many healthy people of middle and lower ages were affected by an enormous effect, sometimes even death [1] [2] [3] [4] . Unfortunately, there is no test that can distinguish live Covid-19 virus, therefore, no test for infection is currently available. A person who tests positive with any kind of test may or may not be infectious. Moreover, several issues related to are not yet clear such as viral load, viral shedding, infection, infectiousness, and duration of infectiousness. On the other hand, the response of people's bodies and the extent of their susceptibility to disease varies, despite the close convergence of both in age and health status. Some people do not feel they have been infected with Covid-19, and the infection ended without the person feeling any symptoms or even feeling minor and normal symptoms. However, the status of other people, with similar conditions, may be developed into serious complications.",
            "cite_spans": [
                {
                    "start": 593,
                    "end": 596,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 597,
                    "end": 600,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 601,
                    "end": 604,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 605,
                    "end": 608,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 855,
                    "end": 858,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 859,
                    "end": 862,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 863,
                    "end": 866,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 867,
                    "end": 870,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Problem definition and suggested solution"
        },
        {
            "text": "A total of 634 people tested positive among 3063 tests as at February 20, 2020 on board the Diamond Princess Cruise ship, Yokohama, Japan. Of the 634 confirmed cases, a total of 314 and 320 were reported to be symptomatic and asymptomatic, respectively. The proportion of symptomatic and asymptomatic individuals during the period from 13 to 20 February are illustrated in Fig. 3 , which indicates that there exists a clear evidence that a substantial fraction of Covid-19 infected individuals are asymptomatic [16] [17] [18] . The relatively high proportion of asymptomatic infections could have public health implications. Hence, more attention should be paid for those asymptomatic cases because they could be the hidden source of the spread of the virus infection.",
            "cite_spans": [
                {
                    "start": 511,
                    "end": 515,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 516,
                    "end": 520,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 521,
                    "end": 525,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [
                {
                    "start": 373,
                    "end": 379,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Problem definition and suggested solution"
        },
        {
            "text": "Classifying people into categories according to the extent to which their bodies will be affected by Covid-19, if they are infected with it, may limit the spread of corona disease and even eliminate it for the following reasons; (i) taking appropriate precautionary measures according to the response of the human body has the greatest effect in protecting the individual from actual disease and (ii) the discovery of people who will not show symptoms of the disease or suffer from minor symptoms (e.g., asymptomatic cases) will have a great impact on limiting the spread of the disease. Those people who would not show symptoms act as time bombs as they continue to interact with healthy people and spread the virus without even realizing it. People classification based on their vulnerability level to Covid-19 is presented in Fig. 4 . As illustrated in Fig. 4 , based on the individual vulnerability level to Covid-19, people can be classified into six types (Type A\u2192F). A person of 'Type A' will not show any symptoms if he infected by the virus, hence, he can be considered as asymptomatic case. 'Type A' will not be affected by the virus but he can spread it, so, he should be identified as he will be a silent spreader of the virus. On the other hand, the remaining types (e.g., Type B\u2192F) are considered as symptomatic but with different vulnerability to the virus. To keep the individuals of the society safe, each type must be subjected to different treatments and rules as illustrated in Table 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 829,
                    "end": 835,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 856,
                    "end": 862,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1498,
                    "end": 1505,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Problem definition and suggested solution"
        },
        {
            "text": "This section will review the previous research to detect Covid-19 patients. In Ref. [4] , a fast and accurate strategy called Distance Biased Nave Bayes (DBNB) was introduced to diagnose Covid-19 contaminated patients. This strategy depended on the results of numerical laboratory tests collected from many healthy and infected people. DBNB introduced two main contributions, which are; a hybrid feature selection method and a new classification method. The hybrid feature selection method includes both filter and wrapper methods to choose the best features for the next classification phase. In the hybrid feature selection method, several filter selection methods have been used to quickly select the best subsets features which are used as initial values for individuals of the particle swarm optimization method used as a wrapper method to accurately select the best features. The new classification method combines both statistical and distance modules called weighted Na\u00efve Bayes (NB) and distance reinforcement modules respectively to address the shortcomings of the classic NB. DBNB provided the best results compared to several modern methods in terms of accuracy, precision, recall, and execution time. Although the DBNB strategy enhanced the performance of the classic or traditional NB, the test-cost measurement should be performed on the proposed particle swarm optimization method to provide the highest accuracy as well as the lowest cost. Additionally, DBNB implementation depended only on using numerical data rather than using nominal data.",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 87,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "As described in Ref. [1] , a new strategy known as Feature Correlated Nave Bayes (FCNB) was applied to a dataset containing numerical laboratory test results. FCNB is divided into two important stages called pre-processing and classification. Three important phases were used in the pre-processing stage and one phase in the classification stage. The first three phases are as follows; feature selection, feature clustering, and master feature weighting. The feature selection phase was used to choose the most informative features that have an impact on Covid-19. The feature clustering phase was then utilized to aggregate features into groups, with each group termed master feature. Finally, the classification stage depended on a new weighted NB, which had significant advantages. According to the results of the experiments, the FCNB strategy could accurately classify Covid-19 patients. Also, the FCNB could take into account the correlation between features and could minimize the classification time as it takes into account the weights of the used master feature. Although the benefits of FCNB, it did not use outlier rejection method to reject outliers from the dataset before learning the classification method. Additionally, the FCNB suffers from that its implementation depended only on the use of numerical data rather than the use of nominal data.",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 24,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "In [19] , a Convolution Neural Network (CNN) model has been used to detect Covid-19 patients using a dataset of Computed Tomography (CT) images. The suggested CNN model had two key algorithms, which are called; CNN architecture and AlexNet, which served as a transfer-learning algorithm. Despite its simplicity, the accuracy of this method is insufficient to accurately diagnose Covid-19 patients. Additionally, it did not use feature selection method or outlier rejection method to filter the data before learning the detection model. Hence, the experiment results demonstrated that utilizing a pre-trained network produced the highest accuracy while using a modified CNN provided the lowest accuracy. In Ref. [2] , a new Hybrid Diagnosis Strategy (HDS) was proposed. HDS relied on a new mechanism for rating the chosen features by projecting them into a newly presented patient space. In fact, feature rank was determined by two factors named feature weight and feature's binding degree to its neighbors in the patient space. Then, a hybrid classification model was used to accurately classify the new patient to determine whether or not he was infected. This hybrid classification model used two classifiers called a fuzzy inference engine and a deep neural network. The proposed HDS provided the best recall, precision, accuracy, and F-measure values compared to other recent strategies. The proposed HDS is distinguished by its reliance on using feature selection method to filter the Covid-19 dataset from irrelevant features before learning the classification technique. Thus, it could provide accurate classifications. Additionally, the HDS depended on numerical laboratory tests that have proven effective in detecting Covid-19 patients. Despite the benefits of the proposed HDS, the overall system performance was low because HDS did not take into account the input uncertainty that referred to the effect of driving a simulation with input distributions according to real data.",
            "cite_spans": [
                {
                    "start": 3,
                    "end": 7,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 711,
                    "end": 714,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "The Covid-19 Patients Detection strategy (CPDS) has been introduced to provide a more accurate diagnosis of Covid-19 patients as described in Ref. [3] . CPDS introduced two contributions based on CT images of non-Covid-19 persons and Covid-19 patients. The 1st contribution represents a new feature selection approach called Hybrid feature Selection Method (HFSM) which consists of two stages, namely; fast and accurate stages. The goal of the HFSM was to choose the most important features. The 2nd contribution represents an Improved K-Nearest Neighbor (IKNN) classification model, which focuses on evaluating the degree of both closeness and strength of each neighbor of the tested item before selecting just the qualified neighbors for classification. The CPDS could accurately detect infected patients with minimum time penalty. Although the benefits of the proposed CPDS, it did not use outlier rejection technique to remove outliers. Also, CPDS implementation depended on using CT image data rather than using numerical laboratory tests.",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 150,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "In [20] , AM-SdenseNet model that includes Convolution Block Attention module and Depthwise Separable Dense Convolutional Network was introduced to diagnose Covid-19 patients based on the CT images dataset. In this work, a publicly available data set COVID-CTx that includes the largest number of positive cases has been established. The proposed AM-SdenseNet outperformed several techniques through experiments where it could provide fast and accurate diagnosis which extremely important to reduce the spreading of infection. Although the COVID-CTx dataset enabled the diagnosis model to provide fast and accurate results, large networks still could not be trained. Additionally, it did not use feature selection or outlier rejection method to correctly learning the diagnosis model. It has not been tested on a different types of datasets such as blood tests. As provided in Ref. [21] , the ResNet-50 deep learning model as a new artificial intelligent system was used to diagnose Covid-19 patients based on the 3D CT images. The evaluation results showed that the ResNet-50 deep learning model outperformed the 3DResNet18 and 3D-ResNet50 models as it could provide accurate results. Although the benefits of the ResNet-50 model, it needed to run several ResNet-50 architectures and also it needed a high memory that might prevent the use of this model in many applications like the mobile telemedicine networks. Finally, modern Covid-19 diagnostic strategies have proven effective in diagnosing Covid-19 patients, but are not being used to classify people based on their vulnerability by Covid-19 yet. In this paper, several recent Covid-19 diagnostic strategies will be compared to our proposed Distance Based Classification Strategy (DBCS) strategy to classify people based on their vulnerability by Covid-19. Table 2 shows the recent related work for Covid-19 diagnosis strategies.",
            "cite_spans": [
                {
                    "start": 3,
                    "end": 7,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 882,
                    "end": 886,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 1815,
                    "end": 1822,
                    "text": "Table 2",
                    "ref_id": null
                }
            ],
            "section": "Related work"
        },
        {
            "text": "The proposed Distance Based Classification Strategy (DBCS) will be detailed through this section. DBCS aims to classify people into six classes based on their vulnerability by Covid-19 in which special procedures and precautionary measures are applied for each type. Really, DBCS consists of three sequential phases, which are; ORP, FSP, and CP as shown in Fig. 5 . In ORP, HOR method will be provided in order to quickly and accurately reject outliers as possible based on using standard division and IBPSO. FSP aims to select the best features using HFS method that consists of Chi-square as a filter technique and IBGWO as a wrapper technique. These three phases will be depicted in details in the next sub-sections.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 357,
                    "end": 363,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "The proposed Distance Based Classification Strategy (DBCS)"
        },
        {
            "text": "Outlier rejection is the process of finding data items that are very different from expectation in training dataset [8] [9] [10] [11] [12] [13] . The existence of outlier items in the input training set may cause unexpected behavior of the used classifier during the testing phase. In DBND, ORP aims to detect outlier items in training dataset and then reject those data to make the diagnostic model able to quickly give accurate values. In fact, outlier items can decrease the accuracy of the classification model. Thus, it is an essential process to eliminate the subset of rare data before starting to train the classification model [8] [9] [10] [11] [12] [13] . Many popular rejection methods are applied to evolve the performance of classification model. These rejection methodologies are classified to three main groups, called; cluster-based methodologies, neighbor-based methodologies, and statistical-based methodologies [23] [24] [25] [26] . In fact, statistical-based methodologies and distance-based methodologies that belong to neighbor-based methods represent the most popular outlier rejection techniques. Although these popular techniques are simple and fast, they may cannot accurately remove outlier items.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 119,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 120,
                    "end": 123,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 124,
                    "end": 128,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 129,
                    "end": 133,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 134,
                    "end": 138,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 139,
                    "end": 143,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 636,
                    "end": 639,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 640,
                    "end": 643,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 644,
                    "end": 648,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 649,
                    "end": 653,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 654,
                    "end": 658,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 659,
                    "end": 663,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 930,
                    "end": 934,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 935,
                    "end": 939,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 940,
                    "end": 944,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 945,
                    "end": 949,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "During this section, an effective outlier rejection method called Hybrid Outlier Rejection (HOR) method is provided to reject outlier items. HOR aims to enable the classification model to quickly and accurately perform its tasks. The proposed HOR method mainly composes of two stages, which are called; Fast Rejection (FR) and Accurate Rejection (AR) stages as shown in Fig. 6 . In FR stage, standard division is used as a statistical-based methodology to quickly eliminate outliers from the training dataset as possible [22, 25] . In AR stage, Improved Binary Particle Swarm Optimization (IBPSO) method is used as an optimization method to accurately reject the rest of outliers in the data to evolve the performance of the classification model [26, 27] . Although IBPSO can accurately reject outlier items in the training dataset, it suffers from the computational time. Thus, standard division method in FR stage has been preceded IBPSO to quickly eliminate outlier items before passing the medical dataset to IBPSO method in AR stage. This process aims to reduce the execution time of IBPSO and to provide a robust training dataset without outlier items.",
            "cite_spans": [
                {
                    "start": 521,
                    "end": 525,
                    "text": "[22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 526,
                    "end": 529,
                    "text": "25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 746,
                    "end": 750,
                    "text": "[26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 751,
                    "end": 754,
                    "text": "27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 370,
                    "end": 376,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "Thus, the proposed HOR aims to quickly and accurately reject outliers from the training dataset before learning the diagnostic model. At the end, the optimal subset of training data will be used to enable the classification model to perform its tasks well. Although IBPSO has been widely applied in many works, it is used in this work as an outlier rejection method by using a credible fitness function called Small Average Distance (SAD) that represents a distance-based outlier rejection method. Accordingly, AR stage implements an optimization technique called IBPSO based on SAD methodology as a credible fitness function. Hence, AR stage contains a hybrid method that includes IBPSO as an optimization technique [26, 27] and SAD as an outlier rejection technique [28] . Finally, HOR represents a hybrid rejection method that mainly consists of two techniques, called; (i) standard division as a statistical outlier rejection method and (ii) IBPSO as an optimization technique that depends on distance-based methodology that is called SAD as a fitness function.",
            "cite_spans": [
                {
                    "start": 717,
                    "end": 721,
                    "text": "[26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 722,
                    "end": 725,
                    "text": "27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 768,
                    "end": 772,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "Initially, Particle Swarm Optimization (PSO) was built to address many optimization problems represented in continuous numbers search space. However, several problems such as outlier rejection process cannot occur in continuous search space but it can occur in binary search spaces (discrete form) [26, 27] . Hence, Binary PSO (BPSO) is a modified version of PSO to provide solutions to binary problems. Really, BPSO \u2022 No need for continuous follow-up, but Home isolation is necessary as soon as symptoms appear.",
            "cite_spans": [
                {
                    "start": 298,
                    "end": 302,
                    "text": "[26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 303,
                    "end": 306,
                    "text": "27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "\u2022 A person of type B can be allowed to be in crowded places.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "\u2022 Simple patient treatments can be followed whenever the symptoms appear.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "\u2022 It is preferred to receive the vaccine if it is available.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Outlier rejection phase (ORP)"
        },
        {
            "text": "Type C Simple Symptoms, But Deteriorate (SSBD)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Symptomatic"
        },
        {
            "text": "\u2022 The same treatments as SSND, but more serious patient treatments can be followed whenever the symptoms appear. Type D",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium"
        },
        {
            "text": "\u2022 Precautionary measures must be applied, such as staying at home.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium Symptoms (MS)"
        },
        {
            "text": "\u2022 A person of type D is not allowed to be in crowded places.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium Symptoms (MS)"
        },
        {
            "text": "\u2022 Serious patient treatments can be followed whenever the symptoms appear.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium Symptoms (MS)"
        },
        {
            "text": "\u2022 For persons of type D, Vaccination is recommended. Type E High Symptoms (HS) High \u2022 Persons of Type E (or F) must receive the vaccine as soon as possible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium Symptoms (MS)"
        },
        {
            "text": "\u2022 Strict precautionary measures must be applied, he/she must staying at home. Type F",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medium Symptoms (MS)"
        },
        {
            "text": "A.H. Rabie et al.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Very High Symptoms (VHS)"
        },
        {
            "text": "The recent related work for Covid-19 diagnosis strategies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Table 2"
        },
        {
            "text": "Distance Biased Na\u00efve Bayes (DBNB) [4] DBNB contains two important methods, called; features selection and diagnosis method. Hence, DBNB begins to select the best features in the collected dataset and then use the diagnosis method to diagnose Covid-19 patients.",
            "cite_spans": [
                {
                    "start": 35,
                    "end": 38,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Technique Description Advantages Disadvantages"
        },
        {
            "text": "This technique enhances the performance of traditional Na\u00efve Bayes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Technique Description Advantages Disadvantages"
        },
        {
            "text": "-It is needed to provide the highest accuracy as well as the lowest cost by performing test-cost on the proposed feature selection method. -DBNB implementation depended only on using numerical data rather than using nominal data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Technique Description Advantages Disadvantages"
        },
        {
            "text": "Na\u00efve Bayes (FCNB) [1] FCNB was provided as a new Covid-19 detection strategy in which it consists of two main stages called pre-processing stage and classification stage. While pre-processing stage aims to select the informative features and then convert them to weight space, classification stage aims to provide accurate diagnoses based on weighted NB with several improvements.",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 22,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Feature Correlated"
        },
        {
            "text": "-The accuracy of Covid-19 patients detection is achieved. -The proposed weighted NB and distance reinforcement modules could overcome the issues of traditional weighted NB. -It taken in the consideration the correlation between features. -It minimizes the classification time as it take into consideration the weights of the used master feature.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Correlated"
        },
        {
            "text": "-No outlier rejection technique have been used to reject outliers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Correlated"
        },
        {
            "text": "-FCNB implementation based only on using numerical data rather than using nominal data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Correlated"
        },
        {
            "text": "Network (CNN( model [19] CNN was developed to detect Covid-19 patients using a dataset of CT images. The suggested CNN model includes two major algorithms, called; CNN architecture and AlexNet as a transfer learning method.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 24,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Convolution Neural"
        },
        {
            "text": "Hybrid Diagnosis Strategy (HDS) [2] HDS depended on a new methodology for ranking the elected features by projecting them into an introduced patient space.",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 35,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Simple to implement. The proposed model's accuracy is insufficient for diagnosing Covid-19."
        },
        {
            "text": "Performance of overall system is low because HDS does not take in the consideration the input uncertainty that refers to the effect of driving a simulation with input distributions according to real data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "HDS depended on numerical laboratory tests that have proven effective in detecting Covid-19 patients."
        },
        {
            "text": "Detection Strategy (CPDS) [3] CPDS was introduced to detect Covid-19 patients using enhanced KNN classifier based on the most important features. These features were elected using hybrid feature selection technique.",
            "cite_spans": [
                {
                    "start": 26,
                    "end": 29,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Covid-19 Patients"
        },
        {
            "text": "CPDS could accurately detect infected patients with minimum time penalty.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Covid-19 Patients"
        },
        {
            "text": "-No outlier rejection technique have been used to reject outliers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Covid-19 Patients"
        },
        {
            "text": "-CPDS implementation depended on using CT image data rather than using numerical laboratory tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Covid-19 Patients"
        },
        {
            "text": "Separable Dense Convolutional Network with Convolution Block Attention (AM-SdenseNet) module [20] AM-SdenseNet model was introduced to diagnose Covid-19 patients based on the CT images dataset.",
            "cite_spans": [
                {
                    "start": 93,
                    "end": 97,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Depthwise"
        },
        {
            "text": "AM-SdenseNet could provide fast and accurate diagnosis which extremely important to reduce the spreading of infection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Depthwise"
        },
        {
            "text": "-Large networks still could not be trained.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Depthwise"
        },
        {
            "text": "-it did not use feature selection or outlier rejection method to correctly learning the diagnosis model. -It has not been tested on a different types of datasets such as blood tests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Depthwise"
        },
        {
            "text": "The ResNet-50 model as a new artificial intelligent system was used to diagnose Covid-19 patients based on the 3D CT images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "The ResNet-50 model outperformed the 3DResNet18 and 3D-ResNet50 models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "-The ResNet-50needed to run several ResNet-50 architectures -It needed a high memory. depends on the use of the sigmoid function that is used to convert the positions of particles in the population into discrete space. Thus, all particles in the population can only have binary values (0 or 1) to cope with the outlier rejection problem that uses zero value as a valid item and one value as an outlier item to make as great as possible the model's performance. While BPSO has the advantages of being adaptable, simple, and flexible which enable it to accurately detect and then reject outlier items in the binary space, it suffers from the computational time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "Consequently, HOR is provided to quickly and accurately detect and then reject outlier items by utilizing the benefits of both standard division as a statistical-based method and IBPSO as an optimization method based on distance-based methodology as a fitness function and tackling their problems. The sequential steps of HOR method using 'nt' training items are illustrated in Fig. 6 . To implement HOR method, the medical dataset should be collected from hospitals. Then, the collected data should be passed to FR stage to implement standard division method to quickly reject outlier items from training dataset as possible (e.g., tt \"the number of valid items in the training dataset\"), where, tt < nt [22, 25] . Then, the training dataset with 'tt' valid items, which are passed from FR stage, are forwarded to AR stage to enable IBPSO to quickly give accurate subset of valid training items without outliers. Secondly, iterations of IBPSO will continue until discontinuation criteria are met. Finally, the most significant subset of valid training items is presented in the best position called global position in the swarm. SAD, as a fitness function, is applied to evaluate particles in the swarm by calculating the average distance from each particle in the swarm and the center of every class category.",
            "cite_spans": [
                {
                    "start": 705,
                    "end": 709,
                    "text": "[22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 710,
                    "end": 713,
                    "text": "25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 378,
                    "end": 384,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "Initially, IBPSO starts with a Swarm (Sw) that consists of many particles (birds) as solutions. In IBPSO, each bird or particle in Sw represents a potential solution (i.e. a subset of the valid training items in training dataset) in an tt-dimensional search space. Accordingly, a binary string representation is used to represent a subset of valid items in each bird. Each particle's size or length equals the same number of training items in the training dataset. In fact, the bird bits (positions) may contain either zero or one value. The elimination of the gth item in the particular subset in the particle as an outlier item can be denoted by one, and the existence of the gth item as a valid item can be denoted by zero. An example to clarify the idea, a representation of each particle (bird) is provided in Table 3 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 815,
                    "end": 822,
                    "text": "Table 3",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": ". At the end, Pos Global offers the global optimum solution. Consequently, using IBPSO as an outlier rejection method needs to perform many sequential steps as offered in Fig. 6 . In AR stage, the representation of 'n p ' birds in Sw is performed and then the evaluation (fitness) function of IBPSO is applied for measuring the evaluation degree of each bird Pos i (subset of valid training items) based on a distance-based method called SAD. In fact, SAD method is implemented on every particle Pos i in swarm Sw where it represents the aggregated summation of the average distance at every class that is can be calculated using (1) .",
            "cite_spans": [
                {
                    "start": 630,
                    "end": 633,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 177,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where fitness value (Pos i ) is the fitness or evaluation value for the position of ith particle (Pos). In fact, the fitness function represents a distance based method called SAD. Thus, fitness value (Pos i ) can be represented as SAD (Pos i ). Avg C represents the average distance based on the valid training items which belong to class c in the ith particle; where c = 1,2, \u2026,cl. cl is the total number of class categories. The best particle provides the lowest fitness value (SAD) and vice versa. According to every particle, the average distance Avg C of the valid items which belong to class c can be measured using (2).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where q'-z are the valid training items in class c without z items as outliers and Eclid(I g ,Center c ) represents the distance between gth item;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "Center c (f m )] using Euclidean Distance [29] . g is an index that refers to the valid training item in the particle which belongs to the class c; g = 1,2, \u2026,q'-z. Consequently, if item I g belongs to class c, then Eclid(I g , Center c ) can be calculated using (3).",
            "cite_spans": [
                {
                    "start": 42,
                    "end": 46,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where I g (f j ) is the value of item I g at the feature f j . Center c (f j ) is the center value of class c at the feature f j , and m represents the number of features. The center of class c according to jth feature f j (Center c (f j )) is calculated using (4).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where I g (f j ) represents the value of training item I g that belongs to class c at the feature f j . q' represents the number of training items which are belonging to class c. IBPSO method searches for the best bird (solution) in order to reduce SAD(Pos i ). Based on evaluation values for the birds in Sw, Pos Personal and Pos Global in each particle memory will be updated using (5) and (6) Pos pi+1 is the personal fittest position of (i + 1) th bird. Pos Personal and Pos Global are used for updating every bird's velocity Vel i in the next iteration (itr + 1) using (7) [12, 26, 27] .",
            "cite_spans": [
                {
                    "start": 578,
                    "end": 582,
                    "text": "[12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 583,
                    "end": 586,
                    "text": "26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 587,
                    "end": 590,
                    "text": "27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "Vel i (itr + 1) = w * Vel i (itr) + (c 1 r 1 (Pos pi (itr) \u2212 Pos i (itr))) + (c 2 r 2 (Pos G (itr) \u2212 Pos i (itr)))",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "Where itr is the current iteration, Vel i (itr + 1) represents the velocity of ith bird at the next iteration, and Vel i (itr) is the velocity of ith bird at the current iteration. Pos pi (itr) is the personal fittest position of ith bird at the current iteration; Pos Personal (Pos i ) and Pos G (itr) is the global fittest position in the swarm Sw at the current iteration; Pos Global . Additionally, Pos i (itr) represents the current position of ith bird at the current iteration. w represents the inertia weight where it is used to control the impact of the previous history of velocities on the current velocity; w\u2208 [0.9-1.2] [12] . c 1 represents the cognitive constant while c 2 is the social acceleration constant; c 1 ,c 2 \u2208 [2-4]. Both r 1 and r 2 refer to random numbers; r 1 ,r 2 \u2208[0-1] [12] . Based on the calculation of velocity Vel i for every bird in Sw, the velocity of bird can refer to the probability distribution with the main role to randomly produce the bird position. Thus, the sigmoid function is implemented to determine a new position of ith bird (Pos i (itr + 1)) based on binary values using (8) .",
            "cite_spans": [
                {
                    "start": 632,
                    "end": 636,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 800,
                    "end": 804,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1122,
                    "end": 1125,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where Pos j i (itr +1) is the value of ith bird at jth position in the next iteration itr + 1; j = 1,2,3, \u2026,tt. Additionally, rand(0,1) represents a random value that belongs to [0,1] and sigmoid(Vel j i ) indicates to the sigmoid function which represents the probability of jth bit that contains either 0 or 1 value that can be calculated by using (9) .",
            "cite_spans": [
                {
                    "start": 350,
                    "end": 353,
                    "text": "(9)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "where the base of the natural logarithm is represented in e. According to the new position Pos i (itr + 1) of every bird in Sw, the evaluation value of every bird is measured using the fitness function in (1) . The steps of IBPSO will continue until the finishing condition is met. Finally, the fittest bird of the whole swarm Pos Global represents the solution and the algorithm terminates. All training items denoted by zero in this bird represent the valid items which can be used to accurately learn the classification model (e.g, n \"the final number of valid items in the training dataset\"), but the training items denoted by one represent outliers which should be removed. Finally, the 'n' of valid items is the best subset of training items used to correctly learn the classification model; n < tt. The steps of HOR are presented in Algorithm 1. After eliminating outlier items from training dataset, feature selection process should be implemented to select the most signification features on class category to quickly enable the classification model to give more accurate results. Thus, feature selection process will be applied on dataset without outliers in the next sub-section.",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 208,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50 deep learning model (ResNet-50) [21]"
        },
        {
            "text": "In fact, it is not only outlier rejection process is the process that affects the efficiency of the classification model, but also feature selection process has a great effect on improving its efficiency by enabling it to give a faster and more accurate classification [8] [9] [10] [11] [12] [13] . The cause of overfitting problem may be the presence of non-informative features in the healthcare dataset [30] [31] [32] . Thus, feature selection process will be implemented on dataset during this phase to select the most effective features on the used classifier. Feature selection process can be performed by using filter or wrapper methods [30] [31] [32] . While filter methods are simple and fast, these methods may not optimally select the best features. On the other hand, wrapper methods can accurately select subset of informative features that have an impact on the classification method. Recently, optimization techniques are used as feature selection methods to accurately select the best subset of features. Through this section, a Hybrid Feature Selection (HFS) method as a simple but effective selection methodology is introduced to select the best features that enable the classification model to quickly and accurately perform its tasks. HFS method integrates between wrapper and filter techniques to quickly and accurately eliminate irrelevant features. The proposed HFS method composes of two stages called Fast Selection (FS) stage and Accurate Selection (AS) stage as shown in Fig. 7 . In FS stage, Chi-square is used as a filter method to quickly remove non-informative features in the healthcare dataset [10] . In AS stage, Improved Binary Gray Wolf Optimization (IBGWO) method is used as an optimization method to accurately select the best features that can evolve the performance of the classification model [33] . Although IBGWO can accurately eliminate irrelevant features, its execution time is very high. Thus, Chi-square method in FS stage has been preceded IBGWO to quickly eliminate irrelevant features before passing the medical dataset to IBGWO method in AS stage. This process aims to reduce the execution time of IBGWO and to provide a pure dataset without irrelevant features.",
            "cite_spans": [
                {
                    "start": 269,
                    "end": 272,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 273,
                    "end": 276,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 277,
                    "end": 281,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 282,
                    "end": 286,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 287,
                    "end": 291,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 292,
                    "end": 296,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 406,
                    "end": 410,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 416,
                    "end": 420,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 644,
                    "end": 648,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 649,
                    "end": 653,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 654,
                    "end": 658,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1627,
                    "end": 1631,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1834,
                    "end": 1838,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [
                {
                    "start": 1498,
                    "end": 1504,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Feature selection phase (FSP)"
        },
        {
            "text": "Thus, the proposed HFS aims to quickly and accurately select the most effective features in the dataset. Finally, both training and testing dataset based on an optimal subset of features are used to enable the classifier to perform its tasks well. Although IBGWO has been widely applied in many works, it is used in this work as a feature selection method by employing a reliable fitness function that represents the average accuracy value from several classification models (e.g., 'nc' classifiers). The use of many classification models to calculate the fitness degree of each search agent (wolf) aims to generalize the fitness evaluation of each search agent in the population. Accordingly, AS stage uses a machine learning method called IBGWO as a wrapper method based on average accuracy value from 'nc' of classifiers as a reliable fitness function. Finally, HFS is a hybrid method that consists of two important approaches, which are; (i) Chi-square as a filter method and (ii) IBGWO as a wrapper method that depends on average accuracy value from 'nc' of classifiers as a fitness function.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection phase (FSP)"
        },
        {
            "text": "Initially, Gray Wolf Optimization (GWO) built to address many optimization problems represented in continuous numbers search space. However, several problems such as feature selection process cannot A.H. Rabie et al. occur in continuous search space but it can occur in binary search spaces (discrete form) [33] [34] [35] . Hence, Binary GWO (BGWO) is a modified version of GWO to provide solutions to binary problems. Really, BGWO depends on using the sigmoid function that is used to convert the positions of the search agents (wolves) in the population from the continuous search space into discrete space. Thus, all search agents in the population can only have binary values (0 or 1) to cope with the feature selection problem that depends on selecting or not selecting the best subset of features to make as great as possible the model's performance. While BGWO has the advantages of being adaptable, simple, and flexible which enable it to accurately select the best subset of features in the binary space, its execution time is very high. Consequently, HFS is provided to quickly and accurately select the best subset of features by utilizing the benefits of both Chi-square as a filter selection technique and IBGWO as a wrapper selection technique and tackling their problems.",
            "cite_spans": [
                {
                    "start": 204,
                    "end": 216,
                    "text": "Rabie et al.",
                    "ref_id": null
                },
                {
                    "start": 307,
                    "end": 311,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 312,
                    "end": 316,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 317,
                    "end": 321,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "To implement IBGWO method, it follows the same steps for implementing the standard BGWO, with the difference that IBGWO is distinguished by using a better fitness function to evaluate every search agent in the population. The fitness function used in IBGWO is the average accuracy value from several classification models trained on the same subset of features in dataset to generalize the evaluation of each search agent in the population. In other words, the calculation of fitness values for search agents in IBGWO depends on several classifiers rather than using only a particular classifier to ensure the generality of the feature selection. Hence, the subset of features which have a significant and effective effect on most classification methods and not for a particular one classifier will be selected to ensure the effectiveness of the selected features on any classification model. Fig. 7 shows the main steps of implementing HFS method using 'm' features. To implement HFS method, the filtered data passed from the previous phase called ORP should be entered to FS stage for implementing the Chi-square method to quickly select t subset of informative features (e.g., t \"the number of selected features in the dataset\"), where, t<m. Then, the dataset with 't' features, which are selected from FS stage, are passed to AS stage to enable IBGWO to quickly select the best features as possible. Secondly, iterations of IBGWO will continue until discontinuation criteria are met. Finally, the best search agent in the population called Alpha (\u03b1) introduces the most significant features.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 893,
                    "end": 899,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "Initially, IBGWO starts with a Population (Pop) that consists of many search agents (e.g., \"wolves\") as solutions. In BGWO, each search agent in Pop is a potential solution (i.e. a subset of the most effective features) in an t-dimensional search space. Accordingly, a binary string representation is used to represent a subset of informative features in each search agent. Each search agent's size or length equals the same number of features presented in the medical dataset. Actually, the search agent bits (positions) may contain either zero or one value. The elimination of the k th feature in the particular subset in the search agent can be denoted by zero, and the selection of the k th feature can be denoted by one. An example to clarify the idea, a single search agent is represented in Table 4 , assuming t = 10, hence; F = {f 1 , f 2 , f 3 , \u2026., f 10 }.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 798,
                    "end": 805,
                    "text": "Table 4",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "Each search agent in Pop is represented in t-dimension (t = no. of the selected features in FS phase) as a vector that represents the position of i th wolf; W i = (W i 1 , W i 2 ,\u2026,W i t ). Then, the best three solutions based on their fitness values are assigned to W \u03b1 , W \u03b2 , and W \u03b4 as Alpha, Beta, and Delta wolves respectively. Through iterations, the coefficient vectors called A and C should be adjusted for the best solutions; W \u03b1 , W \u03b2 , and W \u03b4 to enable them to update their positions. Based on the updated positions of W \u03b1 , W \u03b2 , and W \u03b4 wolves (best solutions), the reset of other wolves in Pop can update their positions. Finally, the best solution W \u03b1 is used to represent the best subset of features when a termination condition is satisfied. Hence, using IBGWO as a selection method needs to follow several main steps as shown in Fig. 7 . In AS stage, 'n w ' search agents (wolves) are represented in Pop and then the evaluation (fitness) function of IBGWO is applied to calculate the evaluation degree of each search agent W i (subset of input features). The fitness (evaluation) function is the average accuracy value from 'nc' classifiers to ensure that the selected subset of features is the best subset that can enhance the performance of any classifier to provide fast and accurate classification. The fitness function according to 'nc' classifiers can be calculated for i th search agent (W i ) by using (10) .",
            "cite_spans": [
                {
                    "start": 1430,
                    "end": 1434,
                    "text": "(10)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 849,
                    "end": 855,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "Where Fit(W i ) is the fitness value for i th search agent, Accuracy j (W i ) is the accuracy value of j th classifier according to the selected features in i th search agent where j is an index that refers to the used classifiers; j= 1,2,\u2026.,nc. nc is the number of classifiers used to evaluate the selected features in each search agent. To clarify the idea, assume that there are two search agent in population; n_pop = 2 and three classifiers; nc = 3, used to evaluate the selected features in every search agent as presented in Table 5 . According to Table 5 , it is assumed that the used classifiers are Na\u00efve Bayes (NB) [12, 13] , K-Nearest Neighbors (KNN) [3, 12] , and Support Vector Machine (SVM) [9, 13] . Based on their accuracy values for search agents, it is noted that NB and KNN proven that the first search agent (W 1 ) is better than the second one. On the other hand, SVM proven that the second search agent (W 2 ) is better than the first one. Finally, the best search agent is the first one based on the average accuracy value. Accordingly, based on a single classifier, to determine the fitness evaluation for search agents cannot generally provide the optimal subset of features that can adaptive with any used classifier. For this reason, the used fitness function in this work based on using the average accuracy value to provide a global solution.",
            "cite_spans": [
                {
                    "start": 626,
                    "end": 630,
                    "text": "[12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 631,
                    "end": 634,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 663,
                    "end": 666,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 667,
                    "end": 670,
                    "text": "12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 706,
                    "end": 709,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 710,
                    "end": 713,
                    "text": "13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 532,
                    "end": 539,
                    "text": "Table 5",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 555,
                    "end": 562,
                    "text": "Table 5",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "Based on evaluation values for the search agents in Pop, the best three solutions; W \u03b1 , W \u03b2 , and W \u03b4 will be assigned. Then, the other search agents in Pop including Omega (\u03c9) will update their positions based on the position of W \u03b1 , W \u03b2 , and W \u03b4 . The reason is that W \u03b1 , W \u03b2 , and W \u03b4 represent the leaders which have better knowledge about the potential position of prey. Hence, \u03c9 can be guided by these leaders to move toward the optimal position. Before starting to update the positions of search agents in Pop, it is an important to calculate coefficient vectors A and C for the leaders; W \u03b1 , W \u03b2 , and W \u03b4 by using (11) and (12) [33] [34] [35] .",
            "cite_spans": [
                {
                    "start": 642,
                    "end": 646,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 647,
                    "end": 651,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 652,
                    "end": 656,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where r \u2192 1 and r \u2192 2 are random vectors in [0,1] and a \u2192 is the encircling coefficient used to balance the tradeoff between exploration and exploitation. a \u2192 is linearly decreasing from 2 to 0 over iterations by using",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where itr represents the number of iterations and Max_itr represents the maximum number of iterations. After calculating the coefficient vectors A and C for the leaders; W \u03b1 , W \u03b2 , and W \u03b4 , each search agent (e.g., i th search agent) in Pop can update its position in the next iteration (itr+1) based on W \u2192 1 , W \u2192 2 , and W \u2192 3 by using (14) [33] [34] [35] .",
            "cite_spans": [
                {
                    "start": 346,
                    "end": 350,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 351,
                    "end": 355,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 356,
                    "end": 360,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where W \u2192 1 , W \u2192 2 , and W \u2192 3 are the positions of leaders \u03b1, \u03b2, and \u03b4 respectively based on the current wolf (W i ). W \u2192 1 , W \u2192 2 , and W \u2192 3 can be calculated by using (15) (16) (17) [33] [34] [35] . (18) (19) (20) [33] [34] [35] .",
            "cite_spans": [
                {
                    "start": 173,
                    "end": 177,
                    "text": "(15)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 178,
                    "end": 182,
                    "text": "(16)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 183,
                    "end": 187,
                    "text": "(17)",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 188,
                    "end": 192,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 193,
                    "end": 197,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 198,
                    "end": 202,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 205,
                    "end": 209,
                    "text": "(18)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 210,
                    "end": 214,
                    "text": "(19)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 215,
                    "end": 219,
                    "text": "(20)",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 220,
                    "end": 224,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 225,
                    "end": 229,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 230,
                    "end": 234,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where C \u2192 1 , C \u2192 2 , and C \u2192 3 are the coefficient vector C for \u03b1, \u03b2, and \u03b4 respectively which can be calculated as in (12 [33] .",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 123,
                    "text": "(12",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 124,
                    "end": 128,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where Wk binary_i (itr+1) represents the binary value of i th search agent at kth position in the next iteration itr + 1; k=1,2,3,\u2026,t. Additionally, rand (0,1) is a random value that belongs to [0,1] and sig(W i k ) is the sigmoid transfer function that indicates the probability of k th bit that contains either 0 or 1 value calculated by using (22) [33] .",
            "cite_spans": [
                {
                    "start": 346,
                    "end": 350,
                    "text": "(22)",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 351,
                    "end": 355,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "where the base of the natural logarithm is represented in e. According to the new position W k binary_i (itr+1) of every search agent in Pop, the evaluation value of every search agent is measured using the evaluation function in (10) . The steps of IBGWO will continue until the finishing condition is met. Finally, the fittest search agent (W \u03b1 ) represents the solution and the algorithm terminates. According to W \u03b1 as the best solution, all bits denoted by 1 represent the best features that can be used to accurately learn the classification model. After selecting the best subset of features, classification model should be learned based on the filtered data to provide fast and accurate results. The steps of HFS are illustrated in Algorithm 2. After rejecting outliers from training dataset and then selecting the most significant subset of features in the used dataset, classification model should be learned to provide fast and accurate results. Thus, classification process will be applied on dataset without outliers and non-informative features in the next sub-section.",
            "cite_spans": [
                {
                    "start": 230,
                    "end": 234,
                    "text": "(10)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 1. Hybrid Outlier Rejection (HOR) Algorithm."
        },
        {
            "text": "The proposed Distance Based Classification Strategy (DBCS) is built upon distance measures. Assuming cl target classes C = {c 1 , c 2 , \u2026, c cl }. Hence, the distance based probability that an input item x belongs to the target class c i , denoted as; P Dist (x|c i ), relies on measuring the distance among the test item and the training items in an n dimensional feature space. Generally, P Dist (x|c i ) is a weighted sum of three different probabilities as illustrated in (23) .",
            "cite_spans": [
                {
                    "start": 476,
                    "end": 480,
                    "text": "(23)",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Classification phase (CP)"
        },
        {
            "text": "Where P Dist (x|c i ) is the distance based probability that the test item x belongs to the target class c i . \u03b1\u03b1,\u03b2\u03b2, and \u03bb are the considered weights. P DTCC (x|c i ) is the probability based on distance to class center, which relies on the distance between the test item x and the center of the target class c i . P DTNN (x|c i ) is the probability based on distance to nearest neighbors, which relies on measuring the distance from the test item x and a specific set of its nearest neighbors. P AKNN (x|c i ) is the probability based on a proposed Accumulative KNN (AKNN) technique. The belonging degree that the input item x belongs to class c i denoted as Belonging(x|c i ) can be calculated by (24) .",
            "cite_spans": [
                {
                    "start": 700,
                    "end": 704,
                    "text": "(24)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Classification phase (CP)"
        },
        {
            "text": "Belonging(x|c i ) = \u03b1\u03b1 * P DTCC (x|c i ) + \u03b2\u03b2*P DTNN (x|c i ) + \u03bb * P AKNN (x|c i ) (24) Finally, the target class of the input item can be calculated by (25) . More details about the used probabilities (e.g., P DTCC (x|c i ), P DTNN (x|c i ), A.H. Rabie et al. and P AKNN (x|c i )) are illustrated in the next sub-sections.",
            "cite_spans": [
                {
                    "start": 84,
                    "end": 88,
                    "text": "(24)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 154,
                    "end": 158,
                    "text": "(25)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 244,
                    "end": 261,
                    "text": "A.H. Rabie et al.",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Classification phase (CP)"
        },
        {
            "text": "where Target(x|c i ) is the target class of the input item x and c i is an index refers to one of the target classes; c i = 1,2, \u2026,cl.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification phase (CP)"
        },
        {
            "text": "Hybrid Feature Selection (HFS) Algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Algorithm 2."
        },
        {
            "text": "The distance between the item and the class center can be used as an indication to the degree of correlation between the item and the class. Assuming n dimensional feature space, the Euclidian distance can be calculated using (26) . On the other hand, assuming three target classes (e.g., cl = 3) and two dimensional feature space (e.g., n = 2), Fig. 8 illustrates that the more the distance between the class center and the test item x, the less the correlation between the class and the item. Hence, as Fig. 8 Correlation(x,c k ) . Assuming cl target classes, C = {c 1 , c 2 , \u2026, c cl }, then;",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 230,
                    "text": "(26)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 346,
                    "end": 352,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 505,
                    "end": 511,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 512,
                    "end": 531,
                    "text": "Correlation(x,c k )",
                    "ref_id": null
                }
            ],
            "section": "Probability based on distance to class center (P DTCC )"
        },
        {
            "text": "This yields; ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "depicts, since Distance(x,Center(c i ))<Distance(x,Center(c j )) < Distance(x,Center(c k )), this yields; Correlation(x,c i ) > Correlation(x,c j ) >"
        },
        {
            "text": "Finally;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Distance(x, Center(c i )) )"
        },
        {
            "text": "where P DTCC (x|c i ) is the probability based on distance to class center, which relies on the distance between the test item x and the center of the target class c i . Correlation(x,c i ) is a measurement that calculates the correlation between a test item x and the ith class c i by calculating the distance between the test item x and the center of ith class c i . Distance(x, Center(c i )) is the distance between the test item x and the center of ith class c i . \u03be is the proportionality constant and c i is the index that refers to the class number; c i = 1,2, \u2026cl. For illustration, as shown in Fig. 8 , assuming three target classes, C = {c 1 , c 2 , c 3 }, in a two dimensional Table 6 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 603,
                    "end": 609,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 688,
                    "end": 695,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Distance(x, Center(c i )) )"
        },
        {
            "text": "Generally, as explained by the traditional K-Nearest Neighbors (KNN) classifier, an input test item can be classified based on the belonging of its neighbors in the n dimensional feature space [3] . However, traditional KNN algorithm suffers from a technical hurdle, which is specifying the optimal value of K. To overcome such hurdle, the test item is expressed side to side with the labeled items in the employed n dimensional space. The input test item is considered as a center of a Virtual Circle (VC) as illustrated in Fig. 9 . The optimal radius (r opt ) of VC is calculated, then, all labeled items located inside VC are considered for identifying the target class of the input test item. Calculating the optimal radius of VC can be done using four different scenarios as expressed in (27) (28) (29) (30) .where r opt is the optimal radius of VC which can be done using Table 6 The procedure used to calculate P DTCC (illustrative Example).",
            "cite_spans": [
                {
                    "start": 193,
                    "end": 196,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 793,
                    "end": 797,
                    "text": "(27)",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 798,
                    "end": 802,
                    "text": "(28)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 803,
                    "end": 807,
                    "text": "(29)",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 808,
                    "end": 812,
                    "text": "(30)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 525,
                    "end": 531,
                    "text": "Fig. 9",
                    "ref_id": null
                },
                {
                    "start": 878,
                    "end": 885,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Probability based on distance to nearest neighbors (P DTNN )"
        },
        {
            "text": "Distance(x,Center(c j )) P DTCC (x|c i ) Fig. 9 . Calculating probability based on distance to nearest neighbors.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 41,
                    "end": 47,
                    "text": "Fig. 9",
                    "ref_id": null
                }
            ],
            "section": "Class"
        },
        {
            "text": "four different scenarios; r opt = {r opt1, r opt2, r opt3, r opt4 }. x is the test item, Distance(x,NCC) is the distance from the test item to the Nearest Class Center (NCC), Distance(x,FCC) is the distance from the test item to the Farthest Class Center (FCC), n is the number of classes. For each target class, a supporters set, denotes as S(c) is formulated, which includes those items that belong to the class c and located inside the proposed VC. For illustration, as depicted in Fig. 10 , S(c i ) is the set of items that belong to the class c i and are also inside VC. The Belonging Degree (BD) of the test item to a class depends on two basic factors. The first being the number of class supporters, hence, the more the number of class supporters, the more the item belonging degree to the class, while the second element is the average sum of distances between the test item and all the class supporters, hence, the more the average sum of distances between the test item and all class supporters, the less the item belonging degree to the class. This can be formulated through the following equations.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 485,
                    "end": 492,
                    "text": "Fig. 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Class"
        },
        {
            "text": "where \u03bc is the equation constant, assuming \u03bc = 1, then BD is expressed as (31) and P DTNN is formulated as (32) .",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 78,
                    "text": "(31)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 107,
                    "end": 111,
                    "text": "(32)",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Class"
        },
        {
            "text": "Finally;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Class"
        },
        {
            "text": "As depicted in (31) and (32), S(c i ) is the set of items that belong to the class c i and are also inside VC, BD(x, c i ) is the belonging degree of the item x to class c i , C is the set of target classes. Fig. 11 gives an illustration for calculating the probability based on distance to nearest neighbors considering 3 target classes c 1 , c 2 , and c 3 . The numbers in the circles indicates the distance from the test item x to the corresponding supporters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 208,
                    "end": 215,
                    "text": "Fig. 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Class"
        },
        {
            "text": "In spite of its efficiency and simplicity, traditional KNN suffers from a basic hurdle, which is specifying the optimal value of k. Unfortunately, a minor change in the value of k may totally change the final decision, which is the target class of the input test item. This problem is called KNN trapping, which was illustrated in Ref. [3] . To solve this problem, a new instance of the traditional KNN classifier will be introduced in this section, which is called Accumulative KNN (AKNN) . The steps of implementing AKNN are presented in Algorithm 3.",
            "cite_spans": [
                {
                    "start": 336,
                    "end": 339,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 466,
                    "end": 489,
                    "text": "Accumulative KNN (AKNN)",
                    "ref_id": null
                }
            ],
            "section": "Probability based on accumulative KNN algorithm (P AKNN )"
        },
        {
            "text": "The basic idea behind the proposed AKNN is to continuously change the value of k through a pre-defined range and accumulatively calculate a grade for each target class. As illustrated in Algorithm 3, initially, an accumulation limit (final accumulation value), denoted as; \u03c8 is defined, which represents the maximum value of k parameter. The range of \u03c8 can be defined as; 1 < \u03c8 \u2264 minimum(|c i |) \u2200 c i \u2208 C, where |c i | is the number of items (examples) in the target class c i , and minimum(|c i |) is the number of items (examples) in the class with the minimum number of items (smallest class). Then, an iteration is done to calculate the grade of each target class. Initially, the grade of all target classes is set to zero, hence Grade \u2200ci\u2208C (c i ) = 0, and the parameter k is set initially to 1. Hence, the iteration starts with k = 1 and continues by increasing k by one until k reaches the accumulation limit (e.g., \u03c8). In each iteration, based on the current value of k, the target class of the input test item is identified, then the grade of the resultant target class is updated (increased by one) accordingly. The iteration is continued until k reaches the accumulation limit (e.g., \u03c8). At this point the iteration is stopped. The result of the iteration is assigning a grade for each target class. Based on the assigned grade to the target class c i , the probability, using AKNN, that the input test item x belongs to c i (denoted as; P AKNN (x|c i )) can be calculated using (33) .",
            "cite_spans": [
                {
                    "start": 1491,
                    "end": 1495,
                    "text": "(33)",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Algorithm 3. Accumulative KNN Algorithm."
        },
        {
            "text": "where Grade(c i ) is the grade of the target class c i , and \u03c8 is the accumulation limit. Fig. 12 introduces an illustrative example showing how to calculate P AKNN (x|c i ) \u2200 c i \u2208 C considering three different target classes C={c 1 , c 2 , c 3 }. The number of items in c 1 , c 2 , and c 3 (e.g., |c 1 |, |c 2 |, and | c 3 |) equals 10, 7, and 9 respectively. The accumulation limit (e.g., \u03c8) Generally, the basic KNN classifier has two technical hurdles, the first is how to set the optimal value of k, while the second is the KNN laziness. As depicted through the illustrative example shown in Fig. 12 , AKNN uses a pre-defined range for the K parameter. This action solves the first technical hurdle for implementing the basic KNN classifier, which is \"what is the optimal value of k to be used?\". To highlight the basic difference between the traditional KNN algorithm and the proposed AKNN, consider the traditional KNN with k=7. Based on the data illustrated in Fig. 5 , the target class of the input test item x will be c 3 . However, the proposed AKNN takes another decision to classify x to class c 2 since P AKNN (x|c 2 ) is the maximum conditional probability. On the other hand, although the proposed AKNN classifier seems to be simple and straight forward, it inherits another technical hurdle of the basic KNN classifier, which is the laziness. The basic KNN classifier is a lazy learner as it consumes long time during the testing phase. However, since the basic KNN uses a static value of k, the calculations are done once. On the other hand, additional time penalty is added in the case of AKNN as it repeats the calculations accumulatively. Accordingly, the basic problem in AKNN is that it consumes more time to detect the target class of the input test item. However, in the applications that the time is not critical compared to the accuracy such as Covid-19 diagnose, this problem has no importance since the diagnose accuracy has the most priority.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 90,
                    "end": 97,
                    "text": "Fig. 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 598,
                    "end": 605,
                    "text": "Fig. 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 970,
                    "end": 976,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Algorithm 3. Accumulative KNN Algorithm."
        },
        {
            "text": "The critical challenge now is how to set the proper values of the tuning parameters \u03b1\u03b1, \u03b2\u03b2, and \u03bb to guarantee the maximum classification accuracy. To solve this issue, consider the equation Q = q 1 Aa + q 2 Ba + q 3 Ca, which is a linear equation in three variables. The variables are Aa, Ba, and Ca, while q 1 , q 2 , and q 3 are the equation coefficients (weights). The number Q is the constant of the equation. The solution of this equation is a specific point in R 3 such that when the Aa coordinate of the point is multiplied by q 1 , the Ba coordinate of the point is multiplied by q 2 , the Ca coordinate of the point is multiplied by q 3 , and then those three products are added together, the answer equals Q. However, usually, there are infinite solutions of a linear equation of three variables. The set of solutions in R 3 of a linear equation of three variables is a two dimensional plane as illustrated in Fig. 13 . The weights q 1 , q 2 , and q 3 determine the orientation of the solution plane. The problem now is to set the suitable values of q 1 , q 2 , and q 3 to get the suitable orientation of the solution plane.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 921,
                    "end": 928,
                    "text": "Fig. 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Calculating the proper values of \u03b1\u03b1, \u03b2\u03b2, and \u03bb"
        },
        {
            "text": "As depicted in the linear equation in three variables illustrated in Fig. 13 , q 1 , q 2 , and q 3 are the weights in Aa, Ba, and Ca dimensions respectively. Hence, if the value of a specific dimension is effective, the corresponding weight should be increased. For illustration, if the value in the Aa dimension is more important (effective) than the values in Ba A.H. Rabie et al. and Ca dimensions, the weight q 1 should be greater than q 2 and q 3 . Hence; q 1 \u221deffectiveness(Aa), q 2 \u221deffectiveness(Ba), and q 3 \u221d effectiveness(Ca). Now, consider (24) ; Belonging(x|c i ) = \u03be *P DTCC (x|c i ) + \u03b2\u03b2*P DTNN (x|c i ) + \u03bb *P AKNN (x|c i ), it can be concluded that; \u03be\u221deffectiveness(P DTCC (x|c i ))\u21d2\u03be \u2248 effectiveness(P DTCC (x|c i )) \u03b2\u03b2\u221deffectiveness(P DTNN (x|c i ))\u21d2\u03b2\u03b2 \u2248 effectiveness(P DTNN (x|c i )) \u03bb\u221deffectiveness(P AKNN (x|c i ))\u21d2\u03bb \u2248 effectiveness(P AKNN (x|c i ))",
            "cite_spans": [
                {
                    "start": 370,
                    "end": 382,
                    "text": "Rabie et al.",
                    "ref_id": null
                },
                {
                    "start": 552,
                    "end": 556,
                    "text": "(24)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 69,
                    "end": 76,
                    "text": "Fig. 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Calculating the proper values of \u03b1\u03b1, \u03b2\u03b2, and \u03bb"
        },
        {
            "text": "We assume that effectiveness(P T (x|c i )) as the classification accuracy if P T (x|c i ) is the only considered probability for classifying the test item x as; Target(x) = argmax \u2200c i \u2208C (P T (x|c i )) where T refers to DTCC, DTNN, or AKNN. Hence, the proper values of \u03be, \u03b2\u03b2, and \u03bb can be calculated empirically by using a set of labeled items, the classification accuracy can be calculated, then the proper values of \u03be, \u03b2\u03b2, and \u03bb can be identified accordingly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Calculating the proper values of \u03b1\u03b1, \u03b2\u03b2, and \u03bb"
        },
        {
            "text": "In this section, the effectiveness of Distance Based Classification Strategy (DBCS) strategy is examined. CIHI is aided by a novel classification strategy called Distance Based Classification Strategy (DBCS), which uses the Covid-19 dataset to identify people who are vulnerable to Covid-19 infection. Individuals are classified into 6 types using the proposed DBCS, and appropriate preventative actions can be performed for each type. DBCS is comprised of three successive phases; ORP, FSP, and CP. The HOR technique will be given in ORP in order to rapidly and precisely reject outliers by using standard division and IBPSO. FSP uses the HFS technique which includes Chi-square as a filter method and IBGWO as a wrapper method, to choose the most significant subset of features. Finally, CP uses Accumulative K-Nearest Neighbors (AKNN). Our implementation uses the \"NileDS\" dataset that consists of . In this work, 10-fold cross-validation method is used to analyze the classification performance. Based on the 10-fold cross-validation method, the NileDS dataset has been split into ten equal subsets of data. Nine of these ten subsets of data are used for training while the last one is used for testing. Hence, each case (patient) appears nine times in a training set, and appears one time in a test set. Accordingly, the10-fold cross-validation method does not focus on how the cases are partitioned. Confusion matrix matrices will be used to evaluate DBCS [9, 37] . The chosen value of K is assigned empirically. A basic classifier (KNN) is employed using different values of K using 1000 different cases of the employed dataset in which 800 cases is used for training and 200 cases for testing. For each value of K, the corresponding accuracy and error are calculated for the classifier. The optimal value of K is the one which maximizes the classification accuracy and accordingly minimizes the error rate. In our case, the used range is K\u2208 [1, 40] . As illustrated in Fig. 14 , the best value of K, which minimizes the classification error rate is K = 13, hence, it is the used value through the next experiments.",
            "cite_spans": [
                {
                    "start": 1462,
                    "end": 1465,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1466,
                    "end": 1469,
                    "text": "37]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 1949,
                    "end": 1952,
                    "text": "[1,",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1953,
                    "end": 1956,
                    "text": "40]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 1977,
                    "end": 1984,
                    "text": "Fig. 14",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Experimental results"
        },
        {
            "text": "Finding a dataset to be used in the study of Covid-19 is very difficult, because this disease is a relatively new form of coronavirus. We devise a Web-based form to collect routine blood tests from people before and after their infection with Covid-19 in order to overcome this obstacle. This form is associated to the Nile Higher Institute's artificial intelligence lab and can be found at [36] . As shown in Table 7 (a-c), the NileDS dataset contains 50 features collected from numerical laboratory tests. After applying the FS and AS stages in feature selection stage, the number of most important features became 34. The overall number of people who have filled out the form until now is 2215, with 1389 infected people, 396 unconfirmed cases, and 430 un-covid-19 people as shown in Table 8 . The available dataset is divided into two classes; training data (70% of all data) and testing data (30% of all data). Patients in the dataset can be classified into six types (Type (A-F)) based on their individual Covid-19 vulnerability levels. A screenshot from the NileDS dataset is shown in Fig. 15 .",
            "cite_spans": [
                {
                    "start": 391,
                    "end": 395,
                    "text": "[36]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 410,
                    "end": 417,
                    "text": "Table 7",
                    "ref_id": null
                },
                {
                    "start": 787,
                    "end": 794,
                    "text": "Table 8",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 1092,
                    "end": 1099,
                    "text": "Fig. 15",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "NileDS dataset description"
        },
        {
            "text": "In the NileDS dataset, the Covid-19 patients are classified into six classes based on the expected resistance of their body against the Corona virus. If a patient was infected with it, these classes indicate how much damage the virus may cause if the person is actually infected, while other patients were considered as negative. The performance of the classification strategy will be tested using five metrics in the following experiments. The metrics are accuracy, error, recall, precision, and runtime. The confusion matrix can be used to calculate the values of these parameters [9, 37] . As shown in Table 9 , a confusion matrix and associated formulas were used.",
            "cite_spans": [
                {
                    "start": 583,
                    "end": 586,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 587,
                    "end": 590,
                    "text": "37]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [
                {
                    "start": 605,
                    "end": 612,
                    "text": "Table 9",
                    "ref_id": "TABREF10"
                }
            ],
            "section": "Evaluation performance metrics"
        },
        {
            "text": "This section will evaluate the DBCS, which is made up of three successive phases; (i) ORP using HOR technique, (ii) FSP using HFS method, and (iii) CP using AKNN method. After removing outliers in ORP using HOR approach, selecting the most important features in FSP using HFS approach, the filtered data is given to CP to correctly learn the classification model. Table 10 shows the performance of DBCS in terms of accuracy, error, precision, and recall based on 10-fold cross-validation. To demonstrate the efficiency of DBCD, it was compared with several previous Covid-19 classification methods including DBNB [4] , FCNB [1] , CNN [19] , HDS [2] , and CPDS [3] . Fig. (16 -20) and Table 11 illustrate the five metrics; accuracy, error, precision, recall, and run-time of the employed strategies. The results show that DBCS outperforms other classification strategies in terms of accuracy, precision, recall, and run-time performance parameters.",
            "cite_spans": [
                {
                    "start": 613,
                    "end": 616,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 624,
                    "end": 627,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 634,
                    "end": 638,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 645,
                    "end": 648,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 660,
                    "end": 663,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [
                {
                    "start": 364,
                    "end": 372,
                    "text": "Table 10",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 666,
                    "end": 679,
                    "text": "Fig. (16 -20)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 684,
                    "end": 692,
                    "text": "Table 11",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Testing the Distance Based Classification Strategy (DBCS)"
        },
        {
            "text": "According to Table 10 , the performance of DBCS strategy in terms of accuracy, error, precision, and recall at each fold of 10-fold crossvalidation is presented to classify people based on their vulnerability by Covid-19. Additionally, 10-fold values are averaged values across the four metrics. In Table 10 , the best performance values for DBCS strategy are presented at 4,8,9, and10-fold while the worst values are presented at 1,2,3,5,6, and 7-fold. Additionally, the average values in terms of accuracy, error, precision, and recall are 0.90, 0.09, 0.85, and 0.81 respectively. Figures (16 \u2192 19) and Table 11 show that at the number of training samples equal to 973 patients, the accuracy values provided by DBNB, FCNB, CNN, HDS, CPDS, and DBCS are 0.75, 0.71, 0.63, 0.64, 0.66, and 0.91 respectively. According to these results, DBCS obtains the highest accuracy value when two phases, named; the outlier rejection phase and the feature selection phase are used before implementing the classification model to classify Covid-19 patients based on the individual's level of vulnerability to Covid-19. Table 11 show that DBCS outperforms other previous strategies by providing the highest accuracy value, the lowest error value, and the fastest run time.",
            "cite_spans": [
                {
                    "start": 373,
                    "end": 379,
                    "text": "4,8,9,",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 13,
                    "end": 21,
                    "text": "Table 10",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 299,
                    "end": 307,
                    "text": "Table 10",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 583,
                    "end": 600,
                    "text": "Figures (16 \u2192 19)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 605,
                    "end": 613,
                    "text": "Table 11",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 1105,
                    "end": 1113,
                    "text": "Table 11",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Testing the Distance Based Classification Strategy (DBCS)"
        },
        {
            "text": "Several pros and cons of the proposed DBCS will be discussed in this section as presented in Table 12 . According to Table 12 , the proposed DBCS has many benefits such as it is a novel, efficient, applicable, scalable, accurate, and fast strategy. In fact, this paper is the first to provide the issue of predicting how people's bodies will react if they are infected with Covid-19. DBCS is a new prediction strategy used to classify people based on their vulnerability by Covid-19. Additionally, DBCS has high prediction efficiency because it employs three new methods called HOR to reject outliers, HFS to select the best subset of features, and AKNN to accurately classify people. DBCS has also the ability to be applied in hospitals and medical centers because of its simplicity and straightforward during the implementation. DBCS is scalable because it can handle datasets incrementally and it can be used to solve other prediction problems in the medical systems. DBCS can provide more accurate and fast predictions compared to other recent strategies. On the other hand, the proposed DBCS suffers from higher time delay compared with other competitors. The cause of such delay is concentrated in the use of the pre-processing phases, which are; outlier rejection and feature selection. However, this delay does not have an effect on the system performance because the implementation of both outlier rejection and feature selection methods is performed offline. Additionally, providing accurate diagnose is more important than getting fast diagnose.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 93,
                    "end": 101,
                    "text": "Table 12",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 117,
                    "end": 125,
                    "text": "Table 12",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "DBCS pros and cons"
        },
        {
            "text": "A new strategy called Distance Based Classification Strategy (DBCS) has been provided in this paper for classifying individuals into six different types, then suitable precautionary measures can be taken for every type. DBCS composes of three phases called Outlier Rejection Phase (ORP), Feature Selection Phase (FSP), and Classification Phase (CP) to quickly give more accurate classifications. After eliminating outliers in ORP and selecting the most significant features in FSP, filtered data was passed to CP to learn the Accumulative K-Nearest Neighbors (AKNN) classification model. Hybrid Outlier Rejection (HOR) method that combines standard division and Improved Binary Particle Swarm Optimization (IBPSO) methods has been used in ORP to determine outliers and then reject them. On the other hand, Hybrid Feature Selection (HFS) method that consists of Chi-square as a filter method and Improved Binary Gray Wolf Optimization (IBGWO) as a wrapper method has been used in FSP to select the most informative features for improving the performance of classification model and avoiding overfitting. In CP, the core of such classification strategy is a proposed AKNN classifier that was used to quickly and accurately classify patients based on the forward data from ORP and FSP. Experimental results showed that the proposed DBCS provided fast and accurate results compared to the existing methods in terms of accuracy, error, precision, and recall. DBCS introduced accuracy, error, precision, and recall values reach to 0.91, 0.09, 0.86, and 0.84 respectively. Hence, the proposed DBCS provided the best accuracy value that is higher than other recent strategies. Finally, the proposed DBCS based on ORP, FSP, and AKNN in CP introduced fast and more accurate results than the existing techniques in terms of accuracy, precision, recall, and execution time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "In the future, there are many different directions through which the efficiency of the classification strategy proposed in the research can be improved such as; (i) implementing more heuristics such as the deep learning and fuzzy inference methods as well as different classifiers such as; support vector machines in the proposed classification method to obtain more accurate classifications, (ii) testing the efficiency the proposed DBCS using different datasets collected from different regions and at different sizes. Thus, it is possible to accurately determine the efficiency of the proposed strategy, as it is known that the natures and characteristics of human bodies differ from each other at different regions, and therefore the ability of people to resist diseases may differ according to the genetic characteristics and the nature of the environment in which they live, (iii) implementing the presented strategy on It is a test that examines the quantity of bilirubin in the blood and is used to assess liver function.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Future works"
        },
        {
            "text": "It is a test that searches for bilirubin in the urine or blood to determine the amount of conjugated bilirubin.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Direct_Bilirubin"
        },
        {
            "text": "It's a measurement of how much alkaline phosphotase is in your blood. Alkaline_ Phosphotase is an enzyme that's located all over the body. It can be found primarily in the liver, digestive system, kidneys, and bones.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Alkaline_ Phosphotase"
        },
        {
            "text": "ALT is a liver and kidney enzyme that is normally found in the cells. When ALT levels in the blood are high, it indicates that the liver has been damaged. Yes",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Alamine_ Aminotransferase (ALT)"
        },
        {
            "text": "The enzyme AST is generally found in the liver and the heart. When AST levels in the blood are increased, it can signify liver illness, cardiac disease, or pancreatitis. Yes",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Aspartate_ Aminotransferase (AST)"
        },
        {
            "text": "It's a measurement of how much protein is in your blood. When total protein levels are high, it could be a sign of dehydration or malignancy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Total_ Protiens"
        },
        {
            "text": "It is a protein produced by the liver, this test evaluates the amount of albumin in the blood Yes Globulin_Ratio",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Albumin"
        },
        {
            "text": "It is the percentage of albumin to globulin in blood plasma. It is a part of blood test that is used to determine how much potassium is in the blood.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Albumin"
        },
        {
            "text": "It is a blood test that is used to determine the quantity of haemoglobin in our blood.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Haemoglobin"
        },
        {
            "text": "It is a test that is used to determine if a patient has dehydration, anaemia, or polycythaemia. No White blood cell count White blood cells make up the immune system where they help fight infections and other diseases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Packed cell volume"
        },
        {
            "text": "It is a condition in which the blood arteries have consistently high pressure. Hypertension is a serious medical condition that can endanger kidneys, heart, brain, and other organs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Hypertension"
        },
        {
            "text": "Pedal Edema Edema is the medical term for swelling. Body parts swell as a result of injuries and inflammation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes"
        },
        {
            "text": "It is a medical test that predicts the heart disease by measuring electrical activity of the heart. Yes",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Resting electrocardiographic results"
        },
        {
            "text": "Anemia is a medical condition in which the quantity of haemoglobin or red blood cells is low.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Anemia"
        },
        {
            "text": "Diabetes mellitus is a metabolic disorder that impairs the body's ability to produce sugar.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Diabetes mellitus"
        },
        {
            "text": "The coronary arteries transport oxygen, nutrients, and blood to your heart. Coronary artery disease happens when the principal blood arteries in your heart become damaged.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Coronary artery disease"
        },
        {
            "text": "The appetite test is used to determine a person's appetite.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Appetite"
        },
        {
            "text": "The heart rate is determined by the number of beats of the heart per minute bpm).)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Maximum heart rate achieved"
        },
        {
            "text": "Angina is a type of chest pain caused by exercise, stress, or other causes that force the heart to work harder. It's a pretty common symptom of coronary artery disease.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Exercise induced angina"
        },
        {
            "text": "Arteriosclerosis happens when arteries that supplies blood from your heart to the body thicken and stiffen, resulting in decreased blood flow to your tissues and organs.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Atherosclerosis"
        },
        {
            "text": "The liver produced the CRP and the test is used to monitor or identify the inflammatory illnesses.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C-Reactive Protein (CRP)"
        },
        {
            "text": "The LDH test is used to diagnose tissue injury.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Lactate Dehydrogenase (LDH)"
        },
        {
            "text": "Troponins are a protein family that regulates muscle contraction in skeletal and cardiac muscle fibres. Troponin assays measure the amount of cardiac-specific troponin in the blood to diagnose heart injury.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Troponin"
        },
        {
            "text": "Descriptions about the features of NileDS dataset. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Table (7-c)"
        },
        {
            "text": "The LC test determines the lymphocyte count, which is a component of WBC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lymphocytes Count (LC)"
        },
        {
            "text": "The monocytes count test determines the number of monocytes circulating in the human blood.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Yes Monocytes count"
        },
        {
            "text": "Eosinophil is a part of the immune system that aids in disease prevention by avoiding infections and boosting inflammation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Eosinophil"
        },
        {
            "text": "Basophils are formed from bone marrow that and help the immune system work properly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Basophils"
        },
        {
            "text": "GGT is an enzyme that is found all over the body. GGT levels in the blood can be used to diagnose bile duct damage or liver illness.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Gamma-Glutamyl Transpeptidas (GGT)"
        },
        {
            "text": "Chest pain type The presence of abnormal pain between the base of the neck and diaphragm is described as chest pain.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No"
        },
        {
            "text": "This test determines the amount of sugar in a blood after a fasting state.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Fasting blood sugar"
        },
        {
            "text": "Ferritin is responsible for iron storage, and the high value indicates the presence of severe inflammation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Ferritin"
        },
        {
            "text": "CPK is a protein present in the skeletal muscles, brain, and heart. CPK aids in the induction of chemical changes that happen in human body. hardware device (Application Specific Integrated Circuits) such as; Field Programmable Gate Array (FPGA) and Digital Signal Processor (DSP). Hence, we can produce a standalone device for diagnosing and classifying people based on how much their body will react if they are infected with Covid-19. This will certainly be useful in containing the Corona pandemic.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "No Creatine phosphokinase (CPK)"
        },
        {
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Declaration of competing interest"
        },
        {
            "text": "Comparison between DBCS and other recent classification strategies in terms of accuracy, precision, and recall. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Table 11"
        },
        {
            "text": "\u2022 The proposed DBCS has a high delay because it contains outlier rejection and feature selection phases. In fact, the effect of this delay is ignored because both phases are performed offline and this paper aims to provide accurate results more than fast results. Accuracy",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Delay"
        },
        {
            "text": "\u2022 DBCS has high prediction accuracy compared to other recent strategies because it contains three new methods that work smoothly with each other, which are HOR, HFS, and AKNN methods. Accordingly, the whole strategy (e.g., DBCS) provides a high efficiency.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Delay"
        },
        {
            "text": "\u2022 DBCS has the ability to be applied in hospitals and medical centers because it is simple and straightforward and easy to be implemented.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Applicability"
        },
        {
            "text": "\u2022 DBCS is scalable because it can handle data set incrementally. \u2022 It can be used to solve other prediction problems in the medical systems.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Scalability"
        },
        {
            "text": "A.H. Rabie et al. ",
            "cite_spans": [
                {
                    "start": 5,
                    "end": 17,
                    "text": "Rabie et al.",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Scalability"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Accurate detection of covid-19 patients based on feature correlated Na\u00efve Bayes (FCNB) classification strategy",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Mansour",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Badawy",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Journal of Ambient Intelligence and Humanized Computing",
            "volume": "",
            "issn": "",
            "pages": "1--33",
            "other_ids": {
                "DOI": [
                    "https:/link.springer.com/article/10.1007/s12652-020-02883-2"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Detecting covid-19 patients based on fuzzy inference engine and deep neural network",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shaban",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Abo-Elsoud",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Applied Soft Computing",
            "volume": "99",
            "issn": "",
            "pages": "1--19",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "A New COVID-19 patients detection strategy (CPDS) based on hybrid feature selection and enhanced KNN classifier, in: Knowledge-Based Systems",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shaban",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Abo-Elsoud",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "205",
            "issn": "",
            "pages": "1--18",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Accurate Detection Of COVID-19 Patients Based On Distance Biased Na\u0131ve Bayes (DBNB) Classification Strategy",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shaban",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Abo-Elsoud",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2021.108110"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "The epidemiology, diagnosis and treatment of COVID-19",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Zhai",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Long",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Journal of Antimicrobial agents",
            "volume": "55",
            "issn": "",
            "pages": "1--13",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Clinical characteristics of asymptomatic and symptomatic patients with mild COVID-19",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ra",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Clinical Microbiology and Infection",
            "volume": "26",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Characteristics of and important lessons from the coronavirus disease 2019 (COVID-19) outbreak in China",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mcgoogan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Am. Med. Assoc",
            "volume": "323",
            "issn": "Issue13",
            "pages": "1239--1242",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A new strategy of load forecasting technique for smart grids",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Abo-Al-Ez",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Int. J. Mod. Trends Eng. Res. (IJMTER)",
            "volume": "2",
            "issn": "12",
            "pages": "332--341",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "A data mining based load forecasting strategy for smart electrical grids",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Abo-Al-Ezb",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Advanced Engineering Informatics",
            "volume": "30",
            "issn": "",
            "pages": "422--448",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "A fog based load forecasting strategy for smart grids using big electrical data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Cluster Computing",
            "volume": "22",
            "issn": "",
            "pages": "241--270",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "A new outlier rejection methodology for supporting load forecasting in smart grids based on big data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "23",
            "issn": "",
            "pages": "509--535",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A fog based load forecasting strategy based on multi-ensemble classification for smart grids",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of Ambient Intelligence and Humanized Computing",
            "volume": "11",
            "issn": "",
            "pages": "209--236",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Smart Electrical Grids Based on Cloud, IoT, and Big Data Technologies: State of the Art",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabie",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ali",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--32",
            "other_ids": {
                "DOI": [
                    "10.1007/s12652-020-02685-6"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Sensitivity of chest CT for COVID-19: comparison to RT-PCR",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2020200432"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Coronavirus (COVID-19) Classification Using CT Images by Machine Learning Methods",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Barstugan",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Ozkaya",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09424"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "The epidemiological characteristics of an outbreak of 2019 novel coronavirus diseases (COVID-19) in China",
            "authors": [],
            "year": 2020,
            "venue": "Novel Coronavirus Pneumonia Emerg. Response Epidemiol. Team",
            "volume": "41",
            "issn": "2",
            "pages": "145--151",
            "other_ids": {
                "DOI": [
                    "10.3760/cma.j.issn.0254-6450.2020.02.003"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Evidence of SARS-CoV-2 infection in returning travelers from Wuhan, China",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hoehl",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rabenau",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Berger",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kortenbusch",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "N. Engl. J. Med",
            "volume": "41",
            "issn": "2",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1056/NEJMc2001899"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Clinical features of patients infected with 2019 novel coronavirus in",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "395",
            "issn": "",
            "pages": "497--506",
            "other_ids": {
                "DOI": [
                    "10.1016/S0140-6736(20)30183-5"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Diagnosing COVID-19 Pneumonia from X-Ray and CT images using deep learning and transfer learning algorithms",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Maghdid",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Asaad",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ghafoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sadiq",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--8",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.00038"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "A depthwise separable dense convolutional network with convolution block attention module for COVID-19 diagnosis on CT scans",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ning",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Computers in Biology and Medicine",
            "volume": "137",
            "issn": "",
            "pages": "1--13",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Deep learning for diagnosis of COVID-19 using 3D CT scans",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Serte",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Demirel",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Computers in Biology and Medicine",
            "volume": "132",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Detecting Anomalies In Data Stream Using Efficient Techniques : A Review",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Tellis",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Souza",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 2018 International Conference on Control, Power, Communication and Computing Technologies",
            "volume": "",
            "issn": "",
            "pages": "296--298",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Outlier and anomaly pattern detection on data streams",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "The Journal of Supercomputing",
            "volume": "",
            "issn": "",
            "pages": "1--11",
            "other_ids": {
                "DOI": [
                    "10.1007/s11227-018-2674-1"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Large dataset summarization with automatic parameter optimization and parallel processing for local outlier detection",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Shou",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Concurrency Computation Practice and Experience",
            "volume": "30",
            "issn": "",
            "pages": "1--13",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Outlier detection for 2D temperature data",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Posio",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Leivisk\u00e4",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ruuska",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Ruha",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IFAC proceedings volumes",
            "volume": "41",
            "issn": "",
            "pages": "1958--1963",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "MEOD: memory-efficient outlier detection on streaming data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karale",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lazarova",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Koleva",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Poulkov",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Symmetry",
            "volume": "458",
            "issn": "13",
            "pages": "1--11",
            "other_ids": {
                "DOI": [
                    "10.3390/sym13030458"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Particle swarm optimisation for outlier detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohemmed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Browne",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation",
            "volume": "",
            "issn": "",
            "pages": "83--84",
            "other_ids": {
                "DOI": [
                    "10.1145/1830483.1830498"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Outlier detection techniques for wireless sensor networks: a survey",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Meratnia",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Havinga",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Commun. Surv. Tutorials",
            "volume": "12",
            "issn": "2",
            "pages": "159--170",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "A novel D-S based secure localization algorithm for wireless sensor networks",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "7",
            "issn": "",
            "pages": "1945--1954",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Feature selection for high-dimensional classification using a competitive swarm optimizer",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Soft Computing",
            "volume": "22",
            "issn": "",
            "pages": "811--822",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "A new distributed feature selection technique for classifying gene expression data",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ayyad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Labib",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Int. J. Biomath. (IJB)",
            "volume": "",
            "issn": "2",
            "pages": "1--34",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Gene expression cancer classification using modified K-Nearest Neighbors technique",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ayyad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Saleh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Labib",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BioSystems",
            "volume": "176",
            "issn": "",
            "pages": "41--51",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "A new fusion of grey wolf optimizer algorithm with a two-phase mutation for feature selection",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Basset",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "El-Shahat",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "El-Henawy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "De Albuquerque",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Expert Systems with Applications 139",
            "volume": "",
            "issn": "",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Advances in engineering software",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mirjalili",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lewis",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Grey Wolf",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Optimizer",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "69",
            "issn": "",
            "pages": "46--61",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "MbGWO-SFS: Modified Binary Grey Wolf Optimizer Based on Stochastic Fractal Search for Feature Selection",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "El-Kenawy",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Eid",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Saber",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ibrahim",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "107635--107649",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Confusion matrix-based feature selection",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Visa",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Ramsay",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ralescu",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Knaap",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the Twenty Second Midwest Artificial Intelligence and Cognitive Science Conference",
            "volume": "",
            "issn": "",
            "pages": "120--127",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Symptomatic, Asymptomatic, and Pre-symptomatic transmission.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Herd immunity, (A) No Immunization and (B) With immunization.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Symptomatic versus Asymptomatic cases on board the Diamond Princess Cruise ship, Yokohama, Japan, 2020.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "People classification based on their vulnerability level to Covid-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "The proposed DBCS classification strategy.A.H.Rabie et al.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The sequential steps of HOR method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": ", suppose tt = 15, hence; It = {It 1 , It 2 , It 3 , \u2026., It 15 }. The representation of each bird in tt-dimension (tt = no. of training items in the dataset) is introduced as a vector, (Pos i , Pos Personal , Vel i ) where Pos i is the position of ith bird; Pos i =(Pos i Pos i 2 , \u2026,Pos i tt ) and Pos Personal represents the fittest position of the ith bird in its history that achieves the best evaluation value; Pos Personal = Pos pi =(Pos 1 pi , Pos 2 pi , \u2026, Pos tt pi ). Additionally, Vel i represents the velocity of ith bird; Vel i =(Vel i 1 , Vel i 2 , \u2026,Vel i tt ) and the global position (Pos Global ) that indicates to the best position among all the birds in Sw is represented as; Pos Global = Pos-",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "[12,26,27].Pos Personal (Pos i ) = Pos pi = { if ( SAD(Pos i ) < SAD(Pos pi )) Pos pi otherwise (5) Pos Global = Pos G = { Pos pi if ( SAD(Pos pi ) < SAD(Pos pi+1 ))Pos pi+1 otherwise(6) where Pos Personal (Pos i ) is the best solution of ith bird that can be denoted as Pos pi that represents the personal fittest position of ith bird. Pos i is the current position of ith bird. Additionally, SAD(Pos i ) represents the fitness value (called; small average distance) of the ith bird based on its current position. SAD(Pos pi ) represents the evaluation value of the ith bird based on its fittest position. Pos Global represents the fittest bird in whole swarm Sw that can be denoted as Pos G , SAD(Pos pi+1 ) represents the evaluation value of the (i + 1) th bird based on its fittest position, and",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "The sequential steps of HFS method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Calculating Probability based on Distance to Class Center. A.H. Rabie et al. feature space. Based on the data presented in Fig. 8, calculating P DTCC (x| c i ) \u2200 c i \u2208 C using (26) is depicted in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "|c i | = 7. As depicted inFig. 12, calculating P AKNN (x|c i ) \u2200 c i \u2208 C can be accomplished through three sequential steps. In the first step, the K nearest neighbors to the input test item are identified where K = \u03c8. Then, during the second step, Grade \u2200ci\u2208C (c i ) is calculated for each target class starting by K = 1, then incrementing K by one until K reaches the accumulation limit (e.g., \u03c8), which was set previously to 7. After each increment, accumulatively update Grade \u2200ci\u2208C (c i ). Finally, based on Grade \u2200ci\u2208C (c i ), P AKNN \u2200ci\u2208C (x|c i ) can be calculated using(33).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Class supporters.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Calculating Probability Based on Distance to Nearest Neighbors (illustrative example).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Calculating Probability Based on K Nearest Neighbors (illustrative example).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "The error values introduced by DBNB, FCNB, CNN, HDS, CPDS, and DBCS techniques are 0.25, 0.29, 0.36, 0.26, 0.34, and 0.09 respectively. Hence, DBCS can obtain the maximum accuracy value and the minimum error value. DBCS introduces precision value reaches to 0.86 while DBNB, FCNB, CNN, HDS, and CPDS provide precision values equal to 0.73, 0.59, 0.61, 0.63, and 0.55 respectively. The recall values of DBNB, FCNB, CNN, HDS, CPDS, and DBCS are 0.67, 0.61, 0.58, 0.63, 0.62, and 0.83 respectively. Fig. 20 illustrates that DBCS is faster than other strategies; DBNB, FCNB, CNN, HDS, and CPDS. Hence, DBCS has the highest accuracy and the fastest run time. Finally, figures (16 \u2192 20) and",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Solution plan for the 3 variable equation.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Error rate VS K-value.A.H.Rabie et al.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF19": {
            "text": "Count (PC)The platelet count (PC) is a blood test that determines the average number of platelets in a person's blood. Platelets help to heal wounds and avoid dangerous bleeding in the bloodstream.YesNeutrophils Count (NC)Neutrophils are a type of WBC that form about (50-75%) of the total. NC provides vital information on the patient's health condition.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "A snapshot from the NileDS dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF21": {
            "text": "Accuracy of several strategies of Covid-19 detection strategies.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF22": {
            "text": "Error of several strategies of Covid-19 detection.A.H.Rabie et al.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "Precision of several strategies of Covid-19 detection.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF24": {
            "text": "Recall of several strategies of Covid-19 detection.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "People classification based on their vulnerability level to Covid-19. To eliminate virus spread, persons of Type A need continuous follow-up and periodic examination, where he/she may be infected with Corona, despite the absence of symptoms.\u2022 By making sure of constant observation, a person of type A can be allowed to be in crowded places.\u2022 It is preferred to receive the vaccine if it is available.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "representation of each particle.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "An example of single search agent.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Determine the best search agent based on both every classifier and average accuracy.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "-a)Descriptions about the features of NileDS dataset. Glucose is the most common form of sugar detected in the blood.Yes Blood typeFind out what type of blood you have.Yes Blood PressureIt is the pressure exerted on the artery walls.Yes Body Mass Index (BMI) BMI is a metric that reflects how much fat is in your body. It's used to determine if someone is at a healthy weight. Yes Diabetes Pedigree FunctionA function that assesses the risk of diabetes depending on a person's family history. No Total_Bilirubin",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Red blood count It's a blood test that determines how many red blood cells have haemoglobin that transports oxygen throughout the body. Yes Pus Cell countIt is a type of white blood cell (neutrophil) present in pus.No Bacteria testBacteria test are used to aid in the diagnosis of infections whose organisms are not apparent to the human eye Yes Blood urea test It is used to evaluate the concentration of nitrogen in the blood. When your blood urea level rises, it indicates your kidneys are unable to properly eliminate urea from the bloodstream.YesA.H.Rabie et al.",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "-b)Descriptions about the features of NileDS dataset.Serum creatinineMeasure of muscle metabolism that indicates kidney health.Yes SodiumA sodium test used to determine the level of sodium in the blood during a blood test. No Potassium",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "Distribution of cases in the NileDS dataset based on their types.",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Confusion matrix and its formulas.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "The performance of DBCS in terms of accuracy, error, precision, and recall based on 10-fold cross-validation.",
            "latex": null,
            "type": "table"
        },
        "TABREF12": {
            "text": "Fig. 20. Run time of several strategies of Covid-19 detection.",
            "latex": null,
            "type": "table"
        },
        "TABREF13": {
            "text": "Pros and Cons of the proposed DBCS.Novelty\u2022 DBCS is the first to handle the issue of predicting how people's bodies will react if they are infected with Covid-19. Hence, the research idea is novel.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors would like to express their sincere appreciation to Mansoura University for the generous support, specially to the President of Mansoura University for his unending support and gentleness. Also, a special thanks to Dr. Salah Abd Elghafar Mansour for his unending support and generosity. We would also like to express our heartfelt appreciation and gratitude to Dr. Omnia Anees Mansour for assisting us throughout this research and providing us with all of the medical information that we require.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}