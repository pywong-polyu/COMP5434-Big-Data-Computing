{
    "paper_id": "fa877853758d521519883f2d23d64c2115d9e607",
    "metadata": {
        "title": "IoT and Interpretable Machine Learning Based Framework for Disease Prediction in Pearl Millet",
        "authors": [
            {
                "first": "Nidhi",
                "middle": [],
                "last": "Kundu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Geeta",
                "middle": [],
                "last": "Rani",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Vijaypal",
                "middle": [],
                "last": "Singh Dhaka",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Kalpit",
                "middle": [],
                "last": "Gupta",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Siddaiah",
                "middle": [],
                "last": "Chandra Nayak",
                "suffix": "",
                "affiliation": {
                    "laboratory": "ICAR DOS in Biotechnology",
                    "institution": "University of Mysore Manasagangotri",
                    "location": {
                        "postCode": "570005",
                        "settlement": "Mysore",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Sahil",
                "middle": [],
                "last": "Verma",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Chandigarh University",
                    "location": {
                        "postCode": "140413",
                        "settlement": "Mohali",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Muhammad",
                "middle": [],
                "last": "Fazal Ijaz",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Sejong University",
                    "location": {
                        "postCode": "05006",
                        "settlement": "Seoul",
                        "country": "Korea"
                    }
                },
                "email": ""
            },
            {
                "first": "Marcin",
                "middle": [],
                "last": "Wo\u017aniak",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Silesian University of Technology",
                    "location": {
                        "postCode": "44-100",
                        "settlement": "Gliwice",
                        "country": "Poland"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Citation: Kundu, N.; Rani, G.; Dhaka, V.S.; Gupta, K.; Nayak, S.C.; Verma, S.; Ijaz, M.F.; Wo\u017aniak, M. IoT and Interpretable Machine Learning",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The traditional systems of farming focus on meeting the dietary requirements of people and domestic animals. Therefore, the farmers used to grow more nutritious cereals 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Highlighting the need to automate the detection of diseases in the underexplored crop 'pearl millet'.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Automatic collection of the real-time datasets by the IoT system fixed at the farmlands of pearl millet. 3 .",
            "cite_spans": [
                {
                    "start": 105,
                    "end": 106,
                    "text": "3",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "2."
        },
        {
            "text": "Developing the IoT and deep transfer learning-based framework for detection and classification of diseases in pearl millet. 4 .",
            "cite_spans": [
                {
                    "start": 124,
                    "end": 125,
                    "text": "4",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "2."
        },
        {
            "text": "Presenting the comparative analysis of the proposed framework and the systems available in the literature to detect and classify plant diseases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2."
        },
        {
            "text": "The extensive study of literature in plant disease detection and classification gives insights into the techniques employed to collect datasets, pre-processing, disease detection, classification, and visualization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "In the traditional approaches, the farmers manually detect diseased and healthy plants [26] . These approaches lack in the tracking of the essential parameters such as soil type, humidity, temperature, amount of macro and micronutrients in the soil, and nutrient requirements of the crop plant at different stages of its growth and maturity. Moreover, the traditional approaches are time-consuming and need a lot of human effort. Furthermore, the farmers need advice from experts for the correct diagnosis of diseases in crop plants.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 91,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The applications of IoT, computer vision, ML, DL, and deep transfer learning have streamlined the automation of plant disease detection and classification [27, 28] . In this line of research, the authors proposed IoT and ML models for data capturing and disease prediction [29] . They used the drone for capturing the images over a large area in less time. They applied the support vector machine (SVM) for the classification of diseases in rice crops. However, their system did not consider the on-demand capturing of images for real-time monitoring and prediction.",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "[27,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 160,
                    "end": 163,
                    "text": "28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 273,
                    "end": 277,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Furthermore, the authors in [30] utilized the potential of IoT to categorize the healthy and diseased leaves. They anchored the sensors for monitoring of soil quality, temperature, and humidity. They used the camera to capture the images of crop plants. The authors established the interface of sensors and a camera with the Raspberry Pi to store and process the captured data for real-time predictions. They employed the K-means algorithm for clustering images followed by masking of pixels to detect whether the leaf is diseased or healthy.",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 32,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The authors in [31, 32] stated that DL techniques are effective in the early detection of crop diseases. They recommended the use of these techniques to overcome the limitations of traditional approaches. The research works presented in [24, 27, [32] [33] [34] [35] [36] [37] [38] and [39] [40] [41] [42] [43] [44] [45] [46] introduced deep learning (DL) models for the detection and classification of plant diseases. Furthermore, Mohammed Brahimi claimed the supremacy of deep transfer learning over deep learning [27] .",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[31,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 20,
                    "end": 23,
                    "text": "32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[24,",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 242,
                    "end": 245,
                    "text": "27,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 246,
                    "end": 250,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 251,
                    "end": 255,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 256,
                    "end": 260,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 261,
                    "end": 265,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 266,
                    "end": 270,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 271,
                    "end": 275,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 276,
                    "end": 280,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 285,
                    "end": 289,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 295,
                    "end": 299,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 300,
                    "end": 304,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 305,
                    "end": 309,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 310,
                    "end": 314,
                    "text": "[44]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 315,
                    "end": 319,
                    "text": "[45]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 320,
                    "end": 324,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 515,
                    "end": 519,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The authors in [39] collected a dataset of 36,258 images from the AI challenger [47] . However, the dataset comprised images of poor visual quality. They employed the ResNet model on the collected dataset and reported an accuracy of 93.96%.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 80,
                    "end": 84,
                    "text": "[47]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The works presented by the authors in [19, 48, 49] highlighted the importance of collecting imagery datasets and employing an appropriate DL model on the collected dataset for the detection and classification of plant diseases. They also focused on integrating DL models with the IoT systems comprising sensors, a drone, a camera, etc. They claimed that these integrated systems effectively minimize human efforts and reduce the time required for different agricultural practices. These systems are capable of gathering realtime information from farms and quick processing of the collected datasets to predict plant diseases.",
            "cite_spans": [
                {
                    "start": 38,
                    "end": 42,
                    "text": "[19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 43,
                    "end": 46,
                    "text": "48,",
                    "ref_id": "BIBREF48"
                },
                {
                    "start": 47,
                    "end": 50,
                    "text": "49]",
                    "ref_id": "BIBREF49"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The research works discussed by C. Shorten and T. M. Khoshgoftaar in [50] and P. Cao et al., in [51] clarified that employing the augmentation techniques such as geometric transformations, colour space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, neural style transfer, and meta-learning may prove constructive to improve the performance of the DL models. To carry out further research, the authors in [52] conducted the experiments using 124 images downloaded from the Internet. They applied data augmentation techniques such as zoom, rotation, flip, and rescale to increase the size of the dataset to 711 images. In addition, they reported the training accuracy of 95% and the validation accuracy of 89%. The low validation accuracy and impractical implementation using standard memory devices such as mobile phones are the significant limitations of this research. Moreover, they did not consider the parameters such as soil type, temperature, humidity, nutrient requirements, etc. while disease detection. Furthermore, the authors focused only on detecting one disease, 'downy mildew' in pearl millet. Therefore, there is considerable scope for improving the performance and working on the most common diseases such as blast and rust.",
            "cite_spans": [
                {
                    "start": 69,
                    "end": 73,
                    "text": "[50]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 96,
                    "end": 100,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 469,
                    "end": 473,
                    "text": "[52]",
                    "ref_id": "BIBREF52"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "One more research group in [52] exploited the applications of deep transfer learning. They employed pre-trained VGG-16 [53] to detect downy mildew disease [54] in pearl millet. Based on the experiments, they claimed that deep transfer learning effectively extracts the essential features. The extracted features of the pre-trained network are available for reuse. The pre-trained networks reuse these features and continue learning from the more dataset available for training. This improves the performance of the model. Transfer learning is also important for fine-tuning the model according to the size and type of the dataset. The authors also claimed that transfer learning is helpful to avoid overfitting and to improve the model's predictive capacity [24] .",
            "cite_spans": [
                {
                    "start": 27,
                    "end": 31,
                    "text": "[52]",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 119,
                    "end": 123,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 155,
                    "end": 159,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                },
                {
                    "start": 758,
                    "end": 762,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "To work in synergy with the system proposed in [52] , the authors in [23, 55] integrated IoT and DL techniques for disease detection in crops. However, the system could not prove its practical application due to low accuracy.",
            "cite_spans": [
                {
                    "start": 47,
                    "end": 51,
                    "text": "[52]",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 69,
                    "end": 73,
                    "text": "[23,",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 74,
                    "end": 77,
                    "text": "55]",
                    "ref_id": "BIBREF55"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The above discussion of the related research works shows that the integration of DL techniques with IoT provides good opportunities for developing the architectures to automate the collection of imagery and parametric data, storage of collected dataset, plant disease detection, generating alerts, and classification of detected diseases. However, these works lack in sensing the parameters that are the root cause for the plant diseases. Moreover, the collection of imagery datasets requires substantial human effort and high cost. Furthermore, the DL models employed for disease detection and classification report low accuracy and take more time to respond. To the best of our knowledge, there is no automatic and intelligent system for identifying and classifying blast and rust diseases in pearl millet. The potential of integration of IoT and deep transfer learning is still underexploited in the field of agriculture.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Therefore, there is a huge scope for improving the performance of the existing systems and providing a new architecture for the automatic collection of the dataset, detection, and classification of diseases in pearl millet.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "In this section, the authors present the details of the proposed framework, dataset prepared, training mechanism, and evaluation metrics used to evaluate the performance of the models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Materials and Methods"
        },
        {
            "text": "In this manuscript, the authors propose the 'Automatic and Intelligent Data Collector and Classifier' (AIDCC) for the collection of data, detection, and classification of rust, and blast diseases in pearl millet. The framework is an integration of three components, as demonstrated in Figure 1 . Component 1: It comprises the digital drone, camera, global positioning system (GPS), and sensors. A digital drone is a crewless aerial vehicle used to monitor the farmlands [56] . Here, the drone is equipped with a Panasonic GH3 camera 'DJI S1000' that can focus in the range from 25 to 30 m, offers video resolution of 1920 \u00d7 1080, and a CMOS sensor of 16 MP. The camera of the drone clicks the images and transfers them automatically and instantly to the Raspberry Pi and/or cloud storage. It also captures the variation in RGB scaling of plants to spot the major disease areas in the farm. The drone is specified for a flying range of 7 km. The patrolling of the farm using a drone is useful in obtaining the coordinates of the field used by GPS. It saves time and the cost of labor.",
            "cite_spans": [
                {
                    "start": 470,
                    "end": 474,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [
                {
                    "start": 285,
                    "end": 293,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Proposed Framework"
        },
        {
            "text": "In addition to the drone, we used the NIKON D750 digital camera for clicking the pictures. The digital camera is used to capture the desired region such as leaves rather than the complete plant or multiple plants together. Similar to the drone camera, it transfers the captured images directly to the cloud server.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Framework"
        },
        {
            "text": "The GPS module embedded with sensors, drones, and Raspberry Pi is helpful to monitor the location of the diseased plants. It is also important to find the region of farmland where fertilizers and/or water are required. The sensors are anchored with the proposed framework to monitor the changes in soil, temperature, and humidity. For example, the variations in temperature and moisture of soil indicate the susceptibility of pearl millet towards the blast and rust diseases [25] . Moreover, the oospores present in the soil are the primary source to infect the underground parts of plants [54] . Therefore, the sensors anchored for continuous monitoring of the soil can detect the presence of oospores in the soil and help in predicting the disease at an early stage. Furthermore, the hyperspectral sensors are fixed with drone cameras for monitoring the environmental and physical conditions.",
            "cite_spans": [
                {
                    "start": 475,
                    "end": 479,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 590,
                    "end": 594,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [],
            "section": "Proposed Framework"
        },
        {
            "text": "To identify the suitable sensors for the AIDCC, the authors referred to the system proposed in [57] . They used four sensors viz. GY-30, soil sensor, DHT22, and BMP180 sensors to measure the humidity in the soil, temperature, and light intensity. The authors embedded the DS3231 sensor for transferring the information from the mounted sensors to the processor of Raspberry Pi (RPI). Taking clues from the work proposed by N. Materne and M. Inoue in [58] and A. Thorat et al. in [30] , we fitted two DHT11 sensors to measure the temperature and humidity in order to spot the rust and blast diseases at an early stage. These sensors are connected to the Raspberry Pi (RPI) for transmitting the captured information to the cloud server. This information is disseminated as an alert or notification to the farmers on their mobile phones. The role of sensors from information gathering to sending notifications to farmers for a pearl millet farmland is demonstrated in Figure 2 . ",
            "cite_spans": [
                {
                    "start": 95,
                    "end": 99,
                    "text": "[57]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 450,
                    "end": 454,
                    "text": "[58]",
                    "ref_id": "BIBREF58"
                },
                {
                    "start": 462,
                    "end": 475,
                    "text": "Thorat et al.",
                    "ref_id": null
                },
                {
                    "start": 479,
                    "end": 483,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 965,
                    "end": 973,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Proposed Framework"
        },
        {
            "text": "For the dataset collection, the hardware components such as drones, digital cameras, and sensors as shown in component 1 of Figure 1 , were fixed at the farmland of the Indian Council of Agricultural Research-All India Coordinated Research Project (ICAR (AICRP-Mysore center). The pearl millet plants infected with blast and rust diseases were grown purposefully to monitor the symptoms and impacts of these diseases. The characteristics of diseased leaves of pearl millet are shown in Table 1 . The images of pearl millet plants infected by blast and rust diseases were captured in close observation of the plant pathology expert involved in this research. The authors considered 55-to 60-day-old plants for capturing the images since the blast and rust diseases were easily distinguishable at this age of plants. Moreover, the pathology experts claimed that the degree of severity of rust and blast diseases has reached more than 80% in the plants of this age. In these plants, the pathology experts easily identified rust and blast diseases in pearl millet based on their visible symptoms. For example, the leaves of plants infected with blast turned greyish, and water-soaked lesions appear on the foliage [59] . These lesions vary in size from \u22122 to 20 mm. The lesions also vary in shape from roundish, elliptical, diamond shaped to elongated. These lesions may enlarge and become necrotic with an increase in the severity of the disease. On the other hand, the leaves of plants infected with rust contain pinhead chlorotic flecks. These flecks turn into reddish-orange as the disease severity increases. Moreover, the round to elliptical pustules appear on both surfaces of leaves [59] . The observable differences in the patterns of both diseases are important for the precise training of the DL model.",
            "cite_spans": [
                {
                    "start": 1210,
                    "end": 1214,
                    "text": "[59]",
                    "ref_id": null
                },
                {
                    "start": 1687,
                    "end": 1691,
                    "text": "[59]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 124,
                    "end": 132,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 486,
                    "end": 493,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Dataset Preparation"
        },
        {
            "text": "The authors captured 1964 images of leaves of pearl millet infected with blast and 1336 images infected with rust. They divided the prepared dataset into training and testing datasets in the ratio of 70% and 30% of the total dataset, respectively. The number of images in these datasets is shown in Table 2 , and the sample images of blast and rust diseases are shown in Figure 3 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 299,
                    "end": 306,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 371,
                    "end": 379,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Dataset Preparation"
        },
        {
            "text": "The architecture of the 'Custom-Net' model designed to predict the samples infected with blast and rust diseases is shown in Figure 4 . It comprises four convolution layers, and a max-pooling layer follows each convolution layer. Furthermore, the last max-pooling layer is followed by the activation, flatten, and dense layer. [51, 60, 61] , the authors employed the Adam optimizer to deal with the problems of sparse gradients that may be generated on the noisy dataset. This optimizer adopts the best properties of AdaGrad and RMSProp optimization algorithms and favors the better training of the model. Moreover, the authors employed the softmax activation function and categorical cross-entropy loss function for precise training of the proposed network. In addition, they set the learning rate of 0.0001 to optimize the learning of the model and obtain its optimum performance. Furthermore, the authors continuously monitored the model's performance and observed that it reports the optimum performance for the batch size of 16 samples.",
            "cite_spans": [
                {
                    "start": 327,
                    "end": 331,
                    "text": "[51,",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 332,
                    "end": 335,
                    "text": "60,",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 336,
                    "end": 339,
                    "text": "61]",
                    "ref_id": "BIBREF61"
                }
            ],
            "ref_spans": [
                {
                    "start": 125,
                    "end": 133,
                    "text": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "The Architecture of the 'Custom-Net' Model"
        },
        {
            "text": "The authors employed pre-trained and non-pre-trained versions of 'Custom-Net' and state-of-the-art models. The model is named as pre-trained if it is trained on the 'ImageNet dataset' [62] , its weights are saved and it is further trained on the dataset collected in this research. The pre-trained model learns the low-level features such as boundary and edge marking from the 'ImageNet dataset'. It further learns the high-level features such as pattern differences in leaves infected with blast and rust diseases, from the dataset used in this manuscript. In contrast, the model is named as non-pre-trained if it is initialized with random weights and directly trained with the dataset collected in this research. The non-pre-trained model learns both the high level as well as low-level features from the dataset used in this manuscript. Now, to showcase the impact of transfer learning on the shallow neural network, the authors pre-trained the 'Custom-Net' on the publicly available 'ImageNet dataset' comprising more than 14 million images [62] followed by the training on the dataset collected as a part of this research. In addition, they also trained the model only on the collected dataset without using the concept of transfer learning. They compared the results of the pre-trained and non-pre-trained versions of 'Custom-Net' to demonstrate the impact of transfer learning on feature extraction and classification. Moreover, they also plotted the output matrix obtained after each layer of the 'Custom-Net' as shown in Figure 5 . This is important to visualize how the 'Custom-Net' extracts the relevant features and ignores the irrelevant features at its different layers. It is evident from Figure 5 that there are no clear boundaries visible at the initial convolution layers. However, the feature map is reduced, and boundaries are more precise at the later convolution layers and their following max-pooling layers. It is apparent from the last matrix shown in Figure 5 that the model learned to identify even the complex patterns hidden in the image.",
            "cite_spans": [
                {
                    "start": 184,
                    "end": 188,
                    "text": "[62]",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 1046,
                    "end": 1050,
                    "text": "[62]",
                    "ref_id": "BIBREF62"
                }
            ],
            "ref_spans": [
                {
                    "start": 1531,
                    "end": 1539,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1705,
                    "end": 1713,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 1978,
                    "end": 1986,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "The Architecture of the 'Custom-Net' Model"
        },
        {
            "text": "Moreover, it is clear from the matrices shown in Figure 5 that the model starts learning the pixel-level features at the initial layers. Gradually, it starts discarding the features picked from the background and considers only the relevant features for decision-making once it is trained. They also recorded that each epoch takes 4 s and the model completes its training in 20 epochs. The quick training of the model shows its efficacy in feature extraction. Now, for comparing the efficacy of the proposed 'Custom-Net' model, the authors employed the pre-trained as well as non-pre-trained versions of the state-of-the-art models viz. VGG-16, VGG-19 [53] , ResNet-50 [39] , Inception-V3 [42] , and Inception ResNet-V2 [41] to predict the samples infected with blast and rust diseases. ",
            "cite_spans": [
                {
                    "start": 652,
                    "end": 656,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                },
                {
                    "start": 669,
                    "end": 673,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 689,
                    "end": 693,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 720,
                    "end": 724,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [
                {
                    "start": 49,
                    "end": 57,
                    "text": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "The Architecture of the 'Custom-Net' Model"
        },
        {
            "text": "To evaluate the performance of the classifiers accompanied by the 'Automatic and Intelligent Data Collector and Classifier', the authors used the confusion matrix as presented in [53] , average accuracy, precision, recall, and training time. The definitions of these metrics are given below:",
            "cite_spans": [
                {
                    "start": 179,
                    "end": 183,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "Evaluation Metrics"
        },
        {
            "text": "Confusion Matrix: This represents the number of correctly and incorrectly classified samples into each labelled class. Here, TB denotes the number of correctly classified samples of blast disease, FB denotes the number of incorrectly classified samples of blast disease, TR is the number of correctly classified samples of rust disease, and FR is the number of incorrectly classified samples of rust disease. The sample confusion matrix is shown in Table 3 . Based on the labels presented in the confusion matrix, the authors define the evaluation matrices, namely sensitivity, accuracy, precision, recall, F1 score.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 449,
                    "end": 456,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Evaluation Metrics"
        },
        {
            "text": "Average accuracy: It is the measure of the degree of correctness of the classification. It can be calculated using the formula given in Equation (1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1."
        },
        {
            "text": "Precision: This is the measure of classifying the samples of the blast correctly to the blast class. The formula to calculate the precision is given in Equation (2).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2."
        },
        {
            "text": "Recall: This is the measure of correct identification of samples of the blast class from the total number of samples of that class. The formula to calculate the precision is given in Equation (3). ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3."
        },
        {
            "text": "In this section, the authors present the results obtained by evaluating the performance of the trained 'Custom-Net' model on the test dataset comprising 990 images of blast and rust diseases in pearl millet.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "The confusion matrix of the pre-trained 'Custom-Net' model on the training and testing datasets are shown in Table 4a ,b, respectively. Similarly, the confusion matrix of the non-pre-trained 'Custom-Net' model on the training and testing datasets are shown in Table 5a ,b, respectively. It is clear from Tables 4a and 5a that the pre-trained, as well as non-pre-trained models, do not misclassify any sample from the training dataset. Whereas, it is evident from Table 5b that the non-pre-trained 'Custom-Net' model misclassifies only 4 and 8 samples from the testing dataset comprising images of leaves infected with blast and rust diseases, respectively. Furthermore, it is claimed in [63] that the area under the curve (AUC) and receiver operating characteristic (ROC) (AUC-ROC) curves are the most effective tools for visualizing the classification performance of a model. In this manuscript, these curves are used to check the capability of the model to distinguish the rust and blast disease classes. The AUC-ROC curves for different classifiers on the training and testing datasets are shown in Figure 6 . Furthermore, the authors also present the classification performance of the 'Custom-Net' model and state-of-the-art DL models, as shown in Table 6 . It is evident from the results shown in Table 6 that except VGG-16 and VGG-19 models, the pre-trained and non-pre-trained versions of all the DL models employed in this manuscript report the equivalent values of accuracy, precision, recall, and F1 score. ",
            "cite_spans": [
                {
                    "start": 687,
                    "end": 691,
                    "text": "[63]",
                    "ref_id": "BIBREF63"
                }
            ],
            "ref_spans": [
                {
                    "start": 109,
                    "end": 117,
                    "text": "Table 4a",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 260,
                    "end": 268,
                    "text": "Table 5a",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 463,
                    "end": 471,
                    "text": "Table 5b",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 1102,
                    "end": 1110,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 1252,
                    "end": 1259,
                    "text": "Table 6",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 1302,
                    "end": 1309,
                    "text": "Table 6",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Confusion Matrix for Classification"
        },
        {
            "text": "It is evident from Figure 8 that the 'Custom-Net' model reported the highest precision of 99.29%. Moreover, there is a slight difference of 0.19% in the precision of its pre-trained and non-pre-trained versions. It is also clear from Figure 8 that the VGG-16 and VGG-19 models reported the highest precision of 100%. There is a minor variation of 0.18% and 0.71% in the precision of the pre-trained and non-pre-trained versions of VGG-16 and VGG-19, respectively. The other deep learning models viz. Inception ResNet-v2, Inception-v3, and ResNet-50 reported the highest precision of 99.64%, 99.11%, and 99.29%, respectively. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 19,
                    "end": 27,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 234,
                    "end": 242,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Precision"
        },
        {
            "text": "The results shown in Figure 9 indicate that the 'Custom-Net' model reported a recall of 98.59%. A minor variation of 0.20% has been observed in the values of recall of its pre-trained and non-pre-trained versions. Additionally, the results also show that VGG-16 and ResNet-50 reported the highest recall of 100%. Moreover, there is a significant variation of 42.73% and 42.55% in the recall of pre-trained and non-pre-trained versions of VGG-16 and VGG-19, respectively. The Inception ResNet-V2, and Inception-V3 reported the highest values of 99.64% and 99.82%, respectively. Furthermore, there is a minor difference of 0.17% and 0.18% in the recall of the pre-trained and non-pre-trained versions of Inception ResNet-V2 and Inception-V3.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 21,
                    "end": 29,
                    "text": "Figure 9",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Recall"
        },
        {
            "text": "The experimental results demonstrated in Figure 10 show that the 'Custom-Net' model achieved the highest F1 score of 98.94%. It reported a small variation of 0.25% in the F1 score of its pre-trained and non-pre-trained versions. The results shown in Figure 10 also indicate that VGG-16, VGG-19, ResNet-15, Inception-V3, and Inception ResNet-V2, give the highest F1 score values as 99.91%, 99.85%, 99.11%, and 99.64%, respectively. It is also clear from the figure that the VGG-16 and VGG-19 give the highest difference of 27.08% and 26.72%, respectively. There is a minor variation in the F1 score of pre-trained and non-pre-trained versions of ResNet-15, Inception-V3, and Inception ResNet-sV2 models. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 41,
                    "end": 50,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 250,
                    "end": 259,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "F1 Score"
        },
        {
            "text": "To validate the scope of adopting the proposed 'Custom-Net' model and state-of-theart deep learning models viz. Inception ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19 for classifying diseased leaves, the authors demonstrated the training time and the number of trainable parameters in Figures 11 and 12 , respectively. It is noticeable from Figure 12 that the Inception ResNet-V2 model has the maximum number of trainable parameters, whereas the 'Custom-Net' model has the minimum number of trainable parameters. Furthermore, it is clear from the training time shown in Figure 11 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 295,
                    "end": 312,
                    "text": "Figures 11 and 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 351,
                    "end": 360,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 580,
                    "end": 589,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Computation Cost"
        },
        {
            "text": "In this section, the authors present the inferences deduced from the experimental results obtained by employing the 'Custom-Net', Inception ResNet-v2, Inception-v3, ResNet-50, VGG-16, and VGG-19 models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "It is apparent from Figure 6 that the pre-trained version of VGG-16 gives the highest average accuracy. Whereas, the non-pre-trained versions of VGG-16 and VGG-19 reported the minimum value of average accuracy. The pre-training of these models lead to a significant increase of 42.62% in the average accuracy. This proves that these deep networks require a vast dataset for training. Therefore, transfer learning becomes vital for the training of these networks if the dataset size is small. By adopting the advantages of transfer learning, these networks learn the low-level and basic features of the dataset, such as boundary recognition and shape identification. Now, the networks use the weights acquired during pre-training and further learn the recognition of high-level features such as sub-boundaries or details about the image segments.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 20,
                    "end": 28,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "In contrast, with the models viz. Inception ResNet-v2, Inception-v3s, and ResNet-50, a minor impact of transfer learning was reported on the average accuracy. Similarly, a low impact of 0.63% is observed when the 'Custom-Net' model adopted the pre-training and transfer learning.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "It is inferred from the above discussion that the shallow neural networks learn the low-level as well high-level features by training on the small dataset size. At the same time, deep networks either require large datasets for training or transfer learning.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Furthermore, the trends of the precision, recall, and F1 measures of the above-stated models are demonstrated in Figures 7-9 . It is evident from Figure 7 that the non-pretrained VGG-16 and VGG-19 models reported the highest precision of 100%. In contrast, the non-pre-trained Inception-V3 model gave the lowest precision of 99.11%. The other non-pre-trained models viz. Inception ResNet-v2, ResNet-50, and 'Custom-Net' reported 0.36%, 0.71, and 0.71% lower precision than the VGG-16 and VGG-19 models. The small variation in the precision of all the non-pre-trained versions of the above-stated models implies that these models are efficient in recognizing the relevant instances of each class from the input test dataset.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 113,
                    "end": 124,
                    "text": "Figures 7-9",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 146,
                    "end": 154,
                    "text": "Figure 7",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "The discussion proves that both the pre-trained and non-pre-trained models are efficient in recognizing the relevant instances of each class from the input test dataset. Moreover, the pre-training helps discriminate the relevant and irrelevant features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "A further analysis of the results shown in Figure 8 reveals that the pre-trained VGG-16 and ResNet-50 models reported a 100% recall. The other pre-trained models Inception ResNet-v2, Inception-v3, VGG-19, and 'Custom-Net' reported the 0.61%, 0.36%, 0.18, and 1.61% lower values of recall, respectively.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 43,
                    "end": 51,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "It is evident from the comparison of non-pre-trained models that the Inception-v3 reported the highest value of 99.82% recall. The other models viz. Inception ResNet-v2, ResNet-50, and 'Custom-Net' also reported the equivalent values of recall, as shown in Figure 8 . Moreover, there is a minor difference of 0.17% and 0.18% in the recall of the pretrained and non-pre-trained versions of Inception ResNet-V2 and Inception-V3. Therefore, the comparable values of recall for all the above-stated models indicate that all the models are efficient in correctly identifying the blast disease from the leaves of pearl millet.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 257,
                    "end": 265,
                    "text": "Figure 8",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "However, the VGG-16 and VGG-19 models gave the lowest values of 57.27% recall. Moreover, there is a significant variation of 42.73% and 42.55% in the recall of pre-trained and non-pre-trained versions of VGG-16 and VGG-19, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "This proves that transfer learning is important for the deeply layered models such as VGG-16 and VGG-19, in order to minimize the number of misclassification of leaves infected by blast disease to the rust class.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Moreover, it is evident from the F1 score shown in Figure 9 that the pre-trained VGG-16 model reported the highest F1 score of 99.91%. Furthermore, the other models viz. Inception ResNet-v2, Inception-v3, VGG-19, and 'Custom-Net' reported the equivalent values of the F1 score.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 51,
                    "end": 59,
                    "text": "Figure 9",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Simultaneously, it is also observed that the models, viz. 'Custom-Net', ResNet-50, Inception-V3, and Inception ResNet-V2 reported the slight variations of 0.25%, 0.44, 0.18%, and 1.03%, respectively in the F1 score of their pre-trained and non-pre-trained versions. However, the VGG-16 and VGG-19 gave the highest difference of 27.08% and 26.72%, respectively. This proves that transfer learning is important for relevant feature extraction and minimizing the number of misclassifications in VGG-16 and VGG-19 models. However, there is an insignificant impact on the performance of the other above-stated state-of-the-art models. Moreover, the comparable values of the F1 score of all the models reflect that these models are efficient in correctly identifying the samples of the blast as well as rust diseases from the test dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Furthermore, it is coherent from the Grad-CAM plotted in Figures 10 and 11 that the pre-trained 'Custom-Net' model is effective in recognizing the acceptable boundaries from the leaves infected with blast and rust. Therefore, it makes the classification based on the relevant features rather than noise. In contrast, its non-pre-trained version is efficient in identifying all the relevant features. Still, it also picks some features from the background that may increase the number of misclassifications.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 57,
                    "end": 74,
                    "text": "Figures 10 and 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Similarly, the pre-trained versions of the above-stated state-of-the-art models also perform as a better feature extraction than their non-pre-trained versions. This proves that transfer learning helps the model in the extraction of more relevant features, recognizing acceptable boundaries, and preventing the involvement of noise in decision-making.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "However, the 'Custom-Net' model shows comparable values of average accuracy, precision, recall, and F1 score with the state-of-the-art models, but there is a significant decrease in the number of trainable parameters and training time. It is noticeable from Figure 11 that the 'Custom-Net' model has the minimum number of trainable parameters. Moreover, it is evident from the training time presented in Figure 12 that the 'Custom-Net' model requires a minimum time of 4 s per epoch. It completes its training in merely 80 s through 20 epochs. The analysis of training time shows that it requires 84%, 86.6%, 81.81%, 81.81%, and 91.67% lower training time than VGG-16, VGG-19, ResNet-15, Inception-V3, and Inception ResNet-V2 models, respectively. Its efficacy in achieving the classification accuracy comparable to the state-of-the-art models and low training time proves its usability for real-life systems. Furthermore, it is effective in quick decision-making to classify the blast and rust diseased samples in real-time. Table 7 presents the comparative analysis of the approaches available in literature and the approach proposed in this manuscript. Moreover, the technique has a biological significance too. The quick and automatic detection of plants infected with rust and blast helps the farmers apply disease control measures, thus preventing the further spread of diseases to the whole farmland.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 258,
                    "end": 267,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 404,
                    "end": 413,
                    "text": "Figure 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1026,
                    "end": 1033,
                    "text": "Table 7",
                    "ref_id": "TABREF7"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "To further validate the efficacy of the proposed model 'Custom-Net', the authors compared its performance with the state-of-the-art models viz. VGG-16, VGG-19, ResNet-15, Inception-V3, and Inception ResNet-V2. The comparison shows that the 'Custom-Net' model efficiently extracts relevant features and involves the relevant features in the decision-making. It achieved the classification performance equivalent to the InceptionResNet-V2. Moreover, it requires a minimum time for training. Therefore, the authors integrated the 'Custom-Net' model in the 'Automatic and Intelligent Data Collector and Classifier'.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "In the future, there is a scope of making the predictions based on the parametric dataset collected by the data collector part of the proposed framework. Moreover, there is a need to develop a multi-class classifier to classify the healthy plants infected with Downey mildew, blast, smut, ergot, and rust.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "The framework 'Automatic and Intelligent Data Collector and Classifier' (AIDCC) is proposed in this manuscript for automating the collection of imagery and parametric datasets from the pearl millet farmland, feature visualization, and prediction of blast and rust diseases. The framework is an appropriate integration of IoT and deep learning to analyze imagery and numeric data. The hardware components, such as drone cameras, digital cameras, sensors, etc. are anchored in the pearl millet farmland at ICAR, Mysore, India, to collect data automatically. The 'Custom-Net' model is designed as a part of this research and deployed on the cloud server. This DL model processes the data collected by the data collector and provides real-time prediction for the blast and rust diseases in pearl millet. Moreover, to showcase the impact of transfer learning, the authors pre-trained the proposed model on the online available ImageNet dataset. The pre-trained model is further trained on the dataset of 2310 images of leaves of pearl millet infected with blast and rust. The performance of the pre-trained and non-pre-trained 'Custom-Net' models is evaluated. Based on the visualization of features through Grad-CAM, it is concluded that transfer learning improves the extraction of relevant features and helps the model discard the features picked from the background. At the same time, the slight difference of 0.25% in the F1 score of pre-trained and non-pre-trained 'Custom-Net' models prove that being a shallow network, it is equally efficient in making correct classifications even though the training dataset is small.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "Moreover, the authors compared the performance of the pre-trained and non-pretrained state-of-the-art DL models viz. VGG-19, VGG-16, Inception ResNetV2, Inception V3, and ResNet-50 architectures. Furthermore, the authors implemented these models using transfer learning. They employed the pre-trained models on the ImageNet dataset and further trained them on the dataset collected by the data collector of the framework proposed in this research. However, the pre-trained and fine-tuned VGG-19 model outperformed all the models. It achieved the highest values of 99.39%, 99.82%, 99.11%, and 99.46% for the average accuracy, precision, recall, and F1 score, respectively, on the test dataset comprising 990 images of leaves infected with blast and rust. However, this model requires a training time of 600 s that is 86.67% higher than the 'Custom-Net' model. Moreover, the high number of training parameters of 20,089,922 increases its computation cost. Therefore, the authors deployed the pre-trained and fine-tuned 'Custom-Net' model as a classifier in the framework 'AIDCC'. Therefore, this research provides a low-cost and user-friendly framework for automating the data collection, feature visualization, disease detection, and prediction of blast and rust diseases in pearl millet. As a result, it may prove a significant contribution to the food industry and farmers in order to increase the yield and quality of crop products. Data Availability Statement: Data prepared as a part of this research is available at https://www. kaggle.com/kalpitgupta/blast-and-rust-compressed. The researchers who wish to use the dataset available at the above link must cite this article.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Pearl Millet News. Project Coordinator ICAR-All India Coordinated Research Project on Pearl Millet",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Pearl",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Improvement",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The Gazette of India",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "B Y"
                    ],
                    "last": "Authority",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "E W"
                    ],
                    "last": "Delhi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--2",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Millet in Schools by Union Minitry",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Crops that feed the world 11. Pearl Millet (Pennisetum glaucum L.): An important source of food security, nutrition and health in the arid and semi-arid tropics",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Jukanti",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L L"
                    ],
                    "last": "Gowda",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "N"
                    ],
                    "last": "Rai",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Manga",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K"
                    ],
                    "last": "Bhatt",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Food Secur",
            "volume": "8",
            "issn": "",
            "pages": "307--329",
            "other_ids": {
                "DOI": [
                    "10.1007/s12571-016-0557-y"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Using IoT for integrated pest management",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Chougule",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Jha",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mukhopadhyay",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 2016 International Conference on Internet of Things and Applications (IOTA)",
            "volume": "",
            "issn": "",
            "pages": "17--22",
            "other_ids": {
                "DOI": [
                    "10.1109/iota.2016.7562688"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Crop health and its global impacts on the components of food security",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Savary",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bregaglio",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Willocquet",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Gustafson",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mason-D&apos;croz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Sparks",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Castilla",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Djurle",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Allinne",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "311--327",
            "other_ids": {
                "DOI": [
                    "10.1007/s12571-017-0659-1"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "How to feed the world in 2050",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sch\u00fctz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jansen",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Verhoff",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Arch. Kriminol",
            "volume": "228",
            "issn": "",
            "pages": "151--159",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Effects of Greenhouse Gas Emissions on World Agriculture, Food Consumption, and Economic Welfare",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Darwin",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Clim. Chang",
            "volume": "66",
            "issn": "",
            "pages": "191--238",
            "other_ids": {
                "DOI": [
                    "10.1023/B:CLIM.0000043138.67784.27"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Development of a Real-Time Stroke Detection System for Elderly Drivers Using Quad-Chamber Air Cushion and IoT Devices",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hong",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Seo",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Hur",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "SAE Tech. Pap",
            "volume": "",
            "issn": "",
            "pages": "1--5",
            "other_ids": {
                "DOI": [
                    "10.4271/2018-01-0046"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Real-Time Health Monitoring System for Stroke Prognostics",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Healthsos",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "213574--213586",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.3040437"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Real-time gait monitoring system for consumer stroke prediction service",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hong",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "C M"
                    ],
                    "last": "Benjamin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 IEEE International Conference on Consumer Electronics (ICCE)",
            "volume": "",
            "issn": "",
            "pages": "4--6",
            "other_ids": {
                "DOI": [
                    "10.1109/ICCE46568.2020.9043098"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Diabetes prediction using artificial neural network",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "S"
                    ],
                    "last": "El-Jerjawi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Abu-Naser",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Int. J. Adv. Sci. Technol",
            "volume": "2020",
            "issn": "",
            "pages": "327--339",
            "other_ids": {
                "DOI": [
                    "10.1016/b978-0-12-819061-6.00014-8"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Detection Using Convolutional Neural Networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "G"
                    ],
                    "last": "Oza",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rani",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhaka",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Glaucoma",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Handbook of Research on Disease Prediction through Data Analytics and Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Applying Deep Learning for Genome Detection of Coronavirus",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "G"
                    ],
                    "last": "Oza",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhaka",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Pradhan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Verma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Rodrigues",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Multimed. Syst",
            "volume": "2021",
            "issn": "",
            "pages": "1--12",
            "other_ids": {
                "DOI": [
                    "10.1007/s00530-021-00824-3"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Machine Learning and IoT based Disease Predictor and Alert Generator System",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kundu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rani",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhaka",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)",
            "volume": "",
            "issn": "",
            "pages": "764--769",
            "other_ids": {
                "DOI": [
                    "10.1109/ICCMC48092.2020.ICCMC-000142"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "AI-Based Yield Prediction and Smart Irrigation. Stud. Big Data",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sinwar",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhaka",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rani",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "155--180",
            "other_ids": {
                "DOI": [
                    "10.1007/978-981-15-0663-5_8"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Plant species classification using deep convolutional neural network",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Dyrmann",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Karstoft",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Midtiby",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Biosyst. Eng",
            "volume": "151",
            "issn": "",
            "pages": "72--80",
            "other_ids": {
                "DOI": [
                    "10.1016/j.biosystemseng.2016.08.024"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Using Deep Learning for Image-Based Plant Disease Detection. Front",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Mohanty",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Hughes",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Salath\u00e9",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Plant Sci",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3389/fpls.2016.01419"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "A Comparative Analysis of Deep Learning Models Applied for Disease Classification in Bell Pepper",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kundu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Rani",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Dhaka",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC)",
            "volume": "",
            "issn": "",
            "pages": "243--247",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Field Monitoring and Automation Using IOT in Agriculture Domain",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Mohanraj",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ashokumar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Naren",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Procedia Comput. Sci",
            "volume": "93",
            "issn": "",
            "pages": "931--939",
            "other_ids": {
                "DOI": [
                    "10.1016/j.procs.2016.07.275"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "A Survey on Transfer Learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "22",
            "issn": "",
            "pages": "1345--1359",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2009.191"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "An Agricultural IoT System to Accurately Recognize Crop Diseases",
            "authors": [
                {
                    "first": "W.-J",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "Y.-X",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "B.-S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "N"
                    ],
                    "last": "Xiong",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Bekkering",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mdfc-Resnet",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "8",
            "issn": "",
            "pages": "115287--115298",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.3001237"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Transfer Learning and Multi-Model Integration for Disease and Weed Identification",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "Z B"
                    ],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "Z"
                    ],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Dcnn",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Diseases of Millet",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "F"
                    ],
                    "last": "Nyvall",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "F"
                    ],
                    "last": "Nyvall",
                    "suffix": ""
                }
            ],
            "year": 1989,
            "venue": "Field Crop Diseases Handbook",
            "volume": "ICAR",
            "issn": "",
            "pages": "265--280",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Traditional agriculture: A climate-smart approach for sustainable food production",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "S"
                    ],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Energy Ecol. Environ",
            "volume": "2",
            "issn": "",
            "pages": "296--316",
            "other_ids": {
                "DOI": [
                    "10.1007/s40974-017-0074-7"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Deep Learning for Plants Diseases",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Brahimi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Disorder detection of tomato plant(solanum lycopersicum) using IoT and machine learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Narvekar",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "J. Phys",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1088/1742-6596/1432/1/012086"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Early rice disease detection and position mapping system using drone and IoT architecture",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kitpo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 2018 12th South East Asian Technical University Consortium (SEATUC)",
            "volume": "",
            "issn": "",
            "pages": "12--13",
            "other_ids": {
                "DOI": [
                    "10.1109/SEATUC.2018.8788863"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "An IoT based smart solution for leaf disease detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Thorat",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kumari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "D"
                    ],
                    "last": "Valakunde",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 International Conference on Big Data, IoT and Data Science (BID)",
            "volume": "",
            "issn": "",
            "pages": "20--22",
            "other_ids": {
                "DOI": [
                    "10.1109/BID.2017.8336597"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Plant Disease Detection: A Comprehensive Survey",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Chapaneri",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Desai",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ghose",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of the 2020 3rd International Conference on Communication System, Computing and IT Applications (CSCITA)",
            "volume": "",
            "issn": "",
            "pages": "3--4",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Convolution neural network in precision agriculture for plant image recognition and classification",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Abdullahi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sheriff",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Mahieddine",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 Seventh International Conference on Innovative Computing Technology (INTECH)",
            "volume": "",
            "issn": "",
            "pages": "16--18",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Multilayer Convolution Neural Network for the Classification of Mango Leaves Infected by Anthracnose Disease",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "P"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Chouhan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jain",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jain",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "43721--43729",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2019.2907383"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Plant disease identification using explainable 3D deep learning on hyperspectral images",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Nagasubramanian",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sarkar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Ganapathysubramanian",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Plant Methods",
            "volume": "15",
            "issn": "",
            "pages": "1--10",
            "other_ids": {
                "DOI": [
                    "10.1186/s13007-019-0479-8"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Deep Learning for Image-Based Cassava Disease Detection. Front",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ramcharan",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Baranowski",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mccloskey",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Legg",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Hughes",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Plant Sci",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3389/fpls.2017.01852"
                ]
            }
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Plant disease identification from individual lesions and spots using deep learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "G A"
                    ],
                    "last": "Barbedo",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Biosyst. Eng",
            "volume": "180",
            "issn": "",
            "pages": "96--107",
            "other_ids": {
                "DOI": [
                    "10.1016/j.biosystemseng.2019.02.002"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Real-Time Detection of Apple Leaf Diseases Using Deep Learning Approach Based on Improved Convolutional Neural Networks",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "59069--59080",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2019.2914929"
                ]
            }
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Identification of Soybean Leaf Diseases via Deep Learning",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Inst. Eng. (India) Ser. A",
            "volume": "100",
            "issn": "",
            "pages": "659--666",
            "other_ids": {
                "DOI": [
                    "10.1007/s40030-019-00390-y"
                ]
            }
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Deep Residual learning for image recognition",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1512.03385v1"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Going Deeper with Convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sermanet",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Reed",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabinovich",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "21--26",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "A review of unsupervised feature learning and deep learning for time-series modeling",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "L\u00e4ngkvist",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Karlsson",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Loutfi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Pattern Recognit. Lett",
            "volume": "42",
            "issn": "",
            "pages": "11--24",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patrec.2014.01.008"
                ]
            }
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Rethinking the Inception Architecture for Computer Vision",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wojna",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "2261--2269",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2017.243"
                ]
            }
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Efficient convolutional neural networks for mobile vision applications. arXiv 2017",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "G"
                    ],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kalenichenko",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Weyand",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Adam",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mobilenets",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1704.04861"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "AlexNet-level accuracy with 50x fewer parameters and<0.5 MB model size. arXiv 2016",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "N"
                    ],
                    "last": "Iandola",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Moskewicz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ashraf",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Dally",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Keutzer",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Squeezenet",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1602.07360"
                ]
            }
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Image Classification) in ILSVRC",
            "authors": [],
            "year": 2015,
            "venue": "Review: Inception-v3-1st Runner Up",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Deep learning models for plant disease detection and diagnosis",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ferentinos",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Comput. Electron. Agric",
            "volume": "145",
            "issn": "",
            "pages": "311--318",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compag.2018.01.009"
                ]
            }
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "A survey on detection and classification of rice plant diseases",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "B"
                    ],
                    "last": "Prajapati",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "K"
                    ],
                    "last": "Dabhi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)",
            "volume": "",
            "issn": "",
            "pages": "10--11",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "A survey on Image Data Augmentation for Deep Learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shorten",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Big Data",
            "volume": "6",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/s40537-019-0197-0"
                ]
            }
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "A novel data augmentation method to enhance deep neural networks for detection of atrial fibrillation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Mao",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Ning",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Biomed. Signal Process. Control",
            "volume": "56",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.bspc.2019.101675"
                ]
            }
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Deep neural networks with transfer learning in millet crop images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Coulibaly",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kamsu-Foguem",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Kamissoko",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Traore",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Ind",
            "volume": "108",
            "issn": "",
            "pages": "115--120",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compind.2019.02.003"
                ]
            }
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Downy Mildew of Pearl Millet and its Management",
            "authors": [
                {
                    "first": "H",
                    "middle": [
                        "S"
                    ],
                    "last": "Shetty",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "N"
                    ],
                    "last": "Raj",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "R"
                    ],
                    "last": "Kini",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "R"
                    ],
                    "last": "Bishnoi",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "S"
                    ],
                    "last": "Rajpurohit",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [
                        "P"
                    ],
                    "last": "Yadav",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Indian Counc. Agric. Res. Mandor Jodhpur",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Deep learning and IoT for agricultural applications",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Garg",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alam",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Internet of Things (IoT)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Review on Application of Drone Systems in Precision Agriculture",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Mogili",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "B V L"
                    ],
                    "last": "Deepak",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Procedia Comput. Sci",
            "volume": "133",
            "issn": "",
            "pages": "502--509",
            "other_ids": {
                "DOI": [
                    "10.1016/j.procs.2018.07.063"
                ]
            }
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "An AIoT Based Smart Agricultural System for Pests Detection",
            "authors": [
                {
                    "first": "C.-J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y.-Y",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Y.-S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C.-Y",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "Y.-M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "180750--180761",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.3024891"
                ]
            }
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "IoT Monitoring System for Early Detection of Agricultural Pests and Diseases",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Materne",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Inoue",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 2018 12th South East Asian Technical University Consortium (SEATUC)",
            "volume": "",
            "issn": "",
            "pages": "12--13",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "A deep learning-based approach for banana leaf diseases classification",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Amara",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Bouaziz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Algergawy",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Lect. Notes Inform",
            "volume": "266",
            "issn": "",
            "pages": "79--88",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Performance analysis of deep learning CNN models for disease detection in plants using image segmentation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "P S"
                    ],
                    "last": "Berwal",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ghai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Inf. Process. Agric",
            "volume": "7",
            "issn": "",
            "pages": "566--574",
            "other_ids": {
                "DOI": [
                    "10.1016/j.inpa.2019.11.001"
                ]
            }
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Available online: Image-net.org (accessed on 2",
            "authors": [
                {
                    "first": "Imagenet",
                    "middle": [],
                    "last": "Dataset",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "An introduction to ROC analysis",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Fawcett",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Pattern Recognit. Lett",
            "volume": "27",
            "issn": "",
            "pages": "861--874",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patrec.2005.10.010"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The framework of 'Automatic and Intelligent Data Collector and Classifier'.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Role of sensors in the pearl millet farmland. Component 2: This component comprises the Raspberry Pi and cloud storage. It receives the parametric and imagery dataset collected by component 1. Raspberry Pi can store up to 100 images due to its limited storage capacity. Therefore, the photos are sent to the cloud server, if their number exceeds 100, as demonstrated in Figure 1. Component 3: In this component, the DL based classifier classifies the data stored at the cloud server and Raspberry Pi into the rust and blast classes. Component 3 works synchronously with the Raspberry Pi for facilitating real-time predictions and notifying the farmers about the diseases or other variations observed in the farmland.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Sample images of pearl millet infected with blast and rust.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The architecture of the 'Custom-Net' model. Training of 'Custom-Net' and State-of-the-Art Deep Learning Models Based on the set of experiments conducted and the experimental results reported in the related works",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Output matrix of selected layers of 'Custom-Net' model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "AUC-ROC curves of six classifiers on the training and testing datasets.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "shows that the values of average accuracy, reported by the non-pre-trained and pre-trained versions of the 'Custom-Net' and state-of-the-art DL models viz. Inception ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19, are comparable except for the non-pre-trained versions of VGG-16 and VGG-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Average accuracy of different deep learning models. The Non-pre-trained version of the 'Custom-Net' model reported an average accuracy of 98.78%, whereas its pre-trained version reported an average accuracy of 98.15%. Similarly, the non-pre-trained versions of Inception ResNet-V2, Inception-V3, and ResNet-50 reported the average accuracies of 99.49%, 99.39%, and 98.68%, respectively. It is also apparent from Figure 7 that the pre-trained versions of ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19 also reported the comparable values of average accuracies of 98.98%, 99.59%, 99.79%, 99.49, and 99.89%, respectively. However, in strong contrast, the non-pre-trained versions VGG-16 and VGG-19 reported a low average accuracy of 57.27%.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Precision of different deep learning models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Recall of different deep learning models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "F1 score of different deep learning models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "that the 'Custom-Net' model requires a minimum time of only 80 s for training through 20 epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Training time of different deep learning models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Training parameters of different deep learning models.4.7. Grad-CAMNow, the authors plotted the Grad-CAM to visualize the features involved in the classification. The visualization of features involved in classification for the pre-trained and non-pre-trained versions of Inception ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19 are shown inFigures 13 and 14, respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Grad-CAM to visualize the features of pre-trained models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Grad-CAM to visualize the features of non-pre-trained models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Contributions: This research specifies below the individual contributions: Conceptualization, N.K., G.R., V.S.D., K.G.; Data curation, N.K., G.R., S.C.N., S.V., Formal analysis, N.K., G.R., S.C.N., S.V., M.F.I., M.W.; Funding acquisition, M.F.I., M.W.; Investigation, N.K., G.R., V.S.D., K.G.; Methodology S.C.N., S.V., M.F.I., M.W.; Project administration, M.F.I., M.W.; Resources, M.F.I., M.W.; Software, N.K., G.R., V.S.D., K.G., S.C.N., S.V.; Supervision, G.R., V.S.D., S.C.N., S.V., M.F.I., M.W.; Validation N.K., G.R., V.S.D., K.G., S.C.N., S.V., M.F.I., M.W. All authors have read and agreed to the published version of the manuscript. Funding: The authors acknowledge contribution to this project from the Rector of the Silesian University of Technology under a proquality grant grant no. 09/020/RGJ21/0007. This work was supported by the Polish National Agency for Academic Exchange under the Programme PROM International scholarship exchange of PhD candidates and academic staff no. PPI/PRO/2019/1/00051. The authors would like to acknowledge contribution to this research from the National Agency for Academic Exchange of Poland under the Academic International Partnerships program, grant agreement no. PPI/APM/2018/1/00004. Institutional Review Board Statement: Not applicable. Informed Consent Statement: Not applicable.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Characteristics and symptoms of diseased leaves of pearl millet.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Number of images in training and testing datasets of blast and rust.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Sample Confusion matrix.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 4b that the pre-trained 'Custom-Net' model misclassifies 34 samples from the test dataset containing 567 images of plant leaves infected with blast disease. Furthermore, it is clear from Table 4b that the 'Custom-Net' model misclassifies 69 images from the test dataset comprising 423 images of plant leaves infected with rust disease. However, at the same time, it can be observed in",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Confusion matrix of pre-trained 'Custom-Net' model.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Confusion matrix of non-pre-trained 'Custom-Net' model.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Classification performance of different deep learning models.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Comparison of the proposed approach and the approaches available in literature.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors acknowledge the contribution to this project from the Rector of Silesian University of Technology under the pro-quality grant for outstanding researchers. The authors are also grateful to ICAR (Indian Council of Agricultural Research), New Delhi, India for providing the financial support to University of Mysore under AICRP-Pearl millet Scheme.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments:"
        },
        {
            "text": "The authors declare no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflicts of Interest:"
        }
    ]
}