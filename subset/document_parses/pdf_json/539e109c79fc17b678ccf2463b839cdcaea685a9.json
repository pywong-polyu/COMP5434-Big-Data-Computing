{"paper_id": "539e109c79fc17b678ccf2463b839cdcaea685a9", "metadata": {"title": "Diagnosing of Diabetic Retinopathy with Image Dehazing and Capsule Network", "authors": []}, "abstract": [], "body_text": [{"text": "retinopathy, which was done automatically via tissue properties [8] . In another study, Safitri and Juniati ensured an early detection of micro aneurysms (MA) by removing candidate sites for MAs within the retinal image, and then classifying the related regions with a hybrid approach including Gaussian mixing model and a model of support vector machine [9] . Savarkar and colleagues proposed a method of detecting MAs by analyzing density values along discrete segments of different directions centered in the candidate pixel. In this method, the peak values were determined first and then the feature set was determined and classified [10] . Finally, Akremetal et al. have a research of diagnosing DR, done with the fractal analysis, and the k-nearest neighbor (kNN) techniques [11] .", "cite_spans": [{"start": 64, "end": 67, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 355, "end": 358, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 638, "end": 642, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 781, "end": 785, "text": "[11]", "ref_id": "BIBREF10"}], "ref_spans": [], "section": ""}, {"text": "In this chapter, the diagnosis of DR was solved that time with the Capsule Network, which is called also as CapsNet briefly. CapsNet is actually an improved version of the convolutional neural networks (CNN), which is a widely used deep learning technique, as employing important advantages of the deep learning [12] . In addition to the solution in Chap. 4, Deperlioglu and Kose used before a practical image processing method to improve retinal fundus images including HSV, V transformation algorithm and histogram equalization techniques for better classifying the images (diagnosis) with the CNN [13] . An alternative work with the CNN was also done in [14] , by employing histogram equalization (HE) as well as the contrast limited adaptive histogram equalization (CLAHE) for providing better data for the CNN. Also, there is another alternative use of CNN and development of a diagnosis/decision support system with no user input, as done by Pratt et al. in [15] . Here, the question of if CapsNet can improve the results more against especially CNN was tried to be answered with also alternative use of image processing with a simple technique of image dehazing accordingly.", "cite_spans": [{"start": 312, "end": 316, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 600, "end": 604, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 657, "end": 661, "text": "[14]", "ref_id": "BIBREF13"}, {"start": 964, "end": 968, "text": "[15]", "ref_id": "BIBREF14"}], "ref_spans": [], "section": ""}, {"text": "In the study, the diagnosis of the DR was done with two-step approach including image processing and then classification with the CapsNet. For the training/tests, the Kaggle Diabetic Retinopathy Detection database was chosen as the target data in the study. The related stages in detail for the DR diagnosis are represented in Fig. 9 .2.", "cite_spans": [], "ref_spans": [{"start": 327, "end": 333, "text": "Fig. 9", "ref_id": null}], "section": "Materials and Method"}, {"text": "The database of DR provided in the Kaggle platform is briefly a public set including over 80,000 colorful fundus images [16] . The first data set consisted of 88,702 colorful fundus images gathered from a total of 44,351 patients. Images were collected from several primary found centers in California and elsewhere with various digital fundus cameras. As all files in jpeg format, the definitions are respectively 433 \u00d7 289 pixels to 5184 \u00d7 3456 pixels (as the median definition: 3888 \u00d7 2592 pixels), and the related images were uploaded to the EyePACS, which is a DR screening platform [17] . For each eye, the severity of DR was rated by an expert on the ETDRS [18] scale. These are respectively 'absence-of DR', 'mild non-proliferative DR (NPDR)', 'moderate NPDR', 'severe NPDR' and 'proliferative DR (PDR) [19] . ", "cite_spans": [{"start": 120, "end": 124, "text": "[16]", "ref_id": null}, {"start": 588, "end": 592, "text": "[17]", "ref_id": "BIBREF16"}, {"start": 664, "end": 668, "text": "[18]", "ref_id": "BIBREF17"}, {"start": 811, "end": 815, "text": "[19]", "ref_id": null}], "ref_spans": [], "section": "Kaggle Diabetic Retinopathy Database for Diagnosis"}, {"text": "In this study, a simple and fast image enhancement method was used which gives close performance to mixed methods. This method consists of dark-channel prior based image dehazing, and also image guided filter.", "cite_spans": [], "ref_spans": [], "section": "Image Processing"}, {"text": "The dark-channel prior based is a type of statistic for outdoors-free images image dehazing. It uses the approach of an important observation/most local patches on outdoor airless images include some pixels with a very low density in at least onecolor channel. Just before, running that in the haze imaging model, the thickness of the haze and also obtaining of a high-quality haze-free image are possible to be directly predicted. The dark-channel prior here is just a simple but powerful enough prior, in order to be used for removal of single image haze. As a result of combining the haze imaging model with the prior, the removal of single image haze becomes more effective and in an easier form [20] .", "cite_spans": [{"start": 700, "end": 704, "text": "[20]", "ref_id": "BIBREF19"}], "ref_spans": [], "section": "Image Processing"}, {"text": "After dehazing, a guided filter is used for smoothing the colors and sharping the edges. The guided filter formed as from a local linear model ensures calculation of the filtering output, thanks to the contents of a grid image, which may be the input image itself or another different image. Here, it is possible to use the guided filter as an edge protector straightening operator, such as the popular bilateral filter, but has better behavior as close to the related edges. The guided filter can also transfer the structures of the orientation image to the filtering output so that it enables new filtering applications such as guided feathering and the dehazing [21] .", "cite_spans": [{"start": 665, "end": 669, "text": "[21]", "ref_id": "BIBREF20"}], "ref_spans": [], "section": "Image Processing"}, {"text": "The classification approach for diagnosing DR in this study was done with the Capsule Network (CapsNet), which is an effective, recent deep learning techniques. The CapsNet has been applied over the related Kaggle database accordingly, after the image processing phase.", "cite_spans": [], "ref_spans": [], "section": "Classification"}, {"text": "CapsNet is a recent deep learning architecture employing capsules, which are groups of artificial neurons as the data processing components. CapsNet has been developed as a solution for the problem of discarding some information (i.e. position and the pose of the target object) because of the data routing process seen in convolutional neural networks (CNN). In a typical CapsNet, each capsule can determine a single component within the target object, and eventually, all capsules form the whole structure of the object collaboratively [22] [23] [24] . As a typical improvement of the CNN, CapsNet models include multi-layers. Figure 9 .3 represents a typical structure of the CapsNet [25] . ", "cite_spans": [{"start": 538, "end": 542, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 543, "end": 547, "text": "[23]", "ref_id": "BIBREF22"}, {"start": 548, "end": 552, "text": "[24]", "ref_id": "BIBREF23"}, {"start": 687, "end": 691, "text": "[25]", "ref_id": "BIBREF24"}], "ref_spans": [{"start": 629, "end": 637, "text": "Figure 9", "ref_id": null}], "section": "Classification"}, {"text": "As used in different medical applications including especially diagnosis, the following evaluation metrics were used in this study, for evaluating the developed solution [26] :", "cite_spans": [{"start": 170, "end": 174, "text": "[26]", "ref_id": "BIBREF25"}], "ref_spans": [], "section": "Evaluation of the Diagnosis"}, {"text": "gmean = sqrt(Sensitivity * Specificity)", "cite_spans": [], "ref_spans": [], "section": "Evaluation of the Diagnosis"}, {"text": "In the context of the related equations, TrP and FrP mean respectively as the total number of true positive, and the total number of false positive regarding the performed diagnosis. Additionally, TrN and FrN correspond to the total number of true negative, and the total number of false negatives seen within the diagnosis N is for the total number of the data/samples, as meaning also sum of positives (P), and negatives (N). For a specific classification technique, precision of diagnosing correctly is associated with the ratio of accuracy. On the other hand, the Sensitivity is for defining the extent to which the classifier defines target class formation correctly, and the Specificity is for the separation capability for target classes [27, 28] .", "cite_spans": [{"start": 745, "end": 749, "text": "[27,", "ref_id": "BIBREF26"}, {"start": 750, "end": 753, "text": "28]", "ref_id": "BIBREF27"}], "ref_spans": [], "section": "Evaluation of the Diagnosis"}, {"text": "MATLAB r2017a software was used in all image processing and the classification/diagnosis processes. In the study, 200 color fundus digital images in the Kaggle database were used to evaluate the performance of the image processing supporting CapsNet model. At this point, 200 images including 157 no DR (0), 10 mild NPDR (1), 27 moderate NPDR (2), 4 severe NPDR (3), and 2 proliferative DR (PDR) (4) were selected and used accordingly. Consequently, the output classes of the classification are five such as 0, 1, 2, 3, and 4.", "cite_spans": [], "ref_spans": [], "section": "Application and Evaluation"}, {"text": "First, image enhancement to these images was performed. Figure 9 .4 shows the images after the image enhancement steps for 46_left.jpeg. In the image processing studies, entropy value and mean value were examined in order to evaluate the obtained results. For example, for the \"46_left.jpeg\" image, the entropy value of the original image measured is 2.2036. The Entropy value of the improved image increased to 2.6634. Similarly, the mean value regarding the original image is 204.2431. The mean value of the improved image has increased to 209.6221. Since higher entropy and mean values mean better visualization, there is improvement in images.", "cite_spans": [], "ref_spans": [{"start": 56, "end": 64, "text": "Figure 9", "ref_id": null}], "section": "Application and Evaluation"}, {"text": "In order to better understand the improvements in the image, only original images and improved images are shown in Fig. 9 .5.", "cite_spans": [], "ref_spans": [{"start": 115, "end": 121, "text": "Fig. 9", "ref_id": null}], "section": "Application and Evaluation"}, {"text": "In the context of the DR diagnosis process, the obtained colorful fundus images were classified by the CapsNet model. In order to design a model for diagnosing the DR, the CapsNet here consisted of 5 layers at total. These layers are respectively image input layer (with parameters of [195 322 3]), convolutional layer (3 \u00d7 3 \u00d7 256), primary caps (3 \u00d7 3 \u00d7 (1 \u00d7 256)), fundus caps ((7 \u00d7 7) \u00d7 256), and the output layer (classification layer).", "cite_spans": [], "ref_spans": [], "section": "Application and Evaluation"}, {"text": "In the classification/diagnosis, 200 images from the Kaggle database were used while 80% of these images were for training, and the remaining 20% was for the test. For randomly selected training and test data, the classification process was repeated 20 times. The obtained findings in terms of the lowest-average-highest values for the performance evaluation metrics are given in Table 9 .1. As it is seen from the obtained findings the combination of the image dehazing and the CapsNet model has high values in terms of different evaluation metrics. That can be indicated that the diagnosis solution has a very high sampling, selection and estimation ability.", "cite_spans": [], "ref_spans": [{"start": 380, "end": 387, "text": "Table 9", "ref_id": "TABREF0"}], "section": "Application and Evaluation"}, {"text": "In this chapter, it is aimed to explain an easy method instead of creating DR diagnostic methods by not using different heavy-detailed image processing methods and artificial intelligence techniques. In this context, easy diagnosis of diabetic retinopathy by defogging of the fundus image using a dark canal priority method and classification using capsule networks (CapsNet) have been proposed. In order to test the performance of the proposed method, an application was created with Kaggle Diabetic Retinopathy diagnosis database. After image processing, a classification study was performed with a CapsNet model. A total of 20 trials were performed and the average values of the criteria used in performance evaluation were taken. Obtained results show that the developed model a very high sampling, selection and estimation ability. Thus, the proposed method is very effective and efficient in the diagnosis of DR from retinal fundus images. For the future works different image processing method can be added or different variations of the CapsNet can also be implemented.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "The humankind has always been dealing with serious disease needing early diagnosis for better treatment results at end. As the diabetic retinopathy (DR) has the potential of causing blindness, the associated literature of artificial intelligence has given a remarkable emphasis for designing diagnosis solutions, which has early diagnosis mechanism. In order to achieve that, image processing and machine/deep learning all have great synergy to develop innovative and robust solutions. As similar, this chapter provided an alternative solution combining image dehazing and the Capsule Network (CapsNet). The solution provided here is just another example of diagnosing DR, as explained before in Chap. 4, too. It can be clearly seen that there are open ways to derive alternative solutions for trying to improve obtained results. The solutions provided in both Chap. 4 and this chapter can also be applied for diagnosis of alternative diseases, which can be diagnosed from image data.", "cite_spans": [], "ref_spans": [], "section": "Summary"}, {"text": "As the chapters past so far provided a general collection of medical decision support rising over diagnosis processes, there are still many more alternative research ways to be done, by considering the wide variety of diseases. Although the humankind desires a disease-free world, that seems impossible because of the chaos in the life and the nature itself. However, the future will be still associated with further developments and alternative solution ideas in the intersection of artificial intelligence and the field of medical. By considering deep learning and the topic of medical decision support systems, the final Chap. 10 is devoted to a general discussion on what kind of future may be shaped thanks to strong relation between deep learning-oriented decision support solutions and the medical.", "cite_spans": [], "ref_spans": [], "section": "Summary"}, {"text": "The readers interested in learning more about medical image analysis and the role of image processing techniques in this manner are referred to [29] [30] [31] [32] [33] [34] [35] [36] .", "cite_spans": [{"start": 144, "end": 148, "text": "[29]", "ref_id": "BIBREF28"}, {"start": 149, "end": 153, "text": "[30]", "ref_id": null}, {"start": 154, "end": 158, "text": "[31]", "ref_id": "BIBREF30"}, {"start": 159, "end": 163, "text": "[32]", "ref_id": "BIBREF31"}, {"start": 164, "end": 168, "text": "[33]", "ref_id": "BIBREF32"}, {"start": 169, "end": 173, "text": "[34]", "ref_id": "BIBREF33"}, {"start": 174, "end": 178, "text": "[35]", "ref_id": "BIBREF34"}, {"start": 179, "end": 183, "text": "[36]", "ref_id": "BIBREF35"}], "ref_spans": [], "section": "Further Learning"}, {"text": "Image processing and deep learning combinations are used in solving many different medical problems. As a very recent collection for understanding some about the current state, the readers can read [37] [38] [39] [40] [41] [42] [43] .", "cite_spans": [{"start": 198, "end": 202, "text": "[37]", "ref_id": "BIBREF36"}, {"start": 203, "end": 207, "text": "[38]", "ref_id": "BIBREF37"}, {"start": 208, "end": 212, "text": "[39]", "ref_id": "BIBREF38"}, {"start": 213, "end": 217, "text": "[40]", "ref_id": "BIBREF39"}, {"start": 218, "end": 222, "text": "[41]", "ref_id": "BIBREF40"}, {"start": 223, "end": 227, "text": "[42]", "ref_id": "BIBREF41"}, {"start": 228, "end": 232, "text": "[43]", "ref_id": "BIBREF42"}], "ref_spans": [], "section": "Further Learning"}, {"text": "As the world is currently (at the time of finalizing the book) dealing with the pandemic caused by the COVID-19 virus, there are also some recently published works focusing on image-based analyzes for coronavirus/COVID-19 diagnosis. Some of them are [44] [45] [46] [47] [48] [49] .", "cite_spans": [{"start": 250, "end": 254, "text": "[44]", "ref_id": "BIBREF43"}, {"start": 255, "end": 259, "text": "[45]", "ref_id": "BIBREF44"}, {"start": 260, "end": 264, "text": "[46]", "ref_id": "BIBREF45"}, {"start": 265, "end": 269, "text": "[47]", "ref_id": "BIBREF46"}, {"start": 270, "end": 274, "text": "[48]", "ref_id": "BIBREF47"}, {"start": 275, "end": 279, "text": "[49]", "ref_id": "BIBREF48"}], "ref_spans": [], "section": "Further Learning"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Identification and classification of microaneurysms for early detection of diabetic retinopathy", "authors": [{"first": "M", "middle": ["U"], "last": "Akram", "suffix": ""}, {"first": "S", "middle": [], "last": "Khalid", "suffix": ""}, {"first": "S", "middle": ["A"], "last": "Khan", "suffix": ""}], "year": 2013, "venue": "Pattern Recognit", "volume": "46", "issn": "1", "pages": "107--116", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Blindness Causes", "authors": [], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Deep image mining for diabetic retinopathy screening", "authors": [{"first": "G", "middle": [], "last": "Quellec", "suffix": ""}], "year": 2017, "venue": "Med. Image Anal", "volume": "39", "issn": "", "pages": "178--193", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Detection and classification of retinal lesions for grading of diabetic retinopathy", "authors": [{"first": "U", "middle": ["M"], "last": "Akram", "suffix": ""}], "year": 2014, "venue": "Comput. Biol. Med", "volume": "45", "issn": "", "pages": "161--171", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Computer-aided diagnosis of diabetic retinopathy: A review", "authors": [{"first": "M", "middle": ["R"], "last": "Mookiah", "suffix": ""}, {"first": "", "middle": [], "last": "Krishnan", "suffix": ""}], "year": null, "venue": "Comput. Biol. Med", "volume": "43", "issn": "12", "pages": "2136--2155", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Severity grading of DME from retina images: A combination of PSO and FCM with bayes classifier", "authors": [{"first": "K", "middle": ["S"], "last": "Sreejini", "suffix": ""}, {"first": "V", "middle": ["K"], "last": "Govindan", "suffix": ""}], "year": 2013, "venue": "Int. J. Comput. Applications", "volume": "81", "issn": "16", "pages": "11--17", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Automatic Grading of Diabetic Retinopathy on a Public Database", "authors": [{"first": "L", "middle": [], "last": "Seoud", "suffix": ""}, {"first": "J", "middle": [], "last": "Chelbi", "suffix": ""}, {"first": "F", "middle": [], "last": "Cheriet", "suffix": ""}, {"first": ";", "middle": ["X"], "last": "Chen", "suffix": ""}, {"first": "M", "middle": ["K"], "last": "Garvin", "suffix": ""}, {"first": "J", "middle": ["J"], "last": "Liu", "suffix": ""}, {"first": "E", "middle": [], "last": "Trusso", "suffix": ""}, {"first": "Y", "middle": [], "last": "Xu", "suffix": ""}], "year": 2015, "venue": "Proceedings of the Ophthalmic Medical Image Analysis Second International Workshop, OMIA 2015, Held in Conjunction with MICCAI", "volume": "", "issn": "", "pages": "97--104", "other_ids": {"DOI": ["10.17077/omia.1032"]}}, "BIBREF7": {"ref_id": "b7", "title": "An integrated index for the ident", "authors": [{"first": "U", "middle": ["R"], "last": "Acharya", "suffix": ""}, {"first": "E", "middle": ["Y K"], "last": "Ng", "suffix": ""}, {"first": "J", "middle": ["H"], "last": "Tan", "suffix": ""}], "year": null, "venue": "J. Med. Syst", "volume": "36", "issn": "3", "pages": "2011--2020", "other_ids": {"DOI": ["10.1007/s10916-011-9663-8"]}}, "BIBREF8": {"ref_id": "b8", "title": "Classification of Diabetic Retinopathy Using Fractal Dimension Analysis of Eye Fundus Image", "authors": [{"first": "D", "middle": ["W"], "last": "Safitri", "suffix": ""}, {"first": "D", "middle": [], "last": "Juniati", "suffix": ""}], "year": 2017, "venue": "International Conference on Mathematics: Pure, Applied and Computation. AIP Conf. Proc. 1867", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1063/1.4994414"]}}, "BIBREF9": {"ref_id": "b9", "title": "Diabetic retinopathy using image processing detection, classification and analysis", "authors": [{"first": "S", "middle": ["P"], "last": "Savarkar", "suffix": ""}, {"first": "N", "middle": [], "last": "Kalkar", "suffix": ""}, {"first": "S", "middle": ["L"], "last": "Tade", "suffix": ""}], "year": 2013, "venue": "Int. J. Adv. Comput. Res", "volume": "3", "issn": "11", "pages": "585--588", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Identification and classification of microaneurysms for early detection of diabetic retinopathy. Pattern Recogn", "authors": [{"first": "M", "middle": ["U"], "last": "Akrametal", "suffix": ""}, {"first": "S", "middle": [], "last": "Khalid", "suffix": ""}, {"first": "S", "middle": ["A"], "last": "Khan", "suffix": ""}], "year": 2013, "venue": "", "volume": "46", "issn": "", "pages": "107--116", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Deep learning: Autoencoders fundamentals and types", "authors": [{"first": "P", "middle": [], "last": "Chandrayan", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Diagnosis of Diabetic Retinopathy by Using Image Processing and Convolutional Neural Network", "authors": [{"first": "O", "middle": [], "last": "Deperl\u0131oglu", "suffix": ""}, {"first": "U", "middle": [], "last": "K\u00f6se", "suffix": ""}], "year": 2018, "venue": "2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network", "authors": [{"first": "D", "middle": ["J"], "last": "Hemanth", "suffix": ""}, {"first": "O", "middle": [], "last": "Deperlioglu", "suffix": ""}, {"first": "U", "middle": [], "last": "Kose", "suffix": ""}], "year": 2019, "venue": "Neural Comput. Appl", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1007/s00521-018-03974-0"]}}, "BIBREF14": {"ref_id": "b14", "title": "Convolutional neural networks for diabetic retinopathy", "authors": [{"first": "H", "middle": [], "last": "Pratt", "suffix": ""}], "year": 2016, "venue": "Procedia Comput. Sci", "volume": "90", "issn": "", "pages": "200--205", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "EyePACS: An adaptable telemedicine system for dia-betic retinopathy screening", "authors": [{"first": "J", "middle": [], "last": "Cuadros", "suffix": ""}, {"first": "G", "middle": [], "last": "Bresnick", "suffix": ""}], "year": 2009, "venue": "J. Diabetes Sci. Technol", "volume": "3", "issn": "3", "pages": "509--516", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Proposed international clinical diabetic retinopathy and diabetic macular edema disease severity scales", "authors": [{"first": "C", "middle": ["P"], "last": "Wilkinson", "suffix": ""}, {"first": "F", "middle": ["L"], "last": "Ferris", "suffix": ""}, {"first": "R", "middle": ["E"], "last": "Klein", "suffix": ""}, {"first": "P", "middle": ["P"], "last": "Lee", "suffix": ""}, {"first": "C", "middle": ["D"], "last": "Agardh", "suffix": ""}, {"first": "M", "middle": [], "last": "Davis", "suffix": ""}, {"first": "D", "middle": [], "last": "Dills", "suffix": ""}, {"first": "A", "middle": [], "last": "Kampik", "suffix": ""}, {"first": "R", "middle": [], "last": "Pararajasegaram", "suffix": ""}, {"first": "J", "middle": ["T"], "last": "Verdaguer", "suffix": ""}], "year": 2003, "venue": "Ophthalmology", "volume": "110", "issn": "9", "pages": "1677--1682", "other_ids": {"DOI": ["10.1016/s0161-6420(03)00475-5"]}}, "BIBREF19": {"ref_id": "b19", "title": "Single image haze removal using dark channel prior", "authors": [{"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "J", "middle": [], "last": "Sun", "suffix": ""}, {"first": "X", "middle": [], "last": "Tang", "suffix": ""}], "year": 2010, "venue": "IEEE Trans. Pattern Anal. Mach. Intell", "volume": "33", "issn": "12", "pages": "2341--2353", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Guided image filtering (European Conference on Computer Vision", "authors": [{"first": "K", "middle": [], "last": "He", "suffix": ""}, {"first": "J", "middle": [], "last": "Sun", "suffix": ""}, {"first": "X", "middle": [], "last": "Tang", "suffix": ""}], "year": 2010, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Dynamic routing between capsules", "authors": [{"first": "S", "middle": [], "last": "Sabour", "suffix": ""}, {"first": "N", "middle": [], "last": "Frosst", "suffix": ""}, {"first": "G", "middle": ["E"], "last": "Hinton", "suffix": ""}], "year": 2017, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "3856--3866", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Fast Capsnet for Lung Cancer Screening", "authors": [{"first": "A", "middle": [], "last": "Mobiny", "suffix": ""}, {"first": "H", "middle": [], "last": "Van Nguyen", "suffix": ""}], "year": 2018, "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention", "volume": "", "issn": "", "pages": "741--749", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Emotion recognition from multiband EEG signals using CapsNet", "authors": [{"first": "H", "middle": [], "last": "Chao", "suffix": ""}, {"first": "L", "middle": [], "last": "Dong", "suffix": ""}, {"first": "Y", "middle": [], "last": "Liu", "suffix": ""}, {"first": "B", "middle": [], "last": "Lu", "suffix": ""}], "year": 2019, "venue": "Sensors", "volume": "19", "issn": "9", "pages": "", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Remote sensing image scene classification using CNN-CapsNet", "authors": [{"first": "W", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "P", "middle": [], "last": "Tang", "suffix": ""}, {"first": "L", "middle": [], "last": "Zhao", "suffix": ""}], "year": 2019, "venue": "Remote. Sens", "volume": "11", "issn": "5", "pages": "", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Heart sound classification based on scaled spectrogram and tensor decomposition", "authors": [{"first": "W", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "J", "middle": [], "last": "Han", "suffix": ""}, {"first": "S", "middle": [], "last": "Deng", "suffix": ""}], "year": 2017, "venue": "Biomed. Signal Process. Control", "volume": "32", "issn": "", "pages": "20--28", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Classification of phonocardiograms with convolutional neural networks", "authors": [{"first": "O", "middle": [], "last": "Deperlioglu", "suffix": ""}], "year": 2018, "venue": "brain. Broad Res. Artif. Intell. Neurosci", "volume": "9", "issn": "2", "pages": "22--33", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network", "authors": [{"first": "D", "middle": ["J"], "last": "Hemanth", "suffix": ""}, {"first": "O", "middle": [], "last": "Deperlioglu", "suffix": ""}, {"first": "U", "middle": [], "last": "Kose", "suffix": ""}], "year": 2019, "venue": "Neural Comput. Appl", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1007/s00521-018-03974-0"]}}, "BIBREF28": {"ref_id": "b28", "title": "Medical image analysis: Progress over two decades and the challenges ahead", "authors": [{"first": "J", "middle": ["S"], "last": "Duncan", "suffix": ""}, {"first": "N", "middle": [], "last": "Ayache", "suffix": ""}], "year": 2000, "venue": "IEEE Trans. Pattern Anal. Mach. Intell", "volume": "22", "issn": "1", "pages": "85--106", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "Decision Forests for Computer Vision and Medical Image Analysis", "authors": [], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Medical Image Processing, Analysis and Visualization in Clinical Research", "authors": [{"first": "M", "middle": ["J"], "last": "Mcauliffe", "suffix": ""}, {"first": "F", "middle": ["M"], "last": "Lalonde", "suffix": ""}, {"first": "D", "middle": [], "last": "Mcgarry", "suffix": ""}, {"first": "W", "middle": [], "last": "Gandler", "suffix": ""}, {"first": "K", "middle": [], "last": "Csaky", "suffix": ""}, {"first": "B", "middle": ["L"], "last": "Trus", "suffix": ""}], "year": 2001, "venue": "Proceedings 14th IEEE Symposium on Computer-Based Medical Systems (CBMS)", "volume": "", "issn": "", "pages": "381--386", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "Biosignal and Medical Image Processing", "authors": [{"first": "J", "middle": ["L"], "last": "Semmlow", "suffix": ""}, {"first": "B", "middle": [], "last": "Griffel", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "Radiographic Image Analysis-E-Book", "authors": [{"first": "K", "middle": ["M"], "last": "Martensen", "suffix": ""}], "year": 2013, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Biomedical Image Analysis", "authors": [{"first": "R", "middle": ["M"], "last": "Rangayyan", "suffix": ""}], "year": 2004, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "Handbook of Medical Image Processing and Analysis", "authors": [], "year": 2008, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Deep learning and handcrafted method fusion: Higher diagnostic accuracy for melanoma dermoscopy images", "authors": [{"first": "J", "middle": ["R"], "last": "Hagerty", "suffix": ""}, {"first": "R", "middle": ["J"], "last": "Stanley", "suffix": ""}, {"first": "H", "middle": ["A"], "last": "Almubarak", "suffix": ""}, {"first": "N", "middle": [], "last": "Lama", "suffix": ""}, {"first": "R", "middle": [], "last": "Kasmi", "suffix": ""}, {"first": "P", "middle": [], "last": "Guo", "suffix": ""}, {"first": "W", "middle": ["V"], "last": "Stoecker", "suffix": ""}], "year": 2019, "venue": "IEEE J. Biomed. Health Inform", "volume": "23", "issn": "4", "pages": "1385--1391", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Identifying facial phenotypes of genetic disorders using deep learning", "authors": [{"first": "Y", "middle": [], "last": "Gurovich", "suffix": ""}, {"first": "Y", "middle": [], "last": "Hanani", "suffix": ""}, {"first": "O", "middle": [], "last": "Bar", "suffix": ""}, {"first": "G", "middle": [], "last": "Nadav", "suffix": ""}, {"first": "N", "middle": [], "last": "Fleischer", "suffix": ""}, {"first": "D", "middle": [], "last": "Gelbman", "suffix": ""}, {"first": "L", "middle": ["M"], "last": "Bird", "suffix": ""}], "year": 2019, "venue": "Nat. Med", "volume": "25", "issn": "1", "pages": "60--64", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Deep learning-based cardiovascular image diagnosis: A promising challenge", "authors": [{"first": "K", "middle": ["K"], "last": "Wong", "suffix": ""}, {"first": "G", "middle": [], "last": "Fortino", "suffix": ""}, {"first": "D", "middle": [], "last": "Abbott", "suffix": ""}], "year": 2019, "venue": "Future Generation Computer Systems", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "Cancer diagnosis in histopathological image: CNN based approach", "authors": [{"first": "S", "middle": [], "last": "Dabeer", "suffix": ""}, {"first": "M", "middle": ["M"], "last": "Khan", "suffix": ""}, {"first": "S", "middle": [], "last": "Islam", "suffix": ""}], "year": 2019, "venue": "Inform. Med. Unlocked", "volume": "16", "issn": "", "pages": "", "other_ids": {}}, "BIBREF40": {"ref_id": "b40", "title": "Deep learning in Alzheimer's disease: Diagnostic classification and prognostic prediction using neuroimaging data", "authors": [{"first": "T", "middle": [], "last": "Jo", "suffix": ""}, {"first": "K", "middle": [], "last": "Nho", "suffix": ""}, {"first": "A", "middle": ["J"], "last": "Saykin", "suffix": ""}], "year": 2019, "venue": "Front. Aging Neurosci", "volume": "11", "issn": "", "pages": "", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Current status and future trends of clinical diagnoses via image-based deep learning", "authors": [{"first": "J", "middle": [], "last": "Xu", "suffix": ""}, {"first": "K", "middle": [], "last": "Xue", "suffix": ""}, {"first": "K", "middle": [], "last": "Zhang", "suffix": ""}], "year": 2019, "venue": "Theranostics", "volume": "9", "issn": "25", "pages": "", "other_ids": {}}, "BIBREF42": {"ref_id": "b42", "title": "Deep learning IoT system for online stroke detection in skull computed tomography images", "authors": [{"first": "C", "middle": ["M"], "last": "Dourado", "suffix": ""}, {"first": "S", "middle": ["P P"], "last": "Silva", "suffix": ""}, {"first": "R", "middle": ["V M"], "last": "Da N\u00f3brega", "suffix": ""}, {"first": "A", "middle": ["C D S"], "last": "Barros", "suffix": ""}, {"first": "P", "middle": ["P"], "last": "Filho", "suffix": ""}, {"first": "V", "middle": ["H C"], "last": "De Albuquerque", "suffix": ""}], "year": 2019, "venue": "Comput. Netw", "volume": "152", "issn": "", "pages": "25--39", "other_ids": {}}, "BIBREF43": {"ref_id": "b43", "title": "Deep Learning System to Screen Coronavirus Disease 2019 Pneumonia", "authors": [{"first": "X", "middle": [], "last": "Xu", "suffix": ""}, {"first": "X", "middle": [], "last": "Jiang", "suffix": ""}, {"first": "C", "middle": [], "last": "Ma", "suffix": ""}, {"first": "P", "middle": [], "last": "Du", "suffix": ""}, {"first": "X", "middle": [], "last": "Li", "suffix": ""}, {"first": "S", "middle": [], "last": "Lv", "suffix": ""}, {"first": "L", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Chen", "suffix": ""}, {"first": "J", "middle": [], "last": "Su", "suffix": ""}, {"first": "G", "middle": [], "last": "Lang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Li", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2002.09334"]}}, "BIBREF44": {"ref_id": "b44", "title": "Covid-19: Automatic Detection from X-ray Images Utilizing Transfer Learning with Convolutional Neural Networks", "authors": [{"first": "I", "middle": ["D"], "last": "Apostolopoulos", "suffix": ""}, {"first": "T", "middle": [], "last": "Bessiana", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.11617"]}}, "BIBREF45": {"ref_id": "b45", "title": "Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images and Deep Convolutional Neural Networks", "authors": [{"first": "A", "middle": [], "last": "Narin", "suffix": ""}, {"first": "C", "middle": [], "last": "Kaya", "suffix": ""}, {"first": "Z", "middle": [], "last": "Pamuk", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.10849"]}}, "BIBREF46": {"ref_id": "b46", "title": "A Deep Learning Algorithm Using CT Images to Screen for Corona Virus Disease", "authors": [{"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "B", "middle": [], "last": "Kang", "suffix": ""}, {"first": "J", "middle": [], "last": "Ma", "suffix": ""}, {"first": "X", "middle": [], "last": "Zeng", "suffix": ""}, {"first": "M", "middle": [], "last": "Xiao", "suffix": ""}, {"first": "J", "middle": [], "last": "Guo", "suffix": ""}, {"first": "M", "middle": [], "last": "Cai", "suffix": ""}, {"first": "J", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Y", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Meng", "suffix": ""}, {"first": "B", "middle": [], "last": "Xu", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF47": {"ref_id": "b47", "title": "Lung Infection Quantification of COVID-19 in CT Images with Deep Learning", "authors": [{"first": "F", "middle": [], "last": "Shan", "suffix": ""}, {"first": "Y", "middle": [], "last": "Gao", "suffix": ""}, {"first": "J", "middle": [], "last": "Wang", "suffix": ""}, {"first": "W", "middle": [], "last": "Shi", "suffix": ""}, {"first": "N", "middle": [], "last": "Shi", "suffix": ""}, {"first": "M", "middle": [], "last": "Han", "suffix": ""}, {"first": "Z", "middle": [], "last": "Xue", "suffix": ""}, {"first": "Y", "middle": [], "last": "Shi", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.04655"]}}, "BIBREF48": {"ref_id": "b48", "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 CASES From Chest Radiography Images", "authors": [{"first": "L", "middle": [], "last": "Wang", "suffix": ""}, {"first": "A", "middle": [], "last": "Wong", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.09871"]}}}, "ref_entries": {"FIGREF0": {"text": "Eye retina states in the context of DR: a Normal-b Mild NPDR-c Moderate NPDRd Severe NPDR-e Prolific DR-f Macular edema", "latex": null, "type": "figure"}, "FIGREF1": {"text": "The stages in detail for the diagnosis of the diabetic retinopathy", "latex": null, "type": "figure"}, "FIGREF2": {"text": "A typical structure of the capsule network (CapsNet)[25]", "latex": null, "type": "figure"}, "FIGREF3": {"text": "The images after the image processing steps", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Original images and improved images", "latex": null, "type": "figure"}, "TABREF0": {"text": "", "latex": null, "type": "table"}, "TABREF1": {"text": "Table 9.1 The lowest, the average and the highest values of performance metrics", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Criteria </td><td>Lowest </td><td>Average </td><td>Highest\n</td></tr><tr><td>Accuracy </td><td>0.9225 </td><td>0.9484 </td><td>0.9650\n</td></tr><tr><td>Sensitivity </td><td>0.8150 </td><td>0.8468 </td><td>0.8800\n</td></tr><tr><td>Specificity </td><td>0.9650 </td><td>0.9823 </td><td>0.9833\n</td></tr><tr><td>Precision </td><td>0.8950 </td><td>0.8468 </td><td>0.8800\n</td></tr><tr><td>Recall </td><td>0.8150 </td><td>0.8468 </td><td>0.8800\n</td></tr><tr><td>F-score </td><td>0.8150 </td><td>0.8468 </td><td>0.8800\n</td></tr><tr><td>gmean </td><td>0.8143 </td><td>0.8287 </td><td>0.8406\n</td></tr></table></body></html>"}}, "back_matter": []}