{
    "paper_id": "43ca3820329e8ba4cd46c247de65e0ad717d11f4",
    "metadata": {
        "title": "Spark NLP: Natural Language Understanding at Scale",
        "authors": [
            {
                "first": "Veysel",
                "middle": [],
                "last": "Kocaman",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "John Snow Labs Inc. 16192 Coastal Highway Lewes",
                    "location": {
                        "postCode": "19958",
                        "region": "DE",
                        "country": "USA"
                    }
                },
                "email": "veysel@johnsnowlabs.com"
            },
            {
                "first": "David",
                "middle": [],
                "last": "Talby",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "John Snow Labs Inc. 16192 Coastal Highway Lewes",
                    "location": {
                        "postCode": "19958",
                        "region": "DE",
                        "country": "USA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Spark NLP is a Natural Language Processing (NLP) library built on top of Apache Spark ML. It provides simple, performant & accurate NLP annotations for machine learning pipelines that can scale easily in a distributed environment. Spark NLP comes with 1100+ pretrained pipelines and models in more than 192+ languages. It supports nearly all the NLP tasks and modules that can be used seamlessly in a cluster. Downloaded more than 2.7 million times and experiencing 9x growth since January 2020, Spark NLP is used by 54% of healthcare organizations as the world's most widely used NLP library in the enterprise.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Natural language processing (NLP) is a key component in many data science systems that must understand or reason about a text. Common use cases include question answering, paraphrasing or summarising, sentiment analysis, natural language BI, language modelling, and disambiguation. Nevertheless, NLP is always just a part of a bigger data processing pipeline and due to the nontrivial steps involved in this process, there is a growing need for all-in-one solution to ease the burden of text preprocessing at large scale and connecting the dots between various steps of solving a data science problem with NLP. A good NLP library should be able to correctly transform the free text into structured features and let the users train their own NLP models that are easily fed into the downstream machine learning (ML) or deep learning (DL) pipelines with no hassle.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Spark NLP Library"
        },
        {
            "text": "Spark NLP is developed to be a single unified solution for all the NLP tasks and is the only library that can scale up for training and inference in any Spark cluster, take advantage of transfer learning and implementing the latest and greatest algorithms and models in NLP research, and deliver a mission-critical, enterprisegrade solutions at the same time. It is an open-source natural language processing library, built on top of Apache Spark and Spark ML. It provides an easy API to integrate with ML pipelines and it is commercially supported by John Snow Labs Inc, an award-winning healthcare AI and NLP company based in USA.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Spark NLP Library"
        },
        {
            "text": "Spark NLP's annotators utilize rule-based algorithms, machine learning and deep learning models which are implemented using TensorFlow that has been heavily optimized for accuracy, speed, scalability, and memory utilization. This setup has been tightly integrated with Apache Spark to let the driver node run the entire training using all the available cores on the driver node. There is a CuDA version of each TensorFlow component to enable training models on GPU when available. The Spark NLP is written in Scala and provides open-source API's in Python, Java, Scala, and R -so that users do not need to be aware of the underlying implementation details (TensorFlow, Spark, etc.) in order to use it. Since it has an active release cycle (released 26 new versions in 2019 and another 26 in 2020), the latest trends and research in NLP field are embraced and implemented rapidly in a way that could scale well in a cluster setting to allow common NLP pipelines run orders of magnitude faster than what the inherent design limitations of legacy libraries allowed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Spark NLP Library"
        },
        {
            "text": "Spark NLP library has two versions: Open source and enterprise. Open source version has all the features and components that could be expected from any NLP library, using the latest DL frameworks and research trends. Enterprise library is licensed (free for academic purposes) and designed towards solving real world problems in healthcare domain and extends the open source version. The licensed version has the following modules to help researchers and data practitioners in various means: Named entity recognition (NER), assertion status (negativity scope) detection, relation extraction, entity resolution (SNOMED, RxNorm, ICD10 etc.), clinical spell checking, contextual parser, text2SQL, deidentification and obfuscation. High level overview of the components from each version can be seen at ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Spark NLP Library"
        },
        {
            "text": "The COVID-19 pandemic brought a surge of academic research about the virus -resulting in 23,634 new publications between January and June of 2020 [1] and accelerating to 8,800 additions per week from June to November on the COVID-19 Open Research Dataset [2] . Such a high volume of publications makes it impossible for researchers to read each publication, resulting in increased interest in applying natural language processing (NLP) and text mining techniques to enable semi-automated literature review [3] .",
            "cite_spans": [
                {
                    "start": 146,
                    "end": 149,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 255,
                    "end": 258,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 506,
                    "end": 509,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "The impact to research fields"
        },
        {
            "text": "In parallel, there is a growing need for automated text mining of Electronic health records (EHRs) in order to find clinical indications that new research points to. EHRs are the primary source of information for clinicians tracking the care of their patients. Information fed into these systems may be found in structured fields for which values are inputted electronically (e.g. laboratory test orders or results) [4] but most of the time information in these records is unstructured making it largely inaccessible for statistical analysis [5] . These records include information such as the reason for administering drugs, previous disorders of the patient or the outcome of past treatments, and they are the largest source of empirical data in biomedical research, allowing for major scientific findings in highly relevant disorders such as cancer and Alzheimer's disease [6] . Despite the growing interest and ground breaking advances in NLP research and NER systems, easy to use production ready models and tools are scarce in biomedical and clinical domain and it is one of the major obstacles for clinical NLP researchers to implement the latest algorithms into their workflow and start using immediately. On the other hand, NLP tool kits specialized for processing biomedical and clinical text, such as MetaMap [7] and cTAKES [8] typically do not make use of new research innovations such as word representations or neural networks discussed above, hence producing less accurate results [9, 10]. We introduce Spark NLP as the one-stop solution to address all these issues.",
            "cite_spans": [
                {
                    "start": 416,
                    "end": 419,
                    "text": "[4]",
                    "ref_id": null
                },
                {
                    "start": 542,
                    "end": 545,
                    "text": "[5]",
                    "ref_id": null
                },
                {
                    "start": 876,
                    "end": 879,
                    "text": "[6]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "The impact to research fields"
        },
        {
            "text": "A primary building block in such text mining systems is named entity recognition (NER) -which is regarded as a critical precursor for question answering, topic modelling, information retrieval, etc [11] . In the medical domain, NER recognizes the first meaningful chunks out of a clinical note, which are then fed down the processing pipeline as an input to subsequent downstream tasks such as clinical assertion status detection [12] , clinical entity resolution [13] and de-identification of sensitive data [14] . However, segmentation of clinical and drug entities is considered to be a difficult task in biomedical NER systems because of complex orthographic structures of named entities [15] . Sample NER predictions from a clinical text can be found at Figure 3 .",
            "cite_spans": [
                {
                    "start": 198,
                    "end": 202,
                    "text": "[11]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 430,
                    "end": 434,
                    "text": "[12]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 464,
                    "end": 468,
                    "text": "[13]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 509,
                    "end": 513,
                    "text": "[14]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 692,
                    "end": 696,
                    "text": "[15]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [
                {
                    "start": 759,
                    "end": 767,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "The impact to research fields"
        },
        {
            "text": "The next step following an NER model in the clinical NLP pipeline is to assign an assertion status to each named entity given its context. The status of an assertion explains how a named entity (e.g. clinical finding, procedure, lab result) pertains to the patient by assigning a label such as present (\"patient is diabetic\"), absent (\"patient denies nausea\"), conditional (\"dyspnea while climbing stairs\"), or associated with someone else (\"family history of depression\"). In the context of COVID-19, applying an accurate assertion status detection is crucial, since most patients will be tested for and asked about the same set of symptoms and comorbidities -so limiting a text mining pipeline to recognizing medical terms without context is not useful in practice. The flow diagram of such a pipeline can be seen in Figure 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 819,
                    "end": 827,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "The impact to research fields"
        },
        {
            "text": "In our previous study [16] , we showed through extensive experiments that NER module in Spark NLP library exceeds the biomedical NER benchmarks reported by Stanza in 7 out of 8 benchmark datasets and in every dataset reported by SciSpacy without using heavy contextual embeddings like BERT. Using the modified version of the well known BiLSTM-CNN-Char NER architecture [17] into Spark environment, we also presented that even with a general purpose GloVe embeddings (GloVe6B) and with no lexical features, we were able to achieve stateof-the-art results in biomedical domain and produces better results than Stanza in 4 out of 8 benchmark datasets.",
            "cite_spans": [
                {
                    "start": 22,
                    "end": 26,
                    "text": "[16]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 369,
                    "end": 373,
                    "text": "[17]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "The impact to research fields"
        },
        {
            "text": "In another study [18] , we introduced a set of pre-trained NER models that are all trained on biomedical and clinical datasets using the same deep learning architecture. We then illustrated how to extract knowledge and relevant information from unstructured electronic health records (EHR) and COVID-19 Open Research Dataset (CORD-19) by combining these models in a unified & scalable pipeline and shared the results to illustrate extracting valuable information from scientific papers. The results suggest that papers present in the CORD-19 include a wide variety of the many entity types that this new NLP pipeline can recognize, and that assertion status detection is a useful filter on these entities (Figure 2 ). The most frequent phrases from the selected entity types can be found at Table 2 . This bodes well for the richness of downstream analysis that can be done using this now structured and normalized data -such as clustering, dimensionality reduction, semantic similarity, visualization, or graph-based analysis to identity correlated concepts. Moreover, in order to evaluate how fast the pipeline works and how effectively it scales to make use of a compute cluster, we ran the same Spark NLP prediction pipelines in local mode and in cluster mode: and found out that tokenization is 20x faster while the entity extraction is 3.5x faster on the cluster, compared to the single machine run.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 21,
                    "text": "[18]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 705,
                    "end": 714,
                    "text": "(Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 791,
                    "end": 798,
                    "text": "Table 2",
                    "ref_id": null
                }
            ],
            "section": "The impact to research fields"
        },
        {
            "text": "As the creator of Spark NLP, John Snow Labs company has been supporting the researchers around the globe by distributing them a free license to use all the licensed modules both in research projects and graduate level courses at universities, providing hands-on supports when needed, organizing workshops and summits to gather distinguished speakers and running projects with the R&D teams of the top pharmacy companies to help them unlock the potential of unstructured text data buried in their ecosystem. Spark NLP already powers leading healthcare and pharmaceutical companies including Kaiser Permanente, McKesson, Merck, and Roche. Since Spark NLP can also be used offline and deployed in air-gapped networks, the companies and healthcare facilities do not need to worry about exposing the protected health information (PHI). The detailed information about these projects and case studies can be found at [19] , [20] , [21] . Figure 1 : The flow diagram of a Spark NLP pipeline. When we fit() on the pipeline with a Spark data frame, its text column is fed into the DocumentAssembler() transformer and a new column document is created as an initial entry point to Spark NLP for any Spark data frame. Then, its document column is fed into the SentenceDetector() module to split the text into an array of sentences and a new column \"sentences\" is created. Then, the \"sentences\" column is fed into Tokenizer(), each sentence is tokenized, and a new column \"token\" is created. Then, Tokens are normalized (basic text cleaning) and word embeddings are generated for each. Now data is ready to be fed into NER models and then to the assertion model. , SciSpaCy results are from the scispacy-medium models reported in [10] . The official training and validation sets are merged and used for training and then the models are evaluated on the original test sets. For reproducibility purposes, we use the preprocessed versions of these datasets provided by [22] and also used by Stanza. Spark-x prefix in the table indicates our implementation. Bold scores represent the best scores in the respective row. ",
            "cite_spans": [
                {
                    "start": 910,
                    "end": 914,
                    "text": "[19]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 917,
                    "end": 921,
                    "text": "[20]",
                    "ref_id": null
                },
                {
                    "start": 924,
                    "end": 928,
                    "text": "[21]",
                    "ref_id": null
                },
                {
                    "start": 1716,
                    "end": 1720,
                    "text": "[10]",
                    "ref_id": null
                },
                {
                    "start": 1952,
                    "end": 1956,
                    "text": "[22]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [
                {
                    "start": 931,
                    "end": 939,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "The impact to industrial and academic collaborations"
        },
        {
            "text": "We thank our colleagues and research partners who contributed in the former and current developments of Spark NLP library. We also thank our users and customers who helped us improve the library with their feedbacks and suggestions. [9] Y. Zhang, Y. Zhang, P. Qi, C. D. Manning, C. P. Langlotz, Biomedical Table 2 : The most frequent 10 terms from the selected entity types predicted through parsing 100 articles from CORD-19 dataset [2] with an NER model named jsl_ner_wip in Spark NLP. Getting predictions from the model, we can get some valuable information regarding the most frequent disorders or symptoms mentioned in the papers or the most common vital and EKG findings without reading the paper. According to this table, the most common symptom is cough and inflammation while the most common drug ingredients mentioned is oseltamivir and antibiotics. We can also say that cardiogenic oscillations and ventricular fibrillation are the common observations from EKGs while fever and hyphothermia are the most common vital signs. ",
            "cite_spans": [
                {
                    "start": 434,
                    "end": 437,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 306,
                    "end": 313,
                    "text": "Table 2",
                    "ref_id": null
                }
            ],
            "section": "Acknowledgements"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Publishing volumes in major databases related to covid-19",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A T"
                    ],
                    "last": "Silva",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Tsigaris",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Erfanmanesh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Scientometrics",
            "volume": "",
            "issn": "",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Cord-19: The covid-19 open research dataset",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "L"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chandrasekhar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Reas",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Eide",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Funk",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kinney",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Merrill",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "An overview of literature on covid-19, mers and sars: Using text mining and latent dirichlet allocation",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Journal of Information Science",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "A survey on recent advances in named entity recognition from deep learning models",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Yadav",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bethard",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1910.11470"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "i2b2/va challenge on concepts, assertions, and relations in clinical text",
            "authors": [
                {
                    "first": "\u00d6",
                    "middle": [],
                    "last": "Uzuner",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "R"
                    ],
                    "last": "South",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Duvall",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "18",
            "issn": "5",
            "pages": "552--556",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "International classification of diseases 10th edition (icd-10):: main article",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tzitzivacos",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "25",
            "issn": "",
            "pages": "8--10",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Evaluating the state-of-the-art in automatic de-identification",
            "authors": [
                {
                    "first": "\u00d6",
                    "middle": [],
                    "last": "Uzuner",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Szolovits",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "14",
            "issn": "5",
            "pages": "550--563",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Effects of semantic features on machine learning-based drug name recognition systems: word embeddings vs. manually constructed dictionaries",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Information",
            "volume": "6",
            "issn": "4",
            "pages": "848--865",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Biomedical named entity recognition at scale",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kocaman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Talby",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2011.06315"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Named entity recognition with bidirectional lstmcnns",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Chiu",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Nichols",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Transactions of the Association for Computational Linguistics",
            "volume": "4",
            "issn": "",
            "pages": "357--370",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Improving clinical document understanding on covid-19 research with spark nlp",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kocaman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Talby",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2012.04005"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Lessons Learned Building Real-World Healthcare AI Systems",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Labs",
                    "suffix": ""
                },
                {
                    "first": "Apache",
                    "middle": [],
                    "last": "Spark",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "For Healthcare",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Cross-type biomedical named entity recognition with deep multi-task learning",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zitnik",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Bioinformatics",
            "volume": "35",
            "issn": "10",
            "pages": "1745--1752",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Named Entity Recognition is a fundamental building block of medical text mining pipelines, and feeds downstream tasks such as assertion status, entity linking, de-identification, and relation extraction.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Sample clinical entities predicted by a clinical NER model trained on various datasets. There are more than 40 pretrained NER models in Spark NLP Enterprise edition.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Spark NLP library has two versions (open source and enterprise) and each comes with a set of pretrained models and pipelines that could be used out of the box with no further training or dataset.idation of international classification of diseases coding for bone metastases in electronic health records using technology-enabled abstraction, Clinical epidemiology 7 (2015) 441.[5] T. B. Murdoch, A. S. Detsky, The inevitable application of big data to health care, Jama 309 (13) (2013) 1351-1352.[6] G. Perera, M. Khondoker, M. Broadbent, G. Breen, R. Stewart, Factors associated with response to acetylcholinesterase inhibition in dementia: a cohort study from a secondary mental health care case register in london, PloS one 9 (11) (2014) e109484.[7] A. R. Aronson, F.-M. Lang, An overview of metamap: historical perspective and recent advances, Journal of the American Medical Informatics Association 17 (3) (2010) 229-236. [8] G. K. Savova, J. J. Masanz, P. V. Ogren, J. Zheng, S. Sohn, K. C. Kipper-Schuler, C. G. Chute, Mayo clinical text analysis and knowledge extraction system (ctakes): architecture, component evaluation and applications, Journal of the American Medical Informatics Association 17 (5) (2010) 507-513.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "NER performance across different datasets in the biomedical domain. All scores reported are micro-averaged test F1 excluding O's. Stanza results are from the paper reported in [9]",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "and clinical english model packages in the stanza python nlp library, arXiv preprint arXiv:2007.14640.[10] M. Neumann, D. King, I. Beltagy, W. Ammar, Scispacy: Fast and robust models for biomedical natural language processing, arXiv preprint arXiv:1902.07669.Nr. Code metadata description Please fill in this column C1 Current code version v2.7.1 C2 Permanent link to code/repository used for this code version https://github.com/JohnSnowLabs/sparknlp C3 Permanent link to Reproducible Capsule https://github.com/JohnSnowLabs/spark-C8 If available Link to developer documentation/manual https://nlp.johnsnowlabs.com/api/ C9 Support email for questions info@johnsnowlabs.com",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Code metadata (mandatory) Nr. (Executable) software metadata description Please fill in this column S2 Permanent link to executables of this version https://github.com/JohnSnowLabs/sparknl S3 Permanent link to Reproducible Capsule https://github.com/JohnSnowLabs/sparknlp-workshop S4 Legal Software License Apache-2.0 License S5 Computing platforms/Operating Systems Linux, Ubuntu, OSX, Microsoft Windows, Unix-like S6 Installation requirements & dependencies jdk 8, spark S7 If available, link to user manual -if formally published include a reference to the publication in the reference list https://nlp.johnsnowlabs.com/api/ S8 Support email for questions info@johnsnowlabs.com",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}