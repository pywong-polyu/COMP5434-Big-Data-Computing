{
    "paper_id": "acbe65e5d64c3fc15c0a79302e7ba2bc43715da7",
    "metadata": {
        "title": "Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier",
        "authors": [
            {
                "first": "Bejoy",
                "middle": [
                    "Abraham"
                ],
                "last": "Q1",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Madhu",
                "middle": [
                    "S"
                ],
                "last": "Nair",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Artificial Intelligence & Computer Vision Lab",
                    "institution": "Cochin University of Science and Technology",
                    "location": {
                        "postCode": "682022",
                        "settlement": "Kochi",
                        "region": "Kerala",
                        "country": "India"
                    }
                },
                "email": "madhu_s_nair2001@yahoo.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "Keywords: COVID-19 X-ray CNN Bayesnet Multi-CNN a b s t r a c t Corona virus disease-2019 (COVID-19) is a pandemic caused by novel coronavirus. COVID-19",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "is spreading rapidly throughout the world. The gold standard for diagnosing COVID-19 is reverse transcription-polymerase chain reaction (RT-PCR) test. However, the facility for RT-PCR test is limited, which causes early diagnosis of the disease difficult. Easily available modalities like X-ray can be used to detect specific symptoms associated with COVID-19. Pre-trained convolutional neural networks are widely used for computer-aided detection of diseases from smaller datasets. This paper investigates the effectiveness of multi-CNN, a combination of several pre-trained CNNs, for the automated detection of COVID-19 from Xray images. The method uses a combination of features extracted from multi-CNN with correlation based feature selection (CFS) technique and Bayesnet classifier for the prediction of COVID-19. The method was tested using two public datasets and achieved promising results on both the datasets. In the first dataset consisting of 453 COVID-19 images and 497 non-COVID images, the method achieved an AUC of 0.963 and an accuracy of 91.16%. In the second dataset consisting of 71 COVID-19 images and 7 non-COVID images, the method achieved an AUC of 0.911 and an accuracy of 97.44%. The experiments performed in this study proved the effectiveness of pre-trained multi-CNN over single CNN in the detection of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Coronavirus disease 2019 (COVID-19) is a kind of viral pneumonia which is caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It is one among the three respiratory disease outbreak caused by the coronavirus, other two being severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS). As on 7th of May 2020, more than 3.5 million cases of COVID-19 and 250,000 deaths due to the disease have been reported by the World Health Organization (WHO) [1] . WHO has listed COVID-19 as a Public Health Emergency of International Concern (PHEIC) [2] . There is an urgent need for early diagnosis of the disease to prevent further spreading and control the death toll. The gold standard for diagnosing COVID-19 is reverse transcription-polymerase chain reaction (RT-PCR) test [2, 3] . However, the RT-PCR testing facility is inadequate in most of the areas hit by the COVID-19 outbreak [3] . COVID-19 is characterized by a lung infection in the post of the patients [4] . Easily available modalities like Xray and CT can be used for detecting lung infections [4] . It is proven that X-ray and computed tomography (CT) scan can be used effectively for the diagnosis of COVID-19 [5] . However, manual reading of X-ray and CT scan of a large number of patients could be time-consuming. A computeraided diagnosis method could assist the radiologists in predicting COVID-19 from X-ray and CT-scan images [3] . Convolutional neural network (CNN) has shown promising results in the area of computer-aided detection and diagnosis of various diseases. CNN requires a large amount of data for training from scratch. In the case of medical images, it is difficult to obtain a huge number of labelled images. In such cases pre-trained CNNs trained on a large number of natural images like ImageNet can be used [6] . Pre-trained CNNs were earlier used successfully in diagnosis of prostate cancer [7, 8] , breast cancer [9] , brain diseases [10] , leukemia [11] , etc. to name a few. Pre-trained CNN is also found successful in predicting COVID-19 [12] [13] [14] . This paper presents a method for the prediction of COVID-19 using features extracted from multiple pre-trained networks.",
            "cite_spans": [
                {
                    "start": 489,
                    "end": 492,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 581,
                    "end": 584,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 810,
                    "end": 813,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 814,
                    "end": 816,
                    "text": "3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 920,
                    "end": 923,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1000,
                    "end": 1003,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1093,
                    "end": 1096,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1211,
                    "end": 1214,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1433,
                    "end": 1436,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1832,
                    "end": 1835,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1918,
                    "end": 1921,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1922,
                    "end": 1924,
                    "text": "8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1941,
                    "end": 1944,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1962,
                    "end": 1966,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1978,
                    "end": 1982,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 2069,
                    "end": 2073,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 2074,
                    "end": 2078,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 2079,
                    "end": 2083,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The paper is organized as follows. Section 1.1 discusses the related works in the area of computer-aided detection of COVID-19. Section 1.2 describes the contributions of the proposed method. Section 2 describes the proposed multi-CNN, feature selection technique and classifier. Section 3 discusses the results achieved using various combinations of multi-CNN. The section also analyzes the results achieved using various classifiers in comparison with the proposed classifier. Section 4 explains the conclusions reached based on the experimental analysis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Recently, a number of papers were published in the area of computer-aided detection of COVID-19 using pre-trained CNNs from X-ray and CT images. Shi et al. [3] performed a detailed review of the state-of-the-art computer-aided techniques for the detection of COVID-19 from X-ray and CT scans. Narin et al. [12] The above-mentioned methods use X-ray images for the computer-aided detection of COVID-19. Few recent works also prove the effectiveness of CT scans in the detection of COVID-19. He et al. [18] performed transfer learning on a CT dataset, containing 349 COVID-19 CT scans and 397 normal CT scans. The method proposed a novel transfer learning technology called self-trans that learns features that are robust to overfitting. Mei et al. [19] used two CNN models (one for slice selection and another one for diagnosis) in combination with clinical data to predict COVID-19 using CT scans. Shan et al. [20] proposed a deep learning based scheme that uses 'VB-Net', a modification of V-Net architecture for the segmentation of COVID-19 affected areas in chest CT scans. The method used CT scans of 249 subjects for training and 300 subjects for validation. Chen et al. [21] proposed a Residual Attention U-Net for the segmentation of COVID-19 affected areas in CT scans. The dataset used for the method contains 110 CT images. Chen et al. [22] further proposed a contrastive learning technique to train an encoder for the detection of COVID-19 from CT scans. Fan et al. [23] proposed a model that employs implicit reverse attention and explicit edge-attention for the segmentation of COVID-19 infected areas in CT scans.",
            "cite_spans": [
                {
                    "start": 156,
                    "end": 159,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 306,
                    "end": 310,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 500,
                    "end": 504,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 747,
                    "end": 751,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 910,
                    "end": 914,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1176,
                    "end": 1180,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1346,
                    "end": 1350,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1477,
                    "end": 1481,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Related works"
        },
        {
            "text": "In this work, we have chosen to use X-ray for COVID-19 detection as X-ray is cost-effective compared to CT scans.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related works"
        },
        {
            "text": "Contribution of the proposed method",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2."
        },
        {
            "text": "The aforementioned methods have used a single pre-trained CNN to predict COVID-19 from a balanced dataset. The discriminatory features extracted from each pre-trained network will be different. Combination of features extracted from pre-trained CNN is expected to improve the performance of computer-aided diagnosis systems. The proposed method explores a combination of features from multiple CNNs for the diagnosis of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2."
        },
        {
            "text": "The proposed method has the following contributions. iii. Most of the existing works have used a small dataset whereas the proposed method used a relatively large number of COVID-19 cases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "1.2."
        },
        {
            "text": "The method was implemented using two COVID-19 public datasets. The first dataset created by Cohen et al. [24] consists of 560 chest X-ray images. The 560 chest X-ray images were composed of 453 COVID-19 and 107 non-COVID images. 107 non-COVID images consists of either bacterial pneumonia or viral pneumonia. Images with no findings were excluded. 390 chest X-ray images of viral and bacterial pneumonia taken from a Kaggle dataset [25, 26] were added to the 107 non-COVID images to make the dataset a balanced one. The combined dataset (DATASET-1) consists of 950 images of which 453 are COVID-19 and 497 are non-COVID. The second dataset consisting of 71 COVID-19 and 7 non-COVID chest X-ray images was taken from Kaggle [27] . The sub classification of non-COVID images are not available. For performing experimental analysis Dataset-1 was used due to its larger size. To confirm robustness of the method, the results of both Dataset-1 and Dataset-2 are considered. Fig. 1 show sample COVID-19 X-ray images.",
            "cite_spans": [
                {
                    "start": 105,
                    "end": 109,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 432,
                    "end": 436,
                    "text": "[25,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 437,
                    "end": 440,
                    "text": "26]",
                    "ref_id": null
                },
                {
                    "start": 723,
                    "end": 727,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 969,
                    "end": 975,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Dataset"
        },
        {
            "text": "The multi-CNN architecture used in the proposed method consists of a set of pre-trained CNN. Each CNN used in the method was pre-trained using Imagenet [28] which has more than a million natural images belonging to 1000 different classes. Different combinations of pre-trained CNNs are used for feature extraction. CNN consists of three basic layers: convolution, pooling and fully connected layers [29] . Convolution layers perform feature extraction by convolving the input image with a set of learned kernels. The layer typically consists of a combination of convolution operation and activation function. The convolution operation between an image I of dimension p \u00c2 q and a kernel W of size x \u00c2 y that produces a feature map s is defined by the following dot product:",
            "cite_spans": [
                {
                    "start": 152,
                    "end": 156,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 399,
                    "end": 403,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "The output of the convolution layer is then passed through a non-linear activation function. The most common nonlinear activation function used is the rectified linear unit (ReLU) and its variant Leaky ReLu. ReLu is represented as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "where s ij kn is the input at location (i, j) on the nth feature map at kth layer. Leaky ReLu is represented as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "where s ij kn is the input at location (i, j) on the nth feature map at kth layer and b is the slope of negative linear function [30] .",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 133,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "The pooling layer is used to reduce the spatial resolution of the activation map and thereby reducing the number of parameters. Pooling helps to decrease the computational cost Fig. 1 -The four X-ray images in first row corresponds to COVID-19 and the images in second row corresponds to non-COVID. b i o c y b e r n e t i c s a n d b i o m e d i c a l e n g i n e e r i n g x x x ( 2 0 1 9 ) x x x -x x x and over-fitting. Max-pooling and average pooling are the most common methods of pooling.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 177,
                    "end": 183,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Feature extraction"
        },
        {
            "text": "Every neuron in the previous layer are connected to a fully connected (FC) layer. Features generated by the previous layer are flattened in a feature vector by the FC layer. It then performs weight updates to improve the predicting ability of feature vector.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "Densenet201 [31] , InceptionResnetV2 [32] , Shufflenet [33] , Resnet-101 [34] , Darknet-53 [35] , MobilenetV2 [36] , NasnetLarge [37] , Xception [38] , VGG-19 [39] and Squeezenet [40] are the pretrained networks used for experimental analysis in this work. The input X-ray images used in this study are of different formats. The dimension of input images also varies. The input size of Densenet-201, Shufflenet, MobilenetV2, VGG-19 and Resnet-101 are 224 \u00c2 224 whereas that of InceptionResnetV2 and Xception are 299 \u00c2 299. The input size of Nasnetlarge, Darknet-53 and Squeezenet are 331 \u00c2 331, 256 \u00c2 256 and 227 \u00c2 227, respectively. The size of the X-ray images present in the datasets vary. Before passing the images to the pretrained networks a preprocessing is done to make the size of images uniform and also to replicate the colour channels of the grayscale images in the dataset. The images are scaled using bilinear interpolation to make them compatible with input size of the pre-trained network. Features are extracted from the last fully connected layer of the pre-trained CNNs with 1000 neurons. Each pre-trained CNN produces a feature matrix of size n \u00c2 1000, where n is the number of X-ray images. The feature matrices of the muti-CNN are combined together to form a feature matrix of dimension n \u00c2 1000m, where m is the number of pre-trained networks used in the multi-CNN. The best performing multi-CNN of this study used 5 pre-trained CNNs (Squeezenet, Darknet-53, MobilenetV2, Xception, Shufflenet) to produce a feature matrix of dimension 950 \u00c2 5000.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 16,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 37,
                    "end": 41,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 55,
                    "end": 59,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 73,
                    "end": 77,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 91,
                    "end": 95,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 110,
                    "end": 114,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 129,
                    "end": 133,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 145,
                    "end": 149,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 159,
                    "end": 163,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 179,
                    "end": 183,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "Sample activations using last convolutional layer of Squeezenet, Darknet-53, MobilenetV2, Xception and Shufflenet is shown in Fig. 2. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 126,
                    "end": 133,
                    "text": "Fig. 2.",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Feature extraction"
        },
        {
            "text": "Feature matrix of size n \u00c2 1000m is passed to a feature selection unit for selecting the most distinguishing features. A correlation-based feature selection (CFS) algorithm [41] in combination with subset size forward selection (SSFS), a linear forward selection based search technique [42] was utilized to determine the optimal feature subset. CFS evaluates the merit of a subset of features by considering the individual predictive ability of each attribute along with the degree of redundancy among them. Merit of a subset of features is given by where n is the number of features present in the subset, r fc is the mean feature correlation and r ic is the average value of feature intercorrelation. The numerator of the equation represents ability of a set of features in predicting a class whereas the denominator indicates redundancy among them. After computing the merit of subset of features, SSFS based search is performed. SSFS performs an interior cross-validation to determine the effectiveness of feature subsets. A linear forward selection (LFS) is performed on each fold. To estimate the optimal subset size, scores achieved on the test data for each subset size are averaged and subset size with highest average is chosen. Search terminates at the optimal subset size. Finally, a linear forward selection up to the optimal size of subset is conducted on the whole data. CFS in combination with SSFS reduces the dimensionality of features from n \u00c2 1000m to n \u00c2 p, where p is the reduced number of features. The algorithm reduced the dimension of feature vector corresponding to the best performing multi-CNN of this study from 950 \u00c2 5000 to 950 \u00c2 45.",
            "cite_spans": [
                {
                    "start": 173,
                    "end": 177,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 286,
                    "end": 290,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Feature selection"
        },
        {
            "text": "Consider a set of variables, V = m 1 , . . ., m n , where n \u2265 1. A Bayesian network G over a set of variables V represents a network structure G S , and a set of probability tables G P [43] . G S is a directed acyclic graph (DAG) over V.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 189,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "BayesNet classifier"
        },
        {
            "text": "where pa\u00f0\u00de is the set of parents of in G S . A Bayesian network indicates the following probability distribution [43] .",
            "cite_spans": [
                {
                    "start": 113,
                    "end": 117,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "BayesNet classifier"
        },
        {
            "text": "Let m = m 1 , m 2 , m 3 , . . ., m n be a set of attribute variables. A classifier q : m ! c is a function that maps an instance of m to a class c. For using Bayesian network as a classifier, argmax c P(c|m) is computed using the distribution P(V) [43] .",
            "cite_spans": [
                {
                    "start": 248,
                    "end": 252,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                }
            ],
            "ref_spans": [],
            "section": "BayesNet classifier"
        },
        {
            "text": "The feature matrix of dimension n \u00c2 p is passed to a Bayesnet classifier which classifies the images into COVID-19 and non-COVID categories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "BayesNet classifier"
        },
        {
            "text": "Architecture of the proposed method is shown in Fig. 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 48,
                    "end": 54,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "BayesNet classifier"
        },
        {
            "text": "The experiments were performed using a core i7, GTX 1060 6GB GPU. Feature extraction was performed using MATLAB 2020a and classification using Weka 3.6. Area under the receiver operating characteristic curve (AUC) along with accuracy are used as the major performance metrics. Precision, recall and Fmeasure in predicting COVID-19 class are used as the auxilliary performance measures.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental setup"
        },
        {
            "text": "A ten-fold cross-validation was performed on both the datasets. The results achieved are shown in Table 1 . Confusion matrices corresponding to the results are given in Fig. 4 . ROC curves corresponding to results are shown in Fig. 5 . The method achieved considerable performance in both the datasets. 446 among the 453 instances of COVID-19 cases were classified correctly in Dataset-1, achieving a recall of 98.5%. One except all among the 71 COVID-19 cases were predicted correctly in Dataset-2 achieving a recall of 98.6%. The recall obtained in predicting non-COVID cases were 84.5% and 85.7% respectively, in Dataset-1 and Dataset-2. The method achieved a precision of ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 98,
                    "end": 105,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 169,
                    "end": 175,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 227,
                    "end": 233,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Classification results"
        },
        {
            "text": "Default parameter settings were used for all the pre-trained networks used for creating multi-CNN. Tables 2 and 3 displays the parameter settings of the feature selection method and Bayesnet classifier in WEKA. The algorithm used to determine the subset size was set to sequential minimal optimization (SMO). The number of crossvalidation folds used for subset size determination was set to 5. The algorithm for determining the conditional probability tables of the Bayes network was set to simple estimator algorithm. Parameter alpha used for determining the conditional probability tables of the Bayes network was set to 0.3. The search algorithm for searching the network structures was set to hill-climbing algorithm, K2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Parameter setting"
        },
        {
            "text": "Selection of search algorithm associated with feature selection technique Three algorithms, SSFS, best first and greedy stepwise were compared to select the best performing one. Best first and greedy stepwise algorithms achieved the same results in combination with CFS. Best performing algorithm among the three was SSFS. Even though SSFS achieved a slightly lower recall compared to other algorithms, it achieved better precision, F-measure, AUC and accuracy than the other two algorithms. The results achieved using the three algorithms are displayed in Table 4 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 557,
                    "end": 564,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "3.4."
        },
        {
            "text": "Comparison of the proposed pre-trained multi-CNN with single pre-trained CNN Experiments were conducted on features extracted using different combinations of pre-trained networks. The results of various combinations of pre-trained CNNs are shown in Table 5 . The experiments show that combinations of multiple pretrained CNNs outperform that of single CNN. Among the combinations of pre-trained CNNs we experimented with, two multi-CNNs composed of 5 pre-trained networks and three multi-CNN composed of 4 pre-trained networks achieved an AUC above 95% and accuracy above 90%. A multi-CNN which uses a combination of features extracted from 5 different pretrained networks (Squeezenet, Darknet-53, MobilenetV2, Xception, Shufflenet) achieved the best performance. The multi-CNN achieved an AUC of 96.3% and accuracy of 91.1579%. Results achieved using single pre-trained CNNs were less compared to most of the multi CNNs composed of 3 or more pre-trained CNNs. All single pre-trained networks could achieve an AUC of less than 95% and accuracy less than 90% only. The best performing single CNN was MobilenetV2. Even though Mobile-netV2 achieved an AUC of 94.2%, its accuracy was less than 90% only. The experimental analysis proves the efficiency of pretrained multi-CNN over single pre-trained CNN.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 249,
                    "end": 256,
                    "text": "Table 5",
                    "ref_id": "TABREF5"
                }
            ],
            "section": "3.5."
        },
        {
            "text": "Comparison of results achieved using various classifiers Table 6 displays the results achieved using various classifiers in combination with the best performing multi-CNN composed of 5 pre-trained CNNs. Only Bayesnet achieved an accuracy above 90%. All other classifiers could achieve an accuracy below 90% only. Bayesnet, NaiveBayes, LogisticRegression, Random Forest, ADTree and NBTree achieved an AUC above 90%. SVM and AdaBoostM1 could achieve AUC below 90% only. Bayesnet achieved better precision and Fmeasure than the other classifiers. However, the recall achieved by Bayesnet was slightly lower than that achieved by NaiveBayes, SVM and AdaBoostM1. The experimental analysis proves the efficiency of Bayesnet classifier in combination with multi-CNN and correlation-based feature selection technique for the detection of COVID-19.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 57,
                    "end": 64,
                    "text": "Table 6",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "3.6."
        },
        {
            "text": "Comparison with other state-of-the-art methods",
            "cite_spans": [],
            "ref_spans": [],
            "section": "3.7."
        },
        {
            "text": "Most of the existing methods used a small dataset for classification whereas the proposed method used a relatively large dataset. The method was further tested in a second dataset and achieved promising results in both the datasets. The number of images and validation techniques used by the various state-of-the-art methods are different. Table 7 shows the number of images and validation method used by the various authors. Table 8 displays the results of other major state-of-the-art methods along with the proposed best performing multi-CNN (Squeezenet+Darknet-53+Mobilenet +Xception+Shufflenet). A fair comparison of results is not possible due to the difference in the datasets, performance metrics and the validation techniques. However, it is noteworthy that the proposed method has proven its effectiveness in a relatively large dataset consisting of 453 COVID-19 images. b i o c y b e r n e t i c s a n d b i o m e d i c a l e n g i n e e r i n g x x x ( 2 0 1 9 ) x x x -x x x obtained by partitioning the dataset into 80% training data and 20% test data. Unlike cross-validation, testing on a held-out test dataset does not ensure the robustness of the method.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 340,
                    "end": 347,
                    "text": "Table 7",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 426,
                    "end": 433,
                    "text": "Table 8",
                    "ref_id": "TABREF8"
                }
            ],
            "section": "3.7."
        },
        {
            "text": "Even though the method produced good results in a considerably larger dataset, it has few limitations worth mentioning. The method performs classification between COVID-19 and non-COVID X-ray images only. It is not tested in a multi-class classification scenario where the images can be classified as COVID-19, normal and pneumonic. The method does not perform segmentation of the infected region. The combinations of all multi-CNNs are not explored in the paper. It is left to the readers and other researchers to explore more combinations of pre-trained CNNs for the prediction of COVID-19. Being more of images and validation techniques used by the various state-of-the-art methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Limitations of the proposed method"
        },
        {
            "text": "Multi-CNN 453 COVID-19 vs. 497 non-COVID (Dataset-1) 10-fold CV Multi-CNN 71 COVID-19 vs. 7 non-COVID (Dataset-2) 10-fold CV [17] 231 COVID-19 vs. 500 no-findings 10-fold CV [15] 142 COVID-19 vs. 142 normal 70% data for training and 30% testing [12] 50 COVID-19 vs. 50 normal 5-fold CV [13] 250 COVID-19 vs. 250 non-COVID 10-fold CV [13] Training: 250 COVID-19 vs. 250 non-COVID Testing: 74 COVID-19 vs. 36 non-COVID [44] 100 COVID-19 vs. 1431 non-COVID 2-fold CV [14] 25 COVID-19 vs. 25 non-COVID 80% data for training and 20% testing b i o c y b e r n e t i c s a n d b i o m e d i c a l e n g i n e e r i n g x x x ( 2 0 1 9 ) x x x -x x x economical and easily available modality compared to CT scans, the proposed method focused on COVID-19 detection using Xray images. As a future research direction we propose the use of multi-CNN to extract features from CT scans for the detection of COVID-19 and other lung infections.",
            "cite_spans": [
                {
                    "start": 125,
                    "end": 129,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 174,
                    "end": 178,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 245,
                    "end": 249,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 286,
                    "end": 290,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 333,
                    "end": 337,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 417,
                    "end": 421,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 464,
                    "end": 468,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Method Number of images Validation"
        },
        {
            "text": "In this paper, the effectiveness of pre-trained multi-CNN in predicting COVID-19 from X-ray images is investigated. A combination of features extracted from several pre-trained networks in combination with Correlation-based Feature Selection technique and Bayesnet classifier is employed in the method. The best performing multi-CNN used in this study employs a combination of 5 pre-trained CNNs: Squeezenet, Darknet-53, MobilenetV2, Xception and Shufflenet. Results prove the effectiveness of pre-trained multi-CNN over pretrained single CNNs. Experimental analysis performed using two public datasets show that pre-trained multi-CNN in combination with CFS and Bayesnet is effective in the diagnosis of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "Bejoy Abraham and Madhu S. Nair: Conception and design of study, acquisition of data, analysis and/or interpretation of data, drafting the manuscript, revising the manuscript critically for important intellectual content, approval of the version of the manuscript to be published. -0.96 -0.95 - [14] 0.83 1.00 0.91 --b i o c y b e r n e t i c s a n d b i o m e d i c a l e n g i n e e r i n g x x x ( 2 0 1 9 ) x x x -x x x",
            "cite_spans": [
                {
                    "start": 295,
                    "end": 299,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Author contributions"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "WHO. WHO situation report-108",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Molecular immune pathogenesis and diagnosis of covid-19",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Geng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J Pharm Anal",
            "volume": "10",
            "issn": "",
            "pages": "102--110",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Rev Biomed Eng",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/rbme.2020.2987975"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Radiological findings from 81 patients with covid-19 pneumonia in Wuhan, China: a descriptive study",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Alwalid",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Lancet Infect Dis",
            "volume": "20",
            "issn": "4",
            "pages": "425--459",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Portable chest X-ray in coronavirus disease-19 (covid-19): a pictorial review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jacobi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bernheim",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Eber",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Clin Imaging",
            "volume": "64",
            "issn": "",
            "pages": "35--42",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Computer-aided grading of prostate cancer from MRI images using convolutional neural networks",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Abraham",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Nair",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J Intell Fuzzy Syst",
            "volume": "36",
            "issn": "3",
            "pages": "2015--2039",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Automated grading of prostate cancer using convolutional neural network and ordinal class classifier",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Abraham",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Nair",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Inform Med Unlocked",
            "volume": "17",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Computer-aided diagnosis of clinically significant prostate cancer from MRI images using sparse autoencoder and random forest classifier",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Abraham",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Nair",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Biocybern Biomed Eng",
            "volume": "38",
            "issn": "3",
            "pages": "733--777",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Automated invasive ductal carcinoma detection based using deep transfer learning with whole-slide images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Celik",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Karabatak",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Pattern Recognit Lett",
            "volume": "133",
            "issn": "",
            "pages": "232--241",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Convolutional neural networks for multi-class brain disease detection using MRI images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "B"
                    ],
                    "last": "Baloglu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Aydin",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput Med Imaging Graph",
            "volume": "78",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Label-free leukemia monitoring by computer vision",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Doan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Case",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Masic",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hennig",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Mcquin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Caicedo",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Cytometry A",
            "volume": "97",
            "issn": "4",
            "pages": "407--421",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Automatic detection of coronavirus disease (covid-19) using X-ray images and deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Narin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kaya",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Pamuk",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.10849"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Artificial intelligence applied on chest X-ray can aid in the diagnosis of covid-19 infection: a first experience from Lombardy",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Castiglioni",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ippolito",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Interlenghi",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "B"
                    ],
                    "last": "Monti",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Salvatore",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Schiaffino",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Covidx-net: a framework of deep learning classifiers to diagnose covid-19 in X-ray images",
            "authors": [
                {
                    "first": "Ee-D",
                    "middle": [],
                    "last": "Hemdan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Shouman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Karar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.11055"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Application of deep learning for fast detection of covid-19 in X-rays using ncovnet",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Panwar",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Siddiqui",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Morales-Menendez",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Covid-19 identification in chest X-ray images on flat and hierarchical classification scenarios",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bertolini",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Teixeira",
                    "suffix": ""
                },
                {
                    "first": "Silla",
                    "middle": [],
                    "last": "Jr",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "N"
                    ],
                    "last": "Costa",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.05835"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Convolutional capsnet: A novel artificial neural network approach to detect covid-19 disease from X-ray images using capsule networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Toraman",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "B"
                    ],
                    "last": "Alakus",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "T\u00fcrkoglu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Sample-efficient deep learning for covid-19 diagnosis based on CT scans",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Artificial intelligence-enabled rapid diagnosis of patients with covid-19",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "H-C",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "K-Y",
                    "middle": [],
                    "last": "Diao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Nat Med",
            "volume": "",
            "issn": "",
            "pages": "1--5",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Lung infection quantification of covid-19 in CT images with deep learning",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.04655"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Residual attention u-net for automated multi-class segmentation of covid-19 chest CT images",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.05645"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Momentum contrastive learning for few-shot covid-19 diagnosis from chest CT images",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2006.13276"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Inf-net: automatic covid-19 lung infection segmentation from CT images",
            "authors": [
                {
                    "first": "D-P",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "G-P",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans Med Imaging",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Covid-19 image data collection",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Identifying medical diagnoses and treatable diseases by image-based deep learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Goldbaum",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Valentim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Baxter",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Cell",
            "volume": "172",
            "issn": "5",
            "pages": "1122--1153",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Covid-19 X rays",
            "authors": [
                {
                    "first": "Amv",
                    "middle": [],
                    "last": "Dadario",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.34740/KAGGLE/DSV/1019469"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Imagenet: a large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Socher",
                    "suffix": ""
                },
                {
                    "first": "L-J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fei-Fei",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "248--55",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Convolutional neural networks: an overview and application in radiology",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yamashita",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nishio",
                    "suffix": ""
                },
                {
                    "first": "Rkg",
                    "middle": [],
                    "last": "Do",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Togashi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Insights Imaging",
            "volume": "9",
            "issn": "4",
            "pages": "611--640",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bernal",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kushibar",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Asfaw",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Valverde",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Oliver",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Mart\u00ed",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Artif Intell Med",
            "volume": "95",
            "issn": "",
            "pages": "64--81",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Alemi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Thirty-first AAAI Conference on Artificial Intelligence",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Shufflenet: an extremely efficient convolutional neural network for mobile devices",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "6848--56",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Yolov3: an incremental improvement",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Farhadi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1804.02767"
                ]
            }
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Mobilenetv2: inverted residuals and linear bottlenecks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sandler",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Howard",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zhmoginov",
                    "suffix": ""
                },
                {
                    "first": "L-C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "4510--4530",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Learning transferable architectures for scalable image recognition",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zoph",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vasudevan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Shlens",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "V"
                    ],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "8697--710",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Deep learning with depthwise separable convolutions",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chollet",
                    "suffix": ""
                },
                {
                    "first": "Xception",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "1251--1259",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 0.5 MB model size",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "N"
                    ],
                    "last": "Iandola",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Moskewicz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ashraf",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Dally",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Keutzer",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1602.07360"
                ]
            }
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Correlation-based feature subset selection for machine learning. Thesis submitted in partial fulfillment of the requirements of the degree of Doctor of Philosophy at the University of Waikato",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Hall",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Large-scale attribute selection using wrappers",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gutlein",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Frank",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Karwath",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Symposium on Computational Intelligence and Data Mining. IEEE",
            "volume": "",
            "issn": "",
            "pages": "332--341",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Bayesian network classifiers in weka for version 3-5-7",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Bouckaert",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Artif Intell Tools",
            "volume": "11",
            "issn": "3",
            "pages": "369--87",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Covid-19 screening on chest X-ray images using deep learning based anomaly detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.12338"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "i. The method uses a multi-CNN comprising of several pre-trained CNNs for the extraction of features from chest X-ray images for the diagnosis of COVID-19. Most of the existing methods have used a single pre-trained CNN. ii. The method uses a combination of multi-CNN with correlation-based feature selection (CFS) and Bayesnet classifier. No existing state-of-the-art methods have employed multi-CNN, CFS based feature selection and Bayesnet classifier for the diagnosis of COVID-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Sample activations. Each image contains sixteen tiles corresponding to sample activations of the original image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Architecture of the proposed method. 3% and 98.4% respectively, in predicting COVID-19 and non-COVID images of Dataset-1. It further achieved a precision of 98.6% and 85.7% in predicting COVID-19 and non-COVID images of Dataset-2. Feature extraction, feature selection and training the classifier using Dataset-1 required a computational time of 165.33 s. Testing using 10% of the images (96 images) required only 15.8136 s. Feature extraction, feature selection and training the classifier using Dataset-1 required a computational time of 18.91 s. Testing using 10% of the images of DATASET-2 required only 3.02 s.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Confusion matrices corresponding to Dataset-1 and Dataset2. The bottom-most diagonal elements indicated in yellow colour represent accuracy. Elements in right most columns represent recall and bottom most rows represent precision.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "ROC curves corresponding to results achieved in Dataset-1 and Dataset-2.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The number of COVID-19 images used by the other methods is considerably less. The method by Panwar et al.[15] achieved a recall of 0.972 in a balanced dataset of 142 COVID-19 and 142 normal images. The result was achieved on a held-out test dataset consisting of 30% of the images. Toraman et al.[17] achieved a precision of 0.916, recall of 0.96, F-measure of 0.938 and an accuracy of 91.24% based on 10-fold cross-validation performed on 231 COVID-19 images and 500 images with nofindings. The method by Narin et al.[12] achieved a recall of 0.96, F-measure of 0.98 and an accuracy of 98%. However, the method was implemented on a small balanced dataset of 50 COVID-19 and 50 non-COVID images.[13] used a balanced dataset of 250 COVID-19 and 250 non-COVID images to achieve a recall of 0.78 and an AUC of 0.98. The proposed method achieved a better recall and AUC in both the datasets. Zhang et al.[44] achieved a recall of 0.96 and AUC of 0.95 using 100 COVID-19 images and 1431 non-COVID images. However, the result was based on splitting the dataset into training and testing data and not based on cross-validation. Hemdan et al.[14] achieved a precision of 0.83, recall of 1.00 and F-measure of 0.91 using a small balanced dataset of 25 COVID-19 and 25 non-COVID images. The result was based on a held-out test dataset",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Results achieved using various datasets.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Parameter settings of CFS.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Comparison of results achieved using various search algorithms in combination with proposed feature selection technique. Results obtained using the best performing algorithm is indicated in bold.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Parameter settings of Bayesnet.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Comparison of results achieved using various pre-trained networks in combination with proposed classifier. Best results achieved using multi-CNN is indicated in bold.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Comparison of results achieved using various classifiers in combination with the proposed network. Results achieved using proposed classifier is shown in bold.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Number",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Results reported by various state-of-the-art methods. Results achieved using the proposed method is indicated in bold.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors declare that there is no conflict of interest.r e f e r e n c e s",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}