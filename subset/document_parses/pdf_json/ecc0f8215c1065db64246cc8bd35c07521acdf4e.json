{
    "paper_id": "ecc0f8215c1065db64246cc8bd35c07521acdf4e",
    "metadata": {
        "title": "Multi-objective Genetic Algorithm Based Deep Learning Model for Automated COVID-19 Detection Using Medical Image Data",
        "authors": [
            {
                "first": "S",
                "middle": [],
                "last": "Bansal",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "M"
                ],
                "last": "Singh",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "R K"
                ],
                "last": "Dubey",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "B K"
                ],
                "last": "Panigrahi",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Purpose In early 2020, the world is amid a significant pandemic due to the novel coronavirus disease outbreak, commonly called the COVID-19. Coronavirus is a lung infection disease caused by the Severe Acute Respiratory Syndrome Coronavirus 2 virus (SARS-CoV-2). Because of its high transmission rate, it is crucial to detect cases as soon as possible to effectively control the spread of this pandemic and treat patients in the early stages. RT-PCR-based kits are the current standard kits used for COVID-19 diagnosis, but these tests take much time despite their high precision. A faster automated diagnostic tool is required for the effective screening of COVID-19. Methods In this study, a new semi-supervised feature learning technique is proposed to screen COVID-19 patients using chest CT scans. The model proposed in this study uses a three-step architecture, consisting of a convolutional autoencoder based unsupervised feature extractor, a multi-objective genetic algorithm (MOGA) based feature selector, and a Bagging Ensemble of support vector machines based binary classifier. The proposed architecture has been designed to provide precise and robust diagnostics for binary classification (COVID vs.nonCOVID). A dataset of 1252 COVID-19 CT scan images, collected from 60 patients, has been used to train and evaluate the model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The best performing classifier within 127 ms per image achieved an accuracy of 98.79%, the precision of 98.47%, area under curve of 0.998, and an F1 score of 98.85% on 497 test images. The proposed model outperforms the current state of the art COVID-19 diagnostic techniques in terms of speed and accuracy. Conclusion The experimental results prove the superiority of the proposed methodology in comparison to existing methods. The study also comprehensively compares various feature selection techniques and highlights the importance of feature selection in medical image data problems.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "A chest infection disease affects the functioning of the lungs [1] . The common lung infections are lung cancer, Chronic Obstructive Pulmonary Disease (COPD), bronchitis, pneumonia and, asthma. Coronavirus disease (COVID-19) is a of lung infection disease caused due to the novel discovered virus known as SARS-CoV-2 [2]. COVID-19 began with reports of unknown causes of pneumonia in Wuhan City, China, around December 2019. The worldwide economy was impacted by the unprecedented rise in COVID-19 cases and it has been declared a pandemic by the World Health Organization [3] .",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 66,
                    "text": "[1]",
                    "ref_id": null
                },
                {
                    "start": 573,
                    "end": 576,
                    "text": "[3]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "On 18 June 2020, a total of 8,379,081 patients became infected with COVID-19, and 215 countries listed 450,101 deaths [3] . The standard diagnostic test for COVID-19 is the Reverse Transcriptase Polymerase Chain Reaction (RT-PCR) [4] . Due to PCR's high selectivity and sensitivity, it is prevalent. The limitations of the PCR technique are (1) time consuming, (2) expensive, (3) shortage of kits, and (4) long production time [5] . A faster and cheaper testing mechanism is required to tackle the alarming rates of spread of COVID-19. Radiological analysis like Chest CT (computed tomography) scans and X-Rays produce high hit-rate in COVID-19 diagnosis. Authors in [6] established a high correlation between radiological results and RT-PCR. The above reasons encouraged developing a cheaper and faster COVID-19 screening mechanism using a radiological approach [7] .",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 121,
                    "text": "[3]",
                    "ref_id": null
                },
                {
                    "start": 230,
                    "end": 233,
                    "text": "[4]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 376,
                    "end": 379,
                    "text": "(3)",
                    "ref_id": null
                },
                {
                    "start": 427,
                    "end": 430,
                    "text": "[5]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 667,
                    "end": 670,
                    "text": "[6]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 863,
                    "end": 866,
                    "text": "[7]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "From the comprehensive analysis of the COVID-19 diagnosis field, it is inferred that the best alternative for COVID-19 detection to the RT-PCR test kits is chest radiography (X-rays and CT scan) [8] . However, CT scan modality seems to be more efficient than chest X-ray for the following reasons: (1) X-rays provide only a 2D perspective whereas CT scan provides a detailed 3D view of the organ, (2) in X-rays, ribs overlap the lungs and heart, whereas, the CT scan does not. A deep-learning-based three-step model is proposed for CT-scan based screening, consisting of a convolutional autoencoder (CAE) based unsupervised feature extractor, an evolutionary algorithm based feature subset selector, and a feature classifier.",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 198,
                    "text": "[8]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A CNN-based dense autoencoder has been used as the feature extractor because of CNN's high representational power and the generality of unsupervised learning from it. The Autoencoder ensures an accurate and diverse feature set, while the feature selector removes all redundant and irrelevant features improving the performance. After obtaining a reduced representation of raw data as a diverse set of features, the evolutionary algorithm based feature subset selectors is used to select optimal feature subsets. Finally, the bagging ensemble of support vector machines (SVM) is trained on the subsets chosen by the various selectors, and their performance is compared. Table 1 consists of various state of the art techniques currently available in the literature of COVID-19 diagnosis. Further, a detailed analysis of the review is presented.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 669,
                    "end": 676,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Works from [10, 11, 13, 14] have used pre-trained CNN models for COVID-19 diagnosis. Transfer Learning techniques are useful when data is limited, but they often fail to learn intricate features unique to the required dataset. Some Table 1 Related work results analysis on COVID-19 screening",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 15,
                    "text": "[10,",
                    "ref_id": null
                },
                {
                    "start": 16,
                    "end": 19,
                    "text": "11,",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 20,
                    "end": 23,
                    "text": "13,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 24,
                    "end": 27,
                    "text": "14]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 232,
                    "end": 239,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Related Works"
        },
        {
            "text": "Key findings [9] infection Size Aware Random Forest method (iSARF) The accuracy of 87.9%, a sensitivity of 90.7%, and a specificity of 83.3% are achieved on chest CT scan [10] ResNet-18 (CNN model) The performance parameters are: specificity: 92.2%, sensitivity: 98.2% and, AUC: 0.996 [11] Pre-trained CheXNet and DenseNet An accuracy of 90.5%, a sensitivity of 100% is achieved using 5323 (COVID19-115, normal -1341, and pneumonia-3867) Chest X-ray images [12] Joint Classification and Segmentation (JCS) Used a dataset of 400 COVID-19 patients (144,167 images) and 350 Non-COVID patients. The model achieves a dice score of 78.3%, sensitivity of 95% and a specificity of 93% for the segmentation task [13] Domain Exten. Transfer Learning (DETL) with Gradient Class Activation Map (Grad-CAM)",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 16,
                    "text": "[9]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 171,
                    "end": 175,
                    "text": "[10]",
                    "ref_id": null
                },
                {
                    "start": 285,
                    "end": 289,
                    "text": "[11]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 457,
                    "end": 461,
                    "text": "[12]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 703,
                    "end": 707,
                    "text": "[13]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "The Data A -Binary classes disease (13 diseases) and normal. Data B -Four classes (normal, pneumonia, other diseases, and Covid19). An accuracy of 95.3% using X-ray scans [14] AlexNet, VGG16, VGG19, GoogleNet, and ResNet50 Pre-trained models used to train CNN on 742 chest CT scans for two binary classes (COVID and non-COVID). The highest accuracy of 82.91% is achieved with the ResNet50 pre-trained CNN model [15] 3-Dimensional deep learning The specificity of 92.2%, a sensitivity of 98.2%, and AUC of 0.996 is achieved by the 3-D CNN model [16] Detail-Oriented Capsule Nets + Peekaboo (patch crop and drop strategy)",
            "cite_spans": [
                {
                    "start": 171,
                    "end": 175,
                    "text": "[14]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[15]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 544,
                    "end": 548,
                    "text": "[16]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "A recall of 91.5%, accuracy of 87.6%, precision of 84.3%, and AUC of 96.1 is achieved on chest CT scan dataset for classification to binary classes(COVID-19 and Non-COVID) [17] Multi-Objective Differential Evolution (MODE) deep learning The performance parameters of MODE outperforms by 1.927% of Kappa statistics, 1.68% of specificity, 1.82% of sensitivity and, 2.09% of F-measure in comparison to authentic CNN models authors have performed fine-tuning, but retraining the last few layers might not change the basic features extracted by the CNN. Authors in [9, 12, 15, 16] have used random forest, peekaboo, and segmentation classification. They have not used explicit feature extractors, and since the classification uses chest CT images, a deep feature extractor architecture like CNN might perform significantly better in this case.",
            "cite_spans": [
                {
                    "start": 172,
                    "end": 176,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 560,
                    "end": 563,
                    "text": "[9,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 564,
                    "end": 567,
                    "text": "12,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 568,
                    "end": 571,
                    "text": "15,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 572,
                    "end": 575,
                    "text": "16]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "The authors in the literature have obtained quality results by focusing only on feature extractors and classifiers. In our work, we propose to shift the attention from feature extraction to feature selection as it is critical to remove the redundant features in an unsupervised extractor and improve the performance of any standard classifier.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "The author in [17] obtained improved results using MO-DE [18] feature selector over Deep CNN models, thus showcasing the importance of proper feature selection technique in medical image classification. We extend their work further and try to analyze and compare various feature reduction and selection techniques ranging from linear dimensionality reduction (principal component analysis-PCA) to various multi-objective feature selectors. We obtained stateof-the-art results, validating their results, and obtaining an improved, robust model for COVID-19 screening.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 18,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 57,
                    "end": 61,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "Further, authors in [19] have found genetic selectors to outperform standard results on the Flavia dataset. Authors in [20] use a Nondominated Sorting Genetic Algorithm II (NSGA-II) based MOGA for feature selection and evaluate its performance on various datasets. Authors in [21] show the use of the GA based feature selector for network intrusion detection. Authors in [22] compare GA based feature selectors on medical datasets focusing on diagnostic radiology. Authors of [22] compare GA based feature selectors to other approaches. In the stated studies, optimization of internal parameters of the MOGA has not been explored. Further, there is no comparative analysis among MOGA and other multi-objective evolutionary techniques for feature selection on medical images. Multi-Objective Optimization using Evolutionary Algorithms has not been well explored in its use as a feature selector.",
            "cite_spans": [
                {
                    "start": 20,
                    "end": 24,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 119,
                    "end": 123,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 276,
                    "end": 280,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 371,
                    "end": 375,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 476,
                    "end": 480,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "We try to improve upon the previous works by analyzing the effects of optimizing parameters of MOGA. We also studied and compared MOGA with other multi-objective evolutionary techniques for feature selection on COVID-19 CT Scan Image Dataset, not done previously by any works.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "References Technique"
        },
        {
            "text": "Autoencoders [23] are unsupervised learning methods trained to reconstruct their inputs, usually by going through a compressed representation of lower dimensionality [24] . Structurally an AE comprises two parts, namely an Encoder and a Decoder. Figure 1 summarizes the structure of an AE.",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 17,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 166,
                    "end": 170,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 246,
                    "end": 254,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Autoencoder (AE) Based Feature Extractor"
        },
        {
            "text": "The encoder (E) converts the input image (x) to an encoded representation (h), which reflects the features of the image due to the constraint to reduce dimensionality. An encoder deterministically maps its input to a reduced representation generally using an affine map:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder (AE) Based Feature Extractor"
        },
        {
            "text": "here W denotes the weights for the encoder part, b represents the bias, and h represents the reduced representation. Similarly, the decoder (D) takes the reduced representation (h) and outputs the reconstructed image (y). An Autoencoder is trained to minimize the reconstruction error of its input. Hence, training of AE can be seen as a minimization of the following cost function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Autoencoder (AE) Based Feature Extractor"
        },
        {
            "text": "where N represents the number of images, x i and y i represent the ith input-output image pair, and Loss is the reconstruction error between two images. Mean squared error has been used as the reconstruction error. CAE combines convolutional operations with the architecture of an AE. The authors of [25] have shown that CAE shows high accuracy in finger vein identification. Since CNN can extract a very detailed set of feature maps from images, convolutional AE has been used as a feature extractor in this study.",
            "cite_spans": [
                {
                    "start": 300,
                    "end": 304,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Autoencoder (AE) Based Feature Extractor"
        },
        {
            "text": "Feature Selector",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi Objective Genetic Algorithm Based"
        },
        {
            "text": "Multi-Objective Optimization is the process of simultaneously optimizing more than one competing objective function. Two Objectives have been considered in this work, namely, classification accuracy and size of feature subset. These are competing objectives, and a single solution optimizing both might not exist. An alternative is to generate a set known as the Pareto Optimal set of solutions. A Pareto There is always a degradation in some objectives, required to improve any objective in a Pareto set of solutions. Consider a set of M objectives that have to be mini-",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi Objective Genetic Algorithm (MOGA)"
        },
        {
            "text": "A solution is said to be Pareto Optimal if there exists no solution which dominates it. All such Pareto Optimal solutions together form the Pareto Optimal Set.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Multi Objective Genetic Algorithm (MOGA)"
        },
        {
            "text": "There exist various algorithms for multi-objective Genetic Optimizations. NSGA-II [26] is one such elitist principle-based algorithm much superior to classic gradient-based approaches. NSGA-II has been used to carry out the multi-objective feature subset selection in this study. Figure 2 summarizes the implementation of NSGA-II.",
            "cite_spans": [
                {
                    "start": 82,
                    "end": 86,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 280,
                    "end": 288,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Multi Objective Genetic Algorithm (MOGA)"
        },
        {
            "text": "Solutions in the population (a.k.a chromosomes) are represented as binary strings. The ith gene in a chromosome is one if the solution contains the ith feature of the input set. For the initial population, random binary chromosomes have been generated.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Initial Population and Encoding"
        },
        {
            "text": "The creation of two new offspring chromosomes using the selected parent pair is known as crossover. Single point crossover has been used in this work, where each gene is randomly selected from one of the parents. Parents are selected using tournament-based selection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Crossover and Mutation"
        },
        {
            "text": "Mutation conserves population diversity. Mutation involves random modifications in the value of the chromosomes. Random bit flip has been used as the mutation operator in this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Crossover and Mutation"
        },
        {
            "text": "The MOGA based selector terminates when either the maximum number of generations or the stall generation limit has been reached. After termination, the selector returns the final population with objective scores and front rankings.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Termination"
        },
        {
            "text": "The SVM ensemble with Bagging is used in classification as SVM is a weak learner [27] . Using many small classifiers can increase robustness and produce low error. Bagging [28] , uses randomized training sets for creating different models. A single classifier's training set is randomly generated by drawing N random data points (N is the size of the original training set) from the original training set with replacement. Figure 3 illustrates the structure of the bagging ensemble-based SVM.",
            "cite_spans": [
                {
                    "start": 81,
                    "end": 85,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 172,
                    "end": 176,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [
                {
                    "start": 423,
                    "end": 431,
                    "text": "Figure 3",
                    "ref_id": null
                }
            ],
            "section": "Ensemble SVM Based Classification"
        },
        {
            "text": "As described above, bootstrap builds K duplicate training datasets from the given training data set (TR) {TR k |k = 1, 2, ..., K} using random re-sampling with replacement.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ensemble SVM Based Classification"
        },
        {
            "text": "After training, the independently trained SVMs are aggregated. Thus, majority voting has been used in the study because it uses upper layer SVM to combine several lower layer SVMs (double layer hierarchical combining).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ensemble SVM Based Classification"
        },
        {
            "text": "A 3-step architecture is proposed for the screening of COVID-19 chest CT scans. The proposed architecture consists of a feature extractor, a feature selector, and a classifier. Flowchart summarizing the proposed architecture is depicted in Fig. 4 An autoencoder based unsupervised learning approach is used to generate features from the CT scan images automatically. This gives us a diverse feature set, essential for this classification.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 240,
                    "end": 246,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Proposed Method"
        },
        {
            "text": "Though diverse, the features extracted by the Autoencoder have very high dimensionality and suffer from a redundancy of features. To remove the extra features, a MOGA based feature selector is proposed to select an optimal set of features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Method"
        },
        {
            "text": "Finally, for classification, a bagging based ensemble of support vector machines is used to carry out the binary classification of the feature sets into COVID-19 and non-COVID classes. A brief outline of the various methods is highlighted in the subsequent study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Method"
        },
        {
            "text": "The input image of size 128 \u00d7 128 \u00d7 3, is fed into the CNN, which contains convolutional layers (kernel size 3) and maxpooling layers (downscaling factor of 2). ReLu activation is applied after every convolution. The encoder layers have 32, 16, and 8 filters (output channels), respectively. A decoder follows the encoder to reconstruct the image using deconvolution and up-sampling layers. The output of the encoder has the shape 14 \u00d7 14 \u00d7 16. This is flattened to generate a feature vector of length 2048 per CT Scan image. The CNN architecture has been summarized in Fig. 5 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 570,
                    "end": 576,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Auto Encoder Structure and Training"
        },
        {
            "text": "The Auto Encoder is trained using the training set with the validation set for validation, as explained in Sect. 4.1. Adam optimizer has been used for training the AE, with Mean Squared Error (MSE) as the loss function. The AE has been trained for two hundred epochs with a batch size of 10 per epoch. Figure 6 shows a reconstruction of test set images by AE. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 302,
                    "end": 310,
                    "text": "Figure 6",
                    "ref_id": null
                }
            ],
            "section": "Auto Encoder Structure and Training"
        },
        {
            "text": "The feature extractor extracts 2048 features from an input image of 128 \u00d7 128 \u00d7 3. MOGA has been applied for selecting a superlative set from the extracted features using two fitness criteria:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Selector"
        },
        {
            "text": "where S is the cardinality of F and F is the subset of features selected, and Accuracy is classification accuracy on the test set. Reducing the number of features ensures that there are no redundant or irrelevant features in the dataset. Classification accuracy is measured on the test set using an SVM.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Selector"
        },
        {
            "text": "Instead of constant Crossover and mutation rates, linear crossover and mutation rates have been used in this study. This ensures a high initial mutation rate preventing premature convergence and a low mutation rate when MOGA is close to the Pareto front. Similarly, the crossover rate is initially low to maintain diversity and gradually increases. Figure 8 shows the plot of the crossover and mutation rates against generations for the MOGA.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 349,
                    "end": 357,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Feature Selector"
        },
        {
            "text": "The summary of GA Parameters is given in Table 3 . For evaluation, an average of 100 runs has been considered. The run summary of the MOGA based selector showing the min., max., avg., and std. dev. of the number features and highest accuracy for the given generation (using SVM as a classifier) is shown in Table 2 . The plot of highest accuracy vs. No of features selected by MOGA is shown in Fig. 7 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 41,
                    "end": 48,
                    "text": "Table 3",
                    "ref_id": null
                },
                {
                    "start": 307,
                    "end": 314,
                    "text": "Table 2",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 394,
                    "end": 400,
                    "text": "Fig. 7",
                    "ref_id": null
                }
            ],
            "section": "Feature Selector"
        },
        {
            "text": "An ensemble of support vector machines (SVM) is used to classify the selected features. The bagging technique is used to construct the SVM ensemble. For classification, the dataset is randomly divided into ten parts, and the individual SVMs are trained independently(bootstrap techniques). These individual models are then aggregated by the deterministic averaging process to make a",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature Classifier"
        },
        {
            "text": "joint decision. Each SVM has an RBF kernel with C and Gamma tuned values using the Genetic Algorithm-based Hyperparameter Optimizer. The classifier's performance, evaluated using the test set, and the number of features is stated in Table 8 . The dataset has been split into three sets, namely training (0.6), validation (0.2), and testing (0.2). The splitting is random, and an average of 5 splits is stated for all evaluations. The summary of the dataset after splitting is stated in Table 4 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 233,
                    "end": 240,
                    "text": "Table 8",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 486,
                    "end": 493,
                    "text": "Table 4",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Feature Classifier"
        },
        {
            "text": "The screening performance of the model was assessed by accuracy (ACC), precision (PRE), area under ROC curve (AUC), recall/sensitivity (REC), and F1 score (F1). Precision is the number of true positives over total positive predictions. Recall is defined as the number of true positives over the number of correct classifications. F1 score is simply the harmonic mean of precision and sensitivity of the model. AUC is the total area contained under a ROC Curve, and it shows the usefulness of tests on the model. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation Metrics"
        },
        {
            "text": "Depth of any Neural Network directly affects its performance, and an optimal depth ensures an accurate and robust model. The reconstruction Structural Similarity Index (SSIM) and Mean Squared Error (MSE) has been used to compare various autoencoders. Three different autoencoders have been considered for this with 2, 3, and 4 convolution layers, respectively, in the encoder. The exact structure of the autoencoders is given below:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison of AE Depths"
        },
        {
            "text": "-2-Layers: two convolution layers of kernel 3x3 with 32 and 64 filters, respectively. Each layer is followed by a max-pooling layer of 2 \u00d7 2. -3-Layers (proposed) : three convolution layers of kernel 3 \u00d7 3 with 16, 32, and 64 filters, respectively. Each layer is followed by a max-pooling layer of 2 \u00d7 2. -4-Layers: four convolution layers of kernel 3x3 with 8, 16, 32, and 64 filters, respectively. Each layer is followed by a max-pooling layer of 2 \u00d7 2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison of AE Depths"
        },
        {
            "text": "The analysis is summarized in Table 5 . The AE has been trained on the train set and tested on the validation set for this analysis. The size of images used is 128x128, and the pixel values have been scaled to lie between 0 and 1.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 30,
                    "end": 37,
                    "text": "Table 5",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Comparison of AE Depths"
        },
        {
            "text": "Bagging ensemble uses several estimators instead of a single estimator for prediction. This improves performance since a single estimator may have high test error, but it is overcome by using many small estimators. A different number of estimators are compared based on their accuracy on the validation set, and the box plot of the accuracy vs. the number of estimators is shown in Fig. 9 . It can be seen that the accuracy improves till 20 estimators, then it saturates.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 382,
                    "end": 388,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Effect of Bagging Estimators on Performance"
        },
        {
            "text": "Optimal population size is obtained by applying the proposed MOGA based selector on the validation set. For obtaining the accuracy values, multiple runs were conducted, and an average of these was recorded. The graphs show the accuracy against the population size of MOGA, which is varied between 50 and 300 in increments of 50. The plot shows that the performance improves up to size 200, after which it stabilizes. Figure 10 shows the plot of the accuracy vs. population size.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 417,
                    "end": 426,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Comparing Different Population Sizes"
        },
        {
            "text": "Improvement of Pareto fronts with generation is studied in this section. The fronts are plotted using 5 points from each generation, with the parameters for MOGA being as stated in Table 3 . Y-axis represents the selected subset's accuracy on the validation set, while the X-axis represents the inverse of the number of features selected. It can be seen that the fronts improve till 150 generations and then the front stabilizes. This is also observed in the overlap of the fronts in generation 150 and 200. Figure 11 shows the generation wise Pareto fronts.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 181,
                    "end": 188,
                    "text": "Table 3",
                    "ref_id": null
                },
                {
                    "start": 508,
                    "end": 517,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Comparing Generation Size of MOGA"
        },
        {
            "text": "This section compares the MOGA based selector, PCA, and Simple GA. Accuracy on the validation set is taken as the comparison metric. PCA, a popular dimensionality reduction technique, is applied with a variance set to 0.95. Simple GA tries to find the optimal feature set using validation accuracy as the fitness function. Direct classification with all the extracted features without any feature selection has also been performed. The results obtained are summarized in Table 6 . Directly using the features without selection results in poor performance of the model. The proposed model outperforms all the techniques in terms of accuracy. In terms of the number of features, it can be seen that MOGA selects considerably fewer features than simple GA. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 471,
                    "end": 478,
                    "text": "Table 6",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Comparison with Simple GA, PCA and No-Selector"
        },
        {
            "text": "Crossover and mutation rates are the parameters that control the convergence of the MOGA selector. A non-constant linear crossover rate has been used in this study to improve the selector's ability to find the optimal front. The proposed selector is compared with constant crossover and mutation rate based MOGA. Accuracy on the validation set averaged over multiple runs is used for this comparison. The result of the analysis is summarized in Table 7 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 445,
                    "end": 452,
                    "text": "Table 7",
                    "ref_id": null
                }
            ],
            "section": "Comparison of Crossover and Mutation Rates"
        },
        {
            "text": "Multiple feature selection techniques, namely Multi-Objective Particle Swarm Optimization (MOPSO) [30] , Multi-Objective Differential Evolution (MODE) [18] and MOGA are compared in this study. The standard implementations of these techniques (except the proposed method) are used for this analysis. Table 8 shows the evaluation results on different selectors. For evaluation, features are extracted using the proposed AE architecture, selected using different selectors, and finally classified using SVM Ensemble. For more effective comparison, the test set, which is unseen by the selectors, is used for the evaluation. The details of the train-test split are provided in Sect. 4-A. The results obtained show that the proposed model outperforms other multi-objective feature selection techniques. Figure 13 shows the confusion matrices obtained for different feature selectors on the test set.",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 151,
                    "end": 155,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [
                {
                    "start": 299,
                    "end": 306,
                    "text": "Table 8",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 798,
                    "end": 807,
                    "text": "Figure 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Comparison of Feature Selectors"
        },
        {
            "text": "For evaluation, the dataset is split according to Table 4 . The proposed method has been evaluated using the test set, composed of 260 COVID-19 chest CT images and 237 non-COVID chest CT Images. The performance is measured based on the evaluation metrics discussed in Sect. IV-B. The features are extracted using the AE encoder defined in III-A and selected using MOGA as described in III B. Finally, the The receiver operator characteristic curve on the proposed model's test set is depicted in Fig. 12 . The area obtained under the ROC Curve (AUC) is 0.998. A high value of AUC shows the robustness of the proposed model. Table 8 summarizes the evaluation results of the proposed architecture. Confusion matrices for different feature selectors on the test set are shown in Fig. 13 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 50,
                    "end": 57,
                    "text": "Table 4",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 496,
                    "end": 503,
                    "text": "Fig. 12",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 624,
                    "end": 631,
                    "text": "Table 8",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 776,
                    "end": 783,
                    "text": "Fig. 13",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Results and Analysis"
        },
        {
            "text": "The proposed study (MOGA) outperforms other multiobjective feature selectors. A decrease in ACC is expected in GA with an increase in the number of variables. As the number of variables for optimizing the selection are less, MOGA outperforms MODE and MOPSO. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results and Analysis"
        },
        {
            "text": "An unsupervised learning-based approach is proposed for feature generation because of the higher feature diversity obtained from such an approach. Various evolutionary and non evolutionary feature selectors are compared in this study, and finally, a MOGA based selector is proposed. An ensemble of SVMs is used for the final classification. The bagging technique is used in the ensemble as it works well with complex feature maps.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The study further finds many insights in feature extraction, feature selection, and classification, which are listed below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "-Unsupervised learning-based feature extractors can provide detailed and accurate feature maps for medical image classification. -Evolutionary Feature Selectors remove data redundancy better than standard techniques like PCA in terms of accuracy and number of features. Not using a feature selector results in inferior performance -Optimizing the number of features and accuracy forces the model to learn from a smaller feature set, resulting in a more robust model since only the most productive features are retained. -MOGA outperforms MOPSA and MODE in medical image classification because of the large number of parameters that need to be optimized for MOPSA and MODE. -Variable Crossover and Mutation rates for MOGA can significantly improve performance in medical image classification. -Bagging improves a classifier's performance, as a large number of classifiers produce a lower test error than a single classifier. This is because diversity compensates for bias.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The proposed model achieves better results than stateof-the-art techniques for all performance metrics. With such high-performance results and a little prediction time compared to Physical RT-PCR tests, the proposed model can be an effective and efficient COVID-19 Chest CT Scan screening Technique. Shortly, clinically verified AI-based diagnosis may be the way for rapid screening and early containment of outbreaks. With increasing structured medical data, deep learning models can be helpful for it. Further, the study proposes that techniques like unsupervised feature extractor and evolutionary feature selector can help address the problem associated with limited COVID-19 radiology data. The study also comprehensively compares various feature selection techniques and highlights the importance of feature selection in medical data problems. The study uses open-sourced dataset for COVID-19 screening. The technique's effectiveness is limited by the dataset available and needs to be verified on other data. Also, for clinical validation, there will be a need to localize the infection regions, map them in the images, and track the degree of infection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The authors declare no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        },
        {
            "text": "Ethical approval All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        },
        {
            "text": "Informed consent Informed consent was obtained from all individual participants included in the study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ],
    "bib_entries": {
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Real-time RT-PCR in Covid-19 detection: Issues affecting the results",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Tahamtana",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ardebili",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Expert Review of Molecular Diagnostics",
            "volume": "20",
            "issn": "",
            "pages": "453--454",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (covid-19) in China: A report of 1014 cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Chest CT manifestations of new coronavirus disease 2019 (covid-19): A pictorial review",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "European Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Essentials for radiologists on covid-19: An update-Radiology scientific expert panel",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Kanne",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Little",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Elicker",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "M"
                    ],
                    "last": "Ketai",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "H"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Coronavirus detection and analysis on chest CT with deep learning",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Frid-Adar",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Sagie",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Sui",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Covidaid: Covid-19 detection using chest X-ray",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mangal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kalia",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Rajgopal",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Rangarajan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Namboodiri",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Banerjee",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Arora",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Jcs: An explainable covid-19 diagnosis system by joint classification and segmentation",
            "authors": [
                {
                    "first": "Y.-H",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "S.-H",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "D.-P",
                    "middle": [],
                    "last": "Fan",
                    "suffix": ""
                },
                {
                    "first": "C.-W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "M.-M",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Deep learning for screening covid-19 using chest X-ray images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Basu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Saha",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "A deep transfer learning model with classical data augmentation and CGAN to detect Covid-19 from chest CT radiography digital images",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Loey",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Smarandache",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "E M"
                    ],
                    "last": "Khalifa",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Rapid AI development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection patient monitoring using deep learning CT image analysis",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gozes",
                    "suffix": ""
                },
                {
                    "first": "F.-A",
                    "middle": [],
                    "last": "Maayan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Greenspan",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "D"
                    ],
                    "last": "Browning",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Radiologist-level covid-19 detection using CT scans with detailoriented capsule networks",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Classification of covid-19 patients from chest CT images using multi-objective differential evolution-based convolutional neural networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Vaishali",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kaur",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "European Journal of Clinical Microbiology Infectious Diseases",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Multi-objective feature selection in classification: A differential evolution approach",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Xue",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Dick",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "N"
                    ],
                    "last": "Browne",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Whigham",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "T"
                    ],
                    "last": "Bui",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ishibuchi",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Tan",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "516--528",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "A genetic algorithm-based feature selection",
            "authors": [
                {
                    "first": "O",
                    "middle": [
                        "H"
                    ],
                    "last": "Babatunde",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Armstrong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Leng",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Diepeveen",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "British Journal of Mathematics Computer Science",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Multi-objective feature subset selection using non-dominated sorting genetic algorithm",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "R"
                    ],
                    "last": "Baig",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Journal of Applied Research and Technology",
            "volume": "13",
            "issn": "1",
            "pages": "145--159",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Feature selection using genetic algorithm to improve classification in network intrusion detection system",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ferriyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Thamrin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Takeda",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Murai",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC)",
            "volume": "",
            "issn": "",
            "pages": "46--49",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "A survey on genetic algorithm based feature selection for disease diagnosis system",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sindhiya",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gunasundari",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14",
            "volume": "",
            "issn": "",
            "pages": "164--169",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Modular learning in neural networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Ballard",
                    "suffix": ""
                }
            ],
            "year": 1987,
            "venue": "Proceedings of the Sixth National Conference on Artificial Intelligence",
            "volume": "1",
            "issn": "",
            "pages": "279--284",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Unsupervised learning and deep architectures",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "B"
                    ],
                    "last": "Autoencoders",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop",
            "volume": "27",
            "issn": "",
            "pages": "37--50",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Convolutional auto-encoder based deep feature learning for finger-vein verification",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE International Symposium on Medical Measurements and Applications (MeMeA)",
            "volume": "",
            "issn": "",
            "pages": "1--5",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A fast and elitist multiobjective genetic algorithm: Nsga-ii",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Deb",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pratap",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Agarwal",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Meyarivan",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "IEEE Transactions on Evolutionary Computation",
            "volume": "6",
            "issn": "2",
            "pages": "182--197",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Popular ensemble methods: An empirical study",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Opitz",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Maclin",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Journal of Artificial Intelligence Research",
            "volume": "11",
            "issn": "",
            "pages": "169--198",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Bagging predictors. Machine Learning",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Breiman",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "123--140",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "SARS-CoV-2 CT-scan dataset: A large dataset of real patients CT scans for SARS-CoV-2 identification",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Soares",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Angelov",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Biaso",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Higa Froes",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Mopso: A proposal for multiple objective particle swarm optimization",
            "authors": [
                {
                    "first": "Coello",
                    "middle": [],
                    "last": "Coello",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A"
                    ],
                    "last": "Lechuga",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600)",
            "volume": "2",
            "issn": "",
            "pages": "1051--1056",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Schema of basic autoencoder set is a set of solutions where no solution is dominated by any other solution in the set.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The working of NSGA-IIFig. 3 A general architecture of SVM ensemble with an aggregation step",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Flowchart summarizing the proposed architecture",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Proposed architecture of Convolution Auto-encoder",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Original and reconstructed (from Convolution Autoencoder) chest CT images from validation set The plot of highest accuracy vs the maximum number of features) Crossover and mutation rates of MOGA vs generations plot5 Data and Validation5.1 DatasetThe images of CT Scans used in this study are taken from the public database of COVID-19 CT Scans by the name of \"SARS-CoV-2 Ct-Scan Dataset\" published and maintained by Soares et al.[29]. The dataset consists of 2482 images of chest CT Scans, out of which 1252 are from patients infected with COVID-19. The remaining 1230 images are from patients of other non-COVID pulmonary Diseases. The presence of other non-COVID respiratory diseases allows the model to learn COVID specific features.The patients considered in the compilation of the dataset mentioned above are from various hospitals in Sao Paulo, Brazil. The COVID-19 CT Scan images are collected from 60 patients (32 males and 28 females). The non-COVID CT Scan images were also collected from 60 patients (30 males and 30 females).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Box plot of validation set accuracy vs number of bagging estimators",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The plot of population size vs validation accuracy for MOGA selector Fig. 11 The plot of various Pareto Fronts w.r.t. Generations, for the proposed MOGA. Five points are chosen from each generation for plotting this graph",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "ROC characteristics curve for the proposed methodology (convolutional autoencoder + MOGA + Bagging Ensemble with SVM) Fig. 13 Confusion matrices of the proposed methodology with different multi objective feature selectors on the test set",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "The brief details of the dataset for CT scans",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Comparison of AE depth on the basis of reconstruction",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Validation accuracies with MOGA, PCA and GA as feature selector The proposed methodology is implemented on python software, running on a CPU. The system architecture uses an Intel Core i7 processor with a 4 GB graphic card, running at 1.80 GHz, a 64-bit operating system, and 16 GB RAM.The proposed architecture achieves an accuracy (ACC) of 98.79%, precision (PRE) of 98.47%, sensitivity (SEN) of 99.23%, F1 score (F1) of 98.85%, specificity (SPE) of 98.31%, net positive rate (NPV) of 99.14% and area under ROC curve (AUC) of 99.8%. The prediction time on the system used is 127 ms per image. The proposed model outperforms the current state of the art COVID-19 diagnostic techniques in terms of speed and accuracy.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Comparative assessment of various feature selectors on the test set Bold indicates the best performance",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}