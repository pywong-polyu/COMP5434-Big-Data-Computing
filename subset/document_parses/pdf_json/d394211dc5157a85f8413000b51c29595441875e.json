{
    "paper_id": "d394211dc5157a85f8413000b51c29595441875e",
    "metadata": {
        "title": "Optimizing Precision and Power by Machine Learning in Randomized Trials, with an Application to COVID-19",
        "authors": [
            {
                "first": "Nicholas",
                "middle": [],
                "last": "Williams",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Weill Cornell Medicine",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Michael",
                "middle": [],
                "last": "Rosenblum",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Johns Hopkins Bloomberg School of Public Health",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "Iv\u00e1n",
                "middle": [],
                "last": "D\u00edaz",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Weill Cornell Medicine",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The rapid finding of effective therapeutics requires the efficient use of available resources in clinical trials. The use of covariate adjustment can yield statistical estimates with improved precision, resulting in a reduction in the number of participants required to draw futility or efficacy conclusions. We focus on time-to-event and ordinal outcomes. When more than a few baseline covariates are available, a key question for covariate adjustment in randomized studies is how to fit a model relating the outcome and the baseline covariates to maximize precision. We present a novel theoretical result establishing conditions for asymptotic normality of a variety of covariate-adjusted estimators that rely on machine learning (e.g., \u2113 1 -regularization, Random Forests, XGBoost, and Multivariate Adaptive Regression Splines), under the assumption that outcome data is missing completely at random. We further present a consistent estimator of the asymptotic variance. Importantly, the conditions do not require the machine learning methods to converge to the true outcome distribution conditional on baseline variables, as long as they converge to some (possibly incorrect) limit. We conducted a simulation study to evaluate the performance of the aforementioned prediction methods in COVID-19 trials using longitudinal data from over 1,500 patients hospitalized with COVID-19 at Weill Cornell Medicine New York Presbyterian Hospital. We found that using \u2113 1 -regularization led to estimators and corresponding hypothesis tests that control type 1 error and are more precise than an unadjusted estimator across all sample sizes tested. We also show that when covariates are not prognostic of the outcome, \u2113 1 -regularization remains as precise as the unadjusted estimator, even at small sample sizes (n = 100). We give an R package adjrct that performs model-robust covariate adjustment for ordinal and time-to-event outcomes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Coronavirus disease 2019 has affected more than 125 million people and caused more than 2.7 million deaths worldwide (World Health Organization 2021). Governments and scientists around the globe have deployed an enormous amount of resources to combat the pandemic with remarkable success, such as the development in record time of highly effective vaccines to prevent disease (e.g., Polack et al. 2020; Baden et al. 2021) . Global and local organizations are launching large-scale collaborations to collect robust scientific data to test potential COVID-19 treatments, including the testing of drugs re-purposed from other diseases as well as new compounds (Kupferschmidt and Cohen 2020) . For example, the World Health Organization launched the SOLIDARITY trial, enrolling almost 12,000 patients in 500 hospital sites in over 30 countries (WHO Solidarity Trial Consortium 2021) . Other large initiatives include the RECOVERY trial (The RECOVERY Collaborative Group 2021) and the ACTIV initiative (Collins and Stoffels 2020). To date, there are approximately 2,400 randomized trials for the treatment of COVID-19 registered in clinicaltrials.gov.",
            "cite_spans": [
                {
                    "start": 383,
                    "end": 402,
                    "text": "Polack et al. 2020;",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 403,
                    "end": 421,
                    "text": "Baden et al. 2021)",
                    "ref_id": null
                },
                {
                    "start": 657,
                    "end": 687,
                    "text": "(Kupferschmidt and Cohen 2020)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 840,
                    "end": 878,
                    "text": "(WHO Solidarity Trial Consortium 2021)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The rapid finding of effective therapeutics for COVID-19 requires the efficient use of available resources. One area where such efficiency is achievable at little cost is in the statistical design and analysis of the clinical trials. Specifically, a statistical technique known as covariate adjustment may yield estimates with increased precision (compared to unadjusted estimators), and may result in a reduction of the time, number of participants, and resources required to draw futility or efficacy conclusions. This results in faster trial designs, which may help accelerate the delivery of effective treatments to patients who need them (and may help rule out ineffective treatments faster).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Covariate adjustment refers to pre-planned analysis methods that use data on patient baseline characteristics to correct for chance imbalances across study arms, thereby yielding more precise treatment effect estimates. The ICH E9 Guidance on Statistical Methods for Analyzing Clinical Trials (FDA and EMA 1998) states that \"Pretrial deliberations should identify those covariates and factors expected to have an important influence on the primary variable(s), and should consider how to account for these in the analysis to improve precision and to compensate for any lack of balance between treatment groups.\" Even though its benefits can be substantial, covariate adjustment is underutilized; only 24%-34% of trials use covariate adjustment (Kahan et al. 2014) .",
            "cite_spans": [
                {
                    "start": 293,
                    "end": 311,
                    "text": "(FDA and EMA 1998)",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 744,
                    "end": 763,
                    "text": "(Kahan et al. 2014)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We focus on estimation of marginal treatment effects, defined as a contrast between study arms in the marginal distribution of the outcome. Many approaches for estimation of marginal treatment effects using covariate adjustment in randomized trials invoke a model relating the outcome and the baseline covariates within strata of treatment. Recent decades have seen a surge in research on the development of model-robust methods for estimating marginal effects that remain consistent even if this outcome regression model is arbitrarily misspecified (e.g., Yang and Tsiatis 2001; Tsiatis et al. 2008; Zhang et al. 2008; Moore and van der Laan 2009a; Austin et al. 2010; Zhang and Gilbert 2010; Benkeser et al. 2020) . We focus on a study of the model-robust covariate adjusted estimators for timeto-event and ordinal outcomes developed by Moore and van der Laan (2009a), , and D\u00edaz et al. (2016) .",
            "cite_spans": [
                {
                    "start": 557,
                    "end": 579,
                    "text": "Yang and Tsiatis 2001;",
                    "ref_id": null
                },
                {
                    "start": 580,
                    "end": 600,
                    "text": "Tsiatis et al. 2008;",
                    "ref_id": null
                },
                {
                    "start": 601,
                    "end": 619,
                    "text": "Zhang et al. 2008;",
                    "ref_id": null
                },
                {
                    "start": 620,
                    "end": 649,
                    "text": "Moore and van der Laan 2009a;",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 650,
                    "end": 669,
                    "text": "Austin et al. 2010;",
                    "ref_id": null
                },
                {
                    "start": 670,
                    "end": 693,
                    "text": "Zhang and Gilbert 2010;",
                    "ref_id": null
                },
                {
                    "start": 694,
                    "end": 715,
                    "text": "Benkeser et al. 2020)",
                    "ref_id": null
                },
                {
                    "start": 877,
                    "end": 895,
                    "text": "D\u00edaz et al. (2016)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "All potential adjustment covariates must be pre-specified in the statistical analysis plan. At the end of the trial, a prespecified prediction algorithm (e.g., random forests, or using regularization for variable selection) will be run and its output used to construct a modelrobust, covariate adjusted estimator of the marginal treatment effect for the trial's primary efficacy analysis. We aim to address the question of how to do this in a model-robust way that guarantees consistency and asymptotic normality, under some weaker regularity conditions than related work (described below). We also aim to demonstrate the potential value added by covariate adjustment combined with machine learning, through a simulation study based on COVID-19 data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As a standard regression method for high-dimensional data, \u2113 1 -regularization has been studied by several authors in the context of covariate selection for randomized studies. For example, Wager et al. (2016) present estimators that are asymptotically normal under strong assumptions that include linearity of the outcome-covariate relationship. Bloniarz et al. (2016) present estimators under a randomization inference framework, and show asymptotic normality of the estimators under assumptions similar to the assumptions made in this paper. Both of these papers present results only for continuous outcomes. The method of Tian et al. (2012) is general and can be applied to continuous, ordinal, binary, and time-to-event data, and its asymptotic properties are similar to the properties of the methods we discuss for the case of \u2113 1 -regularization, under similar assumptions.",
            "cite_spans": [
                {
                    "start": 190,
                    "end": 209,
                    "text": "Wager et al. (2016)",
                    "ref_id": null
                },
                {
                    "start": 347,
                    "end": 369,
                    "text": "Bloniarz et al. (2016)",
                    "ref_id": null
                },
                {
                    "start": 626,
                    "end": 644,
                    "text": "Tian et al. (2012)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "More related to our general approach, Wager et al. (2016) also present a cross-validation procedure that can be used with arbitrary non-parametric prediction methods (e.g., \u2113 1regularization, random forests, etc.) in the estimation procedure. Their proposal amounts to computation of a cross-fitted augmented inverse probability weighted estimator (Chernozhukov et al. 2018) . Their asymptotic normality results, unlike ours, require that that their predictor of the outcome given baseline variables converges to the true regression function. Wu and Gagnon-Bartsch (2018) proposed a \"leave-one-out-potential outcomes\" estimator where automatic prediction can also be performed using any regression procedure such as linear regression or random forests, and they propose a conservative variance estimator. It is unclear as of yet whether Wald-type confidence intervals based on the normal distribution are appropriate for this estimator. As in the above related work that compares the precision of covariate adjusted estimators to the unadjusted estimator, we assume that outcomes are missing completely at random (since otherwise the unadjusted estimator is generally inconsistent).",
            "cite_spans": [
                {
                    "start": 348,
                    "end": 374,
                    "text": "(Chernozhukov et al. 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In Section 3.3, we present our main theorem. It shows that any of a large class of prediction algorithms (e.g., \u2113 1 -regularization, Random Forests, XGBoost, and Multivariate Adaptive Regression Splines) can be combined with the covariate adjusted estimator of Moore and van der Laan (2009b) to produce a consistent, asymptotically normal estimator of the marginal treatment effect, under regularity conditions. These conditions do not require consistent estimation of the outcome regression function (as in key related work described above); instead, our theorem requires the weaker condition of convergence to some (possibly incorrect) limit. We also give a consistent, easy to compute variance estimator. This has important practical implications because it allows the use machine learning coupled with Wald-type confidence intervals and hypothesis tests, under the conditions of the theorem. The above estimator can be used with ordinal or time-to-event outcomes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We next conduct a simulation study to evaluate the performance of the aforementioned machine learning algorithms for covariate adjustment in the context of COVID-19 trials. We simulate two-arm trials comparing a hypothetical COVID-19 treatment to standard of care. The simulated data distributions are generated from longitudinal data on approximately 1,500 patients hospitalized at Weill Cornell Medicine New York Presbyterian Hospital prior to 15 May 2020. We present results for two types of endpoints: time-to-event (e.g., time to intubation or death) and ordinal (e.g., WHO scale, see Marshall et al. 2020) outcomes. For survival outcomes, we present results for two different estimands (i.e., targets of inference): the survival probability at any given time and the restricted mean survival time. For ordinal outcomes we present results for the average log-odds ratio, and for the Mann-Whitney estimand, interpreted as the probability that a randomly chosen treated patient has a better outcome than a randomly chosen control patient (with ties broken at random). Benkeser et al. (2020) used simulations based on the above data source to illustrate the efficiency gains achievable by covariate adjustment with parametric models including a small number of adjustment variables (and not using machine learning to improve efficiency). In this paper we evaluate the performance of four machine learning algorithms (\u2113 1regularization, Random Forests, XGBoost, and Multivariate Adaptive Regression Splines) in several sample sizes, and compare them in terms of their bias, mean squared error, and type-1 and type-2 errors, to unadjusted estimators and to fully adjusted main terms logistic regression with all available variables included. Furthermore, we introduce a new R package adjrct (D\u00edaz and Williams 2021) that can be used to perform model-robust covariate adjustment for ordinal and time-to-event outcomes, and provide R code that can be used to replicate our simulation analyses with other data sources.",
            "cite_spans": [
                {
                    "start": 590,
                    "end": 611,
                    "text": "Marshall et al. 2020)",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1071,
                    "end": 1093,
                    "text": "Benkeser et al. (2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In what follows, we focus on estimating intention-to-treat effects and refer to study arm assignment simply as treatment. We focus on estimation of marginal treatment effects, defined as a contrast between study arms in the marginal distribution of the outcome. We further assume that we have data on n trial participants, represented by n independent and identically distributed copies of data O i : i = 1, . . . , n. We assume O i is distributed as P, where we make no assumptions about the functional form of P except that treatment is independent of baseline covariates (by randomization). We denote a generic draw from the distribution P by O. We use the terms \"baseline covariate\" and \"baseline variable\" interchangeably to indicate a measurement made before randomization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimands"
        },
        {
            "text": "We are interested in making inferences about a feature of the distribution P. We use the word estimand to refer to such a feature. We describe example estimands, which include those used in our simulations studies, below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimands"
        },
        {
            "text": "For ordinal outcomes, assume the observed data is O = (W, A, Y ), where W is a vector of baseline covariates, A is the treatment arm, and Y is an ordinal variable that can take values in {1, . . . , K}. Let F (k, a) = P(Y \u2264 k | A = a) denote the cumulative distribution function for patients in arm A = a, and let f (k, a) = F (k, a) \u2212 F (k \u2212 1, a) denote the corresponding probability mass function. For notational convenience we will sometimes use the \"survival\" function instead: S(k, a) = 1 \u2212 F (k, a). The average log-odds ratio is then equal to",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ordinal Outcomes"
        },
        {
            "text": "and the Mann-Whitney estimand is equal to",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Ordinal Outcomes"
        },
        {
            "text": "The Mann-Whitney estimand can be interpreted as the probability that a randomly drawn patient from the treated arm has a better outcome than a randomly drawn patient from the control arm, with ties broken at random (Ahmad 1996) . The average log-odds ratio is more difficult to interpret and we discourage its use, but we include it in our comparisons because it is a non-parametric extension of the parameter \u03b2 estimated by the commonly used proportional odds model logit{F (k, a)} = \u03b1 k + \u03b2a (D\u00edaz et al. 2016 ).",
            "cite_spans": [
                {
                    "start": 215,
                    "end": 227,
                    "text": "(Ahmad 1996)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 494,
                    "end": 511,
                    "text": "(D\u00edaz et al. 2016",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Ordinal Outcomes"
        },
        {
            "text": "For time to event outcomes, we assume the observed data is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Time to Event Outcomes"
        },
        {
            "text": "where C is a right-censoring time denoting the time that a patient is last seen, and 1{E} is the indicator variable taking the value 1 on the event E and 0 otherwise. We further assume that events are observed at discrete time points {1, . . . , K} (e.g., days) as is typical in clinical trials. The difference in restricted mean survival time is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Time to Event Outcomes"
        },
        {
            "text": "and can be interpreted as a contrast comparing the expected survival time within the first K time units for the treated arm minus the control arm (Chen and Tsiatis 2001; Royston and Parmar 2011). The risk difference at a user-given time point k is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Time to Event Outcomes"
        },
        {
            "text": "and is interpreted as the difference in survival probability for a patient in the treated arm minus the control arm. We note that the MW and RD parameters may be meaningful for both ordinal and time-to-event outcomes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Time to Event Outcomes"
        },
        {
            "text": "For the sake of generality, in what follows we use a common data structure O = (W, A, \u2206 = 1{Y \u2264 C}, Y ) for both ordinal and survival outcomes, where for ordinal outcomes C = K if the outcome is observed and C = 0 if it is missing. Many approaches for estimation of marginal treatment effects using covariate adjustment in randomized trials invoke a model relating the outcome and the baseline covariates within strata of treatment. It is important that the consistency and interpretability of the treatment effect estimates do not rely on the ability to correctly posit such a model. Specifically, in a recent draft guidance (U.S. Food and Drug Administration 2021), the FDA states: \"Sponsors can perform covariate adjusted estimation and inference for an unconditional treatment effect ... in the primary analysis of data from a randomized trial. The method used should provide valid inference under approximately the same minimal statistical assumptions that would be needed for unadjusted estimation in a randomized trial.\" The assumption of a correctly specified model is not typically part of the assumptions needed for an unadjusted analysis, and should therefore be avoided when possible.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimators"
        },
        {
            "text": "All estimands described in this paper can be computed from the cumulative distribution functions (CDF) F (\u00b7, a) for a \u2208 {0, 1}, which can be estimated using the empirical cumulative distribution function (ECDF) or the Kaplan-Meier estimator. Model-robust, covariate adjusted estimators have been developed for the CDF, including, e.g., Chen and Tsiatis (2001) We focus on the model-robust, covariate adjusted estimators of Moore and van der Laan (2009b), D\u00edaz et al. (2016) , and . These estimators have at least two advantages compared to unadjusted estimators based on the ECDF or the Kaplan-Meier estimator. First, with time-to-event outcomes, the adjusted estimator can achieve consistency under an assumption of censoring being independent of the outcome given study arm and baseline covariates (C \u22a5 \u22a5 Y | A, W ), rather than the assumption of censoring in each arm being independent of the outcome marginally (C \u22a5 \u22a5 Y | A) required by unadjusted estimators. The former assumption is arguably more likely to hold in typical situations where patients are lost to follow-up due to reasons correlated with their baseline variables. Second, in large samples and under regularity conditions, the adjusted estimators of D\u00edaz et al. (2016) and can be at least as precise as the unadjusted estimator (this requires that missingness/censoring is completely at random, i.e., that in each arm a \u2208 {0, 1}, C \u22a5 \u22a5 (Y, W )|A = a), under additional assumptions.",
            "cite_spans": [
                {
                    "start": 455,
                    "end": 473,
                    "text": "D\u00edaz et al. (2016)",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1219,
                    "end": 1237,
                    "text": "D\u00edaz et al. (2016)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Estimators"
        },
        {
            "text": "Additionally, under regularity conditions, the three aforementioned adjusted estimators are asymptotically normal. This allows the construction of Wald-type confidence intervals and corresponding tests of the null hypothesis of no treatment effect.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Estimators"
        },
        {
            "text": "While we make no assumption on the functional form of the distribution P (except that treatment is independent of baseline variables by randomization), implementation of our estimators requires a working model for the following conditional probability",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "In time-to-event analysis, this probability is known as the conditional hazard. The expression working model here means that we do not assume that the model represents the true relationship between the outcome and the treatment/covariates. Fitting a working model for m is equivalent to training a prediction model for m (specifically, a prediction model for the probability of Y = k, \u2206 = 1 given Y \u2265 k, A = a, W ), and we sometimes refer to the model fit as a predictor.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "In our simulation studies, we will use the following working models, fitted in a dataset where each participant contributes a row of data corresponding to each time k = 1 through k = Y :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "\u2022 The following pooled main terms logistic regression (LR) logit{m \u03b2 (k, a, W )} = \u03b2 a,0,k + \u03b2 \u22a4 a,1 W estimated with maximum likelihood estimation. Note that this model has (i) separate parameters for each study arm, and (ii) in each arm, intercepts for each possible outcome level k.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "\u2022 The above model fitted with an \u2113 1 penalty on the parameter \u03b2 a,1 (\u2113 1 -LR, Tibshirani 1996; Park and Hastie 2007).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "\u2022 A random forest classification model (RF, Breiman 2001).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "\u2022 An extreme gradient boosting tree ensemble (XGBoost, Friedman 2001 ).",
            "cite_spans": [
                {
                    "start": 45,
                    "end": 68,
                    "text": "(XGBoost, Friedman 2001",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "\u2022 Multivariate adaptive regression splines (MARS, Friedman 1991) .",
            "cite_spans": [
                {
                    "start": 43,
                    "end": 64,
                    "text": "(MARS, Friedman 1991)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "For RF, XGBoost, and MARS, the algorithms are trained in the whole sample {1, . . . , n}. For these algorithms, we also assessed the performance of cross-fitted versions of the estimators. Cross-fitting is sometimes necessary to guarantee that the regularity assumptions required for asymptotic normality of the estimators hold when using data-adaptive regression methods (Klaassen 1987; Zheng and van der Laan 2011; Chernozhukov et al. 2018) , and is performed as follows. Let V 1 , . . . , V J denote a random partition of the index set {1, . . . , n} into J prediction sets of approximately the same size. That is, V j \u2282 {1, . . . , n}; J j=1 V j = {1, . . . , n}; and V j \u2229V j \u2032 = \u2205. In addition, for each j, the associated training sample is given by T j = {1, . . . , n}\\V j . Let m j denote the prediction algorithm trained in T j . Letting j(i) denote the index of the prediction set which contains observation i, cross-fitting entails using only observations in T j(i) for fitting models when making predictions about observation i. That is, the outcome predictions for each subject i are given by m j(i) (u, a, W i ). We let \u03b7 j(i) = ( m j(i) , \u03c0 A , \u03c0 C ) for cross-fitted estimators and \u03b7 j(i) = ( m, \u03c0 A , \u03c0 C ) for non-cross-fitted ones. RF, XGBoost, and MARS were fit using the ranger (Wright and Ziegler 2017), xgboost (Chen et al. 2021), and earth (Milborrow 2020) R packages, respectively. Hyperparameter tuning was performed using cross-validation with the origami (Coyle and Hejazi 2020) R package.",
            "cite_spans": [
                {
                    "start": 372,
                    "end": 387,
                    "text": "(Klaassen 1987;",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 388,
                    "end": 416,
                    "text": "Zheng and van der Laan 2011;",
                    "ref_id": null
                },
                {
                    "start": 417,
                    "end": 442,
                    "text": "Chernozhukov et al. 2018)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Prediction algorithms"
        },
        {
            "text": "Our simulation studies use the TMLE procedure presented in . We will refer to that estimator as TMLE with improved efficiency, or IE-TMLE. We will first present the TMLE of (Moore and van der Laan 2009b), which constitutes the basis for the construction of the IE-TMLE.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "In the supplementary materials we present some of the efficiency theory underlying the construction of the TMLE. Briefly, TMLE is a framework to construct estimators \u03b7 j(i) that solve the efficient influence function estimating equation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "is the efficient influence function for S(k, a) in the non-parametric model that only assumes treatment A is independent of baseline variables W (which holds by design), defined in the supplementary materials. TMLE enjoys desirable properties such as local efficiency, outcome model robustness under censoring completely at random, and asymptotic normality, under regularity assumptions. TMLE estimator definition: Given a predictor m constructed as in the previous subsection and any k, a, the corresponding TMLE estimation procedure for F (k, a) can be summarized in the next steps:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "1. Create a long-form dataset where each participant i contributes the following row of data corresponding to each time u = 0 through k:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "where 1{X} is the indicator variable taking value 1 if X is true and 0 otherwise. 3. Fit a model \u03c0 A (a, W ) for the probability P(A = a | W ). Note that, in randomized trials, this model may be correctly specified by a logistic regression logit \u03c0 A (1, W ) = \u03b1 0 + \u03b1 \u22a4 1 W . Let \u03c0 A (a, W i ) denote the prediction of the model for individual i.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "4. Fit a model \u03c0 C (u, a, W ) for the censoring probabilities P( Y = u, \u2206 = 0 | Y \u2265 u, A = a, W ). For time-to-event outcomes, this is a model for the censoring probabilities. For ordinal outcomes, the only possibilities are that C = 0 (outcome missing) or C = K (outcome observed); in this case we only fit the aforementioned model at u = 0 and we set \u03c0 C (u, a, W ) = 0 for each u > 0. For either outcome type, if there is no censoring (i.e., if P (\u2206 = 1) = 1), then we set \u03c0 C (u, a, W ) = 0 for all u. Let \u03c0 C (u, a, W i ) denote the prediction of this model for individual i, i.e., using the baseline variable values from individual i.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Targeted minimum loss based estimation (TMLE)"
        },
        {
            "text": "For each individual i and each u \u2264 k, compute a \"clever\" covariate H Y,k,u as a function of m, \u03c0 A , and \u03c0 C as detailed in the supplementary materials. The outcome model fit m is then updated by fitting the following logistic regression \"tilting\" model with single parameter \u01eb and offset based on m:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "This can be done using standard statistical software for fitting a logistic regression of the indicator variable 1{ Y = u, \u2206 = 1} on the variable H Y,k,u using offset logit m(u, a, W ) among observations with Y \u2265 u and A = a in the long-form dataset from step 1. The above model fitting process is iterated where at the beginning of each iteration we replace m in the above display and in the definition of H Y,k,u by the updated model fit. We denote the maximum number of iterations that we allow by i max .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "6. Let m(u, a, W i ) denote the estimate of m(u, a, W i ) for individual i at the final iteration of the previous step. Note that this estimator is specific to the value k under consideration.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "7. Compute the estimate of S(k, a) = 1 \u2212 F (k, a) as the following standardized estimator",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "and let the estimator of F (k, a) be 1 \u2212S TMLE (k, a).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "This estimator was originally proposed by Moore and van der Laan (2009b). The role of the clever covariate H Y,k,u is to endow the resulting estimator S(k, a) with properties such as model-robustness compared to unadjusted estimators. In particular, it can be shown that this estimator is efficient when the working model for m is correctly specified. The specific form of the covariate H Y,k,u is given in the supplementary materials. Throughout, the notation m is used to represent the predictor constructed as in Section 3.1 and which is an input to the above TMLE algorithm, while m denotes the updated version of this predictor that is output by the above TMLE algorithm at step 6. IE-TMLE estimator definition: In Section 4 we will compare several machine learning procedures for estimating m in finite samples. The estimators used in the simulation study are the IE-TMLE of , where in addition to updating the initial estimator for the outcome regression m, we also update the estimators of the treatment and censoring mechanisms. Specifically, we replace step 5 of the above procedure with the following: 5. For each individual i construct \"clever\" covariates H Y,k,u , H A , and H C,k,u (defined in the supplementary materials) as a function of m, \u03c0 A , and \u03c0 C . For each k = 1, . . . , K, the model fits are then iteratively updated using logistic regression \"tilting\" models:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "where the iteration is necessary because H Y,k,u , H A , and H C,k,u are functions of m, \u03c0 A , and \u03c0 C that must be updated at each step. As before, for ordinal outcomes we only fit the aforementioned model at u = 0 and we set \u03c0 C (u, a, W ) = 0 for each u > 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "We useS IE\u2212TMLE to denote this estimator. The updating step above combines ideas from Moore and van der Laan (2009b), Gruber and van der Laan (2012), and Rotnitzky et al. (2012) to produce an estimator with the following properties:",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 128,
                    "text": "Gruber and",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 129,
                    "end": 153,
                    "text": "van der Laan (2012), and",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 154,
                    "end": 177,
                    "text": "Rotnitzky et al. (2012)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "(i) Consistency and at least as precise as the Kaplan-Meier and inverse probability weighted estimators;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "(ii) Consistency under violations of independent censoring (unlike the Kaplan-Meier estimator) when either the censoring or survival distributions, conditional on covariates, are estimated consistently and censoring is such that C \u22a5 \u22a5 Y | W, A; and (iii) Nonparametric efficiency when both of these distributions are consistently estimated at rate n 1/4 . Please see for more details on these estimators, which are implemented in the R package adjrct (D\u00edaz and Williams 2021). Next, we present a result (Theorem 1) stating asymptotic normality ofS TMLE using machine learning for prediction that avoids some limitations of existing methods, and present a consistent estimator of its variance. In Section 4 we present simulation results where we evaluate the performance ofS IE\u2212TMLE for covariate adjustment in COVID-19 trials for hospitalized patients. We favorS IE\u2212TMLE in our numerical studies because, unlikeS TMLE , it satisfies property (i) above. The simulation uses Wald-type hypothesis tests based on the asymptotic approximation of Theorem 1, where we note that the variance estimator in the theorem is consistent forS TMLE but it is conservative forS IE\u2212TMLE (Moore and van der Laan 2009b).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5."
        },
        {
            "text": "Most available methods to construct confidence intervals and hypothesis tests in the statistics literature are based on the sampling distribution of the estimator. While using the exact finite-sample distribution would be ideal for this task, such distributions are notoriously difficult to derive for our problem in the absence of strong and unrealistic assumptions (such as linear models with Gaussian noise). Thus, here we focus on methods that rely on approximating the finite-sample distribution using asymptotic results as n goes to infinity. In order to discuss existing methods, it will be useful to introduce and compare the following assumptions:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotically correct confidence intervals and hypothesis tests for TMLE combined with machine learning"
        },
        {
            "text": "A1. Censoring is completely at random, i.e., C \u22a5 \u22a5 (Y, W ) | A = a for each treatment arm a.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Asymptotically correct confidence intervals and hypothesis tests for TMLE combined with machine learning"
        },
        {
            "text": "We abbreviate m(k, a, W ) and m(k, a, W ) by m and m, respectively. Assume the estimator m is consistent in the sense that || m \u2212 m|| = o P (1) for all k \u2208 {1, . . . , K} and a \u2208 {0, 1}. We also assume that there exists a \u03b4 > 0 such that \u03b4 < m < 1 \u2212 \u03b4 with probability 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "A3. Assume the estimator m converges to a possibly misspecified limit m 1 in the sense that || m \u2212 m 1 || = o P (1) for all k \u2208 {1, . . . , K} and a \u2208 {0, 1}, where we emphasize that m 1 can be different from the true regression function m. We also assume that there exists a \u03b4 > 0 such that \u03b4 < m 1 < 1 \u2212 \u03b4 with probability 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "For estimators m of m that use cross-fitting, the function m consists of J maps (one for each training set) from the sample space of O to the interval [0, 1]. In this case, by convention we define || m \u2212 m|| in A2 as the average across the J maps of the L 2 (P) norm of each such map minus m. Convergence of || m \u2212 m|| to 0 in probability is then equivalent to the same convergence where m is replaced by the corresponding map before cross-fitting is applied. The same convention is used in A3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "There are at least two results on asymptotic normality forS TMLE relevant to the problem we are studying. The first result is a general theorem for TMLE (see Appendix A.1 of van der Laan and Rose 2011), stating that the estimator is asymptotically normal and efficient under regularity assumptions which include A2. Among other important implications, this asymptotic normality implies that the variance of the estimators can be consistently estimated by the empirical variance of the efficient influence function. This means that asymptotically correct confidence intervals and hypothesis tests can be constructed using a Wald-type procedure. As stated above, it is often undesirable to assume A2 in the setting of a randomized trial, as it is a much stronger assumption than what would be required for an unadjusted estimator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "The second result of relevance to this paper establishes asymptotic normality of S(k, a) under assumptions that include A3 (Moore and van der Laan 2009a). The asymptotic variance derived by these authors depends on the true outcome regression function m, and is thus difficult to estimate. As a solution, the authors propose to use a conservative estimate of the variance whose computation does not rely on the true regression function m. While this conservative method yields correct type 1 error control, its use is not guaranteed to fully covert precision gains from covariate adjustment into power gains.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "We note that the above asymptotic normality results from related works rely on the additional condition that the estimator m lies in a Donsker class. This assumption may be violated by some of the data-adaptive regression techniques that we consider. Furthermore, we note that resampling methods such as the bootstrap cannot be safely used for variance estimation in this setting. Their correctness is currently unknown when the working model for m is based on data-adaptive regression procedures such as those described in Section 3.1 and used in our simulation studies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "In what follows, we build on recent literature on estimation of causal effects using machine learning to improve upon the aforementioned asymptotic normality results on two fronts. First, we introduce cross-fitting (Klaassen 1987; Zheng and van der Laan 2011; Chernozhukov et al. 2018) to avoid the Donsker condition. Second, and most importantly, we present a novel asymptotic normality result that avoids the above limitations of existing methods regarding strong assumptions (specifically A2) and conservative variance estimators (that may sacrifice power).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "The following are a set of assumptions about how components of the TMLE are implemented, which we'll use in our theorem below:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A2. Let ||f ||"
        },
        {
            "text": "For time-to-event outcomes, the initial estimator \u03a0 C (a, u) is set to be the Kaplan-Meier estimator estimated separately within each treatment arm a. For ordinal outcomes, \u03a0 C (a, 0) is the proportion of missing outcomes in treatment arm a and \u03a0 C (a, u) = 0 for u > 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "A6. The initial estimator m(u, a, W ) is constructed using one of the following:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "1. Any estimator in a parametric working model (i.e., a model that can be indexed by a Euclidean parameter) such as maximum likelihood, \u2113 1 regularization, etc.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "2. Any data-adaptive regression method (e.g., random forests, MARS, XGBoost, etc.) estimated using cross-fitting as described above.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "A7. The regularity conditions in Theorem 5.7 of (van der Vaart 1998, p.45) hold for the maximum likelihood estimator corresponding to each logistic regression model fit in step (5) of the TMLE algorithm.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "Theorem 1. Assume A1 and A3-A7 above. Define the variance estimator",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "Then we have for all k \u2208 {1, . . . , K} and a \u2208 {0, 1} that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "Theorem 1 is a novel result establishing the asymptotic correctness of Wald-type confidence intervals and hypothesis tests for the covariate-adjusted estimatorS TMLE (k, a) based on machine learning regression procedures constructed as stated in A6. For example, the confidence intervalS TMLE (k, a) \u00b1 1.96 \u00d7 \u03c3/ \u221a n has approximately 95% coverage at large sample sizes, under the assumptions of the theorem. The theorem licenses the large sample use of any regression procedure for m when combined with the TMLE of Section 3.2, as long as the regression procedure is either (i) based on a parametric model (such as \u2113 1 -regularization) or (ii) based on cross-fitted data-adaptive regression, and the assumptions of the theorem hold. The theorem states sufficient assumptions under which Wald-type tests from such a procedure will be asymptotically correct. Assumption A3 states that the predictions given by the regression method used to construct the adjusted estimator converge to some arbitrary function (i.e., not assumed to be equal to the true regression function). This assumption is akin to Condition 3 assumed by Bloniarz et al. (2016) in the context of establishing asymptotic normality of a covariateadjusted estimator based on \u2113 1 -regularization. We note that this is an assumption on the predictions themselves and not on the functional form of the predictors. Therefore, issues like collinearity do not necessarily cause problems. While this assumption can hold for many off-the-shelf machine learning regression methods under assumptions on the datagenerating mechanism, general conditions have not been established and the assumption must be checked on a case-by-case basis.",
            "cite_spans": [
                {
                    "start": 1122,
                    "end": 1144,
                    "text": "Bloniarz et al. (2016)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "We note that assumption A1 is stronger than the assumption C \u22a5 \u22a5 Y | A = a required by unadjusted estimators such as the Kaplan-Meier estimator. However, if W is prognostic (meaning that W \u22a5 \u22a5 Y | A = a), then the assumption C \u22a5 \u22a5 Y | A = a required by the Kaplan-Meier estimator cannot generally be guaranteed to hold, unless A1 also holds. Thus, our theorem aligns with the recent FDA draft guidance on covariate adjustment in the sense that \"it provides valid inference under approximately the same minimal statistical assumptions that would be needed for unadjusted estimation in a randomized trial\" (U.S. Food and Drug Administration 2021).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "The construction of estimators based on A5 should be avoided if A1 does not hold. Confidence that A1 holds is typically warranted in trials where the only form of right censoring is administrative. When applied to ordinal outcomes, A1 is trivially satisfied if there is no missing outcome data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "Consider the case where censoring is informative such that A1 does not hold, but censoring at random holds (i.e., C \u22a5 \u22a5 Y | W, A). Then consistency of the estimatorsS TMLE andS IE\u2212TMLE will typically require that at least one of two assumptions hold: (a) that the censoring probabilities \u03c0 C (u, a, w) are estimated consistently, or that (b) the outcome regression m(u, a, w) is estimated consistently. To maximize the chances of either of these conditions being true, we recommend the use of flexible machine learning for both of these regressions, including model selection and ensembling techniques such as the Super Learner (van der Laan et al. 2007 ). The conditions for asymptotic normality ofS TMLE andS IE\u2212TMLE under these circumstances are much stronger than those for Theorem 1, and typically include consistent estimation of both \u03c0 C (u, a, w) and m(u, a, w) at certain rates (e.g., each of them converging at n 1/4 -rate is sufficient, see Appendix A.1 of van der Laan and Rose 2011).",
            "cite_spans": [
                {
                    "start": 637,
                    "end": 653,
                    "text": "Laan et al. 2007",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A5."
        },
        {
            "text": "Our data generating distribution is based on a database of over 1,500 patients hospitalized at Weill Cornell Medicine New York Presbyterian Hospital prior to 15 May 2020. The database includes information on patients 18 years of age and older with COVID-19 confirmed through reverse-transcriptase-polymerase-chain-reaction assays. For a full description of the clinical characteristics and data collection methods of the initial cohort sampling, see Goyal et al. (2020) .",
            "cite_spans": [
                {
                    "start": 450,
                    "end": 469,
                    "text": "Goyal et al. (2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Simulation methods"
        },
        {
            "text": "We evaluate the potential to improve efficiency by adjustment for subsets of the following baseline variables: age, sex, BMI, smoking status, whether the patient required supplemental oxygen within three-hours of presenting to the emergency department, number of comorbidities (diabetes, hypertension, COPD, CKD, ESRD, asthma, interstitial lung disease, obstructive sleep apnea, any rheumatological disease, any pulmonary disease, hepatitis or HIV, renal disease, stroke, cirrhosis, coronary artery disease, active cancer), number of relevant symptoms, presence of bilateral infiltrates on chest x-ray, dyspnea, and hypertension. These variables were chosen because they have been previously identified as risk factors for severe disease (Guan et al. 2020; Goyal et al. 2020; Gupta et al. 2020) , and therefore are likely to improve efficiency of covariate-adjusted effect estimators in randomized trials in hospitalized patients.",
            "cite_spans": [
                {
                    "start": 738,
                    "end": 756,
                    "text": "(Guan et al. 2020;",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 757,
                    "end": 775,
                    "text": "Goyal et al. 2020;",
                    "ref_id": null
                },
                {
                    "start": 776,
                    "end": 794,
                    "text": "Gupta et al. 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Simulation methods"
        },
        {
            "text": "Code to reproduce our simulations may be found at https://github.com/nt-williams/covid-RCT-co",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation methods"
        },
        {
            "text": "We consider two types of outcomes: a time-to-event outcome defined as the time from hospitalization to intubation or death, and a six-level ordinal outcome at 14 days posthospitalization based on the WHO Ordinal Scale for Clinical Improvement (Marshall et al. 2020 ). The categories are as follows: 0, discharged from hospital; 1, hospitalized with no oxygen therapy; 2, hospitalized with oxygen by mask or nasal prong; 3, hospitalized with non-invasive ventilation or high-flow oxygen; 4, hospitalized with intubation and mechanical ventilation; 5, dead. For time to event outcomes, we focus on evaluating the effect of treatment on the RMST at 14 days and the RD at 7 days after hospitalization, and for ordinal outcomes we evaluate results for both the LOR and the Mann-Whitney statistic.",
            "cite_spans": [
                {
                    "start": 243,
                    "end": 264,
                    "text": "(Marshall et al. 2020",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Data generating mechanisms"
        },
        {
            "text": "We simulate datasets for four scenarios where we consider two effect sizes (null versus positive) and two baseline variable settings (prognostic versus not prognostic, where prognostic means marginally associated with the outcome). For each sample size n \u2208 {100, 500, 1500} and for each scenario, we simulated 5000 datasets as follows. To generate datasets where covariates are prognostic, we draw n pairs (W, Y ) randomly from the original dataset with replacement. This generates a dataset where the covariate prognostic strength is as observed in the real dataset. To simulate datasets where covariates are not prognostic, we first draw outcomes Y at random with replacement from the original dataset, and then draw covariates W at random with replacement and independent of the value Y drawn.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data generating mechanisms"
        },
        {
            "text": "For each scenario, a hypothetical treatment variable is assigned randomly for each patient with probability 0.5 independent of all other variables. This produces a data generating distribution with zero treatment effect. Next, a positive treatment effect is simulated for time-to-event outcomes by adding an independent random draw from a \u03c7 2 distribution four degrees of freedom to each patient's observed survival time in the treatment arm. This effect size translates to a difference in RMST of 1.04 and RD of 0.10, respectively. To simulate outcomes being missing completely at random, 5% of the patients are selected at random to be censored, and the censoring times are drawn from a uniform distribution between 1 and 14. A positive treatment effect is simulated for ordinal outcomes by subtracting from each patient's outcome in the treatment arm an independent random draw from a four-parameter Beta distribution with support (0, 5) and parameters (3, 15), rounded to the nearest nonnegative integer. This generates effect sizes for LOR of 0.60 and for MW of 0.46.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data generating mechanisms"
        },
        {
            "text": "We evaluate several estimators. First, we evaluate unadjusted estimators based on substituting the empirical CDF for ordinal outcomes and the Kaplan-Meier estimator for time-to-event outcomes in the parameter definitions of Section 2. We then evaluate adjusted estimator S IE\u2212TMLE (k, a) where the working models are: LR: a fully adjusted estimator using logistic regression including all the variables listed in the previous section, \u2113 1 -LR: \u2113 1 regularization of the previous logistic regression, RF: random forests, MARS: multivariate adaptive regression splines, and XGBoost: extreme gradient boosting tree ensembles.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "For estimators RF, MARS, and XGBoost, we further evaluated cross-fitted versions of the working model. For all adjusted estimators the propensity score \u03c0 A is estimated with an intercept-only model (A4), and the censoring mechanism \u03c0 C is estimated using a Kaplan-Meier estimator fitted independently for each treatment arm (A5) (or equivalently for ordinal outcomes the proportion of missing outcomes within each treatment arm).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Confidence intervals and hypothesis tests are performed using Wald-type statistics, which use an estimate of the standard error. The standard error was estimated based on the asymptotic Gaussian approximation described in Theorem 1. We compare the performance of the estimators in terms of the probability of type-1 error, power, the absolute bias, the variance, and the mean squared error.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "We compute the relative efficiency RE of each estimator compared to the unadjusted estimator as a ratio of the mean squared errors. This relative efficiency can be interpreted as the ratio of sample sizes required by the estimators to achieve the same power at local alternatives, asymptotically (van der Vaart 1998). Equivalently, one minus the relative efficiency is the relative reduction (due to covariate adjustment) in the required sample size to achieve a desired power, asymptotically; e.g., a relative efficiency of 0.8 is approximately equivalent to needing 20% smaller sample size when using covariate adjustment.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "In the presentation of the results, we append the prefix CF to cross-fitted estimators. For example, CF-RF will denote cross-fitted random forests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Tables containing the comprehensive results of the simulations are presented in the supplementary materials. In the remainder of this section we present a summary of the results. First, we note that the use of random forests without cross-fitting exhibits very poor performance, failing to appropriately control type-1 error when the effect is null, and introducing significant bias when the effect is positive. We observed this poor performance across all simulations. Thus, in what follows we omit a discussion of this estimator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Results for the LOR in Tables 3 and 11 show that covariate adjusted estimators have better performance than the unadjusted estimator at small sample sizes, even when the covariates are not prognostic. In these cases, the unadjusted estimator is unstable with large variance due to near-empty outcome categories in some simulated datasets, which causes division by near-zero numbers in the unadjusted LOR estimator. Some covariate adjusted estimators fix this problem by extrapolating model probabilities to obtain better estimates of the probabilities in the near-empty cells.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 23,
                    "end": 38,
                    "text": "Tables 3 and 11",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Simulation results"
        },
        {
            "text": "Tables 1-4 (in the web supplementary materials) display the results for the difference in RMST, RD, LOR, and MW estimands when covariates are prognostic and there is a positive effect size. At sample size n = 1500 all adjusted estimators yield efficiency gains, with CF-RF offering the best RE ranging from 0.51 to 0.67 compared to an unadjusted estimator, while appropriately controlling type-1 error. In contrast, the RE of \u2113 1 -LR at n = 1500 ranged from 0.79 to 0.89.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "At sample size n = 500, \u2113 1 -LR, CF-RF, and XGBoost offer comparable efficiency gains, ranging from 0.29 to 0.99. As the sample size decreases to n = 100 most adjusted estimators yield efficiency losses and the only estimator that retains efficiency gains is \u2113 1 -LR, with RE from 0.86 to 0.92. (An exception is in estimation of the LOR, where the RE of \u2113 1 -LR was 0.1 due to the issue discussed above.)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Efficiency gains for \u2113 1 -LR did not always translate into power gains of a Wald-type hypothesis test compared to other estimators (e.g. LR at n = 100), possibly due to biased variance estimation and/or a poor Gaussian approximation of the distribution of the test statistic. At small sample size n = 100 power was uniformly better for a Wald-type test based on LR compared to \u2113 1 -LR. At sample size n = 500 a Wald-type test based on \u2113 1 -LR seemed to dominate all other algorithms, whereas at n = 1500 all algorithms had comparable power very close to one.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Results when the true treatment effect is zero and covariates are prognostic are presented in Tables 5-8 (in the web supplementary materials). At sample size n = 1500, CF-RF generally provides large efficiency gains with relative efficiencies ranging from 0.66 to 0.77.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "For comparison, \u2113 1 -LR has RE ranging from 0.88 to 0.92. As the sample size decreases to n = 500, \u2113 1 -LR and CF-RF both offer the most efficiency gains while retaining type-1 error control, with RE ranging from 0.74 to 0.88. At small sample sizes n = 100, \u2113 1 -LR consistently leverages efficiency gains from covariate adjustment (RE ranging from 0.73 to 0.95) but its type-1 error (ranging from 0.07 to 0.09) is slightly larger than that of the unadjusted estimator. For estimation of LOR and MW, XGBoost has similar results at sample size n = 100.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Tables 9-12 (in the web supplementary materials) show results for scenarios where the covariates are not prognostic of the outcome but there is a positive effect. This case is interesting because it is well known that adjusted estimators can induce efficiency losses (i.e., RE > 1) by adding randomness to the estimator when there is nothing to be gained from covariate adjustment. We found that \u2113 1 -LR uniformly avoids efficiency losses associated with adjustment for independent covariates, with a maximum RE of 1.03. All other covariate adjustment methods had larger maximum RE. At sample size n = 100, the superior efficiency of the \u2113 1 -LR estimator did not always translate into better power (e.g., compared to LR) due to the use of a Wald-test which relies on an asymptotic approximation to the distribution of the estimator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Results when the true treatment effect is zero and covariates are not prognostic are presented in Tables 13-16 (in the web supplementary materials). In this case, \u2113 1 -LR also avoids efficiency losses across all scenarios, while maintaining a type-1 error that is comparable to that of the unadjusted estimator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "Lastly, at large sample sizes all cross-fitted estimators along with logistic regression estimators yield correct type I error, illustrating the correctness of Wald-type tests proved in Theorem 1. Our simulation results also show that Wald-type hypothesis tests based on dataadaptive machine learning procedures fail to control type 1 error if the regressions procedures are not cross-fitted.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Simulation results"
        },
        {
            "text": "In our numerical studies we found that \u2113 1 -regularized logistic regression offers the best tradeoff between type-I error control and efficiency gains across sample sizes, outcome types, and estimands. We found that this algorithm leverages efficiency gains when efficiency gains are feasible, while protecting the estimators from efficiency losses when efficiency gains are not feasible (e.g., adjusting for covariates with no prognostic power). A direction of future research is the evaluation of bootstrap estimators for the variance and confidence intervals of covariate-adjusted estimators, especially for cases where the Wald-type methods evaluated in this manuscript did not perform well (e.g., \u2113 1 -LR at n = 100).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "We also found that logistic regression can result in large efficiency losses for small sample sizes, with relative efficiencies as large as 1.17 for the RMST estimand, and as large as 7.57 for the MW estimand. Covariate adjustment with \u2113 1 -regularized logistic regression solves this problem, maintaining efficiency when covariates are not prognostic for the outcome, even at small sample sizes. However, Wald-type hypothesis tests do not appropriately translate the efficiency gains of \u2113 1 -regularized logistic regression into more powerful tests. This requires the development of tests appropriate for small samples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "We recommend against using the LOR parameter since it is difficult to interpret and the corresponding estimators (even unadjusted ones) can be unstable at small sample sizes. Covariate adjustment with \u2113 1 -LR, CF-MARS, CF-RF, or CF-XGBoost can aid to improve efficiency in estimation of the LOR parameter over the unadjusted estimator when there are near-empty cells at small sample sizes. This improvement in efficiency did not translate into an improvement in power when using Wald-type hypothesis tests, due to poor small-sample Gaussian approximations or poor variance estimators.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "We discourage the use of non-cross-fitted versions of the machine learning methods evaluated (i.e., RF, XGBoost, MARS) for covariate adjustment. Specifically, we found in simulations that non-cross-fitted random forests can lead to overly biased estimators in the case of a positive effect, and to anti-conservative Wald-type hypothesis tests in the case of a null treatment effect. We found that cross-fitting the random forests alleviated this problem and was able to produce small bias and acceptable type-1 error at all sample sizes. This is supported at large sample sizes by our main theoretical result (Theorem 1) which establishes asymptotic correctness of cross-fitted procedures under regularity conditions. In fact, we found that random forests with cross-fitting provided the most efficiency gains at large sample sizes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "Based on the results of our simulation studies, we recommend that cross-fitting with data-adaptive estimators such as random forests and extreme gradient boosting be considered for covariate selection in trials with large sample sizes (n = 1500 in our simulations). In large sample sizes, it is also possible to consider an ensemble approach such as Super Learning (van der Laan et al. 2007 ) that allows one to select the predictor that yields the most efficiency gains. Traditional model selection with statistical learning is focused on the goal of prediction, and an adaptation of those tools to the goal of maximizing efficiency in estimating the marginal treatment effect is the subject of future research.",
            "cite_spans": [
                {
                    "start": 374,
                    "end": 390,
                    "text": "Laan et al. 2007",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "The conditions for asymptotic normality and consistent variance estimation ofS TMLE (k, a) established in Theorem 1 may be restrictive if censoring is informative. In that case, consistency of theS TMLE (k, a) andS IE\u2212TMLE (k, a) estimators requires that censoring at random holds (i.e., C \u22a5 \u22a5 Y | W, A), and that either the outcome regression or censoring mechanism is consistently estimated. Thus, it is recommended to also estimate the censoring mechanism with machine learning methods that allow for flexible regression. Standard asymptotic normality results for theS TMLE (k, a) andS IE\u2212TMLE (k, a) require consistent estimation of both the censoring mechanism and the outcome mechanism at certain rates (e.g., both estimated at a n 1/4 rate is sufficient). The development of estimators that remain asymptotically normal under the weaker condition that at least one of these regressions is consistently estimated has been the subject of recent research (e.g., D\u00edaz Pei-Yun Chen and Anastasios A. Tsiatis. Causal inference on the difference of the restricted mean lifetime between two groups. Biometrics, 57 (4) ",
            "cite_spans": [
                {
                    "start": 966,
                    "end": 970,
                    "text": "D\u00edaz",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "Similarly, define the following function of the censoring distribution:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "Under the assumption C \u22a5 \u22a5 (Y, W ) | A = a for each treatment arm a, we have Y \u22a5 \u22a5 C | A, W and therefore S(k, a, w) and G(k, a, w) have the following product formula representations:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "At each iteration of the estimation algorithm, the auxiliary covariates frS TMLE andS IE\u2212TMLE are constructed as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "where \u03c0 A , S, and \u03a0 C are the estimates in the current step of the iteration. * corresponding author: ild2005@med.cornell.edu",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recommendations and future directions"
        },
        {
            "text": "Before proving Theorem 1 given in the paper, we introduce some notation and efficiency theory for estimation of S(k, a). We will use the notation of . First, we encode a single participant's data vector O = (W, A, \u2206 = 1{Y \u2264 C}, Y = min(C, Y )) using the following longitudinal data structure:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "where R u = 1{ Y = u, \u2206 = 0} and L u = 1{ Y = u, \u2206 = 1}, for u \u2208 {0, . . . , K}. The sequence R 0 , L 1 , R 1 , L 2 . . . , R K\u22121 , L K in the above display consists of all 0's until the first time that either the event is observed or censoring occurs, i.e., time u = Y . In the former case L u = 1; otherwise R u = 1. For a random variable X, we denote its history through time u asX u = (X 0 , . . . , X u ). For a given scalar x, the expressionX u = x denotes element-wise equality. The corresponding vector (5) for participant i is denoted by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "Define the following indicator variables for each u \u2265 1:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "The variable I u is the indicator based on the data through time u \u2212 1 that a participant is at risk of the event being observed at time u; in other words, I u = 1 means that all the variables R 0 , L 1 , R 1 , L 2 ..., L u\u22121 , R u\u22121 in the data vector (5) equal 0, which makes it possible that L u = 1.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "Analogously, J u is the indicator based on the outcome data through time u and censoring data before time u that a participant is at risk of censoring at time u. By convention we let J 0 = 1. The efficient influence function for estimation of S(k, a) (see Moore and van der Laan 2009) is equal to:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "where we have explicitly added the dependence of the auxiliary covariate H Y on (u, A, W ) to the notation, and have denoted the nuisance parameters with \u03b7 = (m, \u03c0 A , \u03c0 C ). In what follows we will use \u03b8 = S(k, a), and will use \u03b8(\u03b7 1 ) to refer to the target parameter evaluated at a specific distribution implied by \u03b7 1 . We will denote Pf = f (o)dP(o), and Ph(t, a, W ) = h(t, a, w)dP(w) for functions f and h. The efficient influence function has important implications for estimation of S(k, a). First, the variance of D \u03b7 (O) is the non-parametric efficiency bound, meaning that it is the smallest possible variance achievable by any regular estimator (Bickel et al. 1997) . Second, the efficient influence function characterizes the first order bias of a plug-in estimator based on data-adaptive regression. Correction for this first order bias will allow us to establish normality of the estimators. Specifically, for any estimate \u03b7 we have the following first order expansion around the true parameter value \u03b8(\u03b7), proved in Lemma 1 in the Supplementary materials of D\u00edaz et al. (2018) :",
            "cite_spans": [
                {
                    "start": 658,
                    "end": 678,
                    "text": "(Bickel et al. 1997)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1075,
                    "end": 1093,
                    "text": "D\u00edaz et al. (2018)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "where Rem 1 is a second order remainder term given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "and \u03b8( \u03b7) is the substitution estimator",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "The following proposition establishing the robustness of D \u03b7 to misspecification of the model m will be useful to prove consistency of the estimator.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "Proposition 1. Let \u03b7 1 = (m 1 , \u03c0 A,1 , \u03c0 C,1 ) be such that either m 1 = m or (\u03c0 A,1 , \u03c0 C,1 ) = (\u03c0 A , \u03c0 C ). Then PD \u03b7 1 = 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "Recall the cross-fitting procedure described in the main document as follows. Let V 1 , . . . , V J denote a random partition of the index set {1, . . . , n} into J prediction sets of approximately the same size. That is, V j \u2282 {1, . . . , n}; J j=1 V j = {1, . . . , n}; and V j \u2229 V j \u2032 = \u2205. In addition, for each j, the associated training sample is given by T j = {1, . . . , n} \\ V j . Let m j denote the prediction algorithm trained in T j . Letting j(i) denote the index of the validation set which contains observation i, cross-fitting entails using only observations in T j(i) for fitting models when making predictions about observation i. That is, the outcome predictions for each subject i are given by m j(i) (u, a, W i ). Since only m and not ( \u03c0 A , \u03c0 C ) is cross-fitted, we let \u03b7 j(i) = ( m j(i) , \u03c0 A , \u03c0 C ) and \u03b7 j(i) = ( m j(i) , \u03c0 A , \u03c0 C ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B Efficiency theory"
        },
        {
            "text": "In what follows we let P n,j denote the empirical distribution of the prediction set V j , and let G n,j denote the associated empirical process n/J(P n,j \u2212 P). Let G n denote the empirical process \u221a n(P n \u2212 P). We use E(g(O 1 , . . . , O n )) to denote expectation with respect to the joint distribution of (O 1 , . . . , O n ), and use a n b n to mean a n \u2264 cb n for universal constants c. The following lemmas will be useful in the proof of the theorem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "Lemma 1. Assume A1, A4, and A5 . Then we have \u03a0 C (k, a, w) does not depend on w, and \u03c0 A (a, w) does not depend on w. Furthermore, we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "for mean-zero functions \u2206 k,a (O i ) and \u039b a (O i ) of (k, a) and O i that do not depend on W i .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "Proof. This lemma follows by application of the Delta method to the non-parametric maximum likelihood estimators \u03c0 A and \u03a0 C .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "Lemma 2. For two sequences a 1 , . . . , a m and b 1 , . . . , b m we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "in the right hand side and expand the sum to notice it is a telescoping sum.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "The proof of Theorem 1 proceeds as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "Proof. Since censoring is completely at random by A1, we have \u03b8 = S(k, a) = S(k, a, w)dP(w). Let \u03b8 =S TMLE (k, a). Define \u03c3 2 = Var[D \u03b7 1 (O)], where \u03b7 1 = (m 1 , \u03c0 A , \u03c0 C ), and let",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "First, note that \u0398 n N (0, 1) by the central limit theorem. We will now show that | \u0398 n \u2212 \u0398 n | = o P (1), which would yield the result in the theorem. First, note that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "where the last inequality follows because |\u03c3/ \u03c3 \u2212 1| = o P (1) (which follows by Lemma 1 and A3) and because |\u0398 n | = O P (1) by the central limit theorem. We will now show that |\u0398 n \u2212 \u0398 n | = o P (1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "An application of (7) with \u03b7 = \u03b7 yields",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "where the second equality follows because P n D \u03b7 = 0 by definition of \u03b7 (see ). This implies\u0398 n \u2212 \u0398 n = B n,2 + B n,1 , where B n,2 = G n (D \u03b7 \u2212 D \u03b7 1 ) and B n,1 = \u221a nRem 1 ( \u03b7).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "We first tackle the case of A6.2, where the estimators for m are cross-fitted. Note that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "and that D \u03b7 j depends on the full sample through the estimate of the parameter \u03b5 of the logistic tilting model. To make this dependence explicit, we introduce the notation D \u03b7 j , \u03b5 = D \u03b7 j . Let \u03b5 1 denote the probability limit of \u03b5, which exists and is finite by Assumption A7. We can find a deterministic sequence \u03b4 n \u2192 0 satisfying P (| \u03b5 \u2212 \u03b5 1 | < \u03b4 n ) \u2192 1. Let F j n = {D \u03b7 j ,\u03b5 \u2212 D \u03b7 1 : |\u03b5 \u2212 \u03b5 1 | < \u03b4 n }. Because the function \u03b7 j is fixed given the training data, we can apply Theorem 2.14.2 of van der Vaart and Wellner (1996) to obtain",
            "cite_spans": [
                {
                    "start": 515,
                    "end": 539,
                    "text": "Vaart and Wellner (1996)",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "where N [ ] (\u03b1 F j n , F j n , L 2 (P)) is the bracketing number and we take F j n = sup \u03b5:|\u03b5\u2212\u03b5 1 |<\u03b4n |D \u03b7 j ,\u03b5 \u2212 D \u03b7 1 | as an envelope for the class F j n . Theorem 2.7.2 of van der Vaart and Wellner (1996) shows",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 209,
                    "text": "Vaart and Wellner (1996)",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "This shows",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "Since D \u03b7 j , \u03b5 \u2192 D \u03b7 1 and \u03b4 n \u2192 0, F j n = o P (1). The above argument shows that sup f \u2208F j n |G n,j f | = o P (1) for each j, conditional on T j . Thus |B n,2 | = o P (1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "In the case of A6.1, where the estimators for m are not cross-fitted but belong in a parametric family, standard empirical process theory such as Example 19.7 of van der Vaart (1998) shows that D \u03b7 takes values in a Donsker class. Therefore, an application of Theorem 19.24 of van der Vaart (1998) yields |B n,2 | = o P (1).",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 182,
                    "text": "van der Vaart (1998)",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "We now show that |B n,1 | = o P (1). First, Lemma 1 along with the Delta method show that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "for some function \u0393 k,a (O) not depending on W . Thus",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "where the last equality follows from Lemma 2. Expression (7) together with the assumptions of the theorem and Proposition 1 show that the estimator \u03b8 is consistent, and thus {S(k, a, w) \u2212 S(k, a, w)}dP(w) = o P (1).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "The central limit theorem shows that G n \u0393 k,a = O P (1), which yields |B n,1 | = o P (1), concluding the proof of the theorem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C Proof of Theorem 1"
        },
        {
            "text": "D.1 Results for simulations with a positive effect and where the covariates are prognostic of the outcome ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D Tables with simulation results"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "A class of Mann-Whitney-Wilcoxon type statistics",
            "authors": [
                {
                    "first": "Ibrahim",
                    "middle": [
                        "A"
                    ],
                    "last": "Ahmad",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "The American Statistician",
            "volume": "50",
            "issn": "4",
            "pages": "324--327",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "origami: Generalized Framework for Cross-Validation",
            "authors": [
                {
                    "first": "Jeremy",
                    "middle": [],
                    "last": "Coyle",
                    "suffix": ""
                },
                {
                    "first": "Nima",
                    "middle": [],
                    "last": "Hejazi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Statistical inference for data-adaptive doubly robust estimators with survival outcomes",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Statistics in Medicine",
            "volume": "38",
            "issn": "15",
            "pages": "2735--2748",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Doubly robust inference for targeted minimum lossbased estimation in randomized trials with missing outcome data",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [
                        "J"
                    ],
                    "last": "Van Der Laan",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Statistics in Medicine",
            "volume": "36",
            "issn": "24",
            "pages": "3807--3819",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Enhanced precision in the analysis of randomized trials with ordinal outcomes",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Elizabeth",
                    "middle": [],
                    "last": "Colantuoni",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Rosenblum",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Biometrics",
            "volume": "72",
            "issn": "2",
            "pages": "422--431",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "adjrct: Efficient Estimators for Survival and Ordinal Outcomes in RCTs Without Proportional Hazards and Odds Assumptions",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Nicholas",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Improved precision in the analysis of randomized trials with survival outcomes, without assuming proportional hazards",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Elizabeth",
                    "middle": [],
                    "last": "Colantuoni",
                    "suffix": ""
                },
                {
                    "first": "Daniel",
                    "middle": [
                        "F"
                    ],
                    "last": "Hanley",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Rosenblum",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Lifetime Data Analysis",
            "volume": "25",
            "issn": "3",
            "pages": "439--468",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "E9 statistical principles for clinical trials. U.S. Food and Drug Administration: CDER/CBER. European Medicines Agency: CPMP/ICH/363/96",
            "authors": [
                {
                    "first": "Ema",
                    "middle": [],
                    "last": "Fda",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Multivariate adaptive regression splines",
            "authors": [
                {
                    "first": "Jerome",
                    "middle": [
                        "H"
                    ],
                    "last": "Friedman",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "The Annals of Statistics",
            "volume": "19",
            "issn": "1",
            "pages": "1--67",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Greedy function approximation: a gradient boosting machine",
            "authors": [
                {
                    "first": "Jerome",
                    "middle": [
                        "H"
                    ],
                    "last": "Friedman",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "The Annals of Statistics",
            "volume": "29",
            "issn": "5",
            "pages": "1189--1232",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Clinical characteristics of Covid-19 in new york city",
            "authors": [
                {
                    "first": "Monika",
                    "middle": [
                        "M"
                    ],
                    "last": "Gulick",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Safford",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "New England Journal of Medicine",
            "volume": "382",
            "issn": "24",
            "pages": "2372--2374",
            "other_ids": {
                "DOI": [
                    "10.1056/NEJMc2010419"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Targeted minimum loss based estimator that outperforms a given estimator",
            "authors": [
                {
                    "first": "Susan",
                    "middle": [],
                    "last": "Gruber",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [
                        "J"
                    ],
                    "last": "Van Der Laan",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "The International Journal of Biostatistics",
            "volume": "8",
            "issn": "1",
            "pages": "1--22",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Clinical characteristics of Coronavirus Disease 2019 in China",
            "authors": [
                {
                    "first": "Zheng-Yi",
                    "middle": [],
                    "last": "Wei-Jie Guan",
                    "suffix": ""
                },
                {
                    "first": "Yu",
                    "middle": [],
                    "last": "Ni",
                    "suffix": ""
                },
                {
                    "first": "Wen-Hua",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Chun-Quan",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "Jian-Xing",
                    "middle": [],
                    "last": "Ou",
                    "suffix": ""
                },
                {
                    "first": "Lei",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Hong",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Chun-Liang",
                    "middle": [],
                    "last": "Shan",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [
                        "S C"
                    ],
                    "last": "Lei",
                    "suffix": ""
                },
                {
                    "first": "Bin",
                    "middle": [],
                    "last": "Hui",
                    "suffix": ""
                },
                {
                    "first": "Lan-Juan",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "Guang",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Kwok-Yung",
                    "middle": [],
                    "last": "Zeng",
                    "suffix": ""
                },
                {
                    "first": "Ru-Chong",
                    "middle": [],
                    "last": "Yuen",
                    "suffix": ""
                },
                {
                    "first": "Chun-Li",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Tao",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "Ping-Yan",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Jie",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Xiang",
                    "suffix": ""
                },
                {
                    "first": "Jin-Lin",
                    "middle": [],
                    "last": "Shi-Yue Li",
                    "suffix": ""
                },
                {
                    "first": "Zi-Jing",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Yi-Xiang",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "Li",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Yong",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "Ya-Hua",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Peng",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "Jian-Ming",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Ji-Yang",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Zhong",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Gang",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Zhi-Jian",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "Jie",
                    "middle": [],
                    "last": "Shao-Qin Qiu",
                    "suffix": ""
                },
                {
                    "first": "Chang-Jiang",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "Nan-Shan",
                    "middle": [],
                    "last": "Shao-Yong Zhu",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "New England Journal of Medicine",
            "volume": "382",
            "issn": "18",
            "pages": "1708--1720",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Systematic evaluation and external validation of 22 prognostic models among hospitalised adults with COVID-19: an observational cohort study",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Rishi",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Marks",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "A"
                    ],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "Akish",
                    "middle": [],
                    "last": "Samuels",
                    "suffix": ""
                },
                {
                    "first": "Tommy",
                    "middle": [],
                    "last": "Luintel",
                    "suffix": ""
                },
                {
                    "first": "Humayra",
                    "middle": [],
                    "last": "Rampling",
                    "suffix": ""
                },
                {
                    "first": "Matteo",
                    "middle": [],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "Arjun",
                    "middle": [],
                    "last": "Quartagno",
                    "suffix": ""
                },
                {
                    "first": "Marc",
                    "middle": [],
                    "last": "Nair",
                    "suffix": ""
                },
                {
                    "first": "Ibrahim",
                    "middle": [],
                    "last": "Lipman",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Abubakar",
                    "suffix": ""
                },
                {
                    "first": "Wai",
                    "middle": [
                        "Keong"
                    ],
                    "last": "Maarten Van Smeden",
                    "suffix": ""
                },
                {
                    "first": "Bryan",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "Mahdad",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Noursadeghi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "European Respiratory Journal",
            "volume": "56",
            "issn": "6",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1183/13993003.03498-2020"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "The risks and rewards of covariate adjustment in randomized trials: an assessment of 12 outcomes from 8 studies",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Brennan",
                    "suffix": ""
                },
                {
                    "first": "Vipul",
                    "middle": [],
                    "last": "Kahan",
                    "suffix": ""
                },
                {
                    "first": "Caroline",
                    "middle": [
                        "J"
                    ],
                    "last": "Jairath",
                    "suffix": ""
                },
                {
                    "first": "Tim",
                    "middle": [
                        "P"
                    ],
                    "last": "Dor\u00e9",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Morris",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Trials",
            "volume": "15",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Consistent estimation of the influence function of locally asymptotically linear estimators",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Chris",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Klaassen",
                    "suffix": ""
                }
            ],
            "year": 1987,
            "venue": "The Annals of Statistics",
            "volume": "15",
            "issn": "4",
            "pages": "1548--1562",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Race to find COVID-19 treatments accelerates",
            "authors": [
                {
                    "first": "Kai",
                    "middle": [],
                    "last": "Kupferschmidt",
                    "suffix": ""
                },
                {
                    "first": "Jon",
                    "middle": [],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Science",
            "volume": "367",
            "issn": "6485",
            "pages": "1412--1413",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Semiparametric estimation of treatment effect with time-lagged response in the presence of informative censoring",
            "authors": [
                {
                    "first": "Xiaomin",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Anastasios",
                    "middle": [
                        "A"
                    ],
                    "last": "Tsiatis",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Lifetime Data Analysis",
            "volume": "17",
            "issn": "4",
            "pages": "566--593",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "A minimal common outcome measure set for COVID-19 clinical research",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Marshall",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Murthy",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "K"
                    ],
                    "last": "Diaz",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "C"
                    ],
                    "last": "Adhikari",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Angus",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Arabi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "The Lancet Infectious Diseases",
            "volume": "20",
            "issn": "",
            "pages": "192--197",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "earth: Multivariate Adaptive Regression Splines",
            "authors": [
                {
                    "first": "Stephen",
                    "middle": [],
                    "last": "Milborrow",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Covariate adjustment in randomized trials with binary outcomes: targeted maximum likelihood estimation",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kelly",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [
                        "J"
                    ],
                    "last": "Moore",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Van Der Laan",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Statistics in Medicine",
            "volume": "28",
            "issn": "1",
            "pages": "39--64",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Increasing power in randomized trials with right censored outcomes through covariate adjustment",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kelly",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [
                        "J"
                    ],
                    "last": "Moore",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Van Der Laan",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of Biopharmaceutical Statistics",
            "volume": "19",
            "issn": "6",
            "pages": "1099--1131",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Landmark estimation of survival and treatment effect in a randomized clinical trial",
            "authors": [
                {
                    "first": "Layla",
                    "middle": [],
                    "last": "Parast",
                    "suffix": ""
                },
                {
                    "first": "Lu",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                },
                {
                    "first": "Tianxi",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Journal of the American Statistical Association",
            "volume": "109",
            "issn": "505",
            "pages": "384--394",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "L1-regularization path algorithm for generalized linear models",
            "authors": [
                {
                    "first": "Mee",
                    "middle": [
                        "Young"
                    ],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "Trevor",
                    "middle": [],
                    "last": "Hastie",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
            "volume": "69",
            "issn": "4",
            "pages": "659--677",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Safety and efficacy of the bnt162b2 mrna covid-19 vaccine",
            "authors": [
                {
                    "first": "Fernando",
                    "middle": [
                        "P"
                    ],
                    "last": "Polack",
                    "suffix": ""
                },
                {
                    "first": "Stephen",
                    "middle": [
                        "J"
                    ],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "Nicholas",
                    "middle": [],
                    "last": "Kitchin",
                    "suffix": ""
                },
                {
                    "first": "Judith",
                    "middle": [],
                    "last": "Absalon",
                    "suffix": ""
                },
                {
                    "first": "Alejandra",
                    "middle": [],
                    "last": "Gurtman",
                    "suffix": ""
                },
                {
                    "first": "Stephen",
                    "middle": [],
                    "last": "Lockhart",
                    "suffix": ""
                },
                {
                    "first": "John",
                    "middle": [
                        "L"
                    ],
                    "last": "Perez",
                    "suffix": ""
                },
                {
                    "first": "Gonzalo",
                    "middle": [
                        "P\u00e9rez"
                    ],
                    "last": "Marc",
                    "suffix": ""
                },
                {
                    "first": "Edson",
                    "middle": [
                        "D"
                    ],
                    "last": "Moreira",
                    "suffix": ""
                },
                {
                    "first": "Cristiano",
                    "middle": [],
                    "last": "Zerbini",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "New England Journal of Medicine",
            "volume": "383",
            "issn": "27",
            "pages": "2603--2615",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Efficient and Adaptive Estimation for Semiparametric Models",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "J"
                    ],
                    "last": "Bickel",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "A J"
                    ],
                    "last": "Klaassen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ritov",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wellner",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Targeted learning ensembles for optimal individualized treatment rules with time-to-event outcomes",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Oleksandr",
                    "middle": [],
                    "last": "Savenkov",
                    "suffix": ""
                },
                {
                    "first": "Karla",
                    "middle": [],
                    "last": "Ballman",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Biometrika",
            "volume": "105",
            "issn": "3",
            "pages": "723--738",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Improved precision in the analysis of randomized trials with survival outcomes, without assuming proportional hazards",
            "authors": [
                {
                    "first": "Iv\u00e1n",
                    "middle": [],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "Elizabeth",
                    "middle": [],
                    "last": "Colantuoni",
                    "suffix": ""
                },
                {
                    "first": "Daniel",
                    "middle": [
                        "F"
                    ],
                    "last": "Hanley",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Rosenblum",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Lifetime Data Analysis",
            "volume": "25",
            "issn": "3",
            "pages": "439--468",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Increasing power in randomized trials with right censored outcomes through covariate adjustment",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Kelly",
                    "suffix": ""
                },
                {
                    "first": "Mark",
                    "middle": [
                        "J"
                    ],
                    "last": "Moore",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Van Der Laan",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of Biopharmaceutical Statistics",
            "volume": "19",
            "issn": "6",
            "pages": "1099--1131",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Asymptotic Statistics",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Van Der",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Vaart",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Weak Convergence and Emprical Processes",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Aad",
                    "suffix": ""
                },
                {
                    "first": "Jon",
                    "middle": [
                        "A"
                    ],
                    "last": "Van Der Vaart",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Wellner",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "; Rubin and van der Laan (2008); Moore and van der Laan (2009b); Stitelman et al. (2011); Lu and Tsiatis (2011); Brooks et al. (2013); Zhang (2014); Parast et al. (2014); Benkeser et al. (2018); D\u00edaz (2019).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "For each individual i, obtain a prediction m(u, a, W i ) for each pair in the set {(u, a) : a = 0, 1; u = 0, . . . , k}.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "and van der Laan 2017; Benkeser et al. 2017; D\u00edaz 2019). Stanbrook. A substantial and confusing variation exists in handling of baseline covariates in randomized controlled trials: a review of trials published in leading medical journals. Journal of Clinical Epidemiology, 63(2):142-153, 2010. Lindsey R. Baden, Hana M. El Sahly, Brandon Essink, Karen Kotloff, Sharon Frey, Rick Novak, David Diemert, Stephen A. Spector, Nadine Rouphael, C. Buddy Creech, et al. Efficacy and safety of the mRNA-1273 SARS-CoV-2 vaccine. New England Journal of Medicine, 384(5):403-416, 2021. David Benkeser, Marco Carone, M. J. Van Der Laan, and P. B. Gilbert. Doubly robust nonparametric inference on the average treatment effect. Biometrika, 104(4):863-880, 2017. David Benkeser, Marco Carone, and Peter B. Gilbert. Improved estimation of the cumulative incidence of rare outcomes. Statistics in Medicine, 37(2):280-293, 2018. David Benkeser, Iv\u00e1n D\u00edaz, Alex Luedtke, Jodi Segal, Daniel Scharfstein, and Michael Rosenblum. Improving precision and power in randomized trials for COVID-19 treatments using covariate adjustment, for binary, ordinal, and time-to-event outcomes. Biometrics, 2020. Adam Bloniarz, Hanzhong Liu, Cun-Hui Zhang, Jasjeet S. Sekhon, and Bin Yu. Lasso adjustments of treatment effect estimates in randomized experiments. Proceedings of the National Academy of Sciences, 113(27):7383-7390, 2016. Leo Breiman. Random forests. Machine Learning, 45(1):5-32, 2001. Jordan C. Brooks, Mark J. van der Laan, Daniel E. Singer, and Alan S. Go. Targeted minimum loss-based estimation of causal effects in right-censored survival data with timedependent covariates: Warfarin, stroke, and death in atrial fibrillation. Journal of Causal Inference, 1(2):235-254, 2013. doi: 10.1515/jci-2013-0001.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": ":1030-1038, 2001. Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, Rory Mitchell, Ignacio Cano, Tianyi Zhou, Mu Li, Junyuan Xie, Min Lin, Yifeng Geng, and Yutian Li. xgboost: Extreme Gradient Boosting, 2021. URL https://CRAN.R-project.org/package=xgboost. R package version 1.4.1.1. Patrick Royston and Mahesh K. B. Parmar. The use of restricted mean survival time to estimate the treatment effect in randomized clinical trials when the proportional hazards assumption is in doubt. Lu Tian, Tianxi Cai, Lihui Zhao, and Lee-Jen Wei. On the covariate-adjusted estimation for an overall treatment difference with data from a randomized comparative clinical trial. Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Sta-//www.fda.gov/regulatory-information/search-fda-guidance-documents/adjusting-cov Mark J. van der Laan and Sherri Rose. Targeted learning: causal inference for observational and experimental data. Springer Science & Business Media, 2011. A. W. van der Vaart. Asymptotic Statistics. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 1998. doi: 10.1017/CBO9780511802256. A. W. van der Vaart. Asymptotic Statistics. Cambridge University Press, 1998. Min Zhang and Peter B. Gilbert. Increasing the efficiency of prevention trials by incorporating baseline covariates. Statistical Communications in Infectious Diseases, 2(1), 2010. doi: 10.2202/1948-4690.1002. Supplementary Materials for Optimizing Precision and Power by Machine Learning in Randomized Trials, with an Application to COVID-19. Williams 1 , Michael Rosenblum 2 , and Iv\u00e1n D\u00edaz * 1 1 Division of Biostatistics, Department of Population Health Sciences, Weill Cornell Medicine. 2 Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health.Denote the survival function for Y at time k \u2208 {1, . . . , K} conditioned on study arm a and baseline variables w by S(k, a, w)",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Simulation results for the RMST of time to intubation or death at day 14 under a positive effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Simulation results for the RD of time to intubation or death at day 7 under a positive effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Simulation results for the LOR of the modified WHO scale at day 14 under a positive effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Simulation results for the MW estimand of the modified WHO scale at day 14 under a positive effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Simulation results for the RMST of time to intubation or death at day 14 under null treatment effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Simulation results for the RD of time to intubation or death at day 7 under null treatment effect and covariates with prognostic power.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Simulation results for the LOR of the modified WHO scale at day 14 under null treatment effect and covariates with prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "Simulation results for the MW estimand of the modified WHO scale at day 14 under null treatment effect and covariates with prognostic power. Estimator n Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff. D.3 Results for simulations with a positive effect and where the covariates are not prognostic of the outcome",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "Simulation results for the RMST of the time to intubation or death at day 14 under a positive effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Simulation results for the RD of the time to intubation or death at day 7 under a positive effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Simulation results for the LOR of the modified WHO scale at day 14 under a positive effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF12": {
            "text": "Simulation results for the MW of the modified WHO scale at day 14 under a positive effect and covariates with no prognostic power. Estimator n Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff. D.4 Results for simulations with null treatment effect and where the covariates are not prognostic of the outcome",
            "latex": null,
            "type": "table"
        },
        "TABREF13": {
            "text": "Simulation results for the RMST of the time to intubation or death at day 14 under null treatment effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF14": {
            "text": "Simulation results for the RD of the time to intubation or death at day 7 under null treatment effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF15": {
            "text": "Simulation results for the LOR of the modified WHO scale at day 14 under null treatment effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        },
        "TABREF16": {
            "text": "Simulation results for the MW of the modified WHO scale at day 14 under null treatment effect and covariates with no prognostic power.Estimatorn Effect size P(Reject H 0 ) n \u00d7 MSE n \u00d7 Var |Bias| Rel. eff.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}