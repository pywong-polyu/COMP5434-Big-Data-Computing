{
    "paper_id": "127bcf8553446cd7296f99a2c3c1fae29f56766e",
    "metadata": {
        "title": "Deep structured residual encoder-decoder network with a novel loss function for nuclei segmentation of kidney and breast histopathology images",
        "authors": [
            {
                "first": "Amit",
                "middle": [],
                "last": "Kumar Chanchal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "National Institute of Technology Karnataka",
                    "location": {
                        "postCode": "Mangaluru-575025",
                        "settlement": "Surathkal",
                        "region": "Karnataka",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Shyam",
                "middle": [],
                "last": "Lal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "National Institute of Technology Karnataka",
                    "location": {
                        "postCode": "Mangaluru-575025",
                        "settlement": "Surathkal",
                        "region": "Karnataka",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Jyoti",
                "middle": [],
                "last": "Kini",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Manipal Academy of Higher Education",
                    "location": {
                        "region": "Manipal",
                        "country": "India"
                    }
                },
                "email": "kinijyoti@gmail.com"
            },
            {
                "first": "Amit",
                "middle": [
                    "Kumar"
                ],
                "last": "Chanchal",
                "suffix": "",
                "affiliation": {},
                "email": "amit.chanchal01@gmail.com"
            }
        ]
    },
    "abstract": [
        {
            "text": "To improve the process of diagnosis and treatment of cancer disease, automatic segmentation of haematoxylin and eosin (H & E) stained cell nuclei from histopathology images is the first step in digital pathology. The proposed deep structured residual encoder-decoder network (DSREDN) focuses on two aspects: first, it effectively utilized residual connections throughout the network and provides a wide and deep encoder-decoder path, which results to capture relevant context and more localized features. Second, vanished boundary of detected nuclei is addressed by proposing an efficient loss function that better train our proposed model and reduces the false prediction which is undesirable especially in healthcare applications. The proposed architecture experimented on three different publicly available H&E stained histopathological datasets namely: (I) Kidney (RCC) (II) Triple Negative Breast Cancer (TNBC) (III) MoNuSeg-2018. We have considered F1-score, Aggregated Jaccard Index (AJI), the total number of parameters, and FLOPs (Floating point operations), which are mostly preferred performance measure metrics for comparison of nuclei segmentation. The evaluated score of nuclei segmentation indicated that the proposed architecture achieved a considerable margin over five state-of-the-art deep learning models on three different histopathology datasets. Visual segmentation results show that the proposed DSREDN model accurately segment the nuclear regions than those of the state-of-the-art methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Recent research trends shows that the deep learning framework performed very well for segmentation, detection, and other computer vision tasks. In the last decade, with the advancement of new types of computation systems, proper strategies to handle overfitting problems to train very deep networks, and lots of changes that are suitable for deep learning networks. Segmentation of haematoxylin and eosin (H & E) from stained histopathology image is the primary prerequisite in artificial pathology. The histopathology slides preparations are discussed by Slaoui M et al. in [27] , by the following steps: (I) Tissue collection (II) Fixation (III) Embedding (IV) Sectioning (V) De-paraffining (VI) Staining (VII) Digitizing the slide by whole slide imaging (WSI). There are several tissue collection methods which are fine needle aspiration, biopsy needle, excisional biopsy, etc. A larger biopsy has more information than a small needle biopsy because it preserves the large cellular context of histopathology slides. Fixation of tissue is needed for chemical and physical stabilization. Embedding is required to give a particular shape to the tissue such that it can be easily cut by the machines. Sectioning is required to get all three-dimensional tissue information in the form of many thin slides two-dimensional information. Removing paraffin from the sectioned tissue is important, without de-paraffining the tissue may look a little bit blurry in some of the portions. Staining of the tissue slides is required because it is not visible or kind of transparent under bright field microscopy. The most widely used stains for histopathology images are hematoxylin and eosin. Segmentation tasks can be categorized into traditional or handcrafted feature extraction techniques and CNN-based deep learning approaches. Traditional segmentation methods are mostly based on similarity-based approach, discontinuity-based approach, watershed techniques, active contour methods and their variants, superpixel, and clustering-based methods, etc. The similarity-based approach discussed by Gonzalez R C et al. in [8] , is based on local thresholding, global thresholding, adaptive thresholding, Otsu's thresholding, region growing, region splitting, and merging, where these methods try to group and segment similar pixels. For image histogram having flat valleys, the similarity-based approach does not work well and the wrong selection of threshold value may result in over-segmentation and under-segmentation in this case. The discontinuity-based approach tries to segment those pixels which are isolated in some manner like point, line, edges, and it is a mask processing-based approach. This method requires different operators at different stages. Cousty J et al. proposed watershed segmentation method in [4] , based on the split, merge, and marker controlled watershed. Detected boundaries in the watershed method depend on cell complexity. Song T et al. proposed active contour segmentation in [28] , where they consider intensity information and local edge information for the detection of object boundaries. Superpixel segmentation method used by Albayrak A et al. in [1] , is based on the cluster of connected pixels having identical features. It considers the color and coordinate information of neighbor pixels. This technique provides better regional information but is not very effective in the case of cell segmentation. Clustering based segmentation proposed by Win K Y et al. in [37] , performs grouping based on their similarity. In recent research work, most of the authors reported that, the segmentation technique based on a deep convolutional neural network performs far better than the conventional segmentation approach. A concise review of CNN based approach is presented in Section 2. Deep learning segmentation methods also suffer from many challenges. If we categorize these challenges, it will come under the following aspects.",
            "cite_spans": [
                {
                    "start": 556,
                    "end": 574,
                    "text": "Slaoui M et al. in",
                    "ref_id": null
                },
                {
                    "start": 575,
                    "end": 579,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 2109,
                    "end": 2112,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 2808,
                    "end": 2811,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 2999,
                    "end": 3003,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 3175,
                    "end": 3178,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 3494,
                    "end": 3498,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "1. Due to large variations of tissue appearance and a varied spectrum of class and sub-class of tissues, it is difficult to recognize. 2. Segmentation of complex boundaries, overlapped boundaries, and vanishing boundaries is not an easy task. 3. Preparation of ground truth in the case of supervised learning is also a big challenge.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Supervision of experienced pathologists is necessary since prediction accuracy totally depends on annotated ground truth.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In the case of complex histopathology images, conventional methods suffer either over-segmentation or under-segmentation. The proposed approach focuses to separate the overlapped and vanished nuclear regions from histopathology images. To address the challenges in the segmentation of nuclei from histopathology images our contributions in this paper as follows. The manuscript is organised as follows: A brief introduction about segmentation and challenges associated with it is described in Section 1. A concise review of CNN based approach is presented in Section 2. Sections 3 and 4 cover detailed analysis of the proposed method and their implementation with benchmark datasets. Experimental results and discussions are presented in Section 5 and finally, we concluded our work in Section 6.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Most of the CNN architecture for the cell segmentation task consists of an encoder-decoder path for feature extraction. Many of the recent research utilizes lots of potential opportunities like improving training strategies, handling overfitting problems, better optimization methods, and many other strategies to obtain better prediction accuracy. However, many authors reported their result which is very efficient but an accurate and efficient segmentation algorithm is still open-ended research due to complexity in histopathology images. One of the significant contributions by Ronneberger et al. in [26] , called UNet, provides a very good direction and a dramatic breakthrough in the field of biomedical image segmentation. UNet is a symmetric encoder-decoder convolutional network and has a large number of feature channels that allow to extract feature to the higher layer in a deep network. Repeated application of (3 x 3) convolution kernel followed by ReLU activation, (2 x 2) maxpooling and (2 x 2) up-sampling with stride size of 2 and (1 x 1) convolution followed by sigmoid activation at final layer, total of 23 layers in the network. In [36] , Veit A et al. realized through their experiment that if a network has a collection of paths then a shorter path is enough during training or a very deep path is not required during training. These multiple paths do not strongly depend on each other and their smooth co-relation with multiple valid paths increases the performance of the network. In [22] , Milletari F et al. proposed an encoder-decoder convolutional network for three-dimensional data by utilizing dice loss as a loss function. Their empirical evaluation achieves better performance on the strong imbalance dataset. In [24] , Nogues I et al. proposed architecture for detection of lymph nodes by two fully nested supervised convolutional networks and a structured conditional random field optimization strategy. Degradation of information in deeper network addressed by Kaiming He et al. in [9] , by introducing deep residual network which is easier to train and optimize. The residual connection is realized by skipping one or more layers to restore the flow of information in a deep network. For segmentation and detection of histological objects, Chen H et al. in [5] , introduced a contour-aware model that extracts multi-level information under auxiliary supervision. In [10] , Huang G et al. proposed a convolutional network, which strengthens the overall flow of the input feature map by feeding preceding layer input as well as original input both. Their experiment also indicates that due to integration of identity mapping, model learns more compact features and reduces the vanishing gradient problem. In the case of an imbalanced dataset, predictions are biased towards high precision and low recall which is not tolerable especially in the medical field. This problem is addressed by Salehi S M et al. in [29] , which trained the deep network, even with a highly imbalanced dataset, and handled effectively where false negative prediction is much dangerous than false positive. The behavior of loss function such as weighted cross-entropy and dice loss with different learning rates examined by Sudre C H et al. in [30] , on medical images and house dataset. Their experiment found that as the level of imbalance increases overlap measure-based loss function is more effective. A very efficient in terms of memory and time for semantic segmentation of road and indoor scene, an encoder-decoder architecture called SegNet by Badrinarayanan V et al. in [3] . SegNet generates a sparse feature decoder that upsamples with the transferred pool and its lower resolution input from its encoder. To accurately segment near boundary regions Zhou S et al. in [38] , used a residual network with a dilated convolution block. They utilize many hierarchical blocks in parallel to retrieve meaningful semantic information. To handle class imbalance problems or reducing false-negative predictions in healthcare, Hashemi S R in [11] proposes a 3D-dense CNN with Tversky index-based asymmetric similarity loss that trains the network with the lowest surface distance. Complex boundary-related segmentation problem addressed by Naylor P et al. in [25] , by formulating a loss function based on intra-nuclear distance. Their encoder-decoder model outperform on FCN, FCN+PP, Mask R-CNN, U-Net, U-Net+PP experimented with TNBC and MoNuSeg datasets. Meaningful extensions in standard encoder-decoder by incorporating an additional module called attention gate by Schlemper J et al. in [31] , and attention as well as residual mechanism by Lal S et al. in [20] , where network is trained in such a way that it suppress irrelevant features while highlight the meaningful feature. For road scene segmentation Malekijoo A et al. in [23] , utilized the autoencoder-based model where convolution, deconvolution, and pyramid pooling were applied for reinforcing the local feature. For the segmentation of microscopic, MR, and CT images an encoder-decoder architecture by Zhou S et al. in [39] , linked meaningful connections to precisely locate the complex boundaries. For the segmentation of nuclei in pathology images, Lal S et al. model [21] , consists of adaptive color deconvolution, multiscale thresholding followed by morphological operations, and other post-processing steps. For the segmentation of medical images, a novel loss function by Karimi D et al. in [16] , estimated Hausdorff distance using the morphological operation method, distance transformation method, and by circularly convoluted kernels of different radius. Utilizing methods of reduction of the Hausdorff distance, they train CNN for various microscopy images and compare their results with a commonly used loss function. Hanif M S et al. in [12] , proposed a competitive residual network by stacking multiple residual units called wide network. Their study concluded that the performance of such a wide network is better than the deep and thin network. Chanchal A K et al. and Aatresh A A et al. in [2, 6] , used separable convolution pyramid pooling and dimension-wise pyramid pooling for nuclei segmentation tasks. A summary of state-of-the-art DL techniques useful for biomedical image segmentation is presented in Table 1 .",
            "cite_spans": [
                {
                    "start": 605,
                    "end": 609,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1155,
                    "end": 1159,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 1511,
                    "end": 1515,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1518,
                    "end": 1536,
                    "text": "Milletari F et al.",
                    "ref_id": null
                },
                {
                    "start": 1748,
                    "end": 1752,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 2020,
                    "end": 2023,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 2296,
                    "end": 2299,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 2405,
                    "end": 2409,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 2947,
                    "end": 2951,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 3257,
                    "end": 3261,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 3593,
                    "end": 3596,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 3792,
                    "end": 3796,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 4056,
                    "end": 4060,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 4273,
                    "end": 4277,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 4607,
                    "end": 4611,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 4677,
                    "end": 4681,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 4850,
                    "end": 4854,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 5103,
                    "end": 5107,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 5255,
                    "end": 5259,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 5464,
                    "end": 5479,
                    "text": "Karimi D et al.",
                    "ref_id": null
                },
                {
                    "start": 5483,
                    "end": 5487,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 5836,
                    "end": 5840,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 6094,
                    "end": 6097,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 6098,
                    "end": 6100,
                    "text": "6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [
                {
                    "start": 6313,
                    "end": 6320,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Related work"
        },
        {
            "text": "For the segmentation of microscopy images, an encoder-decoder architecture is best suited due to the fact that if an encoder has regular convolution layers, max-pooling layers, then it captures the context in the image very effectively. Decoder path presents the output by gradually applying up-sampling, collecting relevant features from the encoder, and enable precise localization. For each of the filters in the encoder side of the DSREDN network shown in Fig. 1 , accepts input of flexible size. we have applied regular (3 x 3) 2D standard convolution, batch normalization, and max-pooling. To avoid the saturation problems and loss of information while going deeper into the network, we restored the lower layered information by creating an additional path parallel to the main path of the network. These two paths are not strongly correlated to each other and it avoids vanishing gradient problems. For each of the filter sizes, the entire encoder side of the DSREDN network consists of three convolution layers in parallel with a single convoluted path that focused to flow the more contextual feature in the network. Since the effectiveness of the decoder path to generate the final output depends on the collection of contextual features from the encoder side, we have a slightly different path on the decoder side, for the optimal processing of the collected feature. By this procedure, our DSREDN network becomes wide and deep instead of thin and deep. DSREDN network trained with RGB images of size (512 x 512 x 3). Five stages of encoder path having five different filter sizes and corresponding decoder path consist of (a) 2D convolution of kernel size (3 x 3) with ReLU activation (b) A high-resolution layer (c) (2 x 2) max-pooling layer in encoder path to reduce the spatial size of the image and corresponding (2 x 2) up-sampling layer in decoder side to collect contextual feature from encoder side by concatenation operation (d) At the final stage a (1 x 1) convolution is used to map the size (512 x 512 x 16) to (512 x 512 x 1) with sigmoid activation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 460,
                    "end": 466,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Proposed architecture"
        },
        {
            "text": "Convolution layers have a set of kernels to extract the features and weights of those kernels are automatically learnable. We have given an RGB image of size (512 x 512 x 3). For the input vector x(j, k) and filter size h(j, k) the normal 2D convolution results y(j, k) and is expressed in (1) .",
            "cite_spans": [
                {
                    "start": 290,
                    "end": 293,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Standard convolution layer"
        },
        {
            "text": "We have an image of (M x M x C), if we apply N kernel of (K x K x C) on it with a step size of S and padding P, the size of resulting image as in (2) . For single-step size and no padding the resulting feature size as in (3).",
            "cite_spans": [
                {
                    "start": 146,
                    "end": 149,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Standard convolution layer"
        },
        {
            "text": "Proposed DSREDN architecture has a high-resolution encoder and more effective decoder shown in Fig. 2 . The mathematical expression of the flow of features is shown below and it can be seen that these two paths are not strongly dependent on each other and their smooth co-relation with multiple valid paths increases the performance of the network and will reduce the vanishing gradient problem. This wide network strengthens the overall extracted feature map by feeding preceding layer input as well as the original input. Our experiment also indicates that due to the integration of this wide network our model got the additional discriminative capability and is able to retrieve more compact features compared to the other existing deep model. Aggregation of features for high-resolution encoder path is as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 95,
                    "end": 101,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "High resolution layer"
        },
        {
            "text": "Aggregation of features for high resolution decoder path can be expressed as: ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "High resolution layer"
        },
        {
            "text": "If the dataset is linearly separable, then the linear activation function does well, but in the real world, the dataset is rarely linearly separable. The output of the neural network is based on the linear operation of variables and a linear function does not allow the model to learn complex relations. Nonlinear activation function can process almost any nonlinear relation and provide very good prediction results. Nonlinearity helps the model to adapt or generalized with a variety of data. Rectified Linear Unit (ReLU) is the most popular activation function in deep learning models. We have used ReLU activation function in all of the hidden layers of the DSREDN model due to computational simplicity, representational sparsity, and its linear behavior. ReLU activation function and its derivative are expressed mathematically by (4), and (5). At the final stage a (1 x 1) convolution is used to map the size (512 x 512 x 16) to (512 x 512 x 1) with sigmoid activation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Activation function"
        },
        {
            "text": "To make the architecture scale-invariant, rotation invariant, and location invariant pooling is used. pooling operation on (4 x 4) with a step size of S= 2 and kernel K=(2 x 2) is shown in Fig. 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 189,
                    "end": 195,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Pooling layer"
        },
        {
            "text": "A deep network has large number of layers and there are lots of activity happening between these layers. It has been observed that if input at each of the pre-activation is with a single distribution, ideally it should be Gaussian distributed or mean-centered then it is easier to train a very deep network. A constant and small change at an earlier stage of input leads to a significant effect on the latter layer and in that case due to internal co-variate shift shown in Fig. 4 , it is difficult to train a very deep network. To avoid such problems we have applied batch-normalization used by Ioffe S et al. in [13] , so that all input coming from the ",
            "cite_spans": [
                {
                    "start": 614,
                    "end": 618,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 474,
                    "end": 480,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Batch normalization"
        },
        {
            "text": "We have used Google Colab notebook (with 12 GB Google GPU), Tensorflow 2.0, and Keras API for simulation of all models. The most important part of any optimization method in deep learning is about gradient which is used to update the weights. Equation (6) is a general weight update equation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training and implementation"
        },
        {
            "text": "We have used Adam (Adaptive Moment Estimation) optimizer. Adam [19] has integrated with nice features of the RMSProp and Stochastic gradient descent (SGD) with Momentum (SGD +Momentum) algorithms. The final update equation is a combination of RMSProp and SGD with Momentum. Adam is one of the fastest optimization approaches for recent research trends. Followings are the significant controlling parameters that we fine-tuned: (a) Learning rate= 0.0001 for training of all the model with three datasets (b) Weight decay constant, we have selected learning rate and weight decay constant based on trial and error (c) Batch size=4, Larger batch size allow us to parallelize computations to a greater degree but lead to poor generalization (D) The size of the convolution filter used as per available resources. We have considered F1-score used by Lal S et al. and Aatresh A A et al. in [2, 21] , and Aggregated Jaccard Index (AJI) used by Naylor P et al. in [25] , the total number of parameters, and FLOPs (Floating point operations), which are mostly preferred performance measure metrics for comparison of nuclei segmentation.",
            "cite_spans": [
                {
                    "start": 63,
                    "end": 67,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 884,
                    "end": 887,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 888,
                    "end": 891,
                    "text": "21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 956,
                    "end": 960,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Training and implementation"
        },
        {
            "text": "(I) Kidney dataset: Kidney dataset was prepared by Irshad H et al. [14] . it consists of 730 H&E images (400 Pixels x 400 Pixels) and their corresponding ground truth. (II) Triple negative breast cancer (TNBC) dataset: TNBC dataset was prepared by Naylor P et al. [25] . This dataset consists of 50 H&E images (512 Pixels x 512 Pixels) of breast tissue. We performed data augmentation like horizontal flip, vertical flip and rotation such that we have sufficient number of training images. (III) MoNuSeg-2018 dataset: This dataset was prepared by Kumar N et al. [17] and included seven different organs of colon, breast, kidney, liver, stomach, prostate, and bladder. It consists of 44 images (1000 Pixels x 1000 Pixels). We performed patch processing of obtained images to make the input image of dimension (512 Pixels x 512 Pixels) and some data augmentation techniques to make the training set larger.",
            "cite_spans": [
                {
                    "start": 67,
                    "end": 71,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 264,
                    "end": 268,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 562,
                    "end": 566,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Datasets"
        },
        {
            "text": "The deep learning model learns by means of loss function which is driven by a calculation of error. This error is the difference of actual value and predicted value as in the regression problem and the difference of actual distribution and predicted distribution in the case of a classification problem. With the help of suitable optimization algorithm, the loss function learns to reduce the error. Following are the most preferred loss function in the case of binary segmentation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Loss function"
        },
        {
            "text": "Binary Cross-Entropy is a combination of sigmoid activation and Cross-Entropy, which is discussed by Chanchal et al. in [6] . we have a countable set of symbols X=",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 123,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Binary cross-entropy"
        },
        {
            "text": "Y is the discrete probability distribution which represents the probability of occurrence of those symbols. Y= {y 1 , y 2 .........y i , y n }. Let y i = p(x i ) where y i is the probability of occurrence of symbol x i . According to the concept of entropy the minimum number of bits required to represent the i th symbol is x i = log(1/y i ). If we consider entire distribution Y to achieve the optimal number of bits per transmission through some channel, then the optimal number of bits is known as entropy. Mathematically it is just the expected number of bits per encoding and can be shown in (7).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Binary cross-entropy"
        },
        {
            "text": "now let X = . If distributions of Y and Y are equal then entropy and cross-entropy are equal. For binary cross-entropy we consider two classes, class C 1 and class C 2 . (a) Label 1 {0, 1} represents the ground truth label for class C 1 , S 1 represents the sigmoid score for class C 1 (b) Label 2 = {1 \u2212 Label 1 } represents the ground truth label for class C 2 , S 2 = (1 \u2212 S 1 ) represents the sigmoid score for class C 2 . Binary cross-entropy (BCE) used by Ronneberger et al. in [26] and is defined by (8) , and (9).",
            "cite_spans": [
                {
                    "start": 484,
                    "end": 488,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 507,
                    "end": 510,
                    "text": "(8)",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Binary cross-entropy"
        },
        {
            "text": "For skewed data sometimes weighted binary cross entropy (WBCE) loss function performs better. Normally for minority class we assign higher weights. The purpose of using class weights is to change the loss function so that the training loss cannot be minimized within a limit. It is a way of passing weights to the binary cross entropy loss function used by Jadon S et al. and Sugino T et al. in [15, 35] . Equation (10) describes the weighted binary cross entropy loss function. Here \u03b2 is used to assign weights to the more relevant objects. y, and y represents ground truth and predicted results respectively.",
            "cite_spans": [
                {
                    "start": 395,
                    "end": 399,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 400,
                    "end": 403,
                    "text": "35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Weighted binary cross-entropy"
        },
        {
            "text": "In case of binary segmentation and having class imbalance dice loss is a most preferred overlap measure used by Milletari F et al. and Sudre C H et al. in [22, 30] . There is little difference in the calculation of loss using intersection over union (IOU) and dice. Equations (11) , (12) , and (13) describes the dice loss function.",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "[22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 160,
                    "end": 163,
                    "text": "30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 276,
                    "end": 280,
                    "text": "(11)",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 283,
                    "end": 287,
                    "text": "(12)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Dice loss"
        },
        {
            "text": "While the calculation of dice is by calculating the harmonic mean of precision and recall.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dice loss"
        },
        {
            "text": "The proposed loss function has conceived the idea of dynamically scaled cross-entropy loss. Dynamically scaled cross entropy loss which is a pixel based loss that automatically assigns more weight to the portion that of our interest or object portion and down-weight to those which are of less interest with the help of hyper parameter \u03b1 t and \u03b3 coefficient.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed loss function"
        },
        {
            "text": "Dynamically scaled cross-entropy loss For highly imbalanced dataset dynamically scaled cross-entropy loss predict with better accuracy. It is a dynamically scaled cross entropy loss that automatically assigns more weight to the portion that of our interest or object portion and down-weight to those which are of less interest. From BCE loss we can derived dynamically scaled cross-entropy loss Jadon S et al. and Sugino T et al. in [15, 35] , and can be expressed in (14) , (15) , (16) , and (17) .",
            "cite_spans": [
                {
                    "start": 433,
                    "end": 437,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 438,
                    "end": 441,
                    "text": "35]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 468,
                    "end": 472,
                    "text": "(14)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 475,
                    "end": 479,
                    "text": "(15)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 482,
                    "end": 486,
                    "text": "(16)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 493,
                    "end": 497,
                    "text": "(17)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Proposed loss function"
        },
        {
            "text": "To make the notation more convenient we can write: Now BCE can be written in a very precise manner as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed loss function"
        },
        {
            "text": "A modulation factor (1 \u2212 p t ) \u03b3 , \u03b3 > 0 to down-weight the background and assign more weight to object region and a hyper-parameter \u03b1 t , 0 < \u03b1 < 1 make the above loss function dynamically scaled cross-entropy loss. This loss can be expressed in (18) .",
            "cite_spans": [
                {
                    "start": 247,
                    "end": 251,
                    "text": "(18)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Proposed loss function"
        },
        {
            "text": "Proposed loss function calculated based on the concept of dynamically scaled cross entropy loss in (17) . Segmentation results indicated that the dynamically scaled Dice loss shown in (19) better train any encoder-decoder model with histopathological data. Superiority of proposed loss function with F1-score/IOU score of two benchmark model is shown in Table 2 .",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 103,
                    "text": "(17)",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 184,
                    "end": 188,
                    "text": "(19)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [
                {
                    "start": 354,
                    "end": 361,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Dynamically Scaled Cross \u2212 Entropy Loss (p t ) = \u2212\u03b1 t (1 \u2212 p t ) \u03b3 log(p t ) (17)"
        },
        {
            "text": "DI indicates Dice index and the value of \u03b1 t and \u03b3 ranges 0 < \u03b1 t < 1 , 1 < \u03b3 < 3, \u03b2 value can be used to tune false negative and false positive. The training and validation curve showed in Figs. 5, 6, and 7 indicates the proposed loss function better represents the validation data. For the best representation of the model, the training and validation curve should be closer to each other and for optimal bias and variance, they should be collapsed to each other. The model has both curves closer to each other, that model is robust during testing. The large gap between the training and validation curve indicates the model is working very well in training data but not as much as for validation data. Using proposed loss our model is much generalized to work on different types of data. Values in bold indicate the highest performance score of the proposed model among other comparable models",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dynamically Scaled Cross \u2212 Entropy Loss (p t ) = \u2212\u03b1 t (1 \u2212 p t ) \u03b3 log(p t ) (17)"
        },
        {
            "text": "We compared our proposed model with five other CNN models which is a benchmark in the field of biomedical image segmentation. We expressed our simulation results in terms of F1-Score used by Lal S et al. and Aatresh A A et al. in [2, 21] and Aggregated Jaccard Index (AJI) used by Naylor P et al. in [25] . By calculating the harmonic mean of precision and recall, the F1 score is calculated and is the most preferred method to measure the retrieved information. AJI is a connected component-based method which is the improved version of the pixel-based global Jaccard Index. A higher AJI score indicates a better segmentation model. In Table 3 , we compared the DSREDN model with five benchmark models for three histopathological datasets, and Table 4 shows a computational complexity comparison of the proposed DSREDN architecture with other segmentation architecture. Performance is measured in terms of F1 Score, AJI score, and the total number of trainable parameters that describe the training time and complexity. We have considered six sample test images, (two from each of the histopathological datasets) for visualization of results, and presented in Figs. 8, 9, and 10.",
            "cite_spans": [
                {
                    "start": 230,
                    "end": 233,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 234,
                    "end": 237,
                    "text": "21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 300,
                    "end": 304,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [
                {
                    "start": 637,
                    "end": 644,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 745,
                    "end": 752,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Results and discussion"
        },
        {
            "text": "U-Net architecture has repeated application of 3x3 unpadded convolution, a total of 23 convolution layers, 2x2 max-pooling for downsampling, 2x2 upsampling, and each convolution layer followed by ReLU activation. Finally, 1x1 convolution is followed by sigmoid activation. U-Net architecture clearly identifies 51 nuclei out of 57 in image 1, 45 nuclei out of 53 nuclei in image 2. Around 10% to 15% nuclei are not clearly identified by this architecture. Some of the nuclei are in clustered form and some are not predicted. Two nuclei are clustered in image-1 and six are in image 2. Four additional ducts and six additional ducts are predicted in image 1 and image-2 respectively which are actually not desirable. This architecture almost follows a similar prediction pattern in the other four images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "U-Net prediction"
        },
        {
            "text": "A very efficient in terms of memory and time for semantic segmentation of road and indoor scene an encoder-decoder architecture called SegNet. To generate a sparse feature, decoder upsample with the transferred pool and its lower resolution input from its encoder. Its encoder has 13 convolution layers, followed by ReLU activation similar to VGG-16, batch normalized, 2x2 max-pooling, and corresponding 13 layer decoder. SegNet has a slightly different decoder that uses the max-pooling indices to upsample the feature and convolution with a trainable filter bank. Visual segmentation by SegNet indicates that a number of clearly detected nuclei is (80-85%), which is less than U-net. Overlapped nuclei are lesser than U-Net and no undesirable things are detected by this model. The number of partially detected nuclei increases compared to U-Net and is three and two in image-1 and image-2 respectively. The number of nuclei not identified is maximum in this case.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SegNet prediction"
        },
        {
            "text": "Meaningful extensions in standard U-Net by incorporating an additional unit called attention gate that is trained in such a way that it suppresses irrelevant features while highlighting the meaningful feature by strengthening the capability of the decoder. With the use of attention coefficients, this architecture increases the receptive field which is the key for better semantic segmentation. Their attention module can be easily integrated into any other segmentation method. The number of clearly identified nuclei is almost similar to the SegNet model but partially detected nuclei is maximum in this case. Almost 5% of the nuclei are not predicted by this model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Attention U-Net prediction"
        },
        {
            "text": "Complex boundary-related segmentation problem addressed by formulating a loss function based on intranuclear distance. They compare their model, namely DIST with FCN, FCN+PP, Mask R-CNN, U-Net, U-Net+PP for triple-negative breast cancer dataset and other datasets which are of seven different organs. In this architecture, all nuclei are identified either partially or completely. 82-88% nuclei clearly detected. The problem of segmentation of clustered nuclei, somehow solved, but not completely solved. Partially detected nuclei are less as compared to SegNet, U-Net, and Attention U-Net.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dist prediction"
        },
        {
            "text": "For the segmentation of microscopic, MR, and CT images an encoder-decoder architecture that linked meaningful connections to precisely locate the complex boundaries. A dense connection path with dilated convolution blocks guided by modified binary cross-entropy, accurately detects vanishing boundaries of blurry images. In this architecture, prediction accuracy is slightly improved as compared to the Dist algorithm, but with an improvement in accuracy, false detection cases also increased in HMEDN. Four additional things in image-1 and two undesirable things in image-2 have been found.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "HMEDN prediction"
        },
        {
            "text": "The best part of our model is that 90% of the nuclei are clearly identified and the rest of the nuclei are either in clustered form or partially detected. Out of 57 and 53 nuclei in image-1 and image-2, 55 and 48 nuclei clearly detected. Less number of additional and undesirable ducts were detected in the proposed model. Partially detected nuclei are very less in number.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed DSREDN prediction"
        },
        {
            "text": "The predicted image has a morphology closer to the ground truth image. The problem with overlapped nuclei is somehow solved, but not completely solved.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed DSREDN prediction"
        },
        {
            "text": "Less number of undesirable nuclei indicates the less number of false-positive cases, that are less in number in the proposed model. The number of nuclei that have not been detected is a case of false-negative, which is never desirable especially in health care. The predicted morphology closer to the ground truth image means those images have high clinical and diagnostic values. For clinical purposes, the proposed DSREDN model outperforms the five most recent state-of-the-art models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Clinical significance"
        },
        {
            "text": "Reported results of different datasets show that there is a lack of generalizability in the segmentation of the nuclear region from histopathology images. This is mainly due to the histopathology slide and their corresponding ground truth preparation since the clinical significance of predicted output is highly dependent on the prepared slide and their semantic pixel-wise labeling. Another issue of this study is that segmented boundaries are not fine enough and it is still sub-optimal for clinical use. Issue of partially detected nuclei, overlapped nuclei, and false-positive cases found to be proportional to cell complexity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Limitations"
        },
        {
            "text": "This paper proposed a CNN-based architecture called a deep structured residual encoderdecoder network (DSREDN), that addressed two major concerns in automatic nuclei segmentation. The first major concern was to identify nuclei from histopathology images having a widely varied spectrum with a large number of artifacts. This problem was addressed by introducing a powerful encoder-decoder having two paths that have more discriminative capability and were able to retrieve relevant and compact textural information. The implemented networks effectively leverage the strength of residual learning as well as encoder-decoder architecture by incorporating wide and deep network paths that strengthen the intermediate features. We proposed an efficient loss function through careful experimentation and analysis to segment the nuclei having complex or vanishing boundaries which were the second major issue in the segmentation task. We have used the most preferred performance matrices F1-score and AJI score by performing experiments on the three different publicly available H&E stained histopathological datasets. The obtained quality metrics and predicted nuclear regions of the proposed framework were better in comparison to those of the state-of-the-art models. Although the proposed model produced excellent results, the feature space may be enriched further by incorporating a high-performance feature extraction module. Also, the proposed method can be generalized to work on more image modalities. This study is a binary segmentation of histopathology images, here we can only segment the nuclear regions. In future, we can grade these nuclear regions into their sub-types. Few innovative applications of different image modalities were reported by Shoeibi A et al. in [32, 33] , in which generative adversarial networks (GANs), recurrent neural networks (RNNs), autoencoders (AEs), convolutional neural networks (CNNs), deep neural networks (DNNs), and other hybrid networks have been developed for automated detection of COVID-19 and multiple sclerosis. In [18, 34] , Khodatars M et al. and Sadeghi D et al. illustrated the applicability of deep learning for the diagnosis of autism spectrum disorder and schizophrenia disease detection. These examples highlight how the field of computer-aided diagnosis systems is changing rapidly, and that there may still be numerous applications that have not been focused on yet.",
            "cite_spans": [
                {
                    "start": 1776,
                    "end": 1780,
                    "text": "[32,",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1781,
                    "end": 1784,
                    "text": "33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 2066,
                    "end": 2070,
                    "text": "[18,",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 2071,
                    "end": 2074,
                    "text": "34]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Automatic cell segmentation in histopathological images via two-staged superpixel-based algorithms",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Albayrak",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Bilgin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med Biol Eng Comput",
            "volume": "57",
            "issn": "3",
            "pages": "653--665",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Efficient deep learning architecture with dimension-wise pyramid pooling for nuclei segmentation of histopathology images",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Aatresh",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "P"
                    ],
                    "last": "Yatgiri",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Chanchal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ravi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "S"
                    ],
                    "last": "Raghavendra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lal",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kini",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput Med Imaging Graph",
            "volume": "93",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compmedimag.2021.101975"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Badrinarayanan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kendall",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cipolla",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans Pattern Anal Mach Intell",
            "volume": "39",
            "issn": "12",
            "pages": "2481--2495",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Watershed cuts: Thinnings, shortest path forests, and topological watersheds",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cousty",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Bertrand",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Najman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Couprie",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Trans Pattern Anal Mach Intell",
            "volume": "32",
            "issn": "5",
            "pages": "925--939",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "DCAN: deep contour-aware networks for accurate gland segmentation",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Qi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Heng",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1604.02677v1"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Efficient and robust deep learning architecture for segmentation of kidney and breast histopathology images",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Chanchal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lal",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kini",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput Electr Eng",
            "volume": "92",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compeleceng.2021.107177"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "High-resolution deep transferred ASPPU-Net for nuclei segmentation of histopathology images",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Chanchal",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lal",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kini",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Int J Comput Assist Radiol Surg",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/s11548-021-02497-9"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Digital image processing",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "C"
                    ],
                    "last": "Gonzalez",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "E"
                    ],
                    "last": "Woods",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE conference on computer vision and pattern recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2016.90"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE conference on computer vision and pattern recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "2261--2269",
            "other_ids": {
                "DOI": [
                    "10.1109/CVPR.2017.243"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Asymmetric loss functions and deep densely-connected networks for highly-imbalanced medical image segmentation: application to multiple sclerosis lesion detection",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Hashemi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Salehi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erdogmus",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Prabhu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Warfield",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gholipour",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "1721--1735",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2018.2886371"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Competitive residual neural network for image classification",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Hanif",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bilal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ICT Express",
            "volume": "6",
            "issn": "1",
            "pages": "28--37",
            "other_ids": {
                "DOI": [
                    "10.1016/j.icte.2019.06.001"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Batch normalization: accelerating deep network training by reducing internal covariate shift",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ioffe",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1502.03167"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Irshad",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M"
                    ],
                    "last": "Kouhsari",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Waltz",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Bucur",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Nowak",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "W"
                    ],
                    "last": "Knoblauch",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "H"
                    ],
                    "last": "Beck",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Pacifc symposium on biocomputing (PSB)",
            "volume": "",
            "issn": "",
            "pages": "294--305",
            "other_ids": {
                "DOI": [
                    "10.13140/2.1.4067.0721"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "A survey of loss functions for semantic segmentation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jadon",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2006.14822"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Reducing the Hausdorff distance in medical image segmentation with convolutional neural networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Karimi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Salcudean",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans Med Imaging",
            "volume": "39",
            "issn": "2",
            "pages": "499--513",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "A dataset and a technique for generalized nuclear segmentation for computational pathology",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Verma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bhargava",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vahadane",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sethi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans Med Imaging",
            "volume": "36",
            "issn": "7",
            "pages": "1550--1560",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Deep learning for neuroimaging-based diagnosis and rehabilitation of Autism Spectrum Disorder: A review",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khodatars",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shoeibi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sadeghi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ghaasem",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jafari",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moridian",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khadem",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zare",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosravi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Nahavandi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Berk",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput Biol Med",
            "volume": "139",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.compbiomed.2021.104949"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Adam: A method for stochastic optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "International conference on learning representations",
            "volume": "9",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980v9"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "NucleiSegNet: Robust deep learning architecture for the nuclei segmentation of liver cancer histopathology images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lal",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Alabhya",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kanfade",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kini",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput Biol Med",
            "volume": "128",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "A robust method for nuclei segmentation of H&E stained histopathology images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kanfade",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Alabhya",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dsouza",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Chanchal",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Maneesh",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Peryail",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kini",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "7th IEEE international conference on signal processing and integrated networks (SPIN2020)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "V-Net: fully convolutional neural networks for volumetric medical image segmentation, fourth international conference on 3D vision (3DV)",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Milletari",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Ahmadi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "565--571",
            "other_ids": {
                "DOI": [
                    "10.1109/3DV.2016.79"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Convolution-deconvolution architecture with the pyramid pooling module for semantic segmentation",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Malekijoo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Fadaeieslam",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Multimed Tools Appl",
            "volume": "78",
            "issn": "",
            "pages": "32379--32392",
            "other_ids": {
                "DOI": [
                    "10.1007/s11042-019-07990-7"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Automatic lymph node cluster segmentation using holistically-nested neural networks and structured optimization in CT images",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Nogues",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Medical image computing and computerassisted intervention -MICCAI 2016",
            "volume": "9901",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-46723-845"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Segmentation of nuclei in histopathology images by deep regression of the distance map",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Naylor",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lae",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Reyal",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Walter",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Trans Med Imaging",
            "volume": "38",
            "issn": "2",
            "pages": "448--459",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "U-Net: Convolutional networks for biomedical image segmentation",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ronneberger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Fischer",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Brox",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proc. MICCAI",
            "volume": "",
            "issn": "",
            "pages": "234--241",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Histopathology procedures: from tissue sampling to histopathological evaluation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Slaoui",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Fiette",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Methods Mol Biol (Methods Protoc)",
            "volume": "691",
            "issn": "",
            "pages": "69--82",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Dual-channel active contour model for megakaryocytic cell segmentation in bone marrow trephine histology images",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Sanchez",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Eidaly",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Rajpoot",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans Biomed Eng",
            "volume": "64",
            "issn": "12",
            "pages": "2913--2923",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Tversky loss function for image segmentation using 3D fully convolutional deep networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Salehi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erdogmus",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gholipour",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proc, Int Workshop Mach Learn Med Imag",
            "volume": "",
            "issn": "",
            "pages": "379--387",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations. In: Deep learning in medical image analysis and multimodal learning for clinical decision support",
            "authors": [
                {
                    "first": "C",
                    "middle": [
                        "H"
                    ],
                    "last": "Sudre",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Vercauteren",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ourselin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Cardoso",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "240--248",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Attention gated networks: Learning to leverage salient regions in medical images",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Schlemper",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Oktay",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schaap",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Heinrich",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kainz",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Glocker",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Med Image Anal",
            "volume": "53",
            "issn": "",
            "pages": "197--207",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Automated detection and forecasting of covid-19 using deep learning techniques: a review",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shoeibi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khodatars",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jafari",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moridian",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khadem",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sadeghi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hussain",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zare",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [
                        "A"
                    ],
                    "last": "Sani",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bazeli",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Khozeimeh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosravi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Nahavandi",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Shi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2007.10785"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Applications of deep learning techniques for automated multiple sclerosis detection using magnetic resonance imaging: A review, Image and Video Processing",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shoeibi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Khodatars",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jafari",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moridian",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rezaei",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Khozeimeh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Gorriz",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Heras",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Panahiazar",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2105.04881"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "An overview on artificial intelligence techniques for diagnosis of schizophrenia based on magnetic resonance imaging modalities: methods, challenges, and future works",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sadeghi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Shoeibi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Moridian",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khadem",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Alizadehsani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Teshnehlab",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Gorriz",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Nahavandi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2103.03081"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Loss weightings for improving imbalanced brain structure segmentation using fully convolutional networks, healthcare",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sugino",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kawase",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Residual networks behave like ensembles of relatively shallow networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Veit",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wilber",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Belongie",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Neural Inf Process Syst pp",
            "volume": "",
            "issn": "",
            "pages": "550--558",
            "other_ids": {
                "arXiv": [
                    "arXiv:1605.06431"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "2017) K mean clustering based automated segmentation of overlapping cell nuclei in pleural effusion cytology images",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "Y"
                    ],
                    "last": "Win",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Choomchuay",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hamamoto",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "International conference on advanced technologies for communications (ATC)",
            "volume": "",
            "issn": "",
            "pages": "265--269",
            "other_ids": {
                "DOI": [
                    "10.1109/ATC.2017.8167630"
                ]
            }
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Fine-grained segmentation using hierarchical dilated neural networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Adeli",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "In: Medical image computing and computer assisted intervention",
            "volume": "11073",
            "issn": "",
            "pages": "488--496",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "IEEE Transactions on Image Processing",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Adeli",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Yin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lian",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "29",
            "issn": "",
            "pages": "461--475",
            "other_ids": {
                "DOI": [
                    "10.1109/TIP.2019.2919937"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "High resolution encoder path (Left) and decoder path (Right)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Max Pooling, step size S=2 kernel K=2 Multimedia Tools and Applications Internal co-variate shift of batches previous layer guaranteed to be the same distribution and convergence become faster. Batch normalization is an additional layer and works as a regularizer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "..............x i , .x n with probability of occurrence Y = y 1 , y 2 , .......y i , ..y n if we encode symbol X using different symbol X then encoding will require x , i = log 1 y i instead of log 1 y i then we define Cross-Entropy H (Y, Y )",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "8878/0.7732 0.7653/0.6854 0.7460/0.6179 0.9579/0.9261 0.8517/0.7415 0.8065/0.6795 Values in bold indicate the highest performance score of the proposed loss function among other comparable loss functions",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Accuracy and loss plots (Kidney Dataset) (a) Accuracy plot with proposed loss function (b) Accuracy plot with BCE loss function (c) Loss plot with proposed loss function (d) Loss plot with BCE loss function Approximation of dice loss This loss derived from dice coefficient by setting different weight to false positive and false negative with the help of \u03b2 coefficient. Mathematically",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Accuracy and loss plot (TNBC Dataset) (a) Accuracy plot with proposed loss function (b) Accuracy plot with BCE loss function (c) loss plot with proposed loss function (d) Loss plot with BCE loss function",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Accuracy and loss plot (MoNuSeg Dataset) (a) accuracy plot with proposed loss function (b) accuracy plot with BCE loss function (c) loss plot with proposed loss function (d) loss plot with BCE loss function",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Comparison of predicted nuclear regions of five state-of-the-art models on kidney images",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "To strengthen the multi-level intermediate features, our proposed DSREDN model effectively utilized the strength of residual learning. 2. Through empirical evidence and careful experimentation and analysis, we proposed a novel loss function. Visual results and performance matrices indicate that our loss function better trains the model and accurately segment the nuclear regions compared to the state-of-the-art methods.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Summary of state-of-the-art DL techniques used for segmentation of medical images QU Histopathology 2D-CNN, Auxiliary supervision, Transfer learning",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Superiority of proposed loss function F1/AJI with benchmark model",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Performance comparison of different models with three datasets",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Computational complexity comparison of different models",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Conflict of Interests Authors declare that they have no conflict of interest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Declarations"
        },
        {
            "text": "Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "annex"
        }
    ]
}