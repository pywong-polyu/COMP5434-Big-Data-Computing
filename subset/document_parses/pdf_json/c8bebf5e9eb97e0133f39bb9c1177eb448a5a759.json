{
    "paper_id": "c8bebf5e9eb97e0133f39bb9c1177eb448a5a759",
    "metadata": {
        "title": "Wikipedia Citations: A comprehensive dataset of citations with identifiers extracted from English Wikipedia",
        "authors": [
            {
                "first": "Harshdeep",
                "middle": [],
                "last": "Singh",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Robert",
                "middle": [],
                "last": "West",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Giovanni",
                "middle": [],
                "last": "Colavizza",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Amsterdam",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Wikipedia's contents are based on reliable and published sources. To this date, little is known about what sources Wikipedia relies on, in part because extracting citations and identifying cited sources is challenging. To close this gap, we release Wikipedia Citations, a comprehensive dataset of citations extracted from Wikipedia. A total of 29.3M citations were extracted from 6.1M English Wikipedia articles as of May 2020, and classified as being to books, journal articles or Web contents. We were thus able to extract 4.0M citations to scholarly publications with known identifiers -including DOI, PMC, PMID, and ISBN -and further labeled an extra 261K citations with DOIs from Crossref. As a result, we find that 6.7% of Wikipedia articles cite at least one journal article with an associated DOI. Scientific articles cited from Wikipedia correspond to 3.5% of all articles with a DOI currently indexed in the Web of Science. We release all our code to allow the community to extend upon our work and update the dataset in the future. * Corresponding author, g.colavizza@uva.nl 1 https://en.wikipedia.org/wiki/Citation [accessed 2020-01-03].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "\"Citations have several important purposes: to uphold intellectual honesty (or avoiding plagiarism), to attribute prior or unoriginal work and ideas to the correct sources, to allow the reader to determine independently whether the referenced material supports the author's argument in the claimed way, and to help the reader gauge the strength and validity of the material the author has used.\" 1 Wikipedia plays a fundamental role as a source of factual information on the Web: it is widely used by individual users as well as third-party services, such as search engines and knowledge bases [21, 25] . 2 Most importantly, Wikipedia is often perceived and relied upon as a source of \"neutral\" information [26] . The confidence that users and services place on Wikipedia has been found to be usually justified: Wikipedia's content is of general high-quality and up-to-date [33, 16, 11, 19, 32, 7] .",
            "cite_spans": [
                {
                    "start": 396,
                    "end": 397,
                    "text": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 594,
                    "end": 598,
                    "text": "[21,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 599,
                    "end": 602,
                    "text": "25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 605,
                    "end": 606,
                    "text": "2",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 707,
                    "end": 711,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 874,
                    "end": 878,
                    "text": "[33,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 879,
                    "end": 882,
                    "text": "16,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 883,
                    "end": 886,
                    "text": "11,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 887,
                    "end": 890,
                    "text": "19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 891,
                    "end": 894,
                    "text": "32,",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 895,
                    "end": 897,
                    "text": "7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To reach this goal, Wikipedia's verifiability policy mandates that \"people using the encyclopedia can check that the information comes from a reliable source.\" A reliable source is defined, in turn, as a secondary and published, ideally scholarly one. 3 Despite the community's best efforts to add all the needed citations, the majority of articles in Wikipedia might still contain unverified claims, in particular lower-quality ones [22] . The citation practices of editors are also at times not systematic [6, 10] . As a consequence, the efforts to expand and improve Wikipedia's verifiability through citations to sources are increasing [9, 35] .",
            "cite_spans": [
                {
                    "start": 252,
                    "end": 253,
                    "text": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 434,
                    "end": 438,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 508,
                    "end": 511,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 512,
                    "end": 515,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 640,
                    "end": 643,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 644,
                    "end": 647,
                    "text": "35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A crucial question to ask in order to improve Wikipedia's verifiability standards, as well as to better understand its dominant role as a source of information, is the following: what sources are cited in Wikipedia?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "A high portion of citations to sources in Wikipedia refer to scientific or scholarly literature [28] , as Wikipedia is instrumental in providing access to scientific information and in fostering the public understanding of science [20, 13, 22, 37, 24, 46, 23, 41] . Citations in Wikipedia are also useful for users browsing low-quality or underdeveloped articles, as they allow them to look outside of the platform [30] . The literature cited in Wikipedia has been found to positively correlate with the journal popularity, the journal impact factor and to its open access availability [27, 43, 1] . Being cited in Wikipedia can also be considered as an 'altmetric' indicator of impact in itself [42, 18] . A clear influence of Wikipedia on scientific research has in turn been found [44] , despite the general lack of acknowledgement of Wikipedia in the scientific literature [15, 45] . Nevertheless, the evidence on what scientific and scholarly literature is cited in Wikipedia is quite slim. Early studies point to a relative low coverage, indicating that between 1% and 5% of all published journal articles are cited in Wikipedia [34, 39, 49] . Nevertheless, these studies either use of proprietary databases with limited coverage, or only consider specific publishers (PLoS) and academic communities (computer science).",
            "cite_spans": [
                {
                    "start": 96,
                    "end": 100,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 231,
                    "end": 235,
                    "text": "[20,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 236,
                    "end": 239,
                    "text": "13,",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 240,
                    "end": 243,
                    "text": "22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 244,
                    "end": 247,
                    "text": "37,",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 248,
                    "end": 251,
                    "text": "24,",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 252,
                    "end": 255,
                    "text": "46,",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 256,
                    "end": 259,
                    "text": "23,",
                    "ref_id": null
                },
                {
                    "start": 260,
                    "end": 263,
                    "text": "41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 415,
                    "end": 419,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 586,
                    "end": 590,
                    "text": "[27,",
                    "ref_id": null
                },
                {
                    "start": 591,
                    "end": 594,
                    "text": "43,",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 595,
                    "end": 597,
                    "text": "1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 696,
                    "end": 700,
                    "text": "[42,",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 701,
                    "end": 704,
                    "text": "18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 784,
                    "end": 788,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 877,
                    "end": 881,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 882,
                    "end": 885,
                    "text": "45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1135,
                    "end": 1139,
                    "text": "[34,",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 1140,
                    "end": 1143,
                    "text": "39,",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1144,
                    "end": 1147,
                    "text": "49]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Answering the question of what exactly is cited in Wikipedia is challenging for a variety of reasons. First of all, editorial practices are not uniform: citations are often given using citation templates somewhat liberally, 4 making it difficult to detect citations to the same source. Secondly, while some citations contain stable identifiers (e.g., DOIs), others do not. A recent study found that 4.42% Wikipedia articles contain at least one citation with a DOI [24] : a low number which might indicate that we are missing a non-negligible fraction of citations without identifiers. This is a significant limitation since existing databases, such as Altmetrics, do provide Wikipedia citation metrics relying exclusively on citations with identifiers. 5 This in turn limits the scope of results relying on these data.",
            "cite_spans": [
                {
                    "start": 465,
                    "end": 469,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 754,
                    "end": 755,
                    "text": "5",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Our goal here is to overcome these two challenges and expand upon previous work [12] , by providing a dataset of all citations from the English Wikipedia, equipped with identifiers and including the code to replicate and improve upon our work. The dataset is available on Zenodo [40] and the accompanying repository contains all code and further documentation to replicate our results. 6 This article is organized as follows. We start by describing our pipeline focusing on its three main steps: 1) citation template harmonization -to structure every citations in Wikipedia using the same schema; 2) citation classificationto find citations to books and journal articles; and 3) citation identifier look-up -to find identifiers such as DOIs. We subsequently evaluate our results, provide a description of the published dataset, and conclude by highlighting some possible uses of the dataset as well as ideas to improve it further.",
            "cite_spans": [
                {
                    "start": 80,
                    "end": 84,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 279,
                    "end": 283,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 386,
                    "end": 387,
                    "text": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "We start by briefly introducing Wikipedia-specific terminology:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "\u2022 Wikicode: The markup language used to write Wikipedia pages; also known as Wikitext or Wiki markup.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "\u2022 Template: A page that is embedded into other pages to allow for the repetition of information, following a certain Wikicode format. 7 Citation templates are specifically defined to embed citations.",
            "cite_spans": [
                {
                    "start": 134,
                    "end": 135,
                    "text": "7",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "\u2022 Citation: A citation is an abbreviated alphanumeric expression, embedded in Wikicode following a citation template, as shown in Figure 1 ; it usually denotes an entry in the References section of a Wikipedia page, but can be used anywhere on a page too (e.g., Notes, Further work ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 130,
                    "end": 138,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Methodology"
        },
        {
            "text": "Our process can be broken down into the following steps, as illustrated in Figure  2 : 1. Citation data extraction: A Wikipedia dump is used to extract citations from all pages and considering various citation templates. The extracted citations are then mapped to a uniform set of key-value pairings.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 75,
                    "end": 84,
                    "text": "Figure  2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Overview"
        },
        {
            "text": "2. Citation data classification: A classifier is trained to distinguish between citations to journal articles, books, or other Web content. The classifier is trained using a subset of citations already equipped known identifiers or URLs, allowing to label them beforehand. All the remaining citations are then classified.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Overview"
        },
        {
            "text": "3. Citation data lookup: All newly found citations to journal articles are labeled with identifiers (DOIs) using the Crossref API.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Overview"
        },
        {
            "text": "The citation data extraction pipeline is in turn divided into two steps, which are repeated for every Wikipedia article: 1) extraction of all sentences which contain text in Wikicode format, and filtering of sentences using the citation template Wikicode; 2) mapping of extracted citations to the uniform template and creation of a tabular dataset. An example of Wikicode citations, extracted during step 1, is given in Table 1 . The same citations after mapping to a uniform template are given in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 420,
                    "end": 427,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 498,
                    "end": 505,
                    "text": "Table 2",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Citation data extraction"
        },
        {
            "text": "We used the English Wikipedia XML dump from May 2020 and scraped it to get the content of each article/page. The number of unique pages is 6,069,685 after removing redirects since they do not have any citations of their own. Table 1 . When multiple citations to the same source are given in a page, we only consider the first one. The number of extracted citations is 29,276,667.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 225,
                    "end": 232,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Extraction and filtering"
        },
        {
            "text": "Citation templates can vary, and different templates can be used to refer to the same source in different pages. Therefore, we mapped all citations to the same uniform template. For this step, we used the wikiciteparser parser. 9 This parser is written in Lua and it can be imported into Python using the lupa library. 10 The uniform template we use comprises 29 different keys. Initially, the wikiciteparser parser only supported 17 citation templates, thus we added support for an additional 18 of the most frequently used templates. More details on the uniform template keys and the extra templates we implemented can be found in the accompanying repository.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 229,
                    "text": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 319,
                    "end": 321,
                    "text": "10",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Mapping"
        },
        {
            "text": "The resulting uniform key-value dataset can easily be transformed in tabular form for further processing. In particular, this first step allowed us to construct a dataset of citations with identifiers containing approximately 3.928 million citations. These identifiers -including DOI, PMC, PMID and ISBN -allowed us to use such citations as training data for the classifier.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mapping"
        },
        {
            "text": "After having extracted all citations and mapped them to a uniform template, we proceed to train a classifier to distinguish among three categories of cited sources: journal articles, books and Web content. Our primary focus are journal articles, as those cover most citations to scientific sources. We describe here our approach to label a golden dataset to use for training, the features we use for the classifier, and the classification model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Citation data classification"
        },
        {
            "text": "We labelled available citations as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "\u2022 Every citation with a non-null PMC or PMID was labeled as a journal article.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "\u2022 Every citation with a non-null PMC, PMID or DOI and using the citation template for journals and conferences, was labeled as a journal article.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "\u2022 Every citation which had a non-null ISBN was labelled as a book.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "\u2022 All citations with their URL top level domain belonging to the following: nytimes, bbc, washingtonpost, cnn, theguardian, huffingtonpost, indiatimes, were labeled as Web content.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "\u2022 All citations with their URL top level domain belonging to the following: youtube, rollingstone, billboard, mtv, metacritic, discogs, allmusic, were labeled as Web content.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Labeling"
        },
        {
            "text": "After labelling, we removed all identifiers and the type of citation template as features, since they were used to label the dataset. We also removed the fields: URL, work, newspaper, website, for the same reason. The final number of data points used for training and testing the classifier is given in Table 3 , and was partially sampled in order to have a comparable number of journal articles, books and Web content. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 303,
                    "end": 310,
                    "text": "Table 3",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Labeling"
        },
        {
            "text": "We next describe the features we used for the classification model:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "\u2022 Citation text: The text of the citation, in Wikicode syntax.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "\u2022 Citation statement: The text preceding a citation in a Wikipedia article, as it is known that certain statements are more likely to contain citations [35] . We have used the 40 words preceding the first time a source is cited in an article.",
            "cite_spans": [
                {
                    "start": 152,
                    "end": 156,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "\u2022 Part of Speech (POS) tags: POS tags for citation statements could also be correlated to citations. [35] . These were generated using the NLTK library. 11",
            "cite_spans": [
                {
                    "start": 101,
                    "end": 105,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "\u2022 Citation section: The article section a citation occurs in.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "\u2022 Order of the citation within the article, and total number of words of the article.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Features"
        },
        {
            "text": "The model which we constructed is a hybrid deep learning pipeline illustrated in Figure 3 . The features were represented as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 81,
                    "end": 89,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Classification model"
        },
        {
            "text": "\u2022 Citation text: The citation text in Wikicode syntax was fed to a characterlevel bidirectional LSTM [36] on the dummy task of predicting whether the citation text is to a book/journal article or other Web content. The traintest split was done using a 90-10 ratio, yielding a 98.56% test accuracy. We used this dummy task in order to avoid the effects of vocabulary sparsity due to Wikicode syntax. The character-level embeddings are of dimension 300, we aggregated them for every citation text via summation and normalized the resulting vector to sum to one. We used character-level embeddings to deal with Wikicode syntax. The citation text embeddings were trained on the dummy task and froze afterwards.",
            "cite_spans": [
                {
                    "start": 101,
                    "end": 105,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [],
            "section": "Classification model"
        },
        {
            "text": "\u2022 Citation statement: The vocabulary for citation statements contains approximately 443,000 unique tokens, after the removal of tokens which appear strictly less than 5 times in the corpus. We used fastText to generate word-level embeddings for citation statements, using subword information [3] . FastText allowed us to deal with out of vocabulary words. We used the fastText model pre-trained on English Wikipedia. 12",
            "cite_spans": [
                {
                    "start": 292,
                    "end": 295,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Classification model"
        },
        {
            "text": "\u2022 POS tags: The POS tags of citation statements were represented with a bag of words count vector. We were considering the top 35 tags by count frequency.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Classification model"
        },
        {
            "text": "\u2022 Citation section: We used a one-hot encoding for the 150 most common sections within Wikipedia articles. The order of the citation within the article and total number of words of the article were represented as scalars. Once the features had been generated, citation statements and their POS tags were further fed to an LSTM of 64 dimensions to create a single representation. All the resulting feature representations were concatenated and fed into a fully connected neural network with four hidden layers, as shown in Figure 3 . A final Softmax activation function was applied on the output generated by the fully connected layers, to map the output to one of the three categories of interest. We trained the model for five epochs using a train and test split of 90% and 10% respectively. For training, we used the Adam optimizer [17] and a binary crossentropy loss. The model's initial learning rate was set to 0.001, and reduced minimally to 0.00001 once the accuracy metric has stopped improving.",
            "cite_spans": [
                {
                    "start": 834,
                    "end": 838,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [
                {
                    "start": 522,
                    "end": 530,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Classification model"
        },
        {
            "text": "The lookup task entails finding a permanent identifier for every citation missing one. We focused on journal articles for this final step, since they make up the bulk of citations to scientific literature found in Wikipedia for which a stable identifier can be retrieved. We used the Crossref API to get DOIs. 13 Crossref allows to query its API 50 times per second, we used the aiohttp and asyncio libraries to process requests asynchronously. For each citation query, we get a list of possible matches in descending ordered according to a Crossref confidence score. We kept the top three results from each query response.",
            "cite_spans": [
                {
                    "start": 310,
                    "end": 312,
                    "text": "13",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Citation data lookup"
        },
        {
            "text": "In this section we discuss the evaluation of the citation classification and lookup steps.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation"
        },
        {
            "text": "After training the model for five epochs, we attained an accuracy of 98.32% on the test set. The confusion matrix for each of the labels is given in Table 4 . The model is able to distinguish among the three classes very well. The model was then used to classify all the remaining citations from the 29.276 million dataset, that is to say approximately 22.282 million citations. Some examples of results from the classification step are given in Table 6 . The resulting total number of citations per class are given in Table 5 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 149,
                    "end": 156,
                    "text": "Table 4",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 446,
                    "end": 453,
                    "text": "Table 6",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 519,
                    "end": 526,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                }
            ],
            "section": "Classification Evaluation"
        },
        {
            "text": "For the lookup, we evaluated the response of the Crossref API in order to assess how to pick results from it. We tested the API using 10,000 random citations with DOI identifiers and containing 9764 unique title-author pairs. We split this subset into a 80-20 split, tried out different heuristics on 80% of the data points and tested the best one on the remaining 20%. Table 7 shows the results for different heuristics, which confirms that the simple heuristic of picking the first result from Crossref works well.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 370,
                    "end": 377,
                    "text": "Table 7",
                    "ref_id": null
                }
            ],
            "section": "Crossref Evaluation"
        },
        {
            "text": "This still leaves open the question of what Crossref confidence score to use. We picked the threshold for the confidence score to be 34.997 which gave us a precision of 70% and a recall of 67.55% to reach a balance between the two in the evaluation (Figure 4) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 249,
                    "end": 259,
                    "text": "(Figure 4)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Crossref Evaluation"
        },
        {
            "text": "We finally tested the threshold using the 1953 held-out examples, out of which 1246 examples had the correct identifier with the first heuristic (out of 1297) and the threshold, 646 examples gave a different result out of which 521 are over the threshold and only 10 requests were invalid for the API. Hence, the first metadata result is the best result from the Crossref API.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Crossref Evaluation"
        },
        {
            "text": "The lookup process was performed by extracting the title and the first author (if available) for all the potential journal articles and was queried against the Table 7 : Results for each heuristic tested on 80% of the subset.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 160,
                    "end": 167,
                    "text": "Table 7",
                    "ref_id": null
                }
            ],
            "section": "Crossref Evaluation"
        },
        {
            "text": "Matched Not  matched   Invalid request  1st result  5258  2510  43  2nd result  345  7407  59  3rd result  96  7647  67 CrossRef API to get the metadata. The top 3 results from the metadata were taken into account if they existed, and their DOIs and confidence scores were extracted. 260,752 citations were equipped with DOIs using the lookup step and 320,887 unique DOIs were found relating to each of these citations.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 8,
                    "end": 119,
                    "text": "Not  matched   Invalid request  1st result  5258  2510  43  2nd result  345  7407  59  3rd result  96  7647  67",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Heuristic"
        },
        {
            "text": "The resulting Wikipedia Citations dataset is composed of 3 parts:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "1. The main dataset of 29.276 million citations from 35 different citation templates, out of which 3.928 million citations already contained identifiers (Table 8) , and 260,752 out of 947,233 newly-classified citations to journal articles were equipped with DOIs from Crossref.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 153,
                    "end": 162,
                    "text": "(Table 8)",
                    "ref_id": null
                }
            ],
            "section": "Dataset"
        },
        {
            "text": "2. An example subset with the features for the classifier.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "3. Citations classified as journal and their corresponding metadata/identifier extracted from Crossref to make the dataset more complete.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "We start by comparing our dataset with previous work, which focused on citations with identifiers [12] . The total number of citations per identifier type is found to be similar (Table 9 ). Minor discrepancies are likely due to the fact that we do not consider here all the edit history of every Wikipedia page, therefore missing changes between revisions, and that we consider a more recent dump. The total number of distinct identifiers across all Wikipedia, both previously known and newly-found, are given in Table 10 . Considering that in the Web of Science there are 38,829,128 articles with a DOI (version of March 2020), Wikipedia is citing approximately 3.5% of them (1,347,893). We show in Figure 5 the number of citations to books and journal articles published over the time period 2000 to 2020. This figure highlights how books appear to take longer to get cited in Wikipedia after publication. A similar plot, but considering a much wider publication time span (1500-2020) is given in Figure 6 . Most published material in Wikipedia dates from the 1800 onward. We note that a total of 89,098 journal article citations and 193,336 book citations do not contain a publication year. Out of all the 28 template keys including the citation, most are not complete. For example, identifiers are present only in 13.42% of citations whereas URLs are present in 85.25% of citations. This implies that many citations refer to Web contents.",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 102,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 178,
                    "end": 186,
                    "text": "(Table 9",
                    "ref_id": null
                },
                {
                    "start": 513,
                    "end": 521,
                    "text": "Table 10",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 700,
                    "end": 708,
                    "text": "Figure 5",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 999,
                    "end": 1007,
                    "text": "Figure 6",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Descriptive analysis"
        },
        {
            "text": "Out of 6,069,685 pages on Wikipedia, 407,777 have at least one or more citations with a DOI, that is about 6.7%; the proportion goes up to 12.84% for pages with at least one ISBN instead. This higher percentage of pages with DOIs, when compared to previously reported values [24] , is in large part due to our newly found identifiers from Crossref which allowed us to equip with DOIs citations coming from Wikipedia pages with no previous presence of DOIs. We eventually considered the distribution of distinct DOIs per Wikipedia page and it was found that most of the pages have few citations with DOI identifiers, as Table 9 : Number of citations equipped with identifiers (not including the identifiers through lookup), per type and compared with [12] . Note: a citation might be associated with two or more identifier types.",
            "cite_spans": [
                {
                    "start": 275,
                    "end": 279,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 750,
                    "end": 754,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [
                {
                    "start": 619,
                    "end": 626,
                    "text": "Table 9",
                    "ref_id": null
                }
            ],
            "section": "Descriptive analysis"
        },
        {
            "text": "Our shown in Figure 7 . The top journals are listed in Table 11 ), and contain wellknown mega journals (Nature, Science, PNAS) or other reputed venues (Cell, JBC). ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 13,
                    "end": 21,
                    "text": "Figure 7",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 55,
                    "end": 63,
                    "text": "Table 11",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Id."
        },
        {
            "text": "The Wikipedia Citations dataset can be useful for research and applications in a variety of contexts. We suggest a few here.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Research opportunities"
        },
        {
            "text": "What seems to us a low-hanging fruit is a map of Wikipedia sources, following the well-known science mapping and visualization methodologies [38, 4, 5] . Such work would allow to comprehensively answer the question of what is cited from Wikipedia, from which Wikipedia articles, and how knowledge is reported and negotiated in Wikipedia. Answering these questions is critical to inform the community work on improving Wikipedia by finding and filling knowledge gaps and biases, all the same guaranteeing the quality and diversity of the sources Wikipedia relies upon [26, 31, 14, 32, 47] .",
            "cite_spans": [
                {
                    "start": 141,
                    "end": 145,
                    "text": "[38,",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 146,
                    "end": 148,
                    "text": "4,",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 149,
                    "end": 151,
                    "text": "5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 567,
                    "end": 571,
                    "text": "[26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 572,
                    "end": 575,
                    "text": "31,",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 576,
                    "end": 579,
                    "text": "14,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 580,
                    "end": 583,
                    "text": "32,",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 584,
                    "end": 587,
                    "text": "47]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Map of Wikipedia sources"
        },
        {
            "text": "Link prediction in general, and citation recommendation in particular, have been explored for Wikipedia since some time [9, 29, 48] . Recent work has also focused on finding Wikipedia statements where a citation to a source might be needed [35] . Our dataset can further inform these efforts, in particular easing and fostering work on the recommendation of scientific literature to Wikipedia editors.",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 123,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 124,
                    "end": 127,
                    "text": "29,",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 128,
                    "end": 131,
                    "text": "48]",
                    "ref_id": "BIBREF47"
                },
                {
                    "start": 240,
                    "end": 244,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Citation recommendation"
        },
        {
            "text": "Citations from Wikipedia can be used as 'features' in a variety of contexts. They have already been considered as altmetrics for research impact [42] , while they can also be used as features for machine learning applications such as those focused on improving knowledge graphs, starting with Wikidata [8] . It is our hope that more detail and novel use cases will also lead to a gradual improvement of the first version of the dataset which we release here.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 149,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 302,
                    "end": 305,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Citations as features"
        },
        {
            "text": "We publish the Wikipedia Citations dataset, consisting of a total of 29.276M citations extracted from 6.069M articles from English Wikipedia. Citations are equipped with persistent identifiers such as DOIs and ISBNs whenever possible. Specifically, we extracted 3.928M citations with identifiers -including DOI, PMC, PMID, and ISBN -from Wikipedia itself, and further equipped an extra 260,752 citations with DOIs from Crossref. In so doing, we were able to raise the number of Wikipedia articles with at least one DOI from less than 5% to more than 6.7% (which is an additional 105,018 pages with a DOI) and found that Wikipedia is citing approximately 3.5% of the journal articles indexed in the Web of Science. We also release all our code to extend upon our work and update the dataset in the future.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "A set of limitations are worth highlighting, which also constitute possible directions for future work. First of all, the focus on English Wikipedia can and should be rapidly overcome to include all languages in Wikipedia. Our approach can easily be adapted to other languages, provided that external resources (e.g., language models and lookup APIs) allow for them. Secondly, the dataset currently does not account for the edit history of every citation from Wikipedia: this would allow to study knowledge production and negotiation over time: adding 'citation versioning' would be important in this respect. Thirdly, citations are used for a purpose, in a context; our choice to focus on the citation network means that an extension of the dataset could include all the citation statements as well, in order to allow researchers to study the fine-grained purpose of citations. Lastly, the querying and accessibility of the dataset is limited by its size; more work is needed in order to make Wikipedia contents better structured and easier to query [2] .",
            "cite_spans": [
                {
                    "start": 1051,
                    "end": 1054,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "We highlighted a set of possible uses of our dataset, from mapping the sources Wikipedia relies on, to recommending citations and using citation data as features. It is our hope that this release will start a collaborative effort by the community to study, use, maintain and expand work on citations from Wikipedia.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The dataset is made available on Zenodo [40] and the accompanying repository contains all code and further documentation to replicate our results: https:// github.com/Harshdeep1996/cite-classifications-wiki/releases/tag/0. 2.",
            "cite_spans": [
                {
                    "start": 40,
                    "end": 44,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "Data availability"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Science through Wikipedia: A novel representation of open knowledge through co-citation networks",
            "authors": [
                {
                    "first": "Wenceslao",
                    "middle": [],
                    "last": "Arroyo-Machado",
                    "suffix": ""
                },
                {
                    "first": "Daniel",
                    "middle": [],
                    "last": "Torres-Salinas",
                    "suffix": ""
                },
                {
                    "first": "Enrique",
                    "middle": [],
                    "last": "Herrera-Viedma",
                    "suffix": ""
                },
                {
                    "first": "Esteban",
                    "middle": [],
                    "last": "Romero-Fr\u00edas",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "PLOS ONE",
            "volume": "15",
            "issn": "2",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0228713"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "A Graph-structured Dataset for Wikipedia Research",
            "authors": [
                {
                    "first": "Nicolas",
                    "middle": [],
                    "last": "Aspert",
                    "suffix": ""
                },
                {
                    "first": "Volodymyr",
                    "middle": [],
                    "last": "Miz",
                    "suffix": ""
                },
                {
                    "first": "Benjamin",
                    "middle": [],
                    "last": "Ricaud",
                    "suffix": ""
                },
                {
                    "first": "Pierre",
                    "middle": [],
                    "last": "Vandergheynst",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/3308560.3316757"
                ],
                "arXiv": [
                    "arXiv:1903.08597"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Enriching word vectors with subword information",
            "authors": [
                {
                    "first": "Piotr",
                    "middle": [],
                    "last": "Bojanowski",
                    "suffix": ""
                },
                {
                    "first": "Edouard",
                    "middle": [],
                    "last": "Grave",
                    "suffix": ""
                },
                {
                    "first": "Armand",
                    "middle": [],
                    "last": "Joulin",
                    "suffix": ""
                },
                {
                    "first": "Tomas",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1607.04606"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Atlas of science: visualizing what we know",
            "authors": [
                {
                    "first": "Katy",
                    "middle": [],
                    "last": "B\u00f6rner",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Science Mapping: A Systematic Review of the Literature",
            "authors": [
                {
                    "first": "Chaomei",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of Data and Information Science",
            "volume": "2",
            "issn": "2",
            "pages": "1--40",
            "other_ids": {
                "DOI": [
                    "10.1515/jdis-2017-0006"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "{{citation needed}}: the dynamics of referencing in Wikipedia",
            "authors": [
                {
                    "first": "Chih-Chun",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Camille",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the Eighth Annual International Symposium on Wikis and Open Collaboration",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/2462932.2462943"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Covid-19 research in wikipedia. bioRxiv, 2020",
            "authors": [
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Colavizza",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.05.10.087643"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Wikidata from a Research Perspective -A Systematic Mapping Study of Wikidata",
            "authors": [
                {
                    "first": "Mariam",
                    "middle": [],
                    "last": "Farda",
                    "suffix": ""
                },
                {
                    "first": "-",
                    "middle": [],
                    "last": "Sarbas",
                    "suffix": ""
                },
                {
                    "first": "Claudia",
                    "middle": [],
                    "last": "M\u00fcller-Birn",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1908.11153"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Finding News Citations for Wikipedia",
            "authors": [
                {
                    "first": "Besnik",
                    "middle": [],
                    "last": "Fetahu",
                    "suffix": ""
                },
                {
                    "first": "Katja",
                    "middle": [],
                    "last": "Markert",
                    "suffix": ""
                },
                {
                    "first": "Wolfgang",
                    "middle": [],
                    "last": "Nejdl",
                    "suffix": ""
                },
                {
                    "first": "Avishek",
                    "middle": [],
                    "last": "Anand",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "337--346",
            "other_ids": {
                "DOI": [
                    "10.1145/2983323.2983808"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Information Fortification: An Online Citation Behavior",
            "authors": [
                {
                    "first": "Andrea",
                    "middle": [],
                    "last": "Forte",
                    "suffix": ""
                },
                {
                    "first": "Nazanin",
                    "middle": [],
                    "last": "Andalibi",
                    "suffix": ""
                },
                {
                    "first": "Tim",
                    "middle": [],
                    "last": "Gorichanaz",
                    "suffix": ""
                },
                {
                    "first": "Chul",
                    "middle": [],
                    "last": "Meen",
                    "suffix": ""
                },
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "Aaron",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Halfaker",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 2018 ACM Conference on Supporting Groupwork -GROUP '18",
            "volume": "",
            "issn": "",
            "pages": "83--92",
            "other_ids": {
                "DOI": [
                    "10.1145/3148330.3148347"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "When the levee breaks: without bots, what happens to Wikipedia's quality control processes?",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "Stuart",
                    "middle": [],
                    "last": "Geiger",
                    "suffix": ""
                },
                {
                    "first": "Aaron",
                    "middle": [],
                    "last": "Halfaker",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 9th International Symposium on Open Collaboration",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {
                "DOI": [
                    "10.1145/2491055.2491061"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Citations with identifiers in wikipedia",
            "authors": [
                {
                    "first": "Aaron",
                    "middle": [],
                    "last": "Halfaker",
                    "suffix": ""
                },
                {
                    "first": "Bahodir",
                    "middle": [],
                    "last": "Mansurov",
                    "suffix": ""
                },
                {
                    "first": "Miriam",
                    "middle": [],
                    "last": "Redi",
                    "suffix": ""
                },
                {
                    "first": "Dario",
                    "middle": [],
                    "last": "Taraborelli",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.6084/m9.figshare.1299540"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Wikipedia: A Key Tool for Global Public Health Promotion",
            "authors": [
                {
                    "first": "Eckhard",
                    "middle": [],
                    "last": "James M Heilman",
                    "suffix": ""
                },
                {
                    "first": "Michael",
                    "middle": [],
                    "last": "Kemmann",
                    "suffix": ""
                },
                {
                    "first": "Anwesh",
                    "middle": [],
                    "last": "Bonert",
                    "suffix": ""
                },
                {
                    "first": "Brent",
                    "middle": [],
                    "last": "Chatterjee",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ragar",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Graham",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Beards",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "David",
                    "suffix": ""
                },
                {
                    "first": "Matthew",
                    "middle": [],
                    "last": "Iberri",
                    "suffix": ""
                },
                {
                    "first": "Brendan",
                    "middle": [],
                    "last": "Harvey",
                    "suffix": ""
                },
                {
                    "first": "Wouter",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Stomp",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Michael",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Martone",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Daniel",
                    "suffix": ""
                },
                {
                    "first": "Andrea",
                    "middle": [],
                    "last": "Lodge",
                    "suffix": ""
                },
                {
                    "first": "Jacob F De",
                    "middle": [],
                    "last": "Vondracek",
                    "suffix": ""
                },
                {
                    "first": "Casimir",
                    "middle": [],
                    "last": "Wolff",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Liber",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Samir",
                    "suffix": ""
                },
                {
                    "first": "Tim",
                    "middle": [
                        "J"
                    ],
                    "last": "Grover",
                    "suffix": ""
                },
                {
                    "first": "Bertalan",
                    "middle": [],
                    "last": "Vickers",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mesk\u00f3",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Laurent",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Medical Internet Research",
            "volume": "13",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.2196/jmir.1589"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Bias in Wikipedia",
            "authors": [
                {
                    "first": "Christoph",
                    "middle": [],
                    "last": "Hube",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 26th International Conference on World Wide Web Companion -WWW '17 Companion",
            "volume": "",
            "issn": "",
            "pages": "717--721",
            "other_ids": {
                "DOI": [
                    "10.1145/3041021.3053375"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Bridging the gap between wikipedia and academia",
            "authors": [
                {
                    "first": "Dariusz",
                    "middle": [],
                    "last": "Jemielniak",
                    "suffix": ""
                },
                {
                    "first": "Eduard",
                    "middle": [],
                    "last": "Aibar",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "67",
            "issn": "7",
            "pages": "1773--1776",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.23691"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Hot off the wiki: dynamics, practices, and structures in Wikipedia's coverage of the T\u014dhoku catastrophes",
            "authors": [
                {
                    "first": "Brian",
                    "middle": [],
                    "last": "Keegan",
                    "suffix": ""
                },
                {
                    "first": "Darren",
                    "middle": [],
                    "last": "Gergle",
                    "suffix": ""
                },
                {
                    "first": "Noshir",
                    "middle": [],
                    "last": "Contractor",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 7th International Symposium on Wikis and Open Collaboration -WikiSym '11",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/2038558.2038577"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Adam: A method for stochastic optimization",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Diederik",
                    "suffix": ""
                },
                {
                    "first": "Jimmy",
                    "middle": [],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Are wikipedia citations important evidence of the impact of scholarly articles and books",
            "authors": [
                {
                    "first": "Kayvan",
                    "middle": [],
                    "last": "Kousha",
                    "suffix": ""
                },
                {
                    "first": "Mike",
                    "middle": [],
                    "last": "Thelwall",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "68",
            "issn": "3",
            "pages": "762--779",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.23694"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes",
            "authors": [
                {
                    "first": "Srijan",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "West",
                    "suffix": ""
                },
                {
                    "first": "Jure",
                    "middle": [],
                    "last": "Leskovec",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 25th International Conference on World Wide Web",
            "volume": "",
            "issn": "",
            "pages": "591--602",
            "other_ids": {
                "DOI": [
                    "10.1145/2872427.2883085"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Seeking Health Information Online: Does Wikipedia Matter",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Laurent",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "J"
                    ],
                    "last": "Vickers",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "16",
            "issn": "4",
            "pages": "471--479",
            "other_ids": {
                "DOI": [
                    "10.1197/jamia.M3059"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Mohamed Morsey, Patrick van Kleef, S\u00f6ren Auer, and others. DBpedia-A large-scale, multilingual knowledge base extracted from Wikipedia",
            "authors": [
                {
                    "first": "Jens",
                    "middle": [],
                    "last": "Lehmann",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "Isele",
                    "suffix": ""
                },
                {
                    "first": "Max",
                    "middle": [],
                    "last": "Jakob",
                    "suffix": ""
                },
                {
                    "first": "Anja",
                    "middle": [],
                    "last": "Jentzsch",
                    "suffix": ""
                },
                {
                    "first": "Dimitris",
                    "middle": [],
                    "last": "Kontokostas",
                    "suffix": ""
                },
                {
                    "first": "Pablo",
                    "middle": [
                        "N"
                    ],
                    "last": "Mendes",
                    "suffix": ""
                },
                {
                    "first": "Sebastian",
                    "middle": [],
                    "last": "Hellmann",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Semantic Web",
            "volume": "6",
            "issn": "2",
            "pages": "167--195",
            "other_ids": {
                "DOI": [
                    "10.3233/SW-140134"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Analysis of References Across Wikipedia Languages",
            "authors": [
                {
                    "first": "Krzysztof",
                    "middle": [],
                    "last": "W Lodzimierz Lewoniewski",
                    "suffix": ""
                },
                {
                    "first": "Witold",
                    "middle": [],
                    "last": "W\u0229cel",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Abramowicz",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Robertas Dama\u0161evi\u010dius and Vilma Mika\u0161yt\u0117",
            "volume": "756",
            "issn": "",
            "pages": "561--573",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-67642-5_47"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Wikipedia as a gateway to biomedical research: The relative distribution and use of citations in the English Wikipedia",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Lauren",
                    "suffix": ""
                },
                {
                    "first": "John",
                    "middle": [
                        "M"
                    ],
                    "last": "Maggio",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Willinsky",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ryan",
                    "suffix": ""
                },
                {
                    "first": "Daniel",
                    "middle": [],
                    "last": "Steinberg",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Mietchen",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Joseph",
                    "suffix": ""
                },
                {
                    "first": "Ting",
                    "middle": [],
                    "last": "Wass",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "PLOS ONE",
            "volume": "12",
            "issn": "12",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "The Substantial Interdependence of Wikipedia and Google: A Case Study on the Relationship Between Peer Production Communi-ties and Information Technologies",
            "authors": [
                {
                    "first": "Connor",
                    "middle": [],
                    "last": "Mcmahon",
                    "suffix": ""
                },
                {
                    "first": "Isaac",
                    "middle": [],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "Brent",
                    "middle": [],
                    "last": "Hecht",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the Eleventh International AAAI Conference on Web and Social Media",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "The sum of all human knowledge\": A systematic review of scholarly research on the content of Wikipedia",
            "authors": [
                {
                    "first": "Mostafa",
                    "middle": [],
                    "last": "Mesgari",
                    "suffix": ""
                },
                {
                    "first": "Chitu",
                    "middle": [],
                    "last": "Okoli",
                    "suffix": ""
                },
                {
                    "first": "Mohamad",
                    "middle": [],
                    "last": "Mehdi",
                    "suffix": ""
                },
                {
                    "first": "Finn",
                    "middle": [],
                    "last": "Nielsen",
                    "suffix": ""
                },
                {
                    "first": "Arto",
                    "middle": [],
                    "last": "Lanam\u00e4ki",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "66",
            "issn": "2",
            "pages": "219--245",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.23172"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "The Semantic Web: ESWC 2017 Satellite Events",
            "authors": [
                {
                    "first": "Finn\u00e5rup",
                    "middle": [],
                    "last": "Nielsen",
                    "suffix": ""
                },
                {
                    "first": "Daniel",
                    "middle": [],
                    "last": "Mietchen",
                    "suffix": ""
                },
                {
                    "first": "Egon",
                    "middle": [],
                    "last": "Willighagen",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Scholia",
                    "suffix": ""
                },
                {
                    "first": "Wikidata. In Eva",
                    "middle": [],
                    "last": "Scientometrics",
                    "suffix": ""
                },
                {
                    "first": "Katja",
                    "middle": [],
                    "last": "Blomqvist",
                    "suffix": ""
                },
                {
                    "first": "Heiko",
                    "middle": [],
                    "last": "Hose",
                    "suffix": ""
                },
                {
                    "first": "Agnieszka",
                    "middle": [],
                    "last": "Paulheim",
                    "suffix": ""
                },
                {
                    "first": "Fabio",
                    "middle": [],
                    "last": "Lawrynowicz",
                    "suffix": ""
                },
                {
                    "first": "Olaf",
                    "middle": [],
                    "last": "Ciravegna",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Hartig",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "10577",
            "issn": "",
            "pages": "237--259",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-70407-4_36"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Improving Website Hyperlink Structure Using Server Logs",
            "authors": [
                {
                    "first": "Ashwin",
                    "middle": [],
                    "last": "Paranjape",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "West",
                    "suffix": ""
                },
                {
                    "first": "Leila",
                    "middle": [],
                    "last": "Zia",
                    "suffix": ""
                },
                {
                    "first": "Jure",
                    "middle": [],
                    "last": "Leskovec",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the Ninth ACM International Conference on Web Search and Data Mining",
            "volume": "",
            "issn": "",
            "pages": "615--624",
            "other_ids": {
                "DOI": [
                    "10.1145/2835776.2835832"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Quantifying Engagement with Citations on Wikipedia",
            "authors": [
                {
                    "first": "Tiziano",
                    "middle": [],
                    "last": "Piccardi",
                    "suffix": ""
                },
                {
                    "first": "Miriam",
                    "middle": [],
                    "last": "Redi",
                    "suffix": ""
                },
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Colavizza",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "West",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Proceedings of The Web Conference 2020",
            "volume": "",
            "issn": "",
            "pages": "2365--2376",
            "other_ids": {
                "DOI": [
                    "10.1145/3366423.3380300"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Provenance Information in a Collaborative Knowledge Graph: An Evaluation of Wikidata External References",
            "authors": [
                {
                    "first": "Alessandro",
                    "middle": [],
                    "last": "Piscopo",
                    "suffix": ""
                },
                {
                    "first": "Lucie-Aim\u00e9e",
                    "middle": [],
                    "last": "Kaffee",
                    "suffix": ""
                },
                {
                    "first": "Chris",
                    "middle": [],
                    "last": "Phethean",
                    "suffix": ""
                },
                {
                    "first": "Elena",
                    "middle": [],
                    "last": "Simperl",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "The Semantic Web -ISWC 2017",
            "volume": "10587",
            "issn": "",
            "pages": "542--558",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-319-68288-4_32"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "What we talk about when we talk about Wikidata quality: a literature survey",
            "authors": [
                {
                    "first": "Alessandro",
                    "middle": [],
                    "last": "Piscopo",
                    "suffix": ""
                },
                {
                    "first": "Elena",
                    "middle": [],
                    "last": "Simperl",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 15th International Symposium on Open Collaboration",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/3306446.3340822"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Creating, destroying, and restoring value in wikipedia",
            "authors": [
                {
                    "first": "Reid",
                    "middle": [],
                    "last": "Priedhorsky",
                    "suffix": ""
                },
                {
                    "first": "Jilin",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": ")",
                    "middle": [
                        "K"
                    ],
                    "last": "Shyong (tony",
                    "suffix": ""
                },
                {
                    "first": "Katherine",
                    "middle": [],
                    "last": "Lam",
                    "suffix": ""
                },
                {
                    "first": "Loren",
                    "middle": [],
                    "last": "Panciera",
                    "suffix": ""
                },
                {
                    "first": "John",
                    "middle": [],
                    "last": "Terveen",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Riedl",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Proceedings of the 2007 international ACM conference on Conference on supporting group work",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/1316624.1316663"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Altmetrics in the Wild: Using Social Media to Explore Scholarly Impact",
            "authors": [
                {
                    "first": "Jason",
                    "middle": [],
                    "last": "Priem",
                    "suffix": ""
                },
                {
                    "first": "Heather",
                    "middle": [
                        "A"
                    ],
                    "last": "Piwowar",
                    "suffix": ""
                },
                {
                    "first": "Bradley",
                    "middle": [
                        "M"
                    ],
                    "last": "Hemminger",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's Verifiability",
            "authors": [
                {
                    "first": "Miriam",
                    "middle": [],
                    "last": "Redi",
                    "suffix": ""
                },
                {
                    "first": "Besnik",
                    "middle": [],
                    "last": "Fetahu",
                    "suffix": ""
                },
                {
                    "first": "Jonathan",
                    "middle": [],
                    "last": "Morgan",
                    "suffix": ""
                },
                {
                    "first": "Dario",
                    "middle": [],
                    "last": "Taraborelli",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the World Wide Web Conference",
            "volume": "",
            "issn": "",
            "pages": "1567--1578",
            "other_ids": {
                "DOI": [
                    "10.1145/3308558.3313618"
                ]
            }
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Bidirectional recurrent neural networks",
            "authors": [
                {
                    "first": "Mike",
                    "middle": [],
                    "last": "Schuster",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kuldip",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Paliwal",
                    "suffix": ""
                }
            ],
            "year": 1997,
            "venue": "IEEE Transactions on Signal Processing",
            "volume": "45",
            "issn": "11",
            "pages": "2673--2681",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Evolution of Wikipedia's medical content: past, present and future",
            "authors": [
                {
                    "first": "Thomas",
                    "middle": [],
                    "last": "Shafee",
                    "suffix": ""
                },
                {
                    "first": "Gwinyai",
                    "middle": [],
                    "last": "Masukume",
                    "suffix": ""
                },
                {
                    "first": "Lisa",
                    "middle": [],
                    "last": "Kipersztok",
                    "suffix": ""
                },
                {
                    "first": "Diptanshu",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "Mikael",
                    "middle": [],
                    "last": "H\u00e4ggstr\u00f6m",
                    "suffix": ""
                },
                {
                    "first": "James",
                    "middle": [],
                    "last": "Heilman",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of Epidemiology and Community Health",
            "volume": "",
            "issn": "",
            "pages": "2016--208601",
            "other_ids": {
                "DOI": [
                    "10.1136/jech-2016-208601"
                ]
            }
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Mapping knowledge domains. National Acad Sciences",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Richard",
                    "suffix": ""
                },
                {
                    "first": "Katy",
                    "middle": [],
                    "last": "Shiffrin",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "B\u00f6rner",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "A comparative study of academic and Wikipedia ranking",
            "authors": [
                {
                    "first": "Xin",
                    "middle": [],
                    "last": "Shuai",
                    "suffix": ""
                },
                {
                    "first": "Zhuoren",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Xiaozhong",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Johan",
                    "middle": [],
                    "last": "Bollen",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries -JCDL '13",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/2467696.2467746"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Wikipedia Citations: A comprehensive dataset of citations with identifiers extracted from English Wikipedia",
            "authors": [
                {
                    "first": "Harshdeep",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "West",
                    "suffix": ""
                },
                {
                    "first": "Giovanni",
                    "middle": [],
                    "last": "Colavizza",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.5281/zenodo.3940692"
                ]
            }
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Situating Wikipedia as a health information resource in various contexts: A scoping review",
            "authors": [
                {
                    "first": "Denise",
                    "middle": [
                        "A"
                    ],
                    "last": "Smith",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "e0228786, February 2020",
            "volume": "15",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0228786"
                ]
            }
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Scholarly use of social media and altmetrics: A review of the literature",
            "authors": [
                {
                    "first": "Cassidy",
                    "middle": [
                        "R"
                    ],
                    "last": "Sugimoto",
                    "suffix": ""
                },
                {
                    "first": "Sam",
                    "middle": [],
                    "last": "Work",
                    "suffix": ""
                },
                {
                    "first": "Vincent",
                    "middle": [],
                    "last": "Larivi\u00e8re",
                    "suffix": ""
                },
                {
                    "first": "Stefanie",
                    "middle": [],
                    "last": "Haustein",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "68",
            "issn": "9",
            "pages": "2037--2062",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.23833"
                ]
            }
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Amplifying the impact of open access: Wikipedia and the diffusion of science",
            "authors": [
                {
                    "first": "Misha",
                    "middle": [],
                    "last": "Teplitskiy",
                    "suffix": ""
                },
                {
                    "first": "Grace",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Eamon",
                    "middle": [],
                    "last": "Duede",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "68",
            "issn": "9",
            "pages": "2116--2127",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.23687"
                ]
            }
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Science Is Shaped by Wikipedia: Evidence from a Randomized Control Trial",
            "authors": [
                {
                    "first": "Neil",
                    "middle": [],
                    "last": "Thompson",
                    "suffix": ""
                },
                {
                    "first": "Douglas",
                    "middle": [],
                    "last": "Hanley",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "5238",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.2139/ssrn.3039505"
                ]
            }
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "A Study of Citations to Wikipedia in Scholarly Publications",
            "authors": [
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "Tomaszewski",
                    "suffix": ""
                },
                {
                    "first": "Karen",
                    "middle": [
                        "I"
                    ],
                    "last": "Macdonald",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Science & Technology Libraries",
            "volume": "35",
            "issn": "3",
            "pages": "246--261",
            "other_ids": {
                "DOI": [
                    "10.1080/0194262X.2016.1206052"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Mapping the backbone of the Humanities through the eyes of Wikipedia",
            "authors": [
                {
                    "first": "Daniel",
                    "middle": [],
                    "last": "Torres-Salinas",
                    "suffix": ""
                },
                {
                    "first": "Esteban",
                    "middle": [],
                    "last": "Romero-Fr\u00edas",
                    "suffix": ""
                },
                {
                    "first": "Wenceslao",
                    "middle": [],
                    "last": "Arroyo-Machado",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Informetrics",
            "volume": "13",
            "issn": "3",
            "pages": "793--803",
            "other_ids": {
                "DOI": [
                    "10.1016/j.joi.2019.07.002"
                ]
            }
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Assessing the quality of information on wikipedia: A deep-learning approach",
            "authors": [
                {
                    "first": "Ping",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Xiaodan",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of the Association for Information Science and Technology",
            "volume": "71",
            "issn": "1",
            "pages": "16--28",
            "other_ids": {
                "DOI": [
                    "10.1002/asi.24210"
                ]
            }
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "International World Wide Web Conferences Steering Committee",
            "authors": [
                {
                    "first": "Ellery",
                    "middle": [],
                    "last": "Wulczyn",
                    "suffix": ""
                },
                {
                    "first": "Robert",
                    "middle": [],
                    "last": "West",
                    "suffix": ""
                },
                {
                    "first": "Leila",
                    "middle": [],
                    "last": "Zia",
                    "suffix": ""
                },
                {
                    "first": "Jure",
                    "middle": [],
                    "last": "Leskovec",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 25th International Conference on World Wide Web",
            "volume": "",
            "issn": "",
            "pages": "975--985",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "How well developed are altmetrics? A cross-disciplinary analysis of the presence of 'alternative metrics' in scientific publications",
            "authors": [
                {
                    "first": "Zohreh",
                    "middle": [],
                    "last": "Zahedi",
                    "suffix": ""
                },
                {
                    "first": "Rodrigo",
                    "middle": [],
                    "last": "Costas",
                    "suffix": ""
                },
                {
                    "first": "Paul",
                    "middle": [],
                    "last": "Wouters",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Scientometrics",
            "volume": "101",
            "issn": "2",
            "pages": "1491--1513",
            "other_ids": {
                "DOI": [
                    "10.1007/s11192-014-1264-0"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Example of citations in Wikipedia.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Overview of the citation data extraction pipeline. We highlight in blue/grey the outputs at every stage. These examples are illustrative simplifications from the actual dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Citation classification model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Histogram of the Crossref API confidence scores over the validation set of the first result extracted from the lookup.(b) Precision and recall for different Crossref API confidence score thresholds where the x-axis represents the scores returned by the Crossref API.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Evaluation of the Crossref API scores.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Publication years for journal articles and books, for the period 2000-2020.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Number of citations per source publication year (1500-2020).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Presence of identifiers per citation for the 3.92 million citations with identifiers (with 0 = False and 1 = True). These counts sum up to 3,620,124, with an additional 308,268 citations associated with other identifiers such as OCLC, ISSN. The total adds up to 3,928,392 citations with identifiers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Number of distinct cited DOI per Wikipedia page.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": "Different citation templates can be used to refer to the same source.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Citations are mapped to have the same keys.Since we are restricting ourselves to citations which are given in Wikicode format, we used the mwparserfromhell parser, 8 which given as input a Wikipedia page, it returns all text which is written in Wikicode format. Citations are generally present inside <ref> tags or between double curly brackets {{, as shown in",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Number of citations with a known class (* indicates a sampled subset).",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Confusion matrix for citation classification. Results are based on a 10% held-out test set.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Number of newly-classified citations per class.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Example of newly-classified citations.",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Number of distinct DOI and ISBN identifiers across Wikipedia.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Most cited journals.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The authors would like to thank Tiziano Piccardi (EPFL), Miriam Redi (Wikimedia Foundation) and Dario Taraborelli (Chan Zuckerberg Initiative) for their helpful advice.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgements"
        }
    ]
}