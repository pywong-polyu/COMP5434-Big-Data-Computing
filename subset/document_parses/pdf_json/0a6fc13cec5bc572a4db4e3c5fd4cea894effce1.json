{
    "paper_id": "0a6fc13cec5bc572a4db4e3c5fd4cea894effce1",
    "metadata": {
        "title": "A Time-Series-Based New Behavior Trace Model for Crowd Workers That Ensures Quality Annotation",
        "authors": [
            {
                "first": "Fattoh",
                "middle": [],
                "last": "Al-Qershi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11543",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Muhammad",
                "middle": [],
                "last": "Al-Qurishi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11543",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Mehmet",
                "middle": [
                    "Sabih"
                ],
                "last": "Aksoy",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11543",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Mohammed",
                "middle": [],
                "last": "Faisal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "145111",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Mohammed",
                "middle": [],
                "last": "Algabri",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11543",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Citation: Al-Qershi, F.; Al-Qurishi, M.; Aksoy, M.S.; Faisal, M.; Algabri, M. A Time-Series-Based New Behavior Trace Model for Crowd Workers That Ensures Quality Annotation. Sensors 2021, 21, 5007.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Crowdsourcing, a concept first coined by Howe [1] , refers to numerous people being involved in computing tasks to solve problems that are more difficult for computers than humans. It is an alternative mechanism for solving such problems at a lower cost. Therefore, many researchers have resorted to crowdsourcing as a preferable labeling choice in different domains, such as natural language processing [2] and image labeling [3] . Moreover, many researchers have incorporated crowdsourcing into studies on the COVID-19 pandemic [4] , disasters [5] , fake news [6] , and preprocessing for deep learning applications [7, 8] . Such studies leverage the availability of crowdsourcing platforms such as Amazon Mechanical Turk (AMT), as well as the abundant ordinary Internet users (i.e., crowd workers) [9] . Due to the heterogeneous nature of such workers, crowdsourcing is prone to quality concerns.",
            "cite_spans": [
                {
                    "start": 46,
                    "end": 49,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 404,
                    "end": 407,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 427,
                    "end": 430,
                    "text": "[3]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 530,
                    "end": 533,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 546,
                    "end": 549,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 562,
                    "end": 565,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 617,
                    "end": 620,
                    "text": "[7,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 621,
                    "end": 623,
                    "text": "8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 800,
                    "end": 803,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Crowd workers have different motivations, expertise, and backgrounds [10, 11] . Moreover, human-specific factors (e.g., boredom, laziness, and inexperience), identity, and bias are other sources of quality errors [12] . Notably, numerous crowd workers are untrustworthy [13] . The percentage of spammers among crowd workers could be as high as 50% [14] . Moreover, crowd workers may attempt to maximize their monetary rewards by cheating using quick submission [15] or copy and pasting [16] . There are also sophisticated spammers who can evade certain anti-cheating crowdsourcing tests [17] . Others such as Sybil attackers can attack crowdsourcing tasks [17] using pseudo accounts to submit Sensors 2021, 21, 5007 2 of 20 similar answers [18] . All of these problems can lead to deceptive results from such workers or high variability in quality due to variance in their effort or skills. In 2016 at least 20 million adults in the U.S. earned money by working from crowdsourcing like those found on Amazon Mechanical Turk (AMT), a number that is expected to rise with the growth of AI [19] . Furthermore, crowdsourced data processing is performed at scale at many tech companies, with tens of millions of dollars spent every year [20] , so the quality improvement is a critical issue for those companies [21] . To attain high-quality results from crowdsourcing, various approaches have been proposed. A common technique is to evaluate crowd workers' output using gold standards [22] [23] [24] . Unfortunately, many crowd workers may be rejected just due to bad luck on gold set questions. Moreover, spammers are aware of the use of such questions. Another widely used approach involves studying the relationship between crowd workers' answers based on consensus methods such as majority voting [25] [26] [27] [28] . One limitation of such a method is the high costs due to redundancy [29] . Moreover, such methods fail against collusion attacks by malicious workers [18] . Another approach uses motivations such as reputation in advanced quality measures [30] .",
            "cite_spans": [
                {
                    "start": 69,
                    "end": 73,
                    "text": "[10,",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 74,
                    "end": 77,
                    "text": "11]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 213,
                    "end": 217,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 270,
                    "end": 274,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 348,
                    "end": 352,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 461,
                    "end": 465,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 486,
                    "end": 490,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 587,
                    "end": 591,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 656,
                    "end": 660,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 740,
                    "end": 744,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1087,
                    "end": 1091,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 1232,
                    "end": 1236,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1306,
                    "end": 1310,
                    "text": "[21]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1480,
                    "end": 1484,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1485,
                    "end": 1489,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1490,
                    "end": 1494,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1796,
                    "end": 1800,
                    "text": "[25]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1801,
                    "end": 1805,
                    "text": "[26]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1806,
                    "end": 1810,
                    "text": "[27]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1811,
                    "end": 1815,
                    "text": "[28]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 1886,
                    "end": 1890,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1968,
                    "end": 1972,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 2057,
                    "end": 2061,
                    "text": "[30]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "An alternative way to cope with these problems is to study crowd workers' behavior rather than their output. Compared with gold standard and consensus methods, behaviorbased approaches can be generalized across tasks and do not only target closed questions. Moreover, these approaches are free from the cold-start problem, and they do not require workers' historical annotation information.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Regrettably, only a few studies have targeted crowd workers' behavior. Gadiraju et al. [16] studied different workers' behavior limited to online surveys. Hirth et al. [31] examined different time aspects of worker behavior to find the most crucial features related to worker qualifications. Rzeszotarski and Kittur [32] estimated the labeling quality and accuracy of workers on different tasks based on task fingerprints and a set of statistical behavior features. Similarly, Kazai and Zitouni [29] collected experts' behavior and trained a supervised classifier to detect poor crowd workers. However, none of these works have shared their source code or dataset. Leveraging from the open source of [33] , Goyal et al. [34] are the only researchers who have shared their collected dataset. The present study benefited from this dataset and works.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 91,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 168,
                    "end": 172,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 316,
                    "end": 320,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 495,
                    "end": 499,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 700,
                    "end": 704,
                    "text": "[33]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 720,
                    "end": 724,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The contributions of this paper can be summarized as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 It proposes novel time-series-based models in the field of crowdsourcing quality control. \u2022 It introduces two new models with various experiments. The first was based on time-series feature generation, showing the important features of crowd workers' behavior. The other model was based on converting time series into heatmaps and then leveraging from their recurring characteristics to classify the tasks of crowd workers. The latter model establishes a baseline for research in the application of a lightweight deep learning model in the field of crowdsourcing workers' assessment control.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The proposed models possess superior performance. We demonstrated that our models outperform time-series state-of-the-art models such as dynamic time warping (DTW) and time-series support vector classifier (TS-SVC), as well as leading research works by Rzeszotarski and Kittur [32] and Goyal et al. [34] .",
            "cite_spans": [
                {
                    "start": 277,
                    "end": 281,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 299,
                    "end": 303,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "The remainder of this paper is organized as follows. Section 2 presents the related work. Section 3 describes the methodology and the proposed models. Section 4 illustrates the experiment details and results as well as provides the discussion. Finally, Section 5 presents the conclusion and recommendations for future works.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Generally, at least two types of approaches have been explored by researchers to obtain high-quality data from crowd workers, traditional and behavior-tracing approaches. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "In this line of research, quality control is applied to crowd workers' responses. This can be based on other independent human evaluators, who are employed to assess the answers of other crowdsourcing workers [3] . Other studies have implemented consensus algorithms, where multiple answers are gathered for each task. These answers are then aggregated into the most likely answer or the so-called majority vote [35] [36] [37] . Unfortunately, this approach can greatly inflate costs due to the needed redundancy [38] . Furthermore, it is vulnerable to gaming, the majority effect, or at worst Sybil attacks [39] . Another traditional approach is to use gold standard data for filtering workers [22] [23] [24] 40] . These gold data can be created by injecting a few ground truth labels from experts in rich crowd labeling [41] or by gathering a set of experts [22] . These standard data can also be generated automatically from just a few gold unit seeds [23] . A real-time system can evaluate crowd workers' reliability using a collected reference set [24] . A shortcoming of such gold standard data is that they are not always available or applicable in some generative tasks, such as tagging and summarization. Both majority voting and gold data approaches assume that the response spaces are structured (i.e., the tasks have closed questions).",
            "cite_spans": [
                {
                    "start": 209,
                    "end": 212,
                    "text": "[3]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 412,
                    "end": 416,
                    "text": "[35]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 417,
                    "end": 421,
                    "text": "[36]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 422,
                    "end": 426,
                    "text": "[37]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 513,
                    "end": 517,
                    "text": "[38]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 608,
                    "end": 612,
                    "text": "[39]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 695,
                    "end": 699,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 700,
                    "end": 704,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 705,
                    "end": 709,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 710,
                    "end": 713,
                    "text": "40]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 822,
                    "end": 826,
                    "text": "[41]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 860,
                    "end": 864,
                    "text": "[22]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 955,
                    "end": 959,
                    "text": "[23]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1053,
                    "end": 1057,
                    "text": "[24]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Traditional Approaches"
        },
        {
            "text": "Other researchers have applied social motivations such as reputation as a pre-quality filtering approach. A social norm and welfare framework was simulated in [30] to mitigate the \"free-riding\" problem in crowdsourcing. Such an approach entails the drawback of evasion by malicious workers. Such workers can even acquire high reputation scores by accepting tasks that are unlikely to be rejected [32] .",
            "cite_spans": [
                {
                    "start": 159,
                    "end": 163,
                    "text": "[30]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 396,
                    "end": 400,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [],
            "section": "Traditional Approaches"
        },
        {
            "text": "A different line of research is focused in tracing the behavior of crowd workers when performing tasks. Kazai and Zitouni [29] stored experts' behavior as behavior features (e.g., mouse movements, clicks, scrolls, and key-presses) of three different tasks. They applied it to training a gradient boosted decision tree classifier to detect poor crowd workers. Rzeszotarski and Kittur [32] proposed a task fingerprinting prototype that was mainly based on the recording of sequential logs of interface events. They collected statistical features related to time and browsing events, and then applied the prototype in different tasks and investigated decision trees to classify passing versus failing workers. Both of the aforementioned studies applied or necessitated expert behavioral data, which are difficult and costly to acquire in practice. In [31] , the authors developed and applied the behavior approach of application layer monitoring. They studied three time aspects (i.e., completion, working phases, and consideration) using very fine-grained interaction level features to feed a support vector machine. One of their main findings was that a robust correlation existed between task interaction time and workers' qualifications. They focused only on time features and neglected other behavior features. A visualization tool called CrowdScape was introduced in [42] . The researchers visualized both worker behavior and output information. They traced workers by analyzing and showing a highly granular user interface interaction level such as mouse movements, clicks, and focus changes. An analysis of search engine result pages was presented in [43] , which studied the behavior of the assessors working on these pages. The authors defined different patterns based on time analysis and ratings accordingly and reported the possibilities of cheating and noncheating behaviors according to those patterns. Another work [16] was limited to an online survey, and collected data from two pre-defined workers. They presented five different groups of workers differentiated by their behavior. Restricted to a questionnaire, the researchers in [10] studied behavior in terms of five personality traits and observations of workers' interactions with some task parameters, and defined another five types of workers.",
            "cite_spans": [
                {
                    "start": 122,
                    "end": 126,
                    "text": "[29]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 383,
                    "end": 387,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 848,
                    "end": 852,
                    "text": "[31]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1370,
                    "end": 1374,
                    "text": "[42]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 1656,
                    "end": 1660,
                    "text": "[43]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 1928,
                    "end": 1932,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 2147,
                    "end": 2151,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Behavior Tracing Approaches"
        },
        {
            "text": "A recent study [34] leveraged from [29, 32] to generate richer behavior features investigated the feasibility of using these features of crowd workers for classifying the correctness of labels and predicting the labeling accuracy of workers. They applied a random forest classifier and a k-means clustering classifier for transforming sequence-like features. Next, they combined the random forest classifier with a co-training supervised na\u00efve Bayes model for the sequence features. Lastly, some crowdsourcing quality research has focused on the consistency behavior of crowd workers, such [44, 45] . Different from the aforementioned studies, the present study aimed to enrich the research by manipulating data as time-series data. This new angle of data manipulation will create opportunities for enhancing the performance of machine learning (ML) models, either by feeding ML models with spacious features as in our feature-based model or by leveraging deep learning models as in our second image-convolutional neural network (image-CNN) model.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 19,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 35,
                    "end": 39,
                    "text": "[29,",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 40,
                    "end": 43,
                    "text": "32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 590,
                    "end": 594,
                    "text": "[44,",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 595,
                    "end": 598,
                    "text": "45]",
                    "ref_id": "BIBREF45"
                }
            ],
            "ref_spans": [],
            "section": "Behavior Tracing Approaches"
        },
        {
            "text": "To evaluate the performance of the proposed models against baselines and for experimental evaluation, we used the public dataset by Goyal et al. [34] . Its behavior data include 3984 HIT records. The data used for crowdsourcing tasks were collected from the 2014 NIST TREC Web Track.1. AMT workers were asked with judging the relevance of documents on 50 predefined topics. The judgment scale for those HITs was multiscale. For our experiments, we used a binary scale; that is, each record was either labeled as 1 if the worker correctly answered the task or 0 if he or she did not. The behavior features of these workers during their annotation were collected. The features were action-based, such as mouse movement, clicking, and scrolling, as well as time-based, such as total time and dwell time. We focused on action-based and converted them into time-series-based features as we will describe later.",
            "cite_spans": [
                {
                    "start": 145,
                    "end": 149,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "Human intelligent tasks (HITs) are tasks performed by crowd workers in crowdsourcing markets. For each HIT, the browsing behavior events of the worker are recorded. In our methodology, these browsing events were: e \u2208 {mouse movement, key click, focus change, scroll, paste} [34] .",
            "cite_spans": [
                {
                    "start": 274,
                    "end": 278,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Proposed Models"
        },
        {
            "text": "In general, time series can be sampled regularly or irregularly through time and can therefore be represented as a vector of time stamps t i , and associated measurements x i . Let the sampling times be t 0 , t 1 , . . . , t n satisfying 0 < t 0 < . . . < t n . If the time points are equally spaced, that is, (t i+1 \u2212 t i = \u2206 for all i = 0, . . . , n \u2212 1 where \u2206 > 0 is some constant) then the time series is regularly sampled; otherwise, it is an irregularly sampled time series.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Models"
        },
        {
            "text": "In our case, the timestamps of the samples were not equally spaced, which meant that our samples were irregularly sampled time series. For each sample, the representation is an ordered vector of events x = {x 1 , x 2 , . . . , x n } with n measurements, where the associated measurement x i is the time at which the associated browsing action occurred. The HIT vectors have variable lengths depending on the number of actions a worker performed for each HIT. Finally, our two models were based on the manipulation of these samples as irregular time-series-like data. For example, consider a simple HIT log listing four browsing events over a 30-s period: ((t = 0, mouse-move), (t = 8, click), (t = 19, focuschange), (t = 30, click)). We recorded such an example as time-series data. This simple HIT is represented as vector = {0, 8, 19 , 30}; such vectors are the input samples for our two models, namely the feature-based model and the image-CNN model. Figure 1 depicts the two proposed models. First, the browsing behaviors of the crowd workers are captured as sets of events \u2208 e. Then, the timestamps of these events are stored for each HIT as time-series samples. These time-series are the inputs for both models. Whereas the feature-based model receives these samples as time-series features and uses an ML model, the image-CNN model receives them as sets of recurrence plot (RP) images/heatmaps. Finally, for both models, the output is a binary class that predicts whether the worker will label the HIT correctly or incorrectly.",
            "cite_spans": [
                {
                    "start": 830,
                    "end": 832,
                    "text": "8,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 833,
                    "end": 835,
                    "text": "19",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [
                {
                    "start": 954,
                    "end": 962,
                    "text": "Figure 1",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Proposed Models"
        },
        {
            "text": "for each HIT as time-series samples. These time-series are the inputs for both models. Whereas the feature-based model receives these samples as time-series features and uses an ML model, the image-CNN model receives them as sets of recurrence plot (RP) images/heatmaps. Finally, for both models, the output is a binary class that predicts whether the worker will label the HIT correctly or incorrectly. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed Models"
        },
        {
            "text": "In this model, we used feature generation and selection approaches to enhance the ML performance. Leveraging from transformed time-series samples, we generated a huge number of features to train ML models. Then, we selected and shed light on those features that remarkably enhanced the ML models' performance and the most important features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature-Based Model"
        },
        {
            "text": "For each time-series sample (workers' HIT browsing behavior), we generated a set of global time-series features [46] (such as measures of its trend, entropy, and distribution). Then, we applied an ML classifier using these features to classify the samples (HITs). Global features of the time-series samples refer to algorithms that quantify patterns in time series across the full sample (rather than capturing subsequences). These global features are divided into different categories, which are described in the following four subsections.",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 116,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Feature Generation"
        },
        {
            "text": "Statistical:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "In this category, there are some simple statistical features, such as mean, median, variance, standard deviation, and sets of quantiles (where a quantile determines how many values in a distribution are above or below a certain limit). Others include count below the mean and ratio beyond sigma. Other more advanced features such as skewness and kurtosis are measures that define how far the distribution differs from a normal distribution. Another one is Benford correlation, which is a correlation resulting from the Newcomb-Benford's Law distribution [47] .",
            "cite_spans": [
                {
                    "start": 554,
                    "end": 558,
                    "text": "[47]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Transformed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "This category contains two popular transformations. The first is the generation of Fourier transform coefficients. We generated the Fourier coefficients of one-dimensional discrete Fourier transform for real input using the fast Fourier transformation (FFT) algorithm as follows: ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "In this model, we used feature generation and selection approaches to enhance the ML performance. Leveraging from transformed time-series samples, we generated a huge number of features to train ML models. Then, we selected and shed light on those features that remarkably enhanced the ML models' performance and the most important features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature-Based Model"
        },
        {
            "text": "For each time-series sample (workers' HIT browsing behavior), we generated a set of global time-series features [46] (such as measures of its trend, entropy, and distribution). Then, we applied an ML classifier using these features to classify the samples (HITs). Global features of the time-series samples refer to algorithms that quantify patterns in time series across the full sample (rather than capturing subsequences). These global features are divided into different categories, which are described in the following four subsections.",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 116,
                    "text": "[46]",
                    "ref_id": "BIBREF46"
                }
            ],
            "ref_spans": [],
            "section": "Feature Generation"
        },
        {
            "text": "Statistical:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "In this category, there are some simple statistical features, such as mean, median, variance, standard deviation, and sets of quantiles (where a quantile determines how many values in a distribution are above or below a certain limit). Others include count below the mean and ratio beyond sigma. Other more advanced features such as skewness and kurtosis are measures that define how far the distribution differs from a normal distribution. Another one is Benford correlation, which is a correlation resulting from the Newcomb-Benford's Law distribution [47] .",
            "cite_spans": [
                {
                    "start": 554,
                    "end": 558,
                    "text": "[47]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Transformed:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "This category contains two popular transformations. The first is the generation of Fourier transform coefficients. We generated the Fourier coefficients of one-dimensional discrete Fourier transform for real input using the fast Fourier transformation (FFT) algorithm as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "where A is the returned coefficients and a is the time series. Furthermore, we leveraged FFT to extract statistical features of the absolute Fourier transform spectrum, such as spectral centroid (mean), variance, skew, and kurtosis. The second transformation is continuous wavelet transformation (CWT). We applied Mexican hat wavelet [48] , which is the negative normalized second derivative of a Gaussian function: where \u03c3 is the width parameter of the wavelet function \u03c8.",
            "cite_spans": [
                {
                    "start": 334,
                    "end": 338,
                    "text": "[48]",
                    "ref_id": "BIBREF48"
                }
            ],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "\u2022 Information theory/entropy: Different entropy measures were generated, such as sample and approximate entropy [49] and permutation entropy [50] . Other entropy measures were generated from the transformed one such as the binned entropy of the FFT.",
            "cite_spans": [
                {
                    "start": 112,
                    "end": 116,
                    "text": "[49]",
                    "ref_id": "BIBREF49"
                },
                {
                    "start": 141,
                    "end": 145,
                    "text": "[50]",
                    "ref_id": "BIBREF50"
                }
            ],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Time-series-related/others:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "We also generated simple features related to the time-series, such as the sum, length, maximum, and minimum. Other specific time-series features were generated, including absolute energy, which is the sum over the squared values of the samples; energy ratio by chunks, which is the sum of squares or chunk i out of N chunks, and it is a ratio over the whole series; complexity estimation, which estimates how complex the time series is (e.g., whether it has more peaks or valleys); and symmetry, which checks whether the distribution of the sample is symmetrical.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Many features from the previous step have many sub-features. For example, there are nine quantiles and many coefficients for CWT and FFT, and many Fourier entropy bins. For each event e, there are approximately hundreds of generated features. As a result, the number of features returned from the generation step is huge. Therefore, we applied a feature selection/reduction approach to shed light on the most important features, and those remarkable features enhanced the ML models' performance. We selected the extremely randomized trees classifier (ExtraTreeClassifier) for the feature selection/reduction. In our case, the HIT events in terms of time stamps were the vector samples. These samples were the input feature for this approach. The tsfresh [51] module was used for feature generation. In this step, the number of features generated was enormous. There were 3896 features, including the features in the section above, as well as others. These features were divided into training and testing sets for training a random forest (RF) model. Moreover, due to the huge number of features generated, we applied a feature selection approach to find the important features that mainly affect the ML model; then, we shed light on the most important features. We applied the ExtraTreesClassifier [52] for feature selection and then trained and tested the same RF model using these resulting features. We experimented with different thresholds for this step and investigated how they would affect the performance of the model. The list of 78 important features that returned from a mean threshold are shown in Table A1 at Appendix A.",
            "cite_spans": [
                {
                    "start": 754,
                    "end": 758,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                },
                {
                    "start": 1298,
                    "end": 1302,
                    "text": "[52]",
                    "ref_id": "BIBREF52"
                }
            ],
            "ref_spans": [
                {
                    "start": 1611,
                    "end": 1619,
                    "text": "Table A1",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Feature Selection/Reduction"
        },
        {
            "text": "In this model, we first converted the input time-series data into other behavior recurrent samples and then used the CNN model to train and test the new samples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image-CNN Model"
        },
        {
            "text": "Time series can be characterized by a featured recurrent behavior such as irregular periodicities. The recurrence plot (RP) is a famous tool for studying and visualizing such behaviors. It provides a graphical representation of the recurrent patterns in time-series signals. Eckmann et al. [53] proposed the RP as a matrix of pairwise recurrences of phasespace states. For a given trajectory \u2192 x i = (i = 1, 2, 3, . . . , N) and x i \u2208 R m , the RP is defined as follows:",
            "cite_spans": [
                {
                    "start": 290,
                    "end": 294,
                    "text": "[53]",
                    "ref_id": "BIBREF53"
                }
            ],
            "ref_spans": [],
            "section": "Recurrence Plot"
        },
        {
            "text": "where H(\u00b7) is the Heaviside function, ||\u00b7|| is the norm, and \u03b5 is a distance threshold. Basically, R i,j \u2261 1 if time i recurs to a former (or later) state at j, and R i,j \u2261 0 otherwise. In our case, we used a gray level instead of binarization to preserve much information (i.e., to which level x j is close to x i )). The distance between two states || \u2192 x i \u2212 \u2192 x j || was calculated using the Euclidean distance:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recurrence Plot"
        },
        {
            "text": "Regarding \u03b5, we ignored the distance threshold. After calculating the distances, the recurrence matrices were stored as gray-level images (heatmaps) to be inputs for the model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Recurrence Plot"
        },
        {
            "text": "Compared with traditional ML methods, deep learning (DL) recently achieved great success in many computer science fields. CNNs are one of the most popular DL models. CNNs have achieved excellent performance in the image classification field [50] . We used a CNN to classify the images formed from the RP step as introduced in [51] . We used an enhancement of the model by concatenating the feature outputs from the CNN with auxiliary features to optimize the classifier. The details of CNN model are as follows.",
            "cite_spans": [
                {
                    "start": 241,
                    "end": 245,
                    "text": "[50]",
                    "ref_id": "BIBREF50"
                },
                {
                    "start": 326,
                    "end": 330,
                    "text": "[51]",
                    "ref_id": "BIBREF51"
                }
            ],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "The input to our network is an observation set D = {I i , y i ; i = 1, . . . , N} containing N instances of I i \u2208 R d (gray-scale image as the d-dimensional vector, d = 2 and number of channels = 1) with corresponding labels y i \u2208 C (i.e., C{0, 1} for binary classification) annotated by the workers. The goal is to learn the CNN model, represented by f : I \u2192 Y , from the labels that generalized well on unseen data:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "wherep is the predicted label for an unseen image x, and \u03b8 is the learned model parameter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "The 2D convolution layer has the images I masked by a kernel K as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "where i, j are dimensions of the image and m, n are dimensions of the kernel. Now, we consider a kernel K of size k \u00d7 k, and x is a k \u00d7 k patch of the image. The activation is obtained by sliding the k \u00d7 k window and computing",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "where b is a bias and \u03d5 is the activation function. The rectified linear unit (ReLU) [54] is used as follows:",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 89,
                    "text": "[54]",
                    "ref_id": "BIBREF54"
                }
            ],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "Then, a sub-sampling is used by adding a pooling layer (MaxPooling). After that, the flattening of the output is concatenated with a set of auxiliary features that are entered in two layers. These layers are the multilayer perceptron (or neural network). First, the fully connected hidden layer is followed by the output layer as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "For L = 1 (hidden layer):",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "For L = L + 1 (output layer): where h 0 (x) = z(x) that was calculated in (7); W is the weight vector w g = w g,1 , . . . , w g,d ; and \u03b4 is the ReLU activation function for the fully connected layer. Finally, \u03c8 is the activation function of the output layer, which is Sigmoid, and its output is the classification label p. At each step, W L is a matrix for which the number of rows is the number of neurons (features x) in layer L and the number of columns is the number of neurons in layer +1. Regarding the architecture of our model, we defined the startup architecture and then we optimized it by tuning different hyper-parameters. The CNN model had one input channel of size 32 \u00d7 32, which represents the height and width of the gray images (the reason being that the time-series data had variable length, the longest sample being 128 and the smallest being 28; the average length was 32, so we selected the average length). These images were generated from RP mapping; 3985 samples were converted into gray images with variable dimensions. All were resized to the fixed 32 \u00d7 32 dimensions. The number of filters was 32; these filters had a 3 \u00d7 3 window size. Regarding the activation function, ReLU Equation (8) was implemented. The model had a subsampling step using the MaxPooling layer. To prevent the model from overfitting, a dropout with a 0.2 rate value was used. The model was flattened after that to enable the concatenation with auxiliary features. These auxiliary features were used to enhance our CNN model. They are shown in Table 1 (adapted from [32, 34] ). A fully connected layer with 64 neurons was used, followed by another dropout with a 0.5 rate. The last layer in the model is a single neuron with sigmoid activation to classify the images into two classes. For learning, we applied the Adam optimizer [55] . Binary cross entropy was used as the loss function. The number of epochs started with 200 and a batch size of 25. The validation ratio was 20% of the data. For added details, we now describe the output dimensions of the layers. We have image I with dimensions of 32 \u00d7 32, one channel C (grayscale), and a filter size of 3 \u00d7 3. The default stride s of filter movement was 1. Furthermore, the convolution padding p was zero.",
            "cite_spans": [
                {
                    "start": 1566,
                    "end": 1570,
                    "text": "[32,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1571,
                    "end": 1574,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 1829,
                    "end": 1833,
                    "text": "[55]",
                    "ref_id": "BIBREF55"
                }
            ],
            "ref_spans": [
                {
                    "start": 1544,
                    "end": 1551,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "CNN Model"
        },
        {
            "text": "The convolution output dimension = [((I \u2212 K)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "CNN Model"
        },
        {
            "text": "Therefore, the output dimension = 30 \u00d7 30 \u00d7 1. This was put into the pooling layer. In the MaxPooling2D layer in Keras, the default stride equals the pooling size, and our pooling size was 2 \u00d7 2; thus, s = 2. Using Equation (13) features, give the total number of features-7211. This means that W L in Equation (13) has dimensions of 7211 \u00d7 64, namely the features multiplied by the number of neurons of the fully connected layer. The last sigmoid layer produces a label of either 0 or 1. The detailed architecture of this model is presented in Figure 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 545,
                    "end": 553,
                    "text": "Figure 2",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "CNN Model"
        },
        {
            "text": "Therefore, the output dimension = 30 \u00d7 30 \u00d7 1. This was put into the pooling layer. In the MaxPooling2D layer in Keras, the default stride equals the pooling size, and our pooling size was 2 \u00d7 2 ; thus, s = 2. Using Equation (13) again, [((30 \u2212 2) + 2 \u00d7 0) 2] + 1 \u00d7 1 = 15 \u2044 . Consequently, the pooling output dimension = 15 \u00d7 15 \u00d7 1, and we had 32 filters, so the number of features was 15 \u00d7 15 \u00d7 32 = 7200. These features, concatenated with 11 auxiliary features, give the total number of features-7211. This means that W in Equation (13) has dimensions of 7211 \u00d7 64, namely the features multiplied by the number of neurons of the fully connected layer. The last sigmoid layer produces a label of either 0 or 1. The detailed architecture of this model is presented in Figure 2 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 770,
                    "end": 778,
                    "text": "Figure 2",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "CNN Model"
        },
        {
            "text": "To evaluate the classification, we adopted accuracy as the comparison evaluation metric. Moreover, since the dataset had imbalance classes, we used the area under the curve (AUC) of the receiver operating characteristics (ROC) curve scores.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation Metrics"
        },
        {
            "text": "Parameters tuning:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "One of the most common techniques for hyperparameters tuning in machine learning models is cross-validation (CV) using k number of folds. Random forests are not an exception. So, we first tuned the model hyperparameters using 10-fold CV to ensure that the model train and test 10 different data samples. We then calculated the average performance of these divided data samples. We further tuned the hyperparameters by randomizing search of optimized parameters. We defined a grid of hyperparameter ranges and random samples from the grid, performing 10-fold CV with each combination of values. We tuned different parameters using this method and the results were: no bootstrapping, no maximum depth, 131 features as maximum number, 7 minimum number of samples split, and 408 estimators. This optimization improved the performance for feature generation model by 1.7% in terms of accuracy and by non-noticeable improvement for AUC-ROC. Approximately, the feature selection model enhanced accuracy by 1% and it seems like the first model in terms of AUC-ROC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Feature generation and selection:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "For the first model, 3896 features were generated. Therefore, we used ExtraTreesClassifier for feature selection and to demonstrate the important features from among the numerous features. Using ExtraTreesClassifier, we retrieved the importance of each feature. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "To evaluate the classification, we adopted accuracy as the comparison evaluation metric. Moreover, since the dataset had imbalance classes, we used the area under the curve (AUC) of the receiver operating characteristics (ROC) curve scores.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Evaluation Metrics"
        },
        {
            "text": "Parameters tuning:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "One of the most common techniques for hyperparameters tuning in machine learning models is cross-validation (CV) using k number of folds. Random forests are not an exception. So, we first tuned the model hyperparameters using 10-fold CV to ensure that the model train and test 10 different data samples. We then calculated the average performance of these divided data samples. We further tuned the hyperparameters by randomizing search of optimized parameters. We defined a grid of hyperparameter ranges and random samples from the grid, performing 10-fold CV with each combination of values. We tuned different parameters using this method and the results were: no bootstrapping, no maximum depth, 131 features as maximum number, 7 minimum number of samples split, and 408 estimators. This optimization improved the performance for feature generation model by 1.7% in terms of accuracy and by non-noticeable improvement for AUC-ROC. Approximately, the feature selection model enhanced accuracy by 1% and it seems like the first model in terms of AUC-ROC.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "Feature generation and selection:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u2022"
        },
        {
            "text": "For the first model, 3896 features were generated. Therefore, we used ExtraTreesClassifier for feature selection and to demonstrate the important features from among the numerous features. Using ExtraTreesClassifier, we retrieved the importance of each feature. The importance represents the mean decrease in the Gini-impurity. Mean decrease in Gini is a famous measure of variable importance for estimating a target variable in decision trees, random forests, ExtraTrees models. The variable is the feature, and the target is the class. Different means of importance of all features are considered as importance thresholds. The higher the number, the more important the feature. Moreover, we used different thresholds to show how many important features were reduced by the model, as well as the accuracy and AUC-ROC score for each threshold. The thresholds are different means of the importance threshold that resulted from the ExtraTreesClassifier, as presented in Table 2 . It reveals that both the accuracy and AUC-ROC fluctuated between 83% and 80% until the number of features reached 41, when they began to decrease to approximately 78%. In this subsection, we outline the results of our CNN model using various hyperparameters. Since the learning rate is one of the most important hyper-parameters to tune for training deep neural networks, we implemented an experiment to select the most suitable learning rate. We fixed the number of epochs to 300 and the dropout rate for the convolutional layer and dense layer to 0.5 and 0.25, respectively; consequently, the batch size was set to 50. Leveraging from [56] , we set the learning rate range as base_lr = 0.1 and max_lr = 10 \u22126 . We started from a low learning rate and increased it exponentially for every batch using the step size, which we set to step_size = 20.",
            "cite_spans": [
                {
                    "start": 1615,
                    "end": 1619,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [
                {
                    "start": 968,
                    "end": 975,
                    "text": "Table 2",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "\u2022"
        },
        {
            "text": "As Figure 3 shows, there was a continuous decrease until reaching a stable state. The point of stability estimates the most suitable learning rate. We approximated it as 10 \u22124 . We fixed this learning rate for all subsequent hyper-parameters experiments. Regarding the number of epochs, we experimented with the training/validation loss and accuracy against 300 epochs, as shown in Figure 4 . We found that at approximately 150 epochs, the validation accuracy and loss started to be fixed. This meant that the model started to be stable around 150 epochs and it seemed to enter in overfitting just after that. Therefore, we fixed the number of epochs to 150 for the following experiments.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 11,
                    "text": "Figure 3",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 382,
                    "end": 390,
                    "text": "Figure 4",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "\u2022"
        },
        {
            "text": "The importance represents the mean decrease in the Gini-impurity. Mean decrease in Gini is a famous measure of variable importance for estimating a target variable in decision trees, random forests, ExtraTrees models. The variable is the feature, and the target is the class. Different means of importance of all features are considered as importance thresholds. The higher the number, the more important the feature. Moreover, we used different thresholds to show how many important features were reduced by the model, as well as the accuracy and AUC-ROC score for each threshold. The thresholds are different means of the importance threshold that resulted from the ExtraTreesClassifier, as presented in Table 2 . It reveals that both the accuracy and AUC-ROC fluctuated between 83% and 80% until the number of features reached 41, when they began to decrease to approximately 78%. In this subsection, we outline the results of our CNN model using various hyperparameters. Since the learning rate is one of the most important hyper-parameters to tune for training deep neural networks, we implemented an experiment to select the most suitable learning rate. We fixed the number of epochs to 300 and the dropout rate for the convolutional layer and dense layer to 0.5 and 0.25, respectively; consequently, the batch size was set to 50. Leveraging from [56] , we set the learning rate range as base_lr = 0.1 and max_lr = 10 . We started from a low learning rate and increased it exponentially for every batch using the step size, which we set to step_size = 20.",
            "cite_spans": [
                {
                    "start": 1353,
                    "end": 1357,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [
                {
                    "start": 706,
                    "end": 713,
                    "text": "Table 2",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "\u2022"
        },
        {
            "text": "As Figure 3 shows, there was a continuous decrease until reaching a stable state. The point of stability estimates the most suitable learning rate. We approximated it as 10 . We fixed this learning rate for all subsequent hyper-parameters experiments. Regarding the number of epochs, we experimented with the training/validation loss and accuracy against 300 epochs, as shown in Figure 4 . We found that at approximately 150 epochs, the validation accuracy and loss started to be fixed. This meant that the model started to be stable around 150 epochs and it seemed to enter in overfitting just after that. Therefore, we fixed the number of epochs to 150 for the following experiments. Therefore, our initial hyper-parameters were as follows: learning rate: 10 \u22124 , epochs: 150, input dimensions 32 \u00d7 32, and dropout rates for the convolutional layer and dense layer = 0.5 and 0.25, respectively. Table 3 presents the use of different hyper-parameters and the corresponding training, validation accuracy, and loss. We selected the best validation accuracy and loss for fixing the hyper-parameters and then started to tune the next one. Therefore, our initial hyper-parameters were as follows: learning rate: 10 , epochs: 150, input dimensions 32 \u00d7 32, and dropout rates for the convolutional layer and dense layer = 0.5 and 0.25, respectively. Table 3 presents the use of different hyper-parameters and the corresponding training, validation accuracy, and loss. We selected the best validation accuracy and loss for fixing the hyper-parameters and then started to tune the next one. First, we used batch sizes of 25, 50, and 75 and found that the optimal validation accuracy and loss were achieved with a batch size of 50. Second, for the convolutional layer, we used dropout rates of 0.25, 0.50, and 0.75. We noticed that the model attained the optimal validation accuracy and loss with the 0.25 dropout rate. The same was found with the fully connected layer where the 0.25 dropout rate achieved the best results. Finally, we tried some different dimensions for the images, namely 56 \u00d7 56, 28 \u00d7 28, and 32 \u00d7 32, as recommended in [57] . Regarding the training, validation loss, and accuracy across the epochs, since we conducted a k-folding experiment with k = 10, we only present two folds (the third and eighth epochs) in Figure 5 . First, we used batch sizes of 25, 50, and 75 and found that the optimal validation accuracy and loss were achieved with a batch size of 50. Second, for the convolutional layer, we used dropout rates of 0.25, 0.50, and 0.75. We noticed that the model attained the optimal validation accuracy and loss with the 0.25 dropout rate. The same was found with the fully connected layer where the 0.25 dropout rate achieved the best results. Finally, we tried some different dimensions for the images, namely 56 \u00d7 56, 28 \u00d7 28, and 32 \u00d7 32, as recommended in [57] . Regarding the training, validation loss, and accuracy across the epochs, since we conducted a k-folding experiment with k = 10, we only present two folds (the third and eighth epochs) in Figure 5 . ",
            "cite_spans": [
                {
                    "start": 2132,
                    "end": 2136,
                    "text": "[57]",
                    "ref_id": "BIBREF57"
                },
                {
                    "start": 2886,
                    "end": 2890,
                    "text": "[57]",
                    "ref_id": "BIBREF57"
                }
            ],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 11,
                    "text": "Figure 3",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 379,
                    "end": 387,
                    "text": "Figure 4",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 897,
                    "end": 904,
                    "text": "Table 3",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 1344,
                    "end": 1351,
                    "text": "Table 3",
                    "ref_id": "TABREF5"
                },
                {
                    "start": 2326,
                    "end": 2334,
                    "text": "Figure 5",
                    "ref_id": "FIGREF13"
                },
                {
                    "start": 3080,
                    "end": 3088,
                    "text": "Figure 5",
                    "ref_id": "FIGREF13"
                }
            ],
            "section": "\u2022"
        },
        {
            "text": "The proposed models' performances were compared with different baselines using the dataset of Goyal et al. [34] . The first baseline was a decision tree with aggregate features (DT-AF) classifier, which is a classifier model from Rzeszotarski and Kittur [32] . It uses behavior features in addition to updated aggregated behavior features of Goyal et al. [34] . The second baseline was a random forest [58] with the same aggregate features (RF-AF) classifier, which was a generalization of the DT-AF classifier. We applied some optimization for these two baselines like the parameters tuning in Section 4.1.2. Same parameters for RF-AF with our feature-based models, which are random forest algorithms. However, we tuned the parameters less with DT-AF since decision trees had fewer parameters to be tuned. In spite of that, DT-AF had noticeable enhancement compared to no improvement for RF-AF.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 111,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 254,
                    "end": 258,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 355,
                    "end": 359,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 402,
                    "end": 406,
                    "text": "[58]",
                    "ref_id": "BIBREF58"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "The third and fourth baselines were popular classifiers in time-series field. The third was k-nearest neighbor classifier using dynamic time warping (DTW) as a distance measure. This classifier has received enduring interest and been shown to be effective for timeseries classification [59] . DWT is a popular comparison algorithm in time-series analysis that finds an optimal alignment between two given (time-dependent) sequences under certain restrictions [60] , rather than measuring similarity or dis-similarity between two input times series using Euclidian distance between the corresponding points of the inputs. DTW is a very robust method to compare them using a sliding window instead of pair comparison. This is to ignore any phase shifts and speed between the inputs. We consider this simple approach, since it often produces better results than more complex classifiers [61] .",
            "cite_spans": [
                {
                    "start": 286,
                    "end": 290,
                    "text": "[59]",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 459,
                    "end": 463,
                    "text": "[60]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 884,
                    "end": 888,
                    "text": "[61]",
                    "ref_id": "BIBREF61"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "The fourth and final baseline was a support vector classifier SVC for the time series data (TS-SVC). Support vector classifier (SVC) is an algorithm that searches for the optimal separating surface between classes using hyperplane. When there is a non-linearity relation between the data, such as in our case, SVC needs to apply a suitable kernel. In the domains that frequently use time-series data such as bioinformatics, there is increasing domain-kernels usage [62] . We applied SVC with such time-series called global alignment ",
            "cite_spans": [
                {
                    "start": 465,
                    "end": 469,
                    "text": "[62]",
                    "ref_id": "BIBREF62"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "The proposed models' performances were compared with different baselines using the dataset of Goyal et al. [34] . The first baseline was a decision tree with aggregate features (DT-AF) classifier, which is a classifier model from Rzeszotarski and Kittur [32] . It uses behavior features in addition to updated aggregated behavior features of Goyal et al. [34] . The second baseline was a random forest [58] with the same aggregate features (RF-AF) classifier, which was a generalization of the DT-AF classifier. We applied some optimization for these two baselines like the parameters tuning in Section 4.1.2. Same parameters for RF-AF with our feature-based models, which are random forest algorithms. However, we tuned the parameters less with DT-AF since decision trees had fewer parameters to be tuned. In spite of that, DT-AF had noticeable enhancement compared to no improvement for RF-AF.",
            "cite_spans": [
                {
                    "start": 107,
                    "end": 111,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 254,
                    "end": 258,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 355,
                    "end": 359,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 402,
                    "end": 406,
                    "text": "[58]",
                    "ref_id": "BIBREF58"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "The third and fourth baselines were popular classifiers in time-series field. The third was k-nearest neighbor classifier using dynamic time warping (DTW) as a distance measure. This classifier has received enduring interest and been shown to be effective for time-series classification [59] . DWT is a popular comparison algorithm in time-series analysis that finds an optimal alignment between two given (time-dependent) sequences under certain restrictions [60] , rather than measuring similarity or dis-similarity between two input times series using Euclidian distance between the corresponding points of the inputs. DTW is a very robust method to compare them using a sliding window instead of pair comparison. This is to ignore any phase shifts and speed between the inputs. We consider this simple approach, since it often produces better results than more complex classifiers [61] .",
            "cite_spans": [
                {
                    "start": 287,
                    "end": 291,
                    "text": "[59]",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 460,
                    "end": 464,
                    "text": "[60]",
                    "ref_id": "BIBREF60"
                },
                {
                    "start": 885,
                    "end": 889,
                    "text": "[61]",
                    "ref_id": "BIBREF61"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "The fourth and final baseline was a support vector classifier SVC for the time series data (TS-SVC). Support vector classifier (SVC) is an algorithm that searches for the optimal separating surface between classes using hyperplane. When there is a non-linearity relation between the data, such as in our case, SVC needs to apply a suitable kernel. In the domains that frequently use time-series data such as bioinformatics, there is increasing domain-kernels usage [62] . We applied SVC with such time-series called global alignment kernel [63] . This kernel implements a maximum smoothed DTW score across all possible alignments between the two compared time-series samples. TS-SVCs are promising methods for predicting different time-series domains such as financial [64] or biomedicine [65] . No dedicated optimization is applied for these models. We tried some parameter tuning like the number of neighbors, but no noticeable enhancement occurred. This, unfortunately, came with a large increase in time complexity.",
            "cite_spans": [
                {
                    "start": 465,
                    "end": 469,
                    "text": "[62]",
                    "ref_id": "BIBREF62"
                },
                {
                    "start": 540,
                    "end": 544,
                    "text": "[63]",
                    "ref_id": "BIBREF63"
                },
                {
                    "start": 769,
                    "end": 773,
                    "text": "[64]",
                    "ref_id": "BIBREF65"
                },
                {
                    "start": 789,
                    "end": 793,
                    "text": "[65]",
                    "ref_id": "BIBREF66"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "For the DT-AF baseline, we used the default settings. For the RF-AF model, we used an ensemble of 100 trees in the forest. We used the scikit-learn module [66] for these baselines. For DTW, we used two neighbors for distance calculations. For both the DTW and TS-SVC baselines, we implemented the corresponding Tslearn [67] libraries. For the division of data, we used 10-fold cross-validation and the test size was 20% for all models. The experiments were conducted on a machine with the following criteria: a GeForce GTX 980 GPU with 47 GB RAM, using Python 3.8 and Keras API in the Ubuntu 20.04 operating system.4.2.6. Comparison with baselines:",
            "cite_spans": [
                {
                    "start": 155,
                    "end": 159,
                    "text": "[66]",
                    "ref_id": "BIBREF67"
                },
                {
                    "start": 319,
                    "end": 323,
                    "text": "[67]",
                    "ref_id": "BIBREF68"
                }
            ],
            "ref_spans": [],
            "section": "Parameters and Software"
        },
        {
            "text": "In this subsection, we present the classification metrics and results of the proposed methods and baselines. Our models achieved optimal accuracy. The two feature-based models attained accuracies of 83.8% and 81.8%, followed by the image-CNN model, which attained 76.6%. Furthermore, in terms of AUC-ROC, the two feature-based models won, achieving accuracies of 82% and 80.9%, followed by the image-CNN model, which achieved 72.3%. We believe that the image-CNN model was able to achieve better results; however, the number of samples was small, and such CNN deep networks require a huge amount of data. For DTW, we only used two neighbors since any increase in neighbors would increase the time complexity of the model without any noticeable enhancement in performance. TS-SVC had the same time complexity challenge, and the same observations were noted; specifically, any increase in the comparison numbers led to increased quadratic time complexity without a remarkable improvement in the results. Table 4 presents the results of the performance comparison against baselines in terms of accuracy and AUC-ROC with an average 10-fold cross-validation. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1002,
                    "end": 1009,
                    "text": "Table 4",
                    "ref_id": "TABREF7"
                }
            ],
            "section": "Parameters and Software"
        },
        {
            "text": "The feature-based models achieved superior performance over analogous models such as [32, 34] . A significant factor is the large number of features generated from our time-series transformation. Rather than having around twenty features in the baselines, our model has around 4k features in the first feature-based model and 41 features for the worst performance of the second model. The results showed that the feature-based models classified the workers well when their browsing events in HITs were captured as time-series samples. This gives the indication about the good consideration of crowd behavior as a time-series representation. Regarding the optimization of these models, we found that cross validation with main hyperparameter tuning raised the performance around 2%. This is a fine percentage. However, we did not expect more noticeable improvement for further optimization. These models have limited options in the optimizations. Regarding the most important features affecting the performance, as Appendix A shows, the majority were related to either mouse movement or focus change events. Mouse movement was the most significant event followed by focus change and then key clicks. In addition, scrolling and paste events seemed not to exhibit any noticeable enhancement in the ML models. This seems reasonable, since the workers in the HIT used more mouse movements than other events. The focus change gives a good indication about the intention of the workers to do a good work. Generally, among 78 features, we found that 41 features were related to mouse movement, followed by 20 related to focus change and only 16 related to key clicks. In particular, significant features were the transformed ones such as the CWT and FFT coefficients for both focus change and mouse movement. In addition, large sets of quantiles had significant impacts in the ML models. Other statistics such as mouse movement and focus change maximum, minimum, and mean were also important. This indicated that the statistical features of mouse movement and focus change remarkably affected the classifier performance. Mouse movement absolute energy and energy ratio by chunks were other important features. Moreover, especially for mouse movement, approximate entropy was returned as an important feature. This could be reasonable since approximate entropy is designed to work for small data samples (n < 50 points) [68] , and we had n = 32.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 89,
                    "text": "[32,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 90,
                    "end": 93,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 2411,
                    "end": 2415,
                    "text": "[68]",
                    "ref_id": "BIBREF69"
                }
            ],
            "ref_spans": [],
            "section": "Feature-Based Models"
        },
        {
            "text": "Differently, we selected a new model in this research scope compared to saturated ones such as random forest, decision trees [29, 32, 34] . Our image-CNN model archived comparable performance results despite the small number of behavior traces. Such shortage in data samples does not yield competitive performance using such neural networks models [34] . Therefore, one of the factors of such performance is the transformation of the numeric data into heatmap images. CNN is the most widely used deep learning model in the areas of image processing [69] . Many researchers used variations of CNNs for image classification and achieved superior performance such as [70] [71] [72] . Another factor is the intensive optimization for this model. We deepened the optimization in this model to enhance the performance because such models are rare/nonexistent in the research of classifying crowdsourcing workers using their behavior. This model presents a prospective beginning for further research on neural models such as deep CNN and long short-term memory (LSTM) models. For the optimization we implemented hyperparameter optimization HPO [73] . It consists in fixing the various hyperparameters of the model. We optimized global hyperparameters like learning rate, epochs, and regularization parameters such as dropout rates. We started the tuning from the learning rate since it is one of the most important factors [56] . Then, we gradually tuned other significance hyperparameter like number of epochs, batch size, dropout rate, and dimensions. The accuracy and loss monitoring are the key for such tuning. In terms of the number of epochs and the dropout rate, overfitting was alarming. We selected 150 epochs and dropout rates as 0.25 in both layers since other values for epochs and dropout rates led to overfitting. Regarding the image dimension, as expected, 32 \u00d7 32 provided the best results since it was equal to our average time-series sample length, which is 32.",
            "cite_spans": [
                {
                    "start": 125,
                    "end": 129,
                    "text": "[29,",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 130,
                    "end": 133,
                    "text": "32,",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 134,
                    "end": 137,
                    "text": "34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 348,
                    "end": 352,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 549,
                    "end": 553,
                    "text": "[69]",
                    "ref_id": "BIBREF70"
                },
                {
                    "start": 664,
                    "end": 668,
                    "text": "[70]",
                    "ref_id": "BIBREF71"
                },
                {
                    "start": 669,
                    "end": 673,
                    "text": "[71]",
                    "ref_id": "BIBREF72"
                },
                {
                    "start": 674,
                    "end": 678,
                    "text": "[72]",
                    "ref_id": "BIBREF73"
                },
                {
                    "start": 1137,
                    "end": 1141,
                    "text": "[73]",
                    "ref_id": "BIBREF74"
                },
                {
                    "start": 1416,
                    "end": 1420,
                    "text": "[56]",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "Image-CNN Model"
        },
        {
            "text": "The baselines are of two types: (a) state-of-the-art models such as dynamic time warping (DTW) and time-series support vector classifier (TS-SVC). (b) Leading research works by Rzeszotarski and Kittur [32] and Goyal et al. [34] . Regarding their optimizations, for both DT-AF and RF-AF, in terms of accuracy, only DT-AF model achieved considerable enhancement. It reached the performance adjacent to RF-AF model. This could be interpreted based on the small number of features. A small number of features did not result in any performance disparity between decision trees and random forests. However, decision trees needed some more optimization. RF-AF model did not achieve any noticeable enhancement. In terms of AUC-ROC, there was no enhancement for either model. Even after optimizations, DT-AF and RF-AF models still achieved lower performance compared to the proposed models. Alternatively, we did not make any considerable optimizations for DTW or TS-SVC models. For DTW, we only used two neighbors since any increase in neighbors would increase the time complexity of the model without any noticeable enhancement in performance. TS-SVC had the same time complexity challenge, and the same observations were noted; specifically, any increase in the comparison numbers led to increased quadratic time complexity without a remarkable improvement in the results.",
            "cite_spans": [
                {
                    "start": 201,
                    "end": 205,
                    "text": "[32]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 223,
                    "end": 227,
                    "text": "[34]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Baselines"
        },
        {
            "text": "In this study, two new models were proposed to deal with the quality problems related to crowdsourcing. These models depended on time-series data. These data represented the browsing behavior of crowd workers. Each model dealt with the data differently. The feature-based model generated a huge number of features that fed an ML classifier. The richness of the features enhanced the classifier's performance. Our experiments shed light on which features were the most important, and, consequently, on the remarkable browsing events that determine crowdsourced work quality. The image-CNN model gathered the time-series data as recurrent heatmaps and fed a CNN model. The two models provided a classification for HITs that predicted whether a HIT would be performed correctly by a worker based on his or her browsing behavior. Both models significantly outperformed the state-of-the-art and leading classifiers.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "There are some limitations in our work. The training data are limited in this study regarding models such as image-CNN model. The performance of new promising AI approaches, such as deep learning, is strongly correlated with the amount of training data available. Therefore, further research is needed to exploit larger training data. This could be carried out either by creating an extensive dataset and then using this dataset as time series with recent models such as LSTM, or, alternatively, by implementing data augmentation for the generated recurrent images in this study. Undoubtedly, this will enhance the CNN performance, specially with extending the CNN model into deep CNN with more deep layers and more hyperparameter tuning. Another limitation is the transformation into irregular time series samples. Although the performance of the proposed models is noteworthy, having a likely regular time series sample will enhance the models remarkably. Therefore, in future work, we plan to resample time-series using different techniques. Rather than primitive methods such as shifting and imputing, we will exploit more advanced resampling approaches such as periodic identification [74] and causality analysis [75] . One more limitation is the performance of DTW and TS-SVC models. We did not perform an optimization for these models due to the time complexity of such models. However, a window of further research is possible using Faster DWT algorithms [76] similar to [77] . This will feasibly optimize these time series models. ",
            "cite_spans": [
                {
                    "start": 1190,
                    "end": 1194,
                    "text": "[74]",
                    "ref_id": "BIBREF75"
                },
                {
                    "start": 1218,
                    "end": 1222,
                    "text": "[75]",
                    "ref_id": "BIBREF76"
                },
                {
                    "start": 1463,
                    "end": 1467,
                    "text": "[76]",
                    "ref_id": "BIBREF77"
                },
                {
                    "start": 1479,
                    "end": 1483,
                    "text": "[77]",
                    "ref_id": "BIBREF78"
                }
            ],
            "ref_spans": [],
            "section": "Conclusions"
        },
        {
            "text": "In this appendix, we present the details of the features that result from the feature selection stage of the feature-based model at Table A1 . ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 132,
                    "end": 140,
                    "text": "Table A1",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Appendix A"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "The Rise of Crowdsourcing",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Howe",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Handbook of Linguistic Annotation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Poesio",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chamberlain",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Kruschwitz",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Crowdsourcing",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Labeling images with a computer game",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Von Ahn",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dabbish",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Proceedings of the 2004 Conference on Human factors in Computing Systems-CHI'04",
            "volume": "",
            "issn": "",
            "pages": "319--326",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Extracting COVID-19 events from Twitter",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zong",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Baheti",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ritter",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2006.02567"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "CrowdLearn: A crowd-AI hybrid system for deep learning-based damage assessment applications",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Plummer",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)",
            "volume": "2019",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Creating task-generic features for fake news detection",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Olivieri",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Shabani",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sokhn",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Cudr\u00e9-Mauroux",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 52nd Hawaii International Conference on System Sciences",
            "volume": "6",
            "issn": "",
            "pages": "5196--5205",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "AggNet: Deep learning from crowds for mitosis detection in breast cancer histology images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Albarqouni",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Baur",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Achilles",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Belagiannis",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Demirci",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Navab",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "35",
            "issn": "",
            "pages": "1313--1321",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2016.2528120"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Zha, H. Visually explainable recommendation. arXiv 2018",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Human Computation: A Survey and Taxonomy of a Growing Field",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Quinn",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "B"
                    ],
                    "last": "Bederson",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
            "volume": "",
            "issn": "",
            "pages": "1403--1412",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Worker types and personality traits in crowdsourcing relevance labels",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kazai",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kamps",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Milic-Frayling",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 20th ACM International Conference on Information and Knowledge Management-CIKM'11",
            "volume": "",
            "issn": "",
            "pages": "1941--1944",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Minimizing efforts in validating crowd answers",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "Q V"
                    ],
                    "last": "Hung",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "C"
                    ],
                    "last": "Thang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Weidlich",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Aberer",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 2015 ACM International Conference on Manage. of Data-SIGMOD'15",
            "volume": "",
            "issn": "",
            "pages": "999--1014",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Challenges in data crowdsourcing",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Garcia-Molina",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Joglekar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Marcus",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Parameswaran",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Verroios",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "28",
            "issn": "",
            "pages": "901--911",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2016.2518669"
                ]
            }
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A taxonomy of crowdsourcing based on task complexity",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "T"
                    ],
                    "last": "Nakatsu",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "B"
                    ],
                    "last": "Grossman",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L"
                    ],
                    "last": "Iacovou",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "J. Inf. Sci",
            "volume": "40",
            "issn": "",
            "pages": "823--834",
            "other_ids": {
                "DOI": [
                    "10.1177/0165551514550140"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Obtaining high-quality relevance judgments using crowdsourcing",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "B P"
                    ],
                    "last": "Vuurens",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "P"
                    ],
                    "last": "De Vries",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Internet Comput",
            "volume": "16",
            "issn": "",
            "pages": "20--27",
            "other_ids": {
                "DOI": [
                    "10.1109/MIC.2012.71"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Increasing cheat robustness of crowdsourcing tasks",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Eickhoff",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "P"
                    ],
                    "last": "De Vries",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Inf. Retr. Boston",
            "volume": "16",
            "issn": "",
            "pages": "121--137",
            "other_ids": {
                "DOI": [
                    "10.1007/s10791-011-9181-9"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Understanding Malicious Behavior in Crowdsourcing Platforms: The Case of Online Surveys",
            "authors": [
                {
                    "first": "U",
                    "middle": [],
                    "last": "Gadiraju",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kawase",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dietze",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
            "volume": "",
            "issn": "",
            "pages": "18--23",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Detecting Low-Quality Workers in QoE Crowdtesting: A Worker Behavior-Based Approach",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "K P"
                    ],
                    "last": "Mok",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "K C"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Trans. Multimed",
            "volume": "19",
            "issn": "",
            "pages": "530--543",
            "other_ids": {
                "DOI": [
                    "10.1109/TMM.2016.2619901"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Social Turing Tests: Crowdsourcing Sybil Detection. arXiv 2012",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mohanlal",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wilson",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Metzger",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "Y"
                    ],
                    "last": "Zhao",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/ICASSP.2017.7952656"
                ],
                "arXiv": [
                    "arXiv:1205.3856"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "I Want to, but First I Need to: Understanding Crowdworkers' Career Goals, Challenges, and Tensions",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "A"
                    ],
                    "last": "Rivera",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "T"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proceedings of the ACM on Human-Computer Interaction",
            "volume": "5",
            "issn": "",
            "pages": "1--22",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Crowdsourced Data Management: Industry and Academic Perspectives. Found. Trends\u00aeDatabases",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Marcus",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Parameswaran",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "6",
            "issn": "",
            "pages": "1--161",
            "other_ids": {
                "DOI": [
                    "10.1561/1900000044"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Understanding workers, developing effective tasks, and enhancing marketplace dynamics: A Study of a Large Crowdsourcing Marketplace",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jain",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "D"
                    ],
                    "last": "Sarma",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Parameswaran",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Widom",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the VLDB Endowment",
            "volume": "10",
            "issn": "",
            "pages": "829--840",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Le",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Edmonds",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Hester",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Biewald",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation",
            "volume": "",
            "issn": "",
            "pages": "17--20",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Programmatic gold: Trargeted and scalable quality assurance in crowdsourcing",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Oleson",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sorokin",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Laughlin",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Hester",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Le",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Biewald",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence",
            "volume": "",
            "issn": "",
            "pages": "43--48",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Increasing the Reliability of Crowdsourcing Evaluations Using Online Quality Assessment",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Burmania",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Parthasarathy",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Busso",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Trans. Affect. Comput",
            "volume": "7",
            "issn": "",
            "pages": "374--388",
            "other_ids": {
                "DOI": [
                    "10.1109/TAFFC.2015.2493525"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "How much spam can you take? An analysis of crowdsourcing results to increase accuracy",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Vuurens",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "De Vries",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Eickhoff",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the ACM SIGIR Workshop on Crowdsourcing for Information Retrieval (CIR'11)",
            "volume": "",
            "issn": "",
            "pages": "21--26",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Majority Voting and Pairing with Multiple Noisy Labeling",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Sheng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Trans. Knowl. Data Eng",
            "volume": "31",
            "issn": "",
            "pages": "1355--1368",
            "other_ids": {
                "DOI": [
                    "10.1109/TKDE.2017.2659740"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Dynamic weighted majority approach for detecting malicious crowd workers",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nazariani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Barforoush",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Can. J. Electr. Comput. Eng",
            "volume": "42",
            "issn": "",
            "pages": "108--113",
            "other_ids": {
                "DOI": [
                    "10.1109/CJECE.2019.2898260"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Label similarity-based weighted soft majority voting and pairing for crowdsourcing",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Knowl. Inf. Syst",
            "volume": "2020",
            "issn": "",
            "pages": "2521--2538",
            "other_ids": {
                "DOI": [
                    "10.1007/s10115-020-01475-y"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Quality Management in Crowdsourcing using Gold Judges Behavior",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kazai",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Zitouni",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the Ninth ACM International Conference on Web Search and Data Mining",
            "volume": "",
            "issn": "",
            "pages": "267--276",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Reputation-based Incentive Protocols in Crowdsourcing Applications",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Van Der Schaar",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the INFOCOM",
            "volume": "",
            "issn": "",
            "pages": "2140--2148",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Predicting result quality in crowdsourcing using application layer monitoring",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hirth",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Scheuring",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Hossfeld",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Schwartz",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Tran-Gia",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the 2014 IEEE 5th International Conference on Communications and Electronics",
            "volume": "21",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Instrumenting the crowd: Using implicit behavioral measures to predict task performance",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Rzeszotarski",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kittur",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 24th Annual ACM Symposium on User interface Software and Technology",
            "volume": "",
            "issn": "",
            "pages": "13--22",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "MmmTurkey: A Crowdsourcing Framework for Deploying Tasks and Recording Worker Behavior on Amazon Mechanical Turk",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Dang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hutson",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lease",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 4th AAAI Conference on Human Computation and Crowdsourcing (HCOMP)",
            "volume": "",
            "issn": "",
            "pages": "1--3",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Your Behavior Signals Your Reliability: Modeling Crowd Behavioral Traces to Ensure Quality Relevance Annotations",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mcdonnell",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Kutlu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Elsayed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lease",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the Sixth AAAI Conference on Human Computation and Crowdsourcing",
            "volume": "",
            "issn": "",
            "pages": "41--49",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "A glimpse far into the future: Understanding long-term crowd worker quality",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Hata",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Krishna",
                    "suffix": ""
                },
                {
                    "first": "F.-F",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Bernstein",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing-CSCW'17",
            "volume": "",
            "issn": "",
            "pages": "889--901",
            "other_ids": {}
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Get another label? Improving data quality and data mining using multiple, noisy labelers",
            "authors": [
                {
                    "first": "V",
                    "middle": [
                        "S"
                    ],
                    "last": "Sheng",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Provost",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "G"
                    ],
                    "last": "Ipeirotis",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining-KDD 08",
            "volume": "",
            "issn": "",
            "pages": "614--622",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Quantifying test collection quality based on the consistency of relevance judgements",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Scholer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Turpin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sanderson",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Proceedings of the 34th International ACM SIGIR Conference Research and Development in Information Retrieval-SIGIR'11",
            "volume": "",
            "issn": "",
            "pages": "1063--1072",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Mechanical cheat: Spamming schemes and adversarial techniques on crowdsourcing platforms",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "E"
                    ],
                    "last": "Difallah",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Demartini",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Cudr\u00e9-Mauroux",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the CrowdSearch Workshop",
            "volume": "",
            "issn": "",
            "pages": "26--30",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Sybil Defense in Crowdsourcing Platforms",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management",
            "volume": "",
            "issn": "",
            "pages": "1529--1538",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "The Challenge of Variable Effort Crowdsourcing and How Visible Gold Can Help",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hettiachchi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Schaekermann",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mckinney",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lease",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2105.09457"
                ]
            }
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Effective quality assurance for data labels through crowdsourcing and domain expert collaboration",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "H"
                    ],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "W"
                    ],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K D"
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "T"
                    ],
                    "last": "Chuang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "A"
                    ],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Hsieh",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the Advances in Database Technology-EDBT",
            "volume": "",
            "issn": "",
            "pages": "646--649",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "CrowdScape: Interactively visualizing user behavior and output",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Rzeszotarski",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kittur",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology-UIST'12",
            "volume": "",
            "issn": "",
            "pages": "55--62",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "An analysis of assessor behavior in crowdsourced preference judgments",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Carterette",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation",
            "volume": "",
            "issn": "",
            "pages": "17--20",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "A Robust Consistency Model of Crowd Workers in Text Labeling Tasks",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Alqershi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Al-Qurishi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Aksoy",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alrubaian",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Imran",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Access",
            "volume": "8",
            "issn": "",
            "pages": "168381--168393",
            "other_ids": {
                "DOI": [
                    "10.1109/ACCESS.2020.3022773"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Characterizing worker quality using task consistency",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Williams",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "G"
                    ],
                    "last": "Willis",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C"
                    ],
                    "last": "Davis",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Goh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Ellison",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "Deja"
                    ],
                    "last": "Law",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Vu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the Fifth AAAI Conference on Human Computation and Crowdsourcing",
            "volume": "",
            "issn": "",
            "pages": "23--26",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Feature Engineering for Machine Learning and Data Analytics",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Dong",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "The Law of Anomalous Numbers",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Benford",
                    "suffix": ""
                }
            ],
            "year": 1938,
            "venue": "In Proceedings of the American Philosophical Society",
            "volume": "78",
            "issn": "",
            "pages": "551--572",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "A Wavelet Tour of Signal Processing",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mallat",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF49": {
            "ref_id": "b49",
            "title": "Approximate Entropy and Sample Entropy: A Comprehensive Tutorial",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Delgado-Bonal",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Marshak",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Entropy",
            "volume": "21",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/e21060541"
                ]
            }
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Permutation Entropy: A Natural Complexity Measure for Time Series",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Bandt",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Pompe",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Phys. Rev. Lett",
            "volume": "88",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1103/PhysRevLett.88.174102"
                ]
            }
        },
        "BIBREF51": {
            "ref_id": "b51",
            "title": "Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh-A Python package)",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Christ",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Braun",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Neuffer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Kempa-Liehr",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Neurocomputing",
            "volume": "307",
            "issn": "",
            "pages": "72--77",
            "other_ids": {
                "DOI": [
                    "10.1016/j.neucom.2018.03.067"
                ]
            }
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Extremely randomized trees",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Geurts",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ernst",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wehenkel",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Mach. Learn",
            "volume": "63",
            "issn": "",
            "pages": "3--42",
            "other_ids": {
                "DOI": [
                    "10.1007/s10994-006-6226-1"
                ]
            }
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "Recurrence Plots of Dynamical Systems",
            "authors": [
                {
                    "first": "J.-P",
                    "middle": [],
                    "last": "Eckmann",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "O"
                    ],
                    "last": "Kamphorst",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ruelle",
                    "suffix": ""
                }
            ],
            "year": 1987,
            "venue": "Europhys. Lett",
            "volume": "4",
            "issn": "",
            "pages": "973--977",
            "other_ids": {
                "DOI": [
                    "10.1209/0295-5075/4/9/004"
                ]
            }
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Rectified Linear Units Improve Restricted Boltzmann Machines Vinod",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Nair",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Proceedings of the International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "21--24",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "A Method for Stochastic Optimization. arXiv",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Adam",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "Cyclical Learning Rates for Training Neural Networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "N"
                    ],
                    "last": "Smith",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 IEEE Winter Conference on Applications of Computer Vision (WACV)",
            "volume": "",
            "issn": "",
            "pages": "464--472",
            "other_ids": {}
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Classification of time-series images using deep convolutional neural networks. arXiv 2017",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Hatami",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gavet",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Debayle",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1710.00886"
                ]
            }
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Random forests. Random For",
            "authors": [
                {
                    "first": "Y",
                    "middle": [
                        "L"
                    ],
                    "last": "Pavlov",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2019",
            "issn": "",
            "pages": "1--122",
            "other_ids": {
                "DOI": [
                    "10.1201/9780429469275-8"
                ]
            }
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Weighted dynamic time warping for time series classification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [
                        "S"
                    ],
                    "last": "Jeong",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Jeong",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [
                        "A"
                    ],
                    "last": "Omitaomu",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Pattern Recognit",
            "volume": "44",
            "issn": "",
            "pages": "2231--2240",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2010.09.022"
                ]
            }
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "Dynamic Time Warping. In Information Retrieval for Music and Motion",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "M\u00fcller",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "9781402067532",
            "issn": "",
            "pages": "69--84",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Comparison of different weighting schemes for the kNN classifier on time-series data",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Geler",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Kurbalija",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Radovanovi\u0107",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ivanovi\u0107",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Knowl. Inf. Syst",
            "volume": "48",
            "issn": "",
            "pages": "331--378",
            "other_ids": {
                "DOI": [
                    "10.1007/s10115-015-0881-0"
                ]
            }
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Support Vector Machines and Kernel Methods The New Generation of Learning Machines. AI Mag",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Cristianini",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Sch\u00f6lkopf",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "",
            "volume": "23",
            "issn": "",
            "pages": "31--42",
            "other_ids": {}
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "A Kernel for Time Series Based on Global Alignments",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cuturi",
                    "suffix": ""
                },
                {
                    "first": "J.-P",
                    "middle": [],
                    "last": "Vert",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Birkenes",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Matsui",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Proceedings of the 2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP'07",
            "volume": "",
            "issn": "",
            "pages": "15--20",
            "other_ids": {}
        },
        "BIBREF65": {
            "ref_id": "b65",
            "title": "Financial time series forecasting using support vector machines",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "J"
                    ],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Neurocomputing",
            "volume": "55",
            "issn": "",
            "pages": "307--319",
            "other_ids": {
                "DOI": [
                    "10.1016/S0925-2312(03)00372-2"
                ]
            }
        },
        "BIBREF66": {
            "ref_id": "b66",
            "title": "Heartbeat time series classification with support vector machines",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kampouraki",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Manis",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Nikou",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Trans. Inf. Technol. Biomed",
            "volume": "13",
            "issn": "",
            "pages": "512--518",
            "other_ids": {
                "DOI": [
                    "10.1109/TITB.2008.2003323"
                ]
            }
        },
        "BIBREF67": {
            "ref_id": "b67",
            "title": "Scikit-learn: Machine learning in Python",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pedregosa",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Varoquaux",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gramfort",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Michel",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Thirion",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Grisel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Blondel",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Prettenhofer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Weiss",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Dubourg",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "J. Mach. Learn. Res",
            "volume": "12",
            "issn": "",
            "pages": "2825--2830",
            "other_ids": {}
        },
        "BIBREF68": {
            "ref_id": "b68",
            "title": "A Machine Learning Toolkit for Time Series Data",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tavenard",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Vandewiele",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Divo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Androz",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Holtz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Payne",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Woods",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Tslearn",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J. Mach. Learn. Res",
            "volume": "21",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF69": {
            "ref_id": "b69",
            "title": "The appropriate use of approximate entropy and sample entropy with short data sets",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Yentes",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Hunt",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "K"
                    ],
                    "last": "Schmid",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Kaipust",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mcgrath",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Stergiou",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Ann. Biomed. Eng",
            "volume": "41",
            "issn": "",
            "pages": "349--365",
            "other_ids": {
                "DOI": [
                    "10.1007/s10439-012-0668-3"
                ]
            }
        },
        "BIBREF70": {
            "ref_id": "b70",
            "title": "A Comparative Analysis of Gradient Descent-Based Optimization Algorithms on Convolutional Neural Networks",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "M"
                    ],
                    "last": "Dogo",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [
                        "J"
                    ],
                    "last": "Afolabi",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "I"
                    ],
                    "last": "Nwulu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Twala",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "O"
                    ],
                    "last": "Aigbavboa",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the International Conference on Computational Techniques, Electronics and Mechanical Systems (CTEMS)",
            "volume": "",
            "issn": "",
            "pages": "92--99",
            "other_ids": {}
        },
        "BIBREF71": {
            "ref_id": "b71",
            "title": "Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UAVs",
            "authors": [
                {
                    "first": "Dos",
                    "middle": [],
                    "last": "Santos",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Marcato Junior",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ara\u00fajo",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Di Martini",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "R"
                    ],
                    "last": "Tetila",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "C"
                    ],
                    "last": "Siqueira",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "L"
                    ],
                    "last": "Aoki",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Eltner",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Matsubara",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "T"
                    ],
                    "last": "Pistori",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sensors",
            "volume": "19",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s19163595"
                ]
            }
        },
        "BIBREF72": {
            "ref_id": "b72",
            "title": "Grid Based Spherical CNN for Object Detection from Panoramic Images",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sensors",
            "volume": "19",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s19112622"
                ]
            }
        },
        "BIBREF73": {
            "ref_id": "b73",
            "title": "Chimney Detection Based on Faster R-CNN and Spatial Analysis Methods in High Resolution Remote Sensing Images",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sensors",
            "volume": "20",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s20164353"
                ]
            }
        },
        "BIBREF74": {
            "ref_id": "b74",
            "title": "Optimization of deep neural networks: A survey and unified taxonomy",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Talbi",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF75": {
            "ref_id": "b75",
            "title": "Understanding the Lomb-Scargle Periodogram",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Vanderplas",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Astrophys. J. Suppl. Ser",
            "volume": "236",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3847/1538-4365/aab766"
                ]
            }
        },
        "BIBREF76": {
            "ref_id": "b76",
            "title": "Granger Causality Analysis in Irregular Time Series",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Bahadori",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the 2012 SIAM International Conference on Data Mining",
            "volume": "",
            "issn": "",
            "pages": "660--671",
            "other_ids": {}
        },
        "BIBREF77": {
            "ref_id": "b77",
            "title": "Toward accurate dynamic time warping in linear time and space",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Salvador",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Chan",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Fastdtw",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Intell. Data Anal",
            "volume": "11",
            "issn": "",
            "pages": "561--580",
            "other_ids": {
                "DOI": [
                    "10.3233/IDA-2007-11508"
                ]
            }
        },
        "BIBREF78": {
            "ref_id": "b78",
            "title": "A Vehicle Steering Recognition System Based on Low-Cost Smartphone Sensors",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mei",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kuang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "17",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s17030633"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF2": {
            "text": "The proposed models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The proposed models.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "again, [((30 \u2212 2) + 2 \u00d7 0)/2] + 1 \u00d7 1 = 15 . Consequently, the pooling output dimension = 15 \u00d7 15 \u00d7 1, and we had 32 filters, so the number of features was 15 \u00d7 15 \u00d7 32 = 7200. These features, concatenated with 11 auxiliary",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The image-CNN model architecture.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "The image-CNN model architecture.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Optimized learning rate vs. changing in loss.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Optimized learning rate vs. changing in loss.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Optimized number of epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Optimized number of epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "Training/validation accuracy and loss of the image-CNN model across the epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Training/validation accuracy and loss of the image-CNN model across the epochs.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "Contributions: Conceptualization, F.A.-Q. and M.A.-Q.; methodology, F.A.-Q. and M.A.-Q.; software, F.A.-Q., M.A.-Q. and M.A.; validation, M.A.-Q., M.A. and M.F.; investigation, F.A.-Q., M.S.A. and M.F.; resources, F.A.-Q., M.A.-Q. and M.A.; data curation, F.A.-Q. and M.A.-Q.; writingoriginal draft preparation, F.A.-Q. and M.A.-Q.; writing-review and editing, F.A.-Q., M.F. and M.S.A.; visualization, F.A.-Q. and M.A.-Q.; supervision, M.S.A. and M.A.-Q.; funding acquisition, F.A.-Q. All authors have read and agreed to the published version of the manuscript.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "The Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia, through a research group program under Grant RG-1441-503. Institutional Review Board Statement: Not applicable. Informed Consent Statement: Not applicable. Data Availability Statement: Not applicable.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": "The auxiliary features for image-CNN model.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Accuracy and AUC-ROC for features vs. different importance thresholds.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Accuracy and AUC-ROC for features vs. different importance thresholds.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Hyper-parameter tuning.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Hyper-parameter tuning.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Performance comparison against baselines.",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "The features of the feature-based model.",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "Cont.Energy ratio by chunksThe sum of squares of chunk i out of N chunks expressed as a ratio with the sum of squares over the whole series. (10 segments)The average, absolute value of consecutive changes of the series x inside the corridor of quantiles q-low and q-high.Linear trendThe linear least-squares regression for the values of the sample versus the sequence from 0 to length of the sample minus one.Complexity EstimatorThe estimation for a sample complexity (A more complex sample has more peaks, valleys etc.).Absolute sum of changes The sum over the absolute value of consecutive changes in the series x. MMT 62MaximumThe largest value of the sample x.MinimumThe smallest value of the sample x.* MMT: Mouse Movement Time, FCT: Focus Changes Time, CST: Clicks Specific Time.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Acknowledgments: This work was supported by the Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia, through a research group program under Grant RG-1441-503.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        },
        {
            "text": "The authors declare no conflict of interest.Sensors 2021, 21, 5007 ",
            "cite_spans": [
                {
                    "start": 58,
                    "end": 61,
                    "text": "21,",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Conflicts of Interest:"
        }
    ]
}