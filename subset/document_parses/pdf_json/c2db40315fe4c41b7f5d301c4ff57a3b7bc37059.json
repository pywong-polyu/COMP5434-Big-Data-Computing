{
    "paper_id": "c2db40315fe4c41b7f5d301c4ff57a3b7bc37059",
    "metadata": {
        "title": "Unsupervised embedding of trajectories captures the latent structure of mobility",
        "authors": [
            {
                "first": "Dakota",
                "middle": [],
                "last": "Murray",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indiana University",
                    "location": {
                        "postCode": "47408",
                        "settlement": "Bloomington",
                        "region": "IN",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Jisung",
                "middle": [],
                "last": "Yoon",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indiana University",
                    "location": {
                        "postCode": "47408",
                        "settlement": "Bloomington",
                        "region": "IN",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Sadamori",
                "middle": [],
                "last": "Kojaku",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indiana University",
                    "location": {
                        "postCode": "47408",
                        "settlement": "Bloomington",
                        "region": "IN",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Rodrigo",
                "middle": [],
                "last": "Costas",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Leiden University",
                    "location": {
                        "postBox": "P.O. Box 905",
                        "postCode": "2300 AX",
                        "settlement": "Leiden",
                        "country": "The Netherlands"
                    }
                },
                "email": ""
            },
            {
                "first": "Woo-Sung",
                "middle": [],
                "last": "Jung",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Pohang University of Science and Technology",
                    "location": {
                        "addrLine": "Pohang 37673",
                        "country": "Republic of Korea"
                    }
                },
                "email": ""
            },
            {
                "first": "Sta\u0161a",
                "middle": [],
                "last": "Milojevi\u0107",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indiana University",
                    "location": {
                        "postCode": "47408",
                        "settlement": "Bloomington",
                        "region": "IN",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Yong-Yeol",
                "middle": [],
                "last": "Ahn",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Indiana University",
                    "location": {
                        "postCode": "47408",
                        "settlement": "Bloomington",
                        "region": "IN",
                        "country": "USA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Human mobility drives major societal phenomena including epidemics, economies, and innovation. Historically, mobility was constrained by geographic distance, however, in the globalizing world, language, culture, and history are increasingly important. We propose using the neural embedding model word2vec for studying mobility and capturing its complexity. Word2ec is shown to be mathematically equivalent to the gravity model of mobility, and using three human trajectory datasets, we demonstrate that it encodes nuanced relationships between locations into a vector-space, providing a measure of effective distance that outperforms baselines. Focusing on the case of scientific mobility, we show that embeddings uncover cultural, linguistic, and hierarchical relationships at multiple levels of granularity. Connecting neural embeddings to the gravity model opens up new avenues for the study of mobility.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Predicted vs. Actual",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "How far apart are two places? The question is surprisingly hard to answer when it involves human mobility. Although geographic distance has historically constrained human movements, it is becoming less relevant in a world connected by rapid transit and global airline networks.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "For instance, a person living in Australia is more likely to migrate to the United Kingdom, a far-away country with similar language and culture, than to a much closer country such as Indonesia. 1 Similarly, a student in South Korea is more likely to attend a university in Canada than one in North Korea. 2 Although geographic distance has been used as the most prominent basis for models of mobility, such as the Gravity 3 and Radiation 4 models, there have been attempts to define alternative notions of distance, or functional distances, 5-7 from real-world data or a priori relationships between geographic entities.",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 196,
                    "text": "1",
                    "ref_id": null
                },
                {
                    "start": 306,
                    "end": 307,
                    "text": "2",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Yet, functional distances are often low-resolution, computed at the level of countries rather than regions, cities, or organizations, and have focused on only a single facet of mobility at a time, whereas real-world mobility is multi-faceted, influenced simultaneously by geography, language, culture, history, and economic opportunity. Low dimensional distance alone cannot represent the multitude of inter-related factors that drive mobility. Networks offer a solution to representing many dimensions of mobility, yet edges only encode simple relationships between connected entities. Capturing the complexity of mobility requires moving beyond simple functional distances and networks, to learning high-dimensional landscapes of mobility that incorporate the many facets of mobility into a single fine-grained and continuous representation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Here, we apply a neural embedding framework to real-world mobility trajectories and demonstrate that it can encode the complex landscape of human mobility into a dense and continuous vector-space representation, from which we can not only derive a meaningful functional distance between locations but also probe relationships based on culture, language, and even prestige along with the geographic relationship. We embed trajectories from three massive datasets: U.S. passenger flight itinerary records, Korean accommodation reservations, and a dataset of scientists' career mobility between organizations captured in bibliometric records (Detailed descriptions are available in the Methods).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The flight itinerary data, from the Airline Origin and Destination Survey, consists of records of more than 300 million itineraries between 1993 and 2020 documenting domestic flights between 828 airports in the United States. A trajectory is constructed for each passenger flight itinerary, forming an ordered sequence of unique identifiers of the origin and destination airports. The Korean accommodation reservations consist of customer reservation histories across 2018 and 2020 for 1,038 unique accommodation locations in Seoul, South Korea. A trajectory is constructed for each customer, containing the ordered sequences of accommodations they reserved over time. Finally, we use scientific mobility data that captures the affiliation trajectories of nearly 3 million scientists across ten years. We focus in more detail on scientific mobility due to its richness and importance. Scientific mobility-which is a central driver of the globalized scientific enterprise 8, 9 and strongly related to innovation, 10, 11 impact, 12,13 collaboration, 14 and the diffusion of knowledge 10,15 -is not only an important topic in the Science of Science but also ideal for our study thanks to its well-known structural properties such as the centrality of scientifically advanced countries and the strong prestige hierarchy. 16, 17 In spite of its importance, understandings of scientific mobility have been limited by the sheer scope and complexity of the phenomenon, 17, 18 being further confounded by the diminishing role of geography in shaping the landscape of scientific mobility.",
            "cite_spans": [
                {
                    "start": 971,
                    "end": 973,
                    "text": "8,",
                    "ref_id": null
                },
                {
                    "start": 974,
                    "end": 975,
                    "text": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1012,
                    "end": 1015,
                    "text": "10,",
                    "ref_id": null
                },
                {
                    "start": 1016,
                    "end": 1018,
                    "text": "11",
                    "ref_id": null
                },
                {
                    "start": 1048,
                    "end": 1050,
                    "text": "14",
                    "ref_id": null
                },
                {
                    "start": 1317,
                    "end": 1320,
                    "text": "16,",
                    "ref_id": null
                },
                {
                    "start": 1321,
                    "end": 1323,
                    "text": "17",
                    "ref_id": null
                },
                {
                    "start": 1461,
                    "end": 1464,
                    "text": "17,",
                    "ref_id": null
                },
                {
                    "start": 1465,
                    "end": 1467,
                    "text": "18",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Trajectories of scientific mobility are constructed using more than three million namedisambiguated authors who were mobile-having more than one affiliation-between 2008 and 2019, as evidenced by their publications indexed in the Web of Science database (see Methods).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As a scientist's career progresses, they move between organizations or pick up additional (simultaneous) affiliations forming affiliation trajectories (Fig. 1) . Thus, the trajectories encode both migration and co-affiliation-the holding of multiple simultaneous affiliations involving the sharing of time and capital between locations-that is typical of scientific mobility 12, 14 (see",
            "cite_spans": [
                {
                    "start": 375,
                    "end": 378,
                    "text": "12,",
                    "ref_id": null
                },
                {
                    "start": 379,
                    "end": 381,
                    "text": "14",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 151,
                    "end": 159,
                    "text": "(Fig. 1)",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "A vector-space embedding of locations (airports, accommodations, and organizations) is learned by using trajectories as input to the standard with skip-gram negative sampling, or word2vec neural-network architecture (see Methods) . This neural embedding model, originally designed for learning language models, 19 has been making breakthroughs by revealing novel insights into texts, 20-25 networks 26,27 and trajectories. [28] [29] [30] [31] [32] [33] It works under the notion that a good representation should facilitate prediction, learning a mapping between words that can predict a target word based on its context (surrounding words). The model is also computationally efficient, robust to noise, and can encode relations between entities as geometric relationships in the vector space. 22, 25, 34, 35 As a result, each location is encoded into a single vector representation, and vectors relate to one another based on the likelihood of locations appearing adjacent to one another in the same trajectory.",
            "cite_spans": [
                {
                    "start": 221,
                    "end": 229,
                    "text": "Methods)",
                    "ref_id": null
                },
                {
                    "start": 311,
                    "end": 313,
                    "text": "19",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 423,
                    "end": 427,
                    "text": "[28]",
                    "ref_id": null
                },
                {
                    "start": 428,
                    "end": 432,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 433,
                    "end": 437,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 438,
                    "end": 442,
                    "text": "[31]",
                    "ref_id": null
                },
                {
                    "start": 443,
                    "end": 447,
                    "text": "[32]",
                    "ref_id": null
                },
                {
                    "start": 448,
                    "end": 452,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 794,
                    "end": 797,
                    "text": "22,",
                    "ref_id": null
                },
                {
                    "start": 798,
                    "end": 801,
                    "text": "25,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 802,
                    "end": 805,
                    "text": "34,",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 806,
                    "end": 808,
                    "text": "35",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Supporting Information)."
        },
        {
            "text": "To validate our approach, we evaluate the quality of vector representations based on their performance in predicting real-world mobility flows using the gravity model framework. 3 The gravity model is a widely used mobility model [36] [37] [38] [39] that connects the expected flux,\u02c6, between locations based on their populations and distance:",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 179,
                    "text": "3",
                    "ref_id": null
                },
                {
                    "start": 230,
                    "end": 234,
                    "text": "[36]",
                    "ref_id": null
                },
                {
                    "start": 235,
                    "end": 239,
                    "text": "[37]",
                    "ref_id": null
                },
                {
                    "start": 240,
                    "end": 244,
                    "text": "[38]",
                    "ref_id": null
                },
                {
                    "start": 245,
                    "end": 249,
                    "text": "[39]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Supporting Information)."
        },
        {
            "text": "where is the population of location , ( ) is a decay function with respect to distance between locations, and is a constant estimated from data (see Methods). For the flight itinerary data, we use population as the total number of unique passengers who passed through each airport, for the Korean accommodation reservation data, we use the total number of unique customers who booked with each accommodation, and for scientific mobility, we use the mean annual number of unique mobile and non-mobile authors who were affiliated with each organization.\u02c6, which is often referred to as \"expected flux\", 4 is the expected frequency of the co-occurrence of location and in the trajectory in the gravity model.",
            "cite_spans": [
                {
                    "start": 601,
                    "end": 602,
                    "text": "4",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Supporting Information)."
        },
        {
            "text": "The gravity model dictates that the expected flow,\u02c6, (\u02c6=\u02c6), is proportional to the locations' population,\u02c6\u221d , and decays as a function of their distance, ( ). We define the distance function in terms of either the geographic distance between locations or their functional distance in the vector space, which is calculated as the cosine distance between their vectors, termed the embedding distance. The decay function ( ) defines the effect of distance, and different decay functions can model fundamentally different mechanisms 40 such as the cost functions for a given distance and the spatial granularity of the observation. For geographic distance, we define ( ) as the standard power-law function, and for the embedding distance, we use the exponential function, selected as the best performing for each case ( Fig. S7 and Fig. S8 ). Though there is no qualitative difference, the embedding distance outperforms geographic distance regardless of the type of gravity model used (see Tables S3, S4 , S5). The power-law decay function performs best with the geographic distance, likely resulting from the function's suitability for large, complex, and scale-free spatial systems; 41 performance of the embedding distance is similar between the functional forms, though best for the exponential form, which stems from an underlying connection between the function and word2vec that we discuss later.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 816,
                    "end": 823,
                    "text": "Fig. S7",
                    "ref_id": "FIGREF23"
                },
                {
                    "start": 828,
                    "end": 835,
                    "text": "Fig. S8",
                    "ref_id": null
                },
                {
                    "start": 987,
                    "end": 1000,
                    "text": "Tables S3, S4",
                    "ref_id": null
                }
            ],
            "section": "Supporting Information)."
        },
        {
            "text": "We show that the embedding distance better predicts actual mobility flows than the geographic distance across three disparate datasets. In the case of flight itineraries, the embedding distance explains more than twice the expected flux between airports ( 2 = 0.51, Fig. 2a ) than does geographic distance ( 2 = 0.22). Also, the embedding distance produces better predictions of actual flux between airports than does the geographic distance (Fig. 2b ). In the case of Korean accommodation reservations, embedding distance better explains the expected flux ( 2 = 0.57,",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 266,
                    "end": 273,
                    "text": "Fig. 2a",
                    "ref_id": null
                },
                {
                    "start": 442,
                    "end": 450,
                    "text": "(Fig. 2b",
                    "ref_id": null
                }
            ],
            "section": "Embeddings provide functional distance between locations"
        },
        {
            "text": "Fig. 2c) than does geographic distance ( 2 = 0. 25) , and predictions made using the embedding distance outperform those made with geographic distance (Fig. 2d) . This performance is consistent in the case of scientific mobility: the embedding distance explains more than twice the expected flux ( 2 = 0.48, Fig. 2e ) than does the geographic distance ( 2 = 0. 22) , and predictions made using the embedding distance outperform those using the geographic distance ( Fig. 2f) . These patterns hold for the subsets of only domestic (within-country organization pairs, Fig. S7 and Fig. S9c ) and only international mobility flows (across-country organization pairs, Fig. S9d ). The embedding distance also out-performs alternative diffusion-based network distance measures including the personalized-page rank scores calculated from the underlying mobility network (Fig. S5, Fig. S11, Fig. S12 ). The embedding distance derived from neural embedding also explains more of the flux and better predicts mobility flows than simpler embedding baselines, such as distances derived from a singular-value decomposition and a Laplacian",
            "cite_spans": [
                {
                    "start": 48,
                    "end": 51,
                    "text": "25)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 361,
                    "end": 364,
                    "text": "22)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 151,
                    "end": 160,
                    "text": "(Fig. 2d)",
                    "ref_id": null
                },
                {
                    "start": 308,
                    "end": 315,
                    "text": "Fig. 2e",
                    "ref_id": null
                },
                {
                    "start": 466,
                    "end": 474,
                    "text": "Fig. 2f)",
                    "ref_id": null
                },
                {
                    "start": 566,
                    "end": 573,
                    "text": "Fig. S7",
                    "ref_id": "FIGREF23"
                },
                {
                    "start": 578,
                    "end": 586,
                    "text": "Fig. S9c",
                    "ref_id": null
                },
                {
                    "start": 663,
                    "end": 671,
                    "text": "Fig. S9d",
                    "ref_id": null
                },
                {
                    "start": 862,
                    "end": 890,
                    "text": "(Fig. S5, Fig. S11, Fig. S12",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "6"
        },
        {
            "text": "Eigenmap embedding 42 of the underlying location co-occurrence matrix, Levy's symmetric word2vec, 34 and even direct optimization of the gravity model (Fig.S5 and Tables S3, S4, S5 ).",
            "cite_spans": [
                {
                    "start": 98,
                    "end": 100,
                    "text": "34",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [
                {
                    "start": 151,
                    "end": 180,
                    "text": "(Fig.S5 and Tables S3, S4, S5",
                    "ref_id": null
                }
            ],
            "section": "6"
        },
        {
            "text": "In sum, our results demonstrate that, consistently and efficiently, the embedding distance better captures patterns of actual mobility than does the geographic distance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "word2vec and the gravity model Flux (data) c d Figure 2 : Embedding distance encodes functional distance and better predicts mobility in flights, accommodation reservations, and global scientific mobility. a. Embedding distance (cosine distance between organization vectors, top) better explains the expected flux of passengers between U.S. airports than does geographic distance (bottom). The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001 across all fits). The lightness of each hex bin indicates the frequency of organization pairs within it. b. Predictions of flux between airport pairs made using embedding distance (top) outperform those made using geographic distance (bottom). Box-plots show the distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps with = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Results are consistent in the case of scientific mobility. For Korean accommodation reservations, embedding distance better explains the expected flux than does geographic distance (c), and produces better predictions (d). Similarly, in the case of global scientific mobility, embedding distance explains the expected flux between organizations (e) and allows for better predictions (f) than geographic distance.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 47,
                    "end": 55,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "6"
        },
        {
            "text": "learns an embedding by estimating the probability that location has context :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "where the denominator = \u2208A exp( \u00b7 ) is a normalization constant, and A is the set of all locations. Although word2vec generates two embedding vectors and -referred to as the in-vector and out-vector, respectively-we follow convention to use the in-vector as an embedding of location .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Our experiments show that word2vec best explains real-world mobility flow when = 1 8 ( Fig. S4) , with the flow predicted b\u0177",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 87,
                    "end": 95,
                    "text": "Fig. S4)",
                    "ref_id": null
                }
            ],
            "section": "6"
        },
        {
            "text": "where ( ) is the fraction of in the data. In general, calculating is computationally expensive and there are two common approximations: hierarchical softmax 43 and negative sampling. 19 Due to its simplicity and performance, negative sampling is the most widely used strategy, which we also adopt in our study.",
            "cite_spans": [
                {
                    "start": 183,
                    "end": 185,
                    "text": "19",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Although negative sampling is the most common approximation, it is a biased estimator 44, 45 and fits a different probability model. When taking into account this bias, word2vec with skipgram and negative sampling fits a probability model given by",
            "cite_spans": [
                {
                    "start": 86,
                    "end": 89,
                    "text": "44,",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 90,
                    "end": 92,
                    "text": "45",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "where we redefine the normalization constant as = Parameter = 1 is a special choice that ensures that, when the embedding dimension is sufficiently large, there exists optimal in-vectors and out-vectors such that = . 34 Setting = 1 and substituting = into Eq. 4, the flow predicted by word2vec is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "where ( ) = ( ) is the frequency of location in the data, and = \u2208A ( ) is the sum of frequencies of all locations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "The flow is symmetric (i.e., = ) because the skip-gram model neglects whether the context appears before or after the target in the trajectory. If we swap and in Eq. 5, the numerator remains the same but the denominator can be different. Therefore, to ensure = , the denominator should be a constant.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "Taken together, the word2vec model with the negative sampling predicts a flow in the same form as in the gravity model:\u02c6=",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "In other words, word2vec with the skip-gram negative sampling is equivalent to the gravity model, with the mass given by the location's frequency ( ), and the distance measured by their dot similarities. While the gravity model predicts mobility flows from the given mass and locations, word2vec finds locations that best explain the given mobility flow. Therefore, the embedding distance is inherently tied to the mobility flow, and hence, has greater predictive power than the geographic distance and other baselines.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "6"
        },
        {
            "text": "In practice, because we only have limited amounts of noisy data and the optimization may not find the true optimum, the mathematical result may only approximately hold. Indeed, we find that the in-and out-vectors tend to be different and that the cosine similarity tends to better capture real-world mobility than the dot similarity. This result echos other applications of word embedding, such as word analogy testing, 46 in which cosine distance also outperformed dot similarity. Nevertheless, a model with dot similarity has the second-best performance after cosine similarity (Tables S3, S4, S5) , and the embedding distance still outperforms all alternatives we considered.",
            "cite_spans": [
                {
                    "start": 420,
                    "end": 422,
                    "text": "46",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 580,
                    "end": 599,
                    "text": "(Tables S3, S4, S5)",
                    "ref_id": null
                }
            ],
            "section": "6"
        },
        {
            "text": "In the remainder of the paper, we focus on scientific mobility and interrogate the geometric space generated by the neural embedding to shed light on the multi-faceted relationships between organizations. To explore the topological structure of the embedding, we use a topologybased dimensionality reduction method (UMAP 47 ) to obtain a two-dimensional representation of the embedding space (Fig. 3a) . By showing relationships between individual organizations, rather than aggregates such as nations or cities, this projection constitutes the largest and highest resolution \"map\" of scientific mobility to date.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 392,
                    "end": 401,
                    "text": "(Fig. 3a)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Embeddings capture global structure of mobility"
        },
        {
            "text": "Globally, the geographic constraints are conspicuous; organizations tend to form clusters based on their national affiliations and national clusters tend to be near their geographic neighbors. At the same time, the embedding space also reflects a mix of geographic, historic, cultural, and linguistic relationships between regions much more clearly than alternative network representations ( Fig. S13 ) that have been common in studies of scientific mobility. 8, 48 The embedding space also allows us to zoom in on subsets and re-project them to reveal local relationships. For example, re-projecting organizations located in Western, Southern, and Southeastern Asia with UMAP ( Fig. 3b ) reveals a gradient of countries between Egypt and the Philippines that largely corresponds to geography, but with some exceptions seemingly stemming from cultural and religious similarity; Malaysia, with its official religion of Islam, is nearer to Middle Eastern countries in the embedding space than to many geographically-closer South Asian countries. We validate this finding quantitatively with the cosine distance between nations (the centroids of organizations vectors belonging to that country). Malaysia is nearer to many Islamic countries such as Iraq ( = 0.27), Pakistan ( = 0.32), and Saudi Arabia ( = 0.41) than neighboring but Buddhist Thailand ( = 0.43) and neighboring Singapore ( = 0.48).",
            "cite_spans": [
                {
                    "start": 460,
                    "end": 462,
                    "text": "8,",
                    "ref_id": null
                },
                {
                    "start": 463,
                    "end": 465,
                    "text": "48",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 392,
                    "end": 400,
                    "text": "Fig. S13",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 679,
                    "end": 686,
                    "text": "Fig. 3b",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Embeddings capture global structure of mobility"
        },
        {
            "text": "Linguistic and historical ties also affect scientific mobility. We observe that Spanish-speaking Latin American nations are positioned near Spain (Fig. 3c) Mirroring the global pattern, organizations in the United States are largely arranged according to geography (Fig. 3d ). Re-projecting organizations located in Massachusetts (Fig. 3e) reveals structure based on urban centers (Boston vs. Worcester), organization type (e.g., hospi- and Western Europe and the Mediterranean (light green). The cluster structure shows that not only geography but also linguistic ties and cultural between countries are related to scientific mobility.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 146,
                    "end": 155,
                    "text": "(Fig. 3c)",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 265,
                    "end": 273,
                    "text": "(Fig. 3d",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 330,
                    "end": 339,
                    "text": "(Fig. 3e)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Embeddings capture global structure of mobility"
        },
        {
            "text": "We quantify the relative importance of geography (by region), and language (by the most widely-spoken language of each country) using the element-centric clustering similarity, 49 a 13 method that can compare hierarchical clustering and disjoint clustering (geography, language...)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embeddings capture global structure of mobility"
        },
        {
            "text": "at the different level of hierarchy by explicitly adjusting a scaling parameter , acting like a zooming lens. If is high, the similarity is based on the lower levels of the dendrogram, whereas when is low, the similarity is based on higher levels. Fig. 4b demonstrates that regional relationships play a major role at higher levels of the clustering process (low ), and language (family) explains the clustering more at the lower levels (high ). This suggests that the embedding space captures the hierarchical structure of mobility.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 248,
                    "end": 255,
                    "text": "Fig. 4b",
                    "ref_id": null
                }
            ],
            "section": "Embeddings capture global structure of mobility"
        },
        {
            "text": "Prestige hierarchy is known to underpin the dynamics of scientific mobility, in which researchers tend to move to similar or less prestigious organizations. 16, 17 Could the embedding space, to which no explicit prestige information is given, encode a prestige hierarchy? This question is tested by exploiting the geometric properties of the embedding space with SemAxis. 35 Here, we use SemAxis to operationalize the abstract notion of academic prestige, defining an axis in the embedding space where poles are defined using known high-and low-ranked universities.",
            "cite_spans": [
                {
                    "start": 157,
                    "end": 160,
                    "text": "16,",
                    "ref_id": null
                },
                {
                    "start": 161,
                    "end": 163,
                    "text": "17",
                    "ref_id": null
                },
                {
                    "start": 372,
                    "end": 374,
                    "text": "35",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "As an external proxy of prestige, we use the Times Ranking of World Universities (we also use research impact from the Leiden Ranking, 51 see Supporting Information); the high-rank pole is defined as the average vector of the top five U.S. universities according to the rankings, whereas the low-rank pole is defined using the five bottom-ranked (geographically-matched by U.S. census region) universities. We derive an embedding-based ranking for universities based on the geometrical spectrum from the high-ranked to low-ranked poles (see Data and Methods).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "The embedding space encodes the prestige hierarchy of U.S. universities that are coherent with real-world university rankings. The embedding-based ranking is strongly correlated with the Times ranking (Spearman's = 0.73, Fig. 5a ). For reference, the correlation between the Times ranking and the publication impact scores from the Leiden Ranking, 51 a Figure 4 : Geography, then language, conditions international mobility. a. Hierarchically clustered similarity matrix of country vectors aggregated as the mean of all organization vectors within countries with at least 25 organizations. Color of matrix cells corresponds to the cosine similarity between country vectors. Color of country names corresponds to their cluster. Color of three cell columns separated from the matrix corresponds to, from left to right, the region of the country, the language family, 50 and the dominant language. b. Element-centric cluster similarity 49 reveals the factors dictating hierarchical clustering. Region better explains the grouping of country vectors at higher levels of the clustering. Language family, and then the most widely-spoken language, better explain the fine-grained grouping of countries.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 221,
                    "end": 228,
                    "text": "Fig. 5a",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 353,
                    "end": 361,
                    "text": "Figure 4",
                    "ref_id": null
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "bibliometrically-based university ranking, is 0.87 (Spearman's , Fig. 5b ). The correlation between the embedding-based ranking and the Times ranking is robust regardless of the number of organizations used to define the axes (Fig. S18 ), such that even using only the single top-ranked and bottom-ranked universities produces a ranking that is significantly correlated with the Times ranking (Spearman's = 0.46, Fig. S18a ). The correlation is also comparable to more direct measures such as node strength (sum of edge weights, Spearman's = 0.73) and",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 65,
                    "end": 72,
                    "text": "Fig. 5b",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 226,
                    "end": 235,
                    "text": "(Fig. S18",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 413,
                    "end": 422,
                    "text": "Fig. S18a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "eigenvector centrality (Spearman's = 0.76, see Supporting Information) from the mobility network. The strongest outliers that were ranked more highly in the Times ranking than in the embedding-based ranking tend to be large state universities such as Arizona State University and the University of Florida. Those ranked higher in the embedding-based ranking tend to be relatively-small universities near major urban areas such as the University of San Francisco and the University of Maryland Baltimore County, possibly reflecting exchanges of scholars with nearby high-ranked institutions at these locations. In sum, our results suggest that the embedding space is capable of capturing information about academic prestige, even when the representation is learned using data without explicit information on the direction of mobility (as in other formal models 16 ), or prestige.",
            "cite_spans": [
                {
                    "start": 860,
                    "end": 862,
                    "text": "16",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "The axes can be visualized to examine the relative position of organizations along the prestige axis, and along a geographic axis between California and Massachusetts. Prestigious universities such as Columbia, Stanford, MIT, Harvard, and Rockefeller are positioned towards the top of the axis (Fig. 5c ). Universities at the bottom of this axis tend to be regional universities with lower national profiles (yet still ranked by Times Higher Education) and with more emphasis on teaching, such as Barry University and California State University at Long Beach.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 294,
                    "end": 302,
                    "text": "(Fig. 5c",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "By projecting other types of organizations onto the prestige axis, SemAxis offers a new way of representing a continuous spectrum of organizational prestige for which rankings are often low-resolution, incomplete, or entirely absent, such as for regional and liberal arts universities ( Fig. 5d ), research institutes (Fig. 5e ), and government organizations (Fig. 5f ). Their estimated prestige is speculative, though we find that it significantly correlates with their citation impact ( Fig. S22) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 287,
                    "end": 294,
                    "text": "Fig. 5d",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 318,
                    "end": 326,
                    "text": "(Fig. 5e",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 359,
                    "end": 367,
                    "text": "(Fig. 5f",
                    "ref_id": "FIGREF5"
                },
                {
                    "start": 489,
                    "end": 498,
                    "text": "Fig. S22)",
                    "ref_id": null
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "We also find that the size (L2 norm) of the organization embedding vectors provides insights into the characteristics of organizations (Fig. 6 ). Up to a point (around 1,000 researchers), the size of U.S. organization's vectors tends to increase proportionally to the number of researchers (both mobile and non-mobile) with published work; these organizations are primarily teachingfocused institutions, agencies, and hospitals that either are not ranked or have a low ranking.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 135,
                    "end": 142,
                    "text": "(Fig. 6",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "However, at around 1,000 researchers, the size of the vector decreases as the number of researchers increases. These organizations are primarily research-intensive and prestigious universities with higher rank, research outputs, R&D funding, and doctoral students (Fig. S23) .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 264,
                    "end": 274,
                    "text": "(Fig. S23)",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "A similar pattern has been observed in applications of neural embedding to natural language, in which the size of word vectors were found to represent the word's specificity, i.e., the word associated with the vector frequently co-appears with particular context words. 52 If the word in question is universal, appearing frequently in many different contexts, it would not have a large norm due to a lack of strong association with a particular context. Likewise, an organization with a small norm, such as Harvard, appears in many contexts alongside many different organizations in affiliation trajectories-it is well-connected. The concavity of the curve emerges in part from the relationship between the size of the vector and the expected connectedness of the organization, given its size ( ",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 272,
                    "text": "52",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Embeddings capture latent prestige hierarchy"
        },
        {
            "text": "Low\u2212ranked regional and liberal arts colleges Un-filled points are those top and bottom five universities used to span the axis. Even when considering only a total of ten organization vectors, the estimate of the Spearman's rank correlation between the embedding and Times ranking is = 0.73 ( = 145, < 0.0001), which increases when more topand-bottom ranked universities are included (Fig. S18) . b. The Times ranking is correlated with Leiden Ranking of U.S. universities with Spearman's = 0.87 and < 0001. c-f. Illustration of SemAxis projection along two axes; the latent geographic axis, from California to Massachusetts (left to right) and the prestige axis. Shown for U.S. Universities (c), Regional and liberal arts colleges (d), Research institutes (e), and Government organizations (f). Full organization names are listed in Table S1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 384,
                    "end": 394,
                    "text": "(Fig. S18)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 834,
                    "end": 842,
                    "text": "Table S1",
                    "ref_id": null
                }
            ],
            "section": "High\u2212ranked regional and liberal arts colleges"
        },
        {
            "text": "We report that this curve is almost universal across many countries. For instance, China's curve closely mirrors that of the United States (Fig. 6b ). Smaller but scientifically advanced countries such as Australia and other populous countries such as Brazil also exhibit curves similar to the United States (Fig. 6b , inset). Other nations exhibit different curves which lack the portions with decreasing norm, probably indicating the lack of internationally-prestigious institutions. Similar patterns can be found across many of the 30 countries with the most total researchers ( Fig. S24 ; see Supporting Information for more discussion). Size (L2 norm) of organization embedding vectors compared to the number of researchers for U.S. universities. Color indicates the rank of the university from the Times ranking, with 1 being the highest ranked university. Uncolored points are universities not listed on the Times ranking. A concave-shape emerges, wherein larger universities tend to be more distant from the origin (large L2 norm); however, the more prestigious universities tend to have smaller L2 norms. b. We find a similar concave-curve pattern across many countries such as the United States, China, Australia, Brazil, and others (inset, and Fig. S24 ). Some countries exhibit variants of this pattern, such as Egypt, which is missing the right side of the curve. The loess regression lines are shown for each selected country, and for the aggregate of remaining countries, with ribbons mapping to the 99% confidence intervals based on a normal distribution. Loess lines are also shown for organizations in Australia, Brazil, and Egypt (inset).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 139,
                    "end": 147,
                    "text": "(Fig. 6b",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 308,
                    "end": 316,
                    "text": "(Fig. 6b",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 582,
                    "end": 590,
                    "text": "Fig. S24",
                    "ref_id": null
                },
                {
                    "start": 1255,
                    "end": 1263,
                    "text": "Fig. S24",
                    "ref_id": null
                }
            ],
            "section": "California Massachusetts"
        },
        {
            "text": "Neural embedding approaches offer a novel, data-driven solution for efficiently learning an effective and robust representation of locations based on trajectory data, encoding the complex and multi-faceted nature of mobility. We demonstrated that a functional distance derived from the embedding can be used with the gravity model of mobility to better predict real-world mobility than does geographic distance. Embedding distance outperformed geographic distance across distinct and disparate domains, including U.S. flight itineraries, Korean hotel accommodation reservations, and global scientific mobility. We discover that this performance results from neural embeddings implicitly learning gravity law relationships between locations, making them particularly well suited to representing mobility. Focusing on scientific mobility, we find that the embedding successfully encodes many aspects of scientific mobility into a single representation, including global and regional geography, shared languages, and prestige hierarchies, even without explicit information on these factors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "In revealing the correspondence between neural embeddings and the gravity model, the study of human mobility can move beyond geographic and network-based models of mobility, and instead leverage the high-order structure from individuals' mobility trajectories using these robust and efficient methods. While we focus on three domains of mobility, this approach could be applied to many different domains, such as general human migration, transit-network mobility, and more. Once learned, functional distances between locations, such as countries, cities, or organizations, can be published to support future research. Moreover, this approach can be used to learn a functional distance even between entities for which no geographic analog exists, such as between occupational categories based on individuals' career trajectories. In addition to providing a functional distance that supports modeling and predicting mobility patterns, the structure of the neural embedding space is amenable to a range of unique applications 20 for studying mobility. As we have shown, the embedding space allows the visualization of the complex structure of scientific mobility at high resolution across multiple scales, providing a large and detailed map of the landscape of global scientific mobility. Embedding also allows us to quantitatively explore abstract notions such as academic prestige, and can potentially be generalized to other abstract axes. Investigation of the structure of the embedding space, such as the vector norm, reveals universal patterns based on the organization's size and their vector norm that could be leveraged in future studies of mobility.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "This approach, and our study, also have several limitations. First, the skip-gram word2vec model does not leverage directionality, meaning that embedding will be less effective at capturing mobility for which directionality is critical. Future studies may consider bi-directional embeddings, such as BERT, 53 to incorporate directionality, as well as their correspondance to asymetric mobility models, such as the radiation model (4) . Second, the neural embedding approach is most useful in cases of mobility between discrete geographic units such as between countries, cities, and businesses; this approach is less useful in the case of mobility between locations represented using geographic coordinates, such as in the modeling of animal movements. Third, neural embeddings are an inherently stochastic procedure, and so results may change across different iterations. However, in this study we observe all results to be robust to stochasticity, likely emerging from the limited \"vocabulary\" of scientific mobility, airports, and accommodations (several thousand) and the relatively massive datasets used to learn representations (several million trajectories). Applications of word2vec to problem domains where the ratio of the vocabulary to data is smaller, however, should be implemented with caution to ensure that findings are not the result of random fluctuations. Finally, the case of scientific mobility presents domain-specific limitations. Reliance on bibliometric metadata means that we capture only long-term mobility such as migration, rather than the array of more frequent short-term mobility such as conference travel and temporary visits. The kinds of mobility we 21 do capture-migration and co-affiliation-although conceptually different, are treated identically by our model. Also, our data might further suffer from bias based on publication rates: researchers at prestigious organizations tend to have more publications, leading to these organizations appearing more frequently in affiliation trajectories.",
            "cite_spans": [
                {
                    "start": 306,
                    "end": 308,
                    "text": "53",
                    "ref_id": "BIBREF52"
                },
                {
                    "start": 430,
                    "end": 433,
                    "text": "(4)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "Mobility and migration are at the core of human nature and history, driving societal phenomena as diverse as epidemics 39,54 and innovation. [11] [12] [13] [14] [15] However, the paradigm of scientific migration may be changing. Traditional hubs of migration have experienced many politicallymotivated policy changes that affect scientific mobility, such as travel restrictions in the U.S. and U.K.. 55 At the same time, other nations, such as China, are growing into major scientific powers and attractors of talent. 56 Unprecedented health crises such as the COVID-19 pandemic threaten to bring drastic global changes to migration by tightening borders and halting travel.",
            "cite_spans": [
                {
                    "start": 141,
                    "end": 145,
                    "text": "[11]",
                    "ref_id": null
                },
                {
                    "start": 146,
                    "end": 150,
                    "text": "[12]",
                    "ref_id": null
                },
                {
                    "start": 151,
                    "end": 155,
                    "text": "[13]",
                    "ref_id": null
                },
                {
                    "start": 156,
                    "end": 160,
                    "text": "[14]",
                    "ref_id": null
                },
                {
                    "start": 161,
                    "end": 165,
                    "text": "[15]",
                    "ref_id": null
                },
                {
                    "start": 400,
                    "end": 402,
                    "text": "55",
                    "ref_id": null
                },
                {
                    "start": 518,
                    "end": 520,
                    "text": "56",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "By revealing the correspondence between neural embedding and the gravity model and revealing their utility and efficacy, our study opens a new avenue in the study of mobility. Mobility is at the core of many global challenges, and the insights brought forth by our tool can be put to use to inform a better understanding of human mobility, and to inform sensible, effective, sustainable, and humane policies.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "We source U.S. airport itinerary data from the Origin and Destination Survey (DB1B), provided by the Bureau of Transportation Statistics at the United States Department of Transportation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "U.S. flight itinerary data"
        },
        {
            "text": "DB1B is a sample of 10 percent of domestic airline tickets between 1993 and 2020, comprising 307,760,841 passenger itineraries between 828 U.S. airports. Each itinerary is associated with a trajectory of airports including the origin, destination, and intermediary stops.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "U.S. flight itinerary data"
        },
        {
            "text": "We source Korean accommodation reservation data from collaboration with Goodchoice Company LTD. The data contains customer-level reservation trajectories spanning the period of August 2018 through July 2020 and comprising 1,038 unique accommodation locations in Seoul, South Korea.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Korean accommodation reservation data"
        },
        {
            "text": "We source co-affiliation trajectories of authors from the Web of Science database hosted by the For example, France, Qatar, the USA, Iraq, and Luxembourg had the most mobile authors (Fig. S2c ). However, due to their size, the USA, accounted for nearly 40 % of all mobile authors worldwide (Fig. S2a) , with 10 countries accounting for 80 % of all mobility (Fig. S2b ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 182,
                    "end": 191,
                    "text": "(Fig. S2c",
                    "ref_id": null
                },
                {
                    "start": 290,
                    "end": 300,
                    "text": "(Fig. S2a)",
                    "ref_id": null
                },
                {
                    "start": 357,
                    "end": 366,
                    "text": "(Fig. S2b",
                    "ref_id": null
                }
            ],
            "section": "Scientific mobility data"
        },
        {
            "text": "The countries with the highest proportion of mobile scientists are France, Qatar, the United States, and Iraq, whereas those with the lowest are Jamaica, Serbia, Bosnia & Herzegovina, and North Macedonia (Fig. S2c) . In most cases, countries with a high degree of inter-organization mobility also have a high degree of international mobility, indicating that a high proportion of their total mobility is international (Fig. S2d) ; However, some countries such as France and the United States seem to have more domestic mobility than international mobility. While the number of publications has increased year-to-year, the mobility and disciplinary makeup of the dataset has not notably changed across the period of study (Fig. S1 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 204,
                    "end": 214,
                    "text": "(Fig. S2c)",
                    "ref_id": null
                },
                {
                    "start": 418,
                    "end": 428,
                    "text": "(Fig. S2d)",
                    "ref_id": null
                },
                {
                    "start": 721,
                    "end": 729,
                    "text": "(Fig. S1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Scientific mobility data"
        },
        {
            "text": "We embed trajectories by treating them analogously to sentences and locations analogously to words. For U.S. airport itinerary, trajectories are formed from the flight itineraries of individual passenger, in which airports correspond to unique identifiers. In the case of Korean accommodation reservations, trajectories comprise a sequence of accommodations reserved over a customer's history. For scientific mobility, an\"affiliation trajectories\" is constructed for each mobile author, which is built by concatenating together their ordered list of unique organization identifiers, as demonstrated in Fig. 1a . In more complex cases, such as listing multiple affiliations on the same paper or publishing with different affiliations on multiple publications in the same year, the order is randomized within that year, as shown in Fig. 1b .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 602,
                    "end": 609,
                    "text": "Fig. 1a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 830,
                    "end": 837,
                    "text": "Fig. 1b",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Embedding"
        },
        {
            "text": "These trajectories are used as input to the standard skip-gram negative sampling word embedding, commonly known as word2vec. 19 word2vec constructs dense and continuous vector representations of words and phrases, in which distance between words corresponds to a notion of semantic distance. By embedding trajectories, we aim to learn a dense vector for every location, for which the distance between vectors relates to the tendency for two loca- ",
            "cite_spans": [
                {
                    "start": 125,
                    "end": 127,
                    "text": "19",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Embedding"
        },
        {
            "text": "where,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embedding"
        },
        {
            "text": "where and are the \"in-vector\" and \"out-vector\", respectively, = \u2208A exp( \u00b7 ) is a normalization constant, and A is the set of all locations. We follow the standard practice and only use the in-vector, , which is known to be superior to the out-vector in link prediction benchmarks. [20] [21] [22] [23] [24] [25] 27 We used the word2vec implementation in the python package gensim. The skip-gram negative sampling word2vec model has several tunable hyper-parameters, including the embedding dimension , the size of the context window , the minimum frequency threshold min , initial learning rate , shape of negative sampling distribution , the number of the negative samples should be drawn , and the number of iterations. For main results regarding scientific mobility, we used = 300 and = 1, which were the parameters that best explained the flux between locations, though results were robust across different settings (Fig. S4) . Although the original word2vec paper uses = 0.75, 19 here we set = 1.0, though results are only trivially different at different values of (Fig. S5 ). We used = 5, which is suggested default of word2vec. We also use same setting for U.S. airport itinerary and Korean accommodation reservation data.",
            "cite_spans": [
                {
                    "start": 281,
                    "end": 285,
                    "text": "[20]",
                    "ref_id": null
                },
                {
                    "start": 286,
                    "end": 290,
                    "text": "[21]",
                    "ref_id": null
                },
                {
                    "start": 291,
                    "end": 295,
                    "text": "[22]",
                    "ref_id": null
                },
                {
                    "start": 296,
                    "end": 300,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 301,
                    "end": 305,
                    "text": "[24]",
                    "ref_id": null
                },
                {
                    "start": 306,
                    "end": 310,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 311,
                    "end": 313,
                    "text": "27",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 919,
                    "end": 928,
                    "text": "(Fig. S4)",
                    "ref_id": null
                },
                {
                    "start": 1070,
                    "end": 1078,
                    "text": "(Fig. S5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Embedding"
        },
        {
            "text": "To mitigate the effect of less common locations, we set min = 50, limiting to locations appearing at least 50 times across the training trajectories; 744 unique airport for U.S. airport itinerary, 1004 unique accommodations for Korean accommodation reservation data, and 6,580",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embedding"
        },
        {
            "text": "unique organizations for scientific mobility appear in the resulting embedding. We set to its default value of 0.025 and iterate five times over all training trajectories. For scientific mobility, across each training iteration, the order of organizations within a single year is randomized to remove unclear sequential order.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Embedding"
        },
        {
            "text": "Negative sampling trains word2vec using a binary classification task as follows. For each target word , we sample a context word from the given data and label it as positive, denoted by = 1. Then, we sample words \u2113 from a noise distribution 0 (\u2113) and label them as negative, denoted by \u2113 = 0. In word2vec, the noise distribution is given by 0 (\u2113) \u221d (\u2113), where ( ) is the fraction of in the data, and is a hyper-parameter. Then, for the sampled words, we fit a logistic regression model",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "by maximizing the log-likelihood:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "where D is the set of all sampled context words.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "This procedure does not guarantee that the embedding optimally converges, even when increasing the training samples and iterations. 44, 45 To make this bias explicit, let us consider the unbiased variant of negative sampling, i.e., the noise contrastive estimation (NCE). 44, 45 NCE is an unbiased estimator for a probability model of the form:",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 135,
                    "text": "44,",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 136,
                    "end": 138,
                    "text": "45",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 272,
                    "end": 275,
                    "text": "44,",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 276,
                    "end": 278,
                    "text": "45",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "where is a non-negative likelihood function of data , and X is the set of all data. NCE fits a logistic regression model:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "where = ln + ln \u2208X ( ) is a constant and maximizes the log-likelihood",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "by calculating the gradients for embedding vectors , and iteratively updating them (see Supporting Information for full derivation). Note that NCE is an unbiased estimator that has convergence to the optimal embedding in terms of the original word2vec's objective function, 45 if we increase the number of words to sample and the training iterations.",
            "cite_spans": [
                {
                    "start": 274,
                    "end": 276,
                    "text": "45",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "Let us revisit negative sampling from the perspective of NCE. We rewrite the logistic regression model in negative sampling (Eq. 9) in form of the posterior probability:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "where we define the likelihood function by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "which is the unbiased estimator for the probability model",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "Taken together, the conditional probability that SGNS word2vec actually optimizes is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "where = \u2208A ( ) exp( \u00b7 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "An implicit bias in the negative sampling"
        },
        {
            "text": "We calculate as the total number of co-occurrence between two locations and across the data-set. In scientific mobility, = 10 indicates that the number of co-occurrence between both organization and between 2008 and 2019 is 10, as evidenced from their publications.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Distance"
        },
        {
            "text": "Here, we treat = for the sake of simplicity and, in the case of scientific mobility, because directionality cannot easily be derived from bibliometric records, or may not be particularly informative (see Supporting Information).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Distance"
        },
        {
            "text": "We calculate two main forms of distance between locations. The geographic distance, , is the pairwise geographic distance between locations. Geographic distance is calculated as the great circle distance, in kilometers, between pairs of locations. In the case of U.S. flight itinerary and scientific mobility, we impute distance to 1 km when their distance is less than one kilometer. In the case of Korean accommodation reservation data, because this data is intra-city mobility trajectory at a much smaller scale, we impute distance to 0.01 km when their distance is less than 0.01 km. The embedding distance with the cosine distance, , is calculated as = 1 \u2212 \u00b7 , where and are the embedding vectors for locations and , respectively. Note that is not a formal metric because it does not satisfy the triangle inequality. Nevertheless, cosine distance is often shown to be useful in practice. 6, 7, 58 We compare the performance of this cosine-based embedding distance against those derived using dot product similarity and euclidean distance.",
            "cite_spans": [
                {
                    "start": 893,
                    "end": 895,
                    "text": "6,",
                    "ref_id": null
                },
                {
                    "start": 896,
                    "end": 898,
                    "text": "7,",
                    "ref_id": null
                },
                {
                    "start": 899,
                    "end": 901,
                    "text": "58",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Distance"
        },
        {
            "text": "We compare the performance of the embedding distance to many baselines. These include distances derived from simpler embedding approaches, such as Singular Value Decomposi-tion (SVD) and a Laplacian Eigenmap embedding performed on the underlying location cooccurrence matrix. We also use network-based distances, calculating vectors using a Personalized Page Rank approach and measuring the distance between them using cosine distance and Jensen-Shannon Divergence (see Supporting Information) . Finally, we compare the embedding distance against embeddings calculated through direct matrix factorization, following the approach that word2vec implicitley approximates. 34",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 470,
                    "end": 493,
                    "text": "Supporting Information)",
                    "ref_id": null
                }
            ],
            "section": "Distance"
        },
        {
            "text": "We model co-occurences for locations and (referred to as flux), using the gravity law of mobility. 3 The gravity law of mobility, which was inspired by Newton's law of gravity, postulates that attraction between two locations is a function of their population and the distance between them. This formulation and variants have proven useful for modeling and predicting many kinds of mobility. [36] [37] [38] [39] In the gravity law of mobility, the expected flux,\u02c6between two locations and is defined as,\u02c6=",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 100,
                    "text": "3",
                    "ref_id": null
                },
                {
                    "start": 392,
                    "end": 396,
                    "text": "[36]",
                    "ref_id": null
                },
                {
                    "start": 397,
                    "end": 401,
                    "text": "[37]",
                    "ref_id": null
                },
                {
                    "start": 402,
                    "end": 406,
                    "text": "[38]",
                    "ref_id": null
                },
                {
                    "start": 407,
                    "end": 411,
                    "text": "[39]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Gravity Law"
        },
        {
            "text": "where and are the population of locations, defined as the total number of passenger who passed through each airport for U.S. airport itineraries, the total number of customer who We consider separate variants of ( ) for the geographic distance, , and the embedding distance, , report the best-fit model of each distance. For the geographic distance, we use the power-law function of the gravity law, ( ) = \u2212 (Eq. 22). For the embedding distance, we use the exponential function, with ( ) = \u2212 (Eq. 23).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gravity Law"
        },
        {
            "text": "where is the actual flow from the data. The gravity law of mobility is sensitive to accommodations for Korean accommodation reservation data. This value is comparable to other common applications of the gravity law, such as phone calls, commuting, and migration. 4 We follow standard practice and exclude zero flows from our analysis.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 264,
                    "text": "4",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Gravity Law"
        },
        {
            "text": "SemAxis and similar studies 22, 25, 35 demonstrated that \"semantic axes\" can be found from an embedding space by defining the \"poles\" and the latent semantic relationship along the semantic axis can be extracted with simple arithmetic. In the case of natural language, the poles of the axis could be \"good\" and \"bad\", \"surprising\" and \"unsurprising\", or \"masculine\" and \"feminine\". We can use SemAxis to leverage the semantic properties of the embedding vectors to operationalize abstract relationships between organizations. ",
            "cite_spans": [
                {
                    "start": 28,
                    "end": 31,
                    "text": "22,",
                    "ref_id": null
                },
                {
                    "start": 32,
                    "end": 35,
                    "text": "25,",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 36,
                    "end": 38,
                    "text": "35",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "SemAxis"
        },
        {
            "text": "where a higher score for organization indicates that is more closely aligned to + than \u2212 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SemAxis"
        },
        {
            "text": "We define two axes to capture geography and academic prestige, respectively. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SemAxis"
        },
        {
            "text": "Code used in this analysis can be found at https://github.com/murrayds/sci-mobility-emb Supporting Information S1 Text Mobility and science.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Code Availability"
        },
        {
            "text": "As scholars move, they bring their knowledge, skills, and social connections with themcollectively the movements of researchers shape the structure and direction of the global scientific enterprise. For example, prestige-driven mobility between doctoral-granting and employing institution is highly unequal, 16 There are many ways of modeling scientific mobility from bibliographic data, the first consideration being the unit of analysis. Most studies of mobility have focused on countrylevel mobility-the flows of researchers across nations. 12,69-71 Practically, country-level analyses benefit from higher reliability, such that idiosyncrasies and errors inherent to bibliographic databases are mitigated by this higher level of aggregation. Epistemically, country-level analysis is useful for national science governance who aims to understand the status of their country in the global landscape and make informed policy decisions. Analyses at lower levels of analysis are far less common. Regional-level scientific mobility-the flow of researchers between regions or cities within or across countries has been only minimally studied, 72 possibly due to lack of reliable long-term data and lack of policy relevance to national-level lawmakers. Organization-level mobility has the potential to inform institutional policy and to understand the composition of mobility within a single country or region, especially as it relates to organization performance, prestige, and inequality. [15] [16] [17] 73 However, affiliation disambiguation and noise in bibliometric data makes large-scale organization-level analysis challenging. Here, we learn neural-network embeddings of scientific mobility at the level of organizations using a curated bibliographic database. These embeddings are robust to noise, and so are capable of representing clear structure even amid issues with organizational disambiguation. In doing so, embeddings also capture a more detailed understanding of mobility than has been previously studied.",
            "cite_spans": [
                {
                    "start": 308,
                    "end": 310,
                    "text": "16",
                    "ref_id": null
                },
                {
                    "start": 1486,
                    "end": 1490,
                    "text": "[15]",
                    "ref_id": null
                },
                {
                    "start": 1491,
                    "end": 1495,
                    "text": "[16]",
                    "ref_id": null
                },
                {
                    "start": 1496,
                    "end": 1500,
                    "text": "[17]",
                    "ref_id": null
                },
                {
                    "start": 1501,
                    "end": 1503,
                    "text": "73",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Code Availability"
        },
        {
            "text": "Another consideration when analyzing scientific mobility is what kinds of mobility to study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Code Availability"
        },
        {
            "text": "Typical understandings of mobility are directional: movement is always from one place and to another. However, scientific mobility is more complicated. For example, scientists often hold multiple affiliations at a time, 74 listing them as co-affiliations on a single paper, or even choosing a subset of affiliations to use fohabeultiple simultaneous projects. 18 Even clearly-directional migration to another institution is complex-researchers may continue to publish with an old affiliation for projects that began before their move, and they may maintain social and organizational links to their old institution (e.g., collaborators, projects, graduate students) such that there is no clear breakage after migrating. There is also a whole range of short-term scientific mobility, such as visiting scholarships and short-term visits that are only visible through intensive efforts such as manual extraction from CVs. [75] [76] [77] Here, we focus on more long-term mobility that can be derived from bibliographic data. Due to the complexity of scientific mobility, we make the simplifying assumption that all scientific mobility is symmetric or without direction such that any move from an organization to organization is equivalent to a move from to . By assuming non-directional mobility, all mobility events are commensurate, meaning that they can be treated identically in our analysis-this allows us to represent the complexity of mobility without making decisions about the directional of their mobility or which is their main affiliation. Moreover, this assumption has the practical advantage of matching the data format expected by the word2vec model, as well as the theoretical advantage of adhering to the symmetricity assumption of the gravity model of mobility.",
            "cite_spans": [
                {
                    "start": 220,
                    "end": 222,
                    "text": "74",
                    "ref_id": null
                },
                {
                    "start": 360,
                    "end": 362,
                    "text": "18",
                    "ref_id": null
                },
                {
                    "start": 918,
                    "end": 922,
                    "text": "[75]",
                    "ref_id": null
                },
                {
                    "start": 923,
                    "end": 927,
                    "text": "[76]",
                    "ref_id": null
                },
                {
                    "start": 928,
                    "end": 932,
                    "text": "[77]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Code Availability"
        },
        {
            "text": "For each mobile researcher who has at least two distinct affiliations, we construct an affil- This effectively removes the effect of order within a year, as the order cannot be meaningfully established based on co-affiliations in a single paper, or on different affiliations listed on separate papers, for which its date of publication may not be representative of the actual completion of the project.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S3 Text Building affiliation trajectories."
        },
        {
            "text": "Other than restricting to only mobile researchers, we do not perform any filtering or reductions to affiliation trajectories. In the case than an author publishes with organization four times in 0 , and affiliation two times in 1 , then their trajectory will be ( , , , , , ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S3 Text Building affiliation trajectories."
        },
        {
            "text": "Although mobile authors who publish more papers will have longer trajectories, word2vec will skip duplicate consecutive organization IDs, mitigating the impact of long repetitive trajectories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S3 Text Building affiliation trajectories."
        },
        {
            "text": "We examine the gravity model on the Personalized Page Rank (PPR) 78 as a benchmark on the network. We construct the co-occurrence network of organizations, in which each edge between organizations and represents a co-occurence of and in the same affiliation trajectory, with weight given by the sum of the co-occurences over all researchers. and edges are co-occurrence between two organizations. The Personalized Page Rank is a ranking algorithm for nodes based on a random walk process on networks. The walker visiting at a node moves to a neighboring node chosen randomly with a probability proportionally to the weight of the edge in one step. Furthermore, with probability , the walker is teleported back to the starting node. The rank of a node is determined by the probability that the walker visits the node in the stationary state. The stationary distribution of the random walker starting from node , denoted by = ( ), is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "where is a column vector of length with entries that are all zero except the th entry that equals to one, = ( ) is the weighted adjacency matrix. We used = 0.9 here.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "We can think as a representation vector of the organization , and calculate the distance between organizations and , with measuring distance between and to examine the gravity law. We consider two distance measures in this analysis. The first one is cosine distance which is used for our embedding method,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "Also, if we think as a discrete probability distribution, then we can consider Jensen-Shannon divergence (JSD), can be written as,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "where = 1 2 ( + ). We report the result with cosine distance ( 2 = 0.14, Fig. S11 ) and",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 73,
                    "end": 81,
                    "text": "Fig. S11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "Jensen-Shannon divergence ( 2 = 0.19, Fig. S12 ). In both cases, the performance is under the performance of the model with geographical distance. Even though the length of the PPR vectors is extremely larger than the length of our embedding vectors, result with the embedding distance outperforms both of them.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 38,
                    "end": 46,
                    "text": "Fig. S12",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "S4 Text Network-based personalized page rank distances."
        },
        {
            "text": "We use the truncated singular value decomposition (SVD) on the underlying mobility cooccurrence matrix as a baseline embedding. In short, truncated SVD performs linear low-rank approximation of the matrix with given dimensions, . First, we construct the co-occurrence matrix of organizations, given by the co-occurrence of organizations and in the same affiliation trajectory. Then, we apply truncated singular value decomposition with = 300 on the flow matrix directly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S5 Text Singular value decomposition distance."
        },
        {
            "text": "We calculate distance between organizations in the SVD embedding space using cosine distance, finding that it explains slighly more of the flux between organizations than does geo-graphic distance ( 2 = 0.247, Table S3 ). When used as an input to the gravity model, this distance produces better predictions than geographic distance using both the exponential (RMSE = 0.859, Table S4 ) and power-law models (RMSE = 0.839, Table S4 ), performing slightly better with the power-law formulation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 210,
                    "end": 218,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 375,
                    "end": 383,
                    "text": "Table S4",
                    "ref_id": null
                },
                {
                    "start": 422,
                    "end": 430,
                    "text": "Table S4",
                    "ref_id": null
                }
            ],
            "section": "S5 Text Singular value decomposition distance."
        },
        {
            "text": "We also consider Laplacian Eigenmap embeddings 42 as a baseline, which is one of the most fundamental approaches for graph embedding. First, we construct the co-occurrence matrix of organizations, given by the co-occurrence of organizations and in the same affiliation trajectory and degree matrix which is the diagonal matrix for which = . Then we construct graph Lapalcian matrix = \u2212 and apply truncated singular value decomposition in the matrix with = 300.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S6 Text Laplacian Eigenmap distance."
        },
        {
            "text": "We only report results based on the cosine distance between Laplacian embedding vectors, finding that it explains less of the total flux than geographic distance ( 2 = 0.212, Table S3 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 175,
                    "end": 183,
                    "text": "Table S3",
                    "ref_id": null
                }
            ],
            "section": "S6 Text Laplacian Eigenmap distance."
        },
        {
            "text": "When used as an input to the gravity model, the Laplacian cosine distance produces marginallybetter predictions than geographic distance using both the exponential (RMSE = 0.878, Table S4) and power-law models (RMSE = 0.87, Table S5 ), performing slightly better with the power-law formulation.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 224,
                    "end": 232,
                    "text": "Table S5",
                    "ref_id": null
                }
            ],
            "section": "S6 Text Laplacian Eigenmap distance."
        },
        {
            "text": "We also compare the word2vec embedding distnace against a baseline of direct matrix factorization approach, using the symmetric SVD word2vec method. 34 Based on idea of word2vec is just implicit matrix factorization, Levy proposed symmetric SVD word2vec embedding, which should directly compute the embedding that word2vec only attempts to efficiently approximate. First, we construct the matrix of organization",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 151,
                    "text": "34",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "S7 Text Levy's symmetric SVD word2vec distance"
        },
        {
            "text": "where ( , ) is the number of times the location pair ( , ) appears given the window size in the total corpus , ( ) = = ( , ) as the number of items occurred given the window size in , and k is the number of negative samples. We used = 1 and = 5 which is same setting in the our main result. Then, we factorized matrix with truncated singular value decomposition in the matrix with = 300 into \u03a3 , and used the embedding vector as \u221a \u03a3 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S7 Text Levy's symmetric SVD word2vec distance"
        },
        {
            "text": "For this baseline, we report results using the cosine distance, Euclidean distance, and dot product between the embedding vectors. We find that the dot product performs by far the worst, worse than any other baseline considered 2 = 0.004, Table S3 ). The cosine distance performs better, but worse than geographic distance ( 2 = 0.212, Table S3 ). The Euclidean distance performs best, explaining more of the flux than geographic distance, and only being below the embedding distance ( 2 = 0.341, Table S3 ). Focusing on the Euclidean distance, we find that using it as input to the gravity model results in better predictions than geographic distance using both the exponential model (RMSE = 0.803, Table S4 ) and power law models, (RMSE = 0.78, Table S5 ), though it performs slightly better with the power law formulation. We then embed the gravity matrix using two approaches: a truncated singular value decom-position (SVD), and with multidimensional scaling (MDS), which embeds each location in a N-dimensional space such that pairwise distances are preserved as well as possible. Typically, MDS uses Euclidean distance to measure distance between vectors.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 239,
                    "end": 247,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 336,
                    "end": 344,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 497,
                    "end": 505,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 700,
                    "end": 708,
                    "text": "Table S4",
                    "ref_id": null
                },
                {
                    "start": 747,
                    "end": 755,
                    "text": "Table S5",
                    "ref_id": null
                }
            ],
            "section": "S7 Text Levy's symmetric SVD word2vec distance"
        },
        {
            "text": "For this result, we report results using the cosine distance between embedding vectors for the SVD embedding, and the logged Euclidean distance for the MDS embedding. We observe that the gravity-optimized SVD cosine distance has poor performance, more weakly correlated with actual flux than geographic distance ( 2 = 0.122, Table S3 ), and similarly poor prediction error when used as input to the gravity mode. In contrast, the cosine distance between MDS vectors has the second-highest correlation with actual flux, after only the embedding distance ( 2 = 0.355, Table S3 ), and third best for predicting actual flux using both the power-law version of the gravity model (RMSE = 0.795, Table S5 ), though performance is much lower using the exponential form (RMSE = 0.904, Table S4 ). We note that the MDS embedding actually has the lowest prediction error when organizations' populations are defined as the raw frequency during prediction with the power-law model (RMSE = 0.691, Table S5 ); however, we note that the MDS distance is defined with a population of \"All\" mobile and non-mobile scholars, whereas the predictions made in Table S5 using the raw frequency, which likely confounds this result.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 325,
                    "end": 333,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 566,
                    "end": 574,
                    "text": "Table S3",
                    "ref_id": null
                },
                {
                    "start": 689,
                    "end": 697,
                    "text": "Table S5",
                    "ref_id": null
                },
                {
                    "start": 776,
                    "end": 784,
                    "text": "Table S4",
                    "ref_id": null
                },
                {
                    "start": 983,
                    "end": 991,
                    "text": "Table S5",
                    "ref_id": null
                },
                {
                    "start": 1136,
                    "end": 1144,
                    "text": "Table S5",
                    "ref_id": null
                }
            ],
            "section": "S8 Text Direct optimization of gravity model"
        },
        {
            "text": "MDS is also computationally-intensive, requiring upwards of 6 times more time to compute (on the machine used in this analysis) than the more computationally efficient word2vec model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S8 Text Direct optimization of gravity model"
        },
        {
            "text": "Why do neural-embedding approaches, which rely on stochastic gradient descent, outperform Levy's direct matrix factorization, 34 especially given that word2vec is implicitly approximating factorization? We speculate that is stems, in part, from the sensitivity of matrix factorization to small flows between locations. Levy's matrix factorization embeds affiliations and such that their dot similarity is as close as possible to log( / ( ) ( )). If the flow is considerably small or zero, the dot similarity goes to \u2212\u221e, pushing and very far from other affiliations in the embedding space. 34, 79 This is particularly problematic when the window size is small because most affiliation pairs would have no flow, which is indeed the case in our experiments. To circumvent this problem, previous studies 34,79 added a constant flow between the affiliation pairs with no flow. However, in addition to altering the underlying data, these small flows can still have a strong impact on the embedding.",
            "cite_spans": [
                {
                    "start": 589,
                    "end": 592,
                    "text": "34,",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 593,
                    "end": 595,
                    "text": "79",
                    "ref_id": "BIBREF78"
                }
            ],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "It is also well known that singular value decomposition (SVD) is vulnerable to outliers. [80] [81] [82] [83] [84] The stochastic gradient descent algorithm, which is employed in SGNS word2vec, is more robust than SVD and can enhance generalization and effectiveness of word2vec model. [85] [86] [87] S10 Text Organization disambiguation and metadata.",
            "cite_spans": [
                {
                    "start": 89,
                    "end": 93,
                    "text": "[80]",
                    "ref_id": "BIBREF79"
                },
                {
                    "start": 94,
                    "end": 98,
                    "text": "[81]",
                    "ref_id": null
                },
                {
                    "start": 99,
                    "end": 103,
                    "text": "[82]",
                    "ref_id": null
                },
                {
                    "start": 104,
                    "end": 108,
                    "text": "[83]",
                    "ref_id": null
                },
                {
                    "start": 109,
                    "end": 113,
                    "text": "[84]",
                    "ref_id": null
                },
                {
                    "start": 285,
                    "end": 289,
                    "text": "[85]",
                    "ref_id": "BIBREF84"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[86]",
                    "ref_id": "BIBREF85"
                },
                {
                    "start": 295,
                    "end": 299,
                    "text": "[87]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "Affiliations mapped to one of 8,661 organizations, disambiguated following that originally designed for the Leiden Rankings of World Universities. 51 Organizational records were associated with a full name, a type indicating the sector (e.g., University, Government, Industry), and an identifier for the country and city of the organization. Sixteen different sector types were included in the analysis, which we aggregated to four high-level codes: University, Hospital, Government, and Other. Each record was also associated with a latitude and longitude.",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 149,
                    "text": "51",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "However, for many organizations, these geographic coordinates were missing or incorrect. We manually updated the coordinates of 2,267 organizations by searching the institution name and city on Google Maps; in cases where a precise location of the organization could not be identified, we used the coordinates returned when searching the name of the city. The data was further enriched with country-level information, including region, most widely-spoken language, and its language family (e.g., the language family of Spanish is Italic). State/province-level information was added using the reverse geocoding service LocationIQ using each organization's latitude and longitude as input. Regional census classifications were added for states in the United States. For each organization, we calculated size as the average number of unique authors (mobile and non-mobile) who published with that organization across each year of our dataset; in the case that authors publish with multiple affiliations in a single year, they are counted towards each.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "As a result of our disambiguation procedure, some affiliations are mapped to two organizations, one specific, and one more general. For example, any author affiliated with \"Indiana",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "University Bloomington\" will also be listed as being affiliated with the \"Indiana University System\", a more general designation for all public universities in Indiana. However, a more general organization may not always occur alongside the more specific one. For example, a researcher affiliated with the smaller regional school \"Indiana University South Bend\" will be listed as affiliated with only the \"Indiana University System\". We identify all specific organizations that always co-occur along with a more general one. For every career trajectory that includes one of these specific organizations, we remove all occurrences of the more general organization;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "trajectories containing only a general designation are not altered.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S9 Text Why do neural embeddings outperform direct matrix factorization?"
        },
        {
            "text": "Author-name disambiguation, the problem of associating names on papers with individuals authors, remains difficult for the use of bibliometric data. 88 Authors in our dataset have been disambiguated using a rule-based algorithm that makes use of author and paper metadata, such as physical addresses, co-authors, and journal, to score papers on the likelihood of belonging to an author cluster-a cluster of publications believed to have been authored by the same individual. 57 We limit our period of analysis to the period of 2008 to 2019, as in 2008 the Web of Science began indexing additional author-level metadata such as full names and email addresses. The disambiguation algorithm is conservative, favoring splitting clusters over merging.",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 151,
                    "text": "88",
                    "ref_id": null
                },
                {
                    "start": 475,
                    "end": 477,
                    "text": "57",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Past studies have validated this data and shown that the disambiguated authors are comparable 46 to ground-truth records such as those from ORCID and useful for a wide range of bibliometric studies. 12, 18, 48, 55 S12 Text Derivation of Eq.35 -Noise Contrastive Estimation",
            "cite_spans": [
                {
                    "start": 199,
                    "end": 202,
                    "text": "12,",
                    "ref_id": null
                },
                {
                    "start": 203,
                    "end": 206,
                    "text": "18,",
                    "ref_id": null
                },
                {
                    "start": 207,
                    "end": 210,
                    "text": "48,",
                    "ref_id": null
                },
                {
                    "start": 211,
                    "end": 213,
                    "text": "55",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "The noise contrastive estimation (NCE). 44, 45 NCE is an unbiased estimator for a probability model of the form:",
            "cite_spans": [
                {
                    "start": 40,
                    "end": 43,
                    "text": "44,",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 44,
                    "end": 46,
                    "text": "45",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "where is a non-negative likelihood function of data , and X is the set of all data. This general form includes the word2vec model (Eq. (8)), where ( ) = exp( ) and = \u00b7 . NCE fits the probability model using a binary classification task in the same way as in negative sampling but using a Bayesian formalism for logistic regression. Specifically, before the training, we know that 1 in 1+ words is sampled from the given data, which can be modeled as prior probabilities",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Using the Bayes rule, the posterior probability for given word is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Bearing in mind that word is sampled from the given data if = 1 and from the noise",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Assuming that the given data is generated from the probability model to fit, the class-conditional probability, | , is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Putting Eqs. (30) , (31) and (32) together, the posterior probability for is given by",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 17,
                    "text": "(30)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 20,
                    "end": 24,
                    "text": "(31)",
                    "ref_id": null
                },
                {
                    "start": 29,
                    "end": 33,
                    "text": "(32)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "47 which can be rewritten in form of sigmoid function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "where = ln + ln \u2208X ( ) is a constant. NCE maximizes the log-likelihood",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "by calculating the gradients for embedding vectors , and iteratively updating them. An important consequence of this framework is that NCE is an unbiased estimator that has convergence to the optimal embedding in terms of the original word2vec's objective function, J if we increase the number of words to sample and the training iterations. 44, 45 S13 Text Reconstructing Times ranking with network measure.",
            "cite_spans": [
                {
                    "start": 342,
                    "end": 345,
                    "text": "44,",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 346,
                    "end": 348,
                    "text": "45",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "The performance of the embedding ranking in reconstructing the Times ranking is comparable to that of network-derived measures such as degree strength (Spearman's = 0.73, Fig. S20b ). The embedding ranking over-ranks large research-intensive universities such as North Carolina State University, University of Florida, and Texas A&M University, whereas the network-derived ranking over-ranks smaller, more specialized universities such as Brandeis University, Yeshiva University, and University of San Francisco. This suggests that the embedding encodes information on prestige hierarchy at least as well as a network representation, with some noticeable qualitative differences.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 180,
                    "text": "Fig. S20b",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "S14 Text Speculation on variations of the convex-curve pattern.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "The convex-curve pattern observed in Fig. 6 repeats across many countries, with variations. Table S3 : Correlation between flux and distance over metrics, experimental parameters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 37,
                    "end": 43,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 92,
                    "end": 100,
                    "text": "Table S3",
                    "ref_id": null
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Each cell corresponds to the correlation between the real-world flux between scientific organizations (measured with 2 ) and baseline metrics, shown by subsets of mobility data and by definitions of organization population. The asterisk denotes the top-performing distance metric by column. Distance metrics are ordered from highest 2 to lowest, based on global mobility with organization population defined using all mobile and non-mobile authors. \"All\" means that population is defined as the average yearly number of unique mobile and non-mobile scholars who published with the organizations' affiliation; population is defined in the same way for \"Mobile only\", except only using unique mobile researchers; \"Raw freq\" means that organization populations are defined as their frequency across all the trajectories, similar to word frequency in language embedding. Embedding distance, measured as the cosine distance between embedding vectors, explains more of the flux than baselines in nearly every case, except using raw frequency population and domestic and international mobility, where direct optimization of the gravity model works better, as well as Levy's factorization 34",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "for domestic and international only mobility. Table S4 : Prediction error between actual and predicted mobility with exponential gravity model, by metrics and experimental parameters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 46,
                    "end": 54,
                    "text": "Table S4",
                    "ref_id": null
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Each cell corresponds to the prediction error (measured with root mean squared error) when using each distance as input to the exponential form of the gravity model of mobility to predict the flux between organizations, shown by subsets of mobility data, and by definitions of organization population. The asterisk denotes the top-performing distance metric by column (lowest prediction error). Distance metrics are ordered from lowest prediction error to highest, based on global mobility with organization population defined using all mobile and non-mobile authors. \"All\" means that population is defined as the average yearly number of unique mobile and non-mobile scholars who published with the organizations' affiliation; population is defined in the same way for \"Mobile only\", except only using unique mobile researchers; \"Raw freq\" means that organization populations are defined as their frequency across all the trajectories, similar to word frequency in language embedding. Embedding distance, measured as the cosine distance between embedding vectors, results in better predictions of mobility than baselines in nearly every case, however Levy's 's factorization 34",
            "cite_spans": [],
            "ref_spans": [],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "perform better in the case of international and domestic only mobility when using raw frequency populations. Table S5 : Prediction error between actual and predicted mobility with power-law gravity model, by metrics and experimental parameters.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 109,
                    "end": 117,
                    "text": "Table S5",
                    "ref_id": null
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Each cell corresponds to the prediction error (measured with root mean squared error) when using each distance as input to the power-law form of the gravity model of mobility to predict the flux between organizations, shown by subsets of mobility data, and by definitions of organization population. The asterisk denotes the top-performing distance metric by column (lowest prediction error). Distance metrics are ordered from lowest prediction error to highest, based on global mobility with organization population defined using all mobile and non-mobile authors. \"All\" means that population is defined as the average yearly number of unique mobile and non-mobile scholars who published with the organizations' affiliation; population is defined in the same way for \"Mobile only\", except only using unique mobile researchers; \"Raw freq\" means that organization populations are defined as their frequency across all the trajectories, similar to word frequency in language embedding. Embedding distance, measured as the cosine distance between embedding vectors, results in better predictions for global mobility with \"All'; and \"Mobile only\" definitions of population, though direvt gravitylaw opimization with MDS performs better when using raw frequencies to measure organization population, and Levy's factorization 34 perform better here with domestic and international only mobility. Figure S5 : Neural embeddings outperform baselines for scientific mobility. Cosine distance between embedding vectors generated with word2vec explains more of the flux, and better predicts flux when used in the gravity model of mobility than geographic distance and other baselines. Shown is the correlation between the flux and embedding distances, measured with 2 (left), and the prediction error when using the distance as input to the gravity model of mobility. The asterisk denotes the top-performing metric.",
            "cite_spans": [
                {
                    "start": 1320,
                    "end": 1322,
                    "text": "34",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [
                {
                    "start": 1390,
                    "end": 1399,
                    "text": "Figure S5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "For prediction error, we show results based on both the exponential and power-law forms of the gravity model. All embedding-based methods use dimensions of 300. Here, embedding distance is obtained from neural embeddings learned with window size of 1 and = 1. In all cases, organization population is defined as the mean annualized number of unique mobile and non-mobile authors, and flux is calculated for all global mobility. Baselines include the top-performing distance metrics calculated between vectors obtained by personalized-page rank (PPR), singular value decomposition (SVD), laplacian eigenmap, direct-factorization following Levy's approach, 34 and direct optimization of the gravity model using SVD and multidimensional scaling (MDS), as well as the geographic distance between organizations. Embedding distance better explains and predicts flux than any other baseline, though there is some variation by experimental parameters (Table S3, Table S4, and Table S5 ). Figure S6 : Cosine distance is correlated with dot product similarity. We find a relatively high correlation between the embedding distance-one minus the cosine similarity-and the dot product similarity between organization vectors ( 2 = 0.73). Color of each hex bin indicates the frequency of organization pairs. The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001). Figure S8 : For embedding distance, the exponential-decay gravity model is slightly better. Flux between organization pairs predicted by the gravity model with different distance decay functions, i.e., exponential decay function (a) and power-law decay function (b) using embedding distance. Boxplots show the distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps with = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Shown for all pairs of organization (a-b), domestic (c-d), and international only (e-f) mobility. The gravity model with the exponential decay function slightly outperforms that with a power-decay function except in the case of international-only mobility, for which power-decay performs slightly better. Figure S9 : Embedding distance explains more variance for global, within, and across country flux than geographic distance. a. Embedding distance explains more flux than geographic distance (b). The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001 across all fits). Color of each hex bin indicates frequency of organization pairs. Results here are identical to those shown in Fig. 2 . c-d. embedding distance explains more variance when considering only within-country organization pairs. e-f. embedding distance is more robust than geographic distance when considering only across-country organization pairs. Figure S10 : Examine gravity model with dot product on the embedding space. Performance of dot product similarities in explaining and predicting mobility. Similarity scores are calculated as the pairwise dot product between organizational vectors. Dot product similarity performs better than geographic distance, though worse than cosine similarity in explaining global mobility (a), or domestic (b) or international (c) country mobility. The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001 across all fits). Color indicates frequency of organization pairs within each hex bin. Similarly, PPR distance performs comparably to geographic distance in predicting global (d), domestic (e) and international (f) scientific mobility. Boxplots show distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Figure S11 : Personalized page rank with cosine distance. Performance of personalized page rank scores in explaining and predicting mobility. Personalized page rank is calculated for the underlying mobility network, and distance measured as the cosine distance between PPR probability distribution vectors. PPR cosine distance performs roughly similar to geographic distance in explaining global(a), domestic (b), or international (c) country mobility. The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001 across all fits). Color of hex bind indicates frequency of organization pairs. Similarly, PPR distance performs comparably to geographic distance in predicting global (d), domestic (e) and international (f) scientific mobility. Boxplots show distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Performance of personalized page rank scores in explaining and predicting mobility. Personalized page rank is calculated for the underlying mobility network, and distance measured as the Jensen-Shannon Divergence (JSD) between PPR probability distribution vectors. PPR JSD performs roughly similar to geographic distance in explaining global mobility (a), or domestic (b) or international (c) country mobility. Overall, PPR JSD explains more variance in mobility than using cosine distance (Fig. S11) , except for international mobility, for which cosine similarity out-performs JSD. The red line is the line of the best fit. Black dots are mean flux across binned distances. 99% confidence intervals are plotted for the mean flux in each bin based on a normal distribution. Correlation is calculated on the data in the log-log scale ( < 0.0001 across all fits). Color of hex bind indicates frequency of organization pairs. Similarly, PPR JSD performs comparably to geographic distance in predicting global (d), domestic (e) and international (f) scientific mobility. Boxplots show distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Figure S13 : Visualization of global mobility network. The network demonstrates country-level structure, but not at the detail or the extent of the global UMAP projection (Fig. 3a) . Each node corresponds to an organization, whereas weighted edges (not shown) correspond to the flow of mobile researchers between the two organization. Nodes are colored by the country of the organization. Nodes are positioned using the Force Atlas layout algorithm. Table S1 . Figure S22 : SemAxis reconstructs publication impact in non-university sectors. Comparison between the ranking of organizations in each non-university sector by their citation impact and the embedding rank. Citation impact is calculated as the mean-normalized citation score using papers published in the Web of Science database between 2008 and 2019. The embedding rank is derived by first projecting non-university organizations onto the SemAxis axis formed with poles defined using the top five to geographically-matched bottom five universities ranked by the 2018 Times Higher Education ranking of U.S. Universities. a Shows how the correlation between the citation impact and SemAxis rankings differ while varying the size threshold for including an organization. Size is calculated as the mean annualized number of unique authors publishing with that organization. Annotations show the number of organizations remaining at thresholds of 0, 50, and 100. b. Comparison of organizations using a size threshold of 10 for regional and liberal arts colleges, and 50 for research institutes and government organizations; these thresholds were chosen as points thresholds of stability in a. The impact rank is correlated with the embedding rank for regional and liberal arts colleges with Spearman's ",
            "cite_spans": [
                {
                    "start": 655,
                    "end": 657,
                    "text": "34",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [
                {
                    "start": 943,
                    "end": 976,
                    "text": "(Table S3, Table S4, and Table S5",
                    "ref_id": null
                },
                {
                    "start": 980,
                    "end": 989,
                    "text": "Figure S6",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 1557,
                    "end": 1566,
                    "text": "Figure S8",
                    "ref_id": null
                },
                {
                    "start": 2454,
                    "end": 2463,
                    "text": "Figure S9",
                    "ref_id": null
                },
                {
                    "start": 3038,
                    "end": 3044,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 3272,
                    "end": 3282,
                    "text": "Figure S10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 4499,
                    "end": 4509,
                    "text": "Figure S11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 6222,
                    "end": 6232,
                    "text": "(Fig. S11)",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 7091,
                    "end": 7101,
                    "text": "Figure S13",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 7262,
                    "end": 7271,
                    "text": "(Fig. 3a)",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 7541,
                    "end": 7549,
                    "text": "Table S1",
                    "ref_id": null
                },
                {
                    "start": 7552,
                    "end": 7562,
                    "text": "Figure S22",
                    "ref_id": null
                }
            ],
            "section": "S11 Text Author name disambiguation."
        },
        {
            "text": "Proportion Figure S25 : Distribution of organization embedding vector norms by country. Histogram showing the distribution of L2 norm values of organization embedding vectors in each of the 30 countries with the largest number of total unique mobile and non-mobile researchers. Text in each panel shows the number of organizations in the country (n) and the GINI index of inequality of the distribution (g); a small GINI index indicates that the L2 norms of organizations are more balanced, whereas a high GINI value indicates that they are more unequal.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 11,
                    "end": 21,
                    "text": "Figure S25",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "L2 Norm of Organization Vectors by Country"
        }
    ],
    "bib_entries": {
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Global Flow of Tertiary-Level Students",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "The Global Competition for Talent: Mobility of the Highly Skilled",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Box",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Barsi",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "presented at the Proceedings of the 26th International Conference on Neural Information Processing Systems",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mikolov",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Corrado",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dean",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "3111--3119",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "presented at the Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "L"
                    ],
                    "last": "Hamilton",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Leskovec",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Jurafsky",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "1",
            "issn": "",
            "pages": "1489--1501",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "presented at the Proceedings of the Eleventh International AAAI Conference on Web and Social Media",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Nakandala",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "L"
                    ],
                    "last": "Ciampaglia",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Su",
                    "suffix": ""
                },
                {
                    "first": "Y.-Y",
                    "middle": [],
                    "last": "Ahn",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "presented at the Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Grover",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Leskovec",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "855--864",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "presented at the Proceedings of the AAAI Conference on Artificial Intelligence",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Cong",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "An",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "Chee",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "31",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "presented at the Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xiong",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "presented at the Proceedings of the 26th conference on user Modeling, adaptation and personalization",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Solomon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bar",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Yanai",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shapira",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Rokach",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "331--339",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "presented at the Advances in Neural Information Processing Systems 27",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Levy",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Goldberg",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2177--2185",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "presented at the Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "An",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Kwak",
                    "suffix": ""
                },
                {
                    "first": "Y.-Y",
                    "middle": [],
                    "last": "Ahn",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2450--2461",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "presented at the Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gutmann",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hyv\u00e4rinen",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "297--304",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Notes on Noise Contrastive Estimation and Negative Sampling",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Dyer",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1410.8251(cs.LG"
                ]
            }
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "presented at the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Devlin",
                    "suffix": ""
                },
                {
                    "first": "M.-W",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Toutanova",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "1",
            "issn": "",
            "pages": "4171--4186",
            "other_ids": {}
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "presented at the Proceedings of the 14th Science and Technology Indicators Conference",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Caron",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "J"
                    ],
                    "last": "Van Eck",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "79--86",
            "other_ids": {}
        },
        "BIBREF58": {
            "ref_id": "b58",
            "title": "Entropy in urban and regional modelling (Routledge, 2011)",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wilson",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "The Diffusion of Scientific Knowledge Across Time and Space: Evidence from Professional Transitions for the Superstars of Medicine",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Azoulay",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S G"
                    ],
                    "last": "Zivin",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "N"
                    ],
                    "last": "Sampat",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF64": {
            "ref_id": "b64",
            "title": "FASEB journal: official publication of the Federation of American Societies for",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P A"
                    ],
                    "last": "Ioannidis",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Experimental Biology",
            "volume": "18",
            "issn": "",
            "pages": "936--939",
            "other_ids": {}
        },
        "BIBREF67": {
            "ref_id": "b67",
            "title": "Measuring Innovation: A New Perspective",
            "authors": [],
            "year": 2010,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF77": {
            "ref_id": "b77",
            "title": "presented at the Proceedings of the 12th international conference on World Wide Web",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Jeh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Widom",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "271--279",
            "other_ids": {}
        },
        "BIBREF78": {
            "ref_id": "b78",
            "title": "presented at the Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Qiu",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF79": {
            "ref_id": "b79",
            "title": "IEEE transactions on information theory",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Caramanis",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sanghavi",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "58",
            "issn": "",
            "pages": "3047--3064",
            "other_ids": {}
        },
        "BIBREF84": {
            "ref_id": "b84",
            "title": "presented at the International Conference on Machine Learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bassily",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Belkin",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "3325--3334",
            "other_ids": {}
        },
        "BIBREF85": {
            "ref_id": "b85",
            "title": "the International Conference on Machine Learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Smith",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Elsen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "De",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "9058--9067",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Construction of affiliation trajectories from publication records. a. An author published five papers across five time periods, with only one affiliation listed in the byline of each paper. A unique identifier is assigned to each organization and they are assembled into an affiliation trajectory ordered by year of publication. b. If an author lists multiple organization affiliations within the same year, then organization IDs within that year are placed in random order in each training iteration of the word2vec model (for more detail, see Supporting Information).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Supporting Information for the full derivation).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "tals vs. universities), and university systems (University of Massachusetts system vs. Harvard & MIT). For example, even though UMass Boston is located in Boston, it clusters with other universities in the UMass System ( = 0.29) rather than the other typically more highly-ranked and research-focused organizations in Boston ( = 0.39), implying a relative lack of mobility between the two systems. Similar structures can be observed in other states such as among New York's CUNY and SUNY systems (Fig. S14), Pennsylvania's state system (Fig. S15), Texas's Agricultural and Mechanical universities (Fig. S16), and between the University of California and State University of California systems (Fig. S17).Just as the embedding space makes it possible to zoom in on subsets of organizations, it is also possible to zoom out by aggregating organizational vectors. In doing so, we can examine the country-level structure that governs scientific mobility. We define the representative vector of each country as the average of their organizational vectors and, using their cosine similarities, perform hierarchical clustering of nations that have at least 25 organizations represented in the embedding space (seeFig. 4a). The six identified clusters roughly correspond to countries in Asia and North America (orange), Northern Europe (dark blue), the British Commonwealth and Iran (purple), Central and Eastern Europe (light blue), South America and Iberia (dark green),",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Projection of embedding space reveals complex multi-scale structure of organizations. a. UMAP projection 47 of the embedding space reveals country-level clustering. Each point corresponds to an organization and its size indicates the average annual number of mobile and non-mobile authors affiliated with that organization from 2008 to 2019. Color indicates the region. The separation of organizations in Quebec and the rest of Canada is highlighted. b. Zooming into (re-projecting) the area containing countries in Western, South, and Southeast Asia shows a geographic and cultural gradient of country clusters. c. Similarly, zooming into the area containing organizations in Spain, Portugal, South, and Central America shows clustering by most widely-spoken majority language group: Spanish and Portuguese. d. Doing the same for organizations in the United States reveals geographic clustering based on state, roughly grouped by Census Bureau-designated regions, e. Zooming in further on Massachusetts reveals clustering based on urban center (Boston, Worcester), organizational sector (hospitals vs. universities), and university systems and prestige (UMass system vs. Harvard, MIT, etc.).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Embedding captures latent geography and prestige hierarchy. a. Comparison between the ranking of organizations in the Times ranking and the embedding ranking derived using SemAxis.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Size of organization embedding vectors captures prestige and size of organizations. a.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Center for Science and Technology Studies at Leiden University. Trajectories are constructed from author affiliations listed on the byline of publications for an author. Given the limitations of author-name disambiguation, we limit our analyses to papers published after 2008, when the Web of Science began providing full names and institutional affiliations 57 that improved disambiguation (see Supporting Information). This yields 33,934,672 author-affiliation combinations representing 12,963,792 authors. Each author-affiliation combination is associated with the publication year and an ID linking it to one of 8,661 disambiguated organizational affiliations (see Supporting Information for more detail). Trajectories are represented as the list of author-affiliation combinations, ordered by year of publication, and randomly ordered for combinations within the same year. The most fine-grained geographic unit in this data is the organization, such as a university, research institute, business, or government agency. Here, authors are classified as mobile when they have at least two distinct organization IDs in their trajectory, meaning that they have published using two or more distinct affiliations between 2008 and 2019. Under this definition, mobile authors constitute 3,007,192 or 23.2% of all authors and 17,700,095 author-affiliation combinations. Mobile authors were associated with 2.5 distinct organizational affiliations on average. Rates of mobility differ across countries.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "tions to occur in similar contexts. Suppose a trajectory, denoted by ( 1 , 2 , . . . , ), where is the th location in the trajectory. A location, , is considered to have context locations, \u2212 , . . . , \u22121 , +1 , . . . , + , that appear in the window surrounding up to a time lag of , where is the window size parameter truncated at \u2212 \u2265 0 and + \u2264 . Then, the model learns probability ( + | ), where \u2212 \u2264 \u2264 and \u2260 0, by maximizing its log likelihood given by",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "booked with each accommodation for Korean accommodation reservations, and the yearlyaverage count of unique authors, both mobile and non-mobile, affiliated with each organization for scientific mobility. ( ) is a decay function of distance between locations and . Here, we used the most basic gravity model which assumes symmetry of the flow\u02c6=\u02c6and distance = , while there are four proposed variants. 59 There are two popular forms for the ( ): one is a power law function in the form ( ) = \u2212 ( > 0), and the other is an exponential function in the form ( ) = \u2212 ( > 0).41 The parameters for ( ) and are 29 fit to given mobility data using a log-linear regression.4,[36][37][38][39]",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "or zero movement between locations. In our dataset, non-zero flows account for only 4.2 % of all possible pairs of the 6,580 organizations for scientific mobility, while 76.4% of all possible pairs of the 744 airports for U.S. airport Itinerary and 62.5 % of all possible pairs of the 1,004",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "the set of positive and negative pole organization vectors respectively. Then, the average vectors of each set can be calculated as+ = 1 =1 + and \u2212 = 1 =1\u2212 . From these average vectors of each set of poles, the semantic axis is defined as axis = + \u2212 \u2212 . Then, a score of organization is calculated as the cosine similarity of the organization's vector with the axis,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "The poles of the geographic axis are defined as the mean vector of all vectors corresponding to organizations in California, and then the mean of all vectors of organizations in Massachusetts. For the prestige axis, we define a subset of top-ranked universities according to either the Times World University Ranking or based on the mean normalized research impact sourced from the Leiden Ranking. The other end of the prestige axis is the geographically-matched (according to census region) set of universities ranked at the bottom of these rankings. For example, if 20 top-ranked universities are selected and six of them are in the Northeastern U.S., then the bottom twenty will be chosen to also include six from the Northeastern U.S. From the prestige axis, we derive a ranking of universities that we then compare to other formal university rankings using Spearman rank correlation. Flammini, Filippo Menczer, Lili Miao, Xiaoran Yan, Inho Hong, and Esteban Moro Egido. This material is based upon work supported by the Air Force Office of Scientific Research under award number FA9550-19-1-0391. Rodrigo Costas is partially funded by the South African DST-NRF Centre of Excellence in Scientometrics and Science, Technology and Innovation Policy (SciSTIP).Author ContributionsAll authors contributed extensively to the work presented in this paper. D. M. and J.Y. were involved in all stages of conceptualization, analysis, and writing, S.K. developed the theoretical framework, R.C. assembled input data, and W.J., S.M., and Y.A. contributed to conceptualization. All authors discussed the results and commented on the manuscript at all stages.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": ",17 which affects the diffusion of ideas across academia.15 By placing researchers in new social settings, mobility can lead to the formation of new collaborative relationships, 14 which in turn spurs the further diffusion of knowledge and innovations.10,11,60,61 Perhaps resulting from the selection effects of who gets to move, or the reconfiguring of social and epistemic networks, movement is associated with increased scientific impact.12,13,62,63 At the national level, the understanding of mobility has progressed beyond simplistic narratives of brain drain and brain gain, and instead adopts a new perspective of flows of talent.[64][65][66] Under this flow model, a mobile researcher is viewed as contributing to both their origin and destination countries, a perspective that fosters that is evidenced by the strong science of open countries.67 Perhaps because of these individual and national benefits, policy-makers have come to recognize the importance of global mobility. 9,68 Movement is a key mechanism that has clear impacts on the composition and direction of the global scientific workforce and our collective scientific understanding. Understanding the structure and dynamics of mobility is thus essential for understanding global science.S2 Text Modeling scientific mobility.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "iation trajectory based on the affiliations listed on their published papers indexed in the Web of Science database between 2008 and 2019. An author is considered mobile if they published with at least two distinct affiliations during the time period of study. Affiliation names were manually disambiguated, and each was mapped to a unique organization identifier. An affiliation trajectory for an individual researcher is a sequence of organizations in ascending order of year of publication. If a researcher published papers with affiliation in year , in + 1, in + 2 and again in + 3, then the affiliation trajectory is expressed as ( , , , ). In the case that an individual lists multiple affiliations in a single year, affiliations listed on publications published in that year are shuffled between each iteration of the word2vec training process (each epoch). For example, an author who published with affiliation in 0 , and affiliations and in 1 could appear as one of ( , , ) or ( , , ) in each training iteration.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": ", we create an embedding by optimizing for the gravity law directly. Specifically, we construct a gravity matrix of organizations, where each cell of the matrix is calculated as /, where is co-occurrence of organizations and in the same affiliation trajectory, and and are the organizations' populations, defined here as the mean annual member of unique mobile and non-mobile authors affiliated.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "and eigencentrality centrality (Spearman's = 0.76, Fig. S19b). However, while both embedding-and network-based measures relate to university prestige, they are qualitatively and quantitatively different. The embedding-ranking of U.S. universities is less correlated with degree strength (Spearman's = 0.45, Fig. S20a) and eigenvector centrality (Spearman's = 0.55) than with the Times ranking itself (Spearman's = 0.73,",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "example, the representative vector of Chinese organizations has a larger norm than that of the U.S. (\u00af= 2.97 vs\u00af= 2.39, Table S2), causing its curve to be shifted upwards with a larger peak vector norm; this may reflect a tendency for organizations in the U.S. to appear more frequently in different contexts than Chinese organizations. Other nations such as Poland, Iran, and Turkey show a linear relationship between an organization's number of researchers and the vector norm, indicating that their largest organizations belong to very specific contexts (Fig. S24). The organization-level distribution of vector norms reveals deeper heterogeneity. The distribution of the vector norms for the U.S. is relatively skewed, suggesting their large norm is driven by a small and tight community of organizations (skew= \u22120.82, Fig. S25). Germany and the U.K. have comparable representative vector norms to the U.S. (\u00af= 2.6 and = 2.61, respectively), with lower skewness (skew= \u22120.63 and skew= \u22120.55), suggesting more tight community of organizations. The vector norms of organizations in some countries are even more skewed, such as in Iran (\u00af= 3.57, skew= \u22122.13) and China (\u00af= 2.97, skew= \u22121.08), indicating the strong difference between their most-and least-connected organizations. For some countries, their organizations are positively-skewed, though seemingly for different reasons. For example, Austria has a balanced distribution of organization vector norms, suggesting a diverse range of organizations with most being well connected (\u00af= 2.64, = 0.18); Russia,in contrast, has a number of organization vectors of moderate norms, but also several isolated organizations with large vector norms (\u00af= 3.08, = 0.67).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "Publications over time. a. The number of papers published by mobile authors has been steadily increasing from 2008 to 2017, with a small decrease in 2018, which may be due to an artifact of the Web of Science indexing process. Lines correspond to publications by mobile authors, by authors with affiliations in at least two cities, at least two regions, and at least two countries. We did not find major changes in the publication patterns of mobile authors during this time period. b. Lines correspond to the proportion of publications classified as Biology and Health (black), Physics and Engineering (purple), Life and Earth Science (magenta), Social Science and Humanities (orange), and Math and Computer Science (yellow). The rate of publication in Biology and Health has leveled since about 2013, whereas the rate of publication in other fields has steadily increased. c. While the absolute count of publications has increased, the percentage of mobile scholars, and those with affiliations in at least least two cities, regions, or countries, as a proportion of all publications, has remained stable over time. d. The proportion of authors' publications across fields has largely remained steady. Biology and Health Science has comprised the majority of publications across nearly all years but has steadily declined in proportion. However, the proportion of Social Science and Humanities publications has been steadily increasing. PC1: (88.3% of variance explained) PC2: (9.5% of variance explained) Extent and nature of mobility by country. a. The proportion of all mobile researchers contributed by each country. Over 30% of all mobile researchers have been affiliated with organizations in the U.S. during the period of study. b. Cumulative distribution of data shown in (a). The U.S., China, and France, the U.K., and Germany comprise about 70% of all mobile researchers. c. The proportion of each country's researchers who are mobile. The dashed line indicates the proportion of all researchers in the data who are mobile. France, followed by Qatar and the U.S. have the highest proportion of mobile researchers. d. First two principal components of four variables: proportion of researchers in each country mobile across organizations, proportion mobile across cities, proportion mobile across regions, and proportion mobile across countries. The countries are roughly sorted in order of the number of mobile researchers and the fraction of international mobile researchers in the first and second principal components, which are indicated by PC1 and PC2, respectively. PC1 explains 88.3% of the total variance, whereas PC2 explains 9.5% of the total variance.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF21": {
            "text": "Reverse cumulative-distribution function of mobile researchers by geographic scale. a. Survival probability of mobile researchers with respect to the number of organizations in the their affiliation trajectory. All mobile authors were affiliated with at least two organizations (i.e., survival probability of one) and about 25.0% were affiliated with three or more. b. About 70% of mobile authors listed at least two cities represented in their career trajectories. c. 50% of mobile authors have two or more regions represented in their career trajectories. d. Only 17% of mobile authors had two or more countries represented in their career trajectories. Larger dimensions, smaller window size improves embedding performance. The correlation, or amount of flux explained by the embedding distance with varying skip-gram negative sampling hyperparameters. Window size refers to , the size of the context window that defines the context in a trajectory. Smaller window sizes result in an embedding that explains more flux. Embedding dimensions refer to the size of the embedding vector. Larger vectors perform better, though with little difference between 200 and 300. Gamma refers to the parameter in word2vec, which shapes the negative sampling distribution. A value of = 0.75 is the default for word2vec. There is virtually no difference in performance based on . All variants perform better on same-country organization pairs, and worse on different-country pairs, than on all pairs of of organizations than on all pairs. Embeddings with larger dimensions outperform mid-size embeddings for the different-country case.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "For geographic distance, the power-decay gravity model is better. Flux between organization pairs predicted by the gravity model with different distance decay functions, i.e., exponential decay function (a) and power-law decay function (b) using geographic distance. Boxplots show distribution of actual flux for binned values of predicted flux. Box color corresponds to the degree to which the distribution overlaps with = ; a perfect prediction yields all points on the black line. \"RMSE\" is the root-mean-squared error between the actual and predicted values. Shown for all pairs of organization (a-b), domestic (c-d), and international only (e-f) mobility. The gravity model with the power-decay function outperforms that with an exponential decay function.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF27": {
            "text": "Personalized page rank with Jensen-Shannon Divergence.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF29": {
            "text": "UMAP Projection of organizations in Pennsylvania. UMAP projection of the embedding space of organizations in Pennsylvania reveals clustering based on geography, sector, and academic prestige. Each point corresponds to an organization and its size indicates the average annual number of mobile and non-mobile authors affiliated with that organization from 2008 to 2019. Color indicates the sector. UMAP Projection of organizations in Texas. Each point corresponds to an organization and its size indicates the average annual number of mobile and non-mobile authors affiliated with that organization from 2008 to 2019. Color indicates the sector.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF30": {
            "text": "SemRank hierarchy is robust. a. Spearman's ( = 143) between Times prestige rank and embedding rank derived using SemAxis, with poles defined using the top and bottom (geographically matched) ranked universities. Black points show spearman correlation using all organizations; white points show correlation using only universalizes not aggregated in the poles. Including more universities improves performance, but quickly saturates after around five universities. b -f. Comparison between the Times and SemAxis ranks of universities, by the number of universities used to define the poles (n). White points are those top and bottom 20 universities aggregated to define the ends of the axis. The grey box corresponds to the top 20 and bottom 20 ranks. Spearman's details the estimate from Spearman correlation between the two rankings using all universities, including those used to define the ends of each axis. All correlations are significant with < 0.0001. Network centrality is strongly correlated with Times ranking. Comparison between the ranking of organizations by their network-centrality rank and their rank in the 2018 Times Higher Education ranking of U.S. Universities . The Times rank is correlated with degree centrality rank (a) with Spearman's = 0.73, and is correlated with the eigenvector centrality rank (b) with Spearman's = 0.76. All correlations are significant with < 0.0001.Geography and prestige SemAxis by U.S. state. SemAxis projection along two axes, comparing California to Massachusetts universities (left to right), and between the top 20 and geographicallymatched bottom 20 universities ranked by the 2018 Times Higher Education ranking of U.S. Universities (bottom to top). Points correspond to universities shown for California (a), Arizona (b), Washington (c), Massachusetts (d), Connecticut (e), New York (f), Texas (g), Pennsylvania (h), and Florida (i). Grey points correspond to all other U.S. universities. Full organization names listed in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF32": {
            "text": "= 0.49 ( = 48), research institutes with Spearman's = 0.58 ( = 159), and for government organizations with Spearman's = 0.36 ( = 55). All correlations are significant with < 0.001. Factors relating to the L2 norm of vectors for U.S. universities Correlation between the L2 norm of organization embedding vectors of U.S. universities and characteristics of U.S. universities. Dots correspond to organizations. The red line is the line of the best fit with corresponding 99% confidence intervals. Red text is the regression estimate. The blue line is the loess regression line with 99% confidence intervals. Number of authors is the average annual count of unique mobile and non-mobile authors. Rankings are derived from the Times Ranking of World Universities, and the Leiden Rankings of Universities. Remaining variables come from the Carnegie Classification of Higher Education Institutions. The factors that best explain are the number of authors, the rank, the amount of Science and Engineering (S&E) funding, and the number of doctorates granted.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Why does word2vec with the skip-gram with negative sampling model (SGNS) work so well to model mobility? The reason for that is the mathematical equivalence between the SGNS model and the gravity model which we demonstrate below.The word2vec model takes a location trajectory, denoted by ( 1 , 2 , . . . , ), as input. A target location = is considered to have a context location = that appears in the previous or subsequent locations in the trajectory, i.e., \u2208 [ \u2212 , . . . , \u22121 , +1 , . . . , + ]. word2vec",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The U.S. airline itinerary dataset can be found at https://www.transtats.bts.gov/ DataIndex.asp. The raw Korean accommodation reservation dataset, due to privacy concerns, cannot be shared publicly. Due to its proprietary nature, the global scientific mobility dataset, sourced from the Web of Science, cannot be provided; however, metadata and trained neural embeddings have been published at https://doi.org/10.6084/m9.figshare.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Penn State Health Milton S. Hershey Medical Center",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "We thank the Center for Science and Technology Studies at Leiden University for managing and making available the dataset of scientific mobility. We also thank the Goodchoice Company LTD. for making available the dataset of Korean accommodation reservation data. For their comments, we thank Guillaume Cabanac, Cassidy R. Sugimoto ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}