{"paper_id": "c9bfbd62086f9369f9e95b77fd9bd8b89b8849fb", "metadata": {"title": "A Deep CNN-LSTM Framework for Fast Video Coding", "authors": [{"first": "Soulef", "middle": [], "last": "Bouaafia", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Monastir", "location": {"settlement": "Monastir", "country": "Tunisia"}}, "email": ""}, {"first": "Randa", "middle": [], "last": "Khemiri", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Monastir", "location": {"settlement": "Monastir", "country": "Tunisia"}}, "email": "randa.khemiri@fsm.rnu.tn"}, {"first": "Fatma", "middle": ["Ezahra"], "last": "Sayadi", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Monastir", "location": {"settlement": "Monastir", "country": "Tunisia"}}, "email": "sayadifatma@yahoo.fr"}, {"first": "Mohamed", "middle": [], "last": "Atri", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of King Khalid", "location": {"settlement": "Abha", "country": "Saudi Arabia"}}, "email": "matri@kku.edu.sa"}, {"first": "Noureddine", "middle": [], "last": "Liouane", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Monastir", "location": {"settlement": "Monastir", "country": "Tunisia"}}, "email": "noureddine.liouane@enim.rnu.tn"}]}, "abstract": [{"text": "High Efficiency Video Coding (HEVC) doubles the compression rates over the previous H.264 standard for the same video quality. To improve the coding efficiency, HEVC adopts the hierarchical quadtree structured Coding Unit (CU). However, the computational complexity significantly increases due to the full search for Rate-Distortion Optimization (RDO) to find the optimal Coding Tree Unit (CTU) partition. Here, this paper proposes a deep learning model to predict the HEVC CU partition at inter-mode, instead of brute-force RDO search. To learn the learning model, a large-scale database for HEVC inter-mode is first built. Second, to predict the CU partition of HEVC, we propose as a model a combination of a Convolutional Neural Network (CNN) and a Long Short-Term Memory (LSTM) network. The simulation results prove that the proposed scheme can achieve a best compromise between complexity reduction and RD performance, compared to existing approaches.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "Over the last decades, we have noticed the success of deep learning in many application areas, where video and image processing has achieved a favorable outcome. The state-of-the-art video coding is High Efficiency Video Coding (HEVC), also known as H.265, which was standardized in 2013 [1] . Compared to its predecessor H.264/AVC standard, HEVC saves an average BitRate reduction of 50%, while maintaining the same video quality [2] . The hierarchical coding structure adopted in HEVC is the quadtree, including Coding Unit (CU), Prediction Unit (PU), and Transform Unit (TU) [3] . In this regard, the Coding Tree Unit (CTU) is the basic coding structure in which the size of the CTU is 64 \u00d7 64. A CTU can be divided into multiple CUs of different sizes from 64 \u00d7 64 with a depth of 0 to 8 \u00d7 8 with a depth of 3.", "cite_spans": [{"start": 288, "end": 291, "text": "[1]", "ref_id": "BIBREF0"}, {"start": 431, "end": 434, "text": "[2]", "ref_id": "BIBREF1"}, {"start": 578, "end": 581, "text": "[3]", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Introduction"}, {"text": "This exhaustive splitting continues until the minimum possible size of a CU is reached in order to find the optimal CU depth. This process is known as Rate-Distortion Optimization (RDO) which is required for each CTU. Due to the full RDO search, the HEVC computational complexity has considerably increased, making encoding speed a crucial problem in the implementation of HEVC. Accordingly, to enhance the coding efficiency of HEVC, fast algorithms have been proposed for reducing the HEVC complexity caused by the quadtree partition. These fast methods can be summarized into two categories: heuristic and learning-based schemes.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "In heuristic methods, some fast CU decision algorithms have been developed to simplify the RDO process towards reducing HEVC complexity. For example, Cho et al. [4] developed a Bayesian decision rule with low complexity and full RD cost-based fast CU splitting and pruning algorithm. With regard to HEVC inter prediction, Shen et al. in [5] proposed a fast inter-mode decision scheme using inter-level and spatio-temporal correlations in which the prediction mode, motion vector and RD cost were found strongly correlated. To reduce the HEVC complexity, a look-ahead stage based fast CU partitioning and mode decision algorithm was proposed in [6] . Based on pyramid motion divergence, authors in [7] introduced a fast algorithm to split CUs at the HEVC inter coding.", "cite_spans": [{"start": 161, "end": 164, "text": "[4]", "ref_id": "BIBREF3"}, {"start": 337, "end": 340, "text": "[5]", "ref_id": "BIBREF4"}, {"start": 644, "end": 647, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 697, "end": 700, "text": "[7]", "ref_id": "BIBREF6"}], "ref_spans": [], "section": "Introduction"}, {"text": "On the other hand, the search of the optimal mode decision can be modeled as a classification problems. In this regard, researchers adopted learningbased methods in classifying CU mode decision in order to reduce the computational complexity. Shen et al. [8] proposed a CU early termination algorithm for each level of the quadtree CU partition based on weighted SVM. In addition, a fuzzy SVM-based fast CU decision method was proposed by Zhu et al. in [9] to improve the coding efficiency. To reduce the HEVC complexity with deep structure, in [10] , authors developed a fast CU depth decision in HEVC using neural networks to predict split or non-split for inter and intra-mode. Reinforcement Learning (RL) and deep RL are also applied in video coding to learn a classification task, and to find the optimal CU mode decision. In this study, an end-to-end actor-critic RL based CU early termination algorithm for HEVC was developed to improve the coding complexity [11] .", "cite_spans": [{"start": 255, "end": 258, "text": "[8]", "ref_id": "BIBREF7"}, {"start": 453, "end": 456, "text": "[9]", "ref_id": "BIBREF8"}, {"start": 545, "end": 549, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 966, "end": 970, "text": "[11]", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "Introduction"}, {"text": "For video coding, the adjacent video frames exhibit similarity in video content, in which the similarity decreases along with temporal distance between two frames. Figure 1 shows the temporal correlation of CTU partition across HEVC video frames. In HEVC inter-mode, there are long and short-term dependencies of the CU partition across neighboring frames. It is in this context that we propose in this paper Long Short-Term Memory (LSTM) networks to study the temporal dependency of the CU partition across adjacent frames.", "cite_spans": [], "ref_spans": [{"start": 164, "end": 172, "text": "Figure 1", "ref_id": "FIGREF0"}], "section": "Introduction"}, {"text": "Based on our previous work presented in [12] , our deep CNN structure has been proposed to predict the CU splitting in order to reduce the coding performance of inter-mode HEVC. A large-scale training database was established in [12] . Therefore, to predict the inter-mode CU partition, this paper proposes a CNN-LSTM-based learning approach where the aim is to reduce the HEVC complexity in terms of RD performance and encoding time. The paper is organized as follows: Sect. 2 introduces the proposed method, which reduces the HEVC complexity at inter prediction. The evaluation results are shown in Sect. 3. Section 4 concludes this paper.", "cite_spans": [{"start": 40, "end": 44, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 229, "end": 233, "text": "[12]", "ref_id": "BIBREF11"}], "ref_spans": [], "section": "Introduction"}, {"text": "A large-scale database for CU partition of the inter-mode HEVC was established, to train the proposed model, as shown in [12] . However, to construct the database, we selected 114 video sequences with various resolutions (from 352 \u00d7 240 to 2560 \u00d7 1600) [15, 16] . These sequences are divided into three subsets: 86 sequences for training, 10 sequences for validation, and 18 sequences for test. All sequences in our database were encoded by HEVC reference software using the Low Delay P (LDP) (using encoder lowdelay P main.cfg) at four Quantization Parameters (QP) {22, 27, 32, 37}. Therefore, corresponding to different QPs and CU sizes (64 \u00d7 64, 32 \u00d7 32, and 16 \u00d7 16), 12 sub-databases were obtained under LDP configuration.", "cite_spans": [{"start": 121, "end": 125, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 253, "end": 257, "text": "[15,", "ref_id": "BIBREF14"}, {"start": 258, "end": 261, "text": "16]", "ref_id": "BIBREF15"}], "ref_spans": [], "section": "Database for Inter-mode"}, {"text": "According to the temporal correlation of the CU partition of adjacent frames, the proposed scheme is introduced in this section. The proposed LSTM network learns the long and short-term dependencies of the CU partition across frames. In our previous proposed method [12] , all parameters of Deep CNN are trained over the residual CTU and the ground-truth splitting of the CTUs, then the extracted features (F C 1\u2212l ) 3 l=1 of Deep CNN are the input of LSTM network at frame t. These features (F C 1\u2212l ) 3 l=1 are extracted at the first fully connected layer of Deep CNN [12] . The proposed algorithm that combines CNN and LSTM is shown in Fig. 2 . The structure of the LSTM is composed of three LSTM cells corresponding to three levels splitting of each CU. Specifically,F 1 (CU, t) at level 1 indicates whether the CU of size 64 \u00d7 64 is split to sub-CUs of size 32 \u00d7 32. At level 2,", "cite_spans": [{"start": 266, "end": 270, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 570, "end": 574, "text": "[12]", "ref_id": "BIBREF11"}], "ref_spans": [{"start": 639, "end": 645, "text": "Fig. 2", "ref_id": "FIGREF1"}], "section": "CNN-LSTM Network"}, {"text": "i=0 determines the splitting of CUs from 32 \u00d7 32 to 16 \u00d7 16 and {F 3 (CU i,j , t)} 3 i,j=0 denotes the partitioning labels of CUs from 16 \u00d7 16 to 8 \u00d7 8. At each level, the LSTM cells are followed by a fully connected layer. In addition, the output features of the LSTM cells denote by (F C l ) 3 l=1 at frame t. However, the next level LSTM cell is activated to make decisions on the next four CUs at the next level, when the CU of the current level is predicted to be split. Otherwise, the prediction on splitting the current CU is terminated early. Finally, the predicted CU partition of three levels is represented by the combination of", "cite_spans": [{"start": 83, "end": 84, "text": "3", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "CNN-LSTM Network"}, {"text": ". The LSTM model learns the long short-term dependency of CTU partition across frames when the CTU partition is predicted. In fact, the LSTM cell consists of three gates: the input gate i l (t), the forget gate f l (t) and the output gate o l (t). In particular, F C 1\u2212l (t) denotes the input features of the LSTM cell at frame t and F C l (t \u2212 1) is the output features of the LSTM cell of frame t-1 at level l. In the following, these three gates are presented by:", "cite_spans": [], "ref_spans": [], "section": "CNN-LSTM Network"}, {"text": "where the sigmoid function denotes by \u03c3(\u00b7). {W i , W o , W f } are the weights and {b i , b o , b f } are the biases for three gates. At frame t, the state c l (t) of the LSTM cell can be updated by:", "cite_spans": [], "ref_spans": [], "section": "CNN-LSTM Network"}, {"text": "where signifies the element-wise multiplication. The output of the LSTM cell F C l (t) can be determined as follows:", "cite_spans": [], "ref_spans": [], "section": "CNN-LSTM Network"}, {"text": "In the training phase, the LSTM model was trained from the training set of the inter database, which minimizes the loss function between the ground truth and the prediction of CTU partition. Here, the cross entropy is adopted as the loss function. Then, the Stochastic Gradient Descent algorithm with momentum (SGD) is used as a powerful optimization algorithm to update the network weights at each iteration and minimize the loss function.", "cite_spans": [], "ref_spans": [], "section": "CNN-LSTM Network"}, {"text": "This section introduces the experimental results to evaluate the encoding performance of our proposed approach. Our experiments were integrated in HEVC reference test model HM, which were tested on JCT-VC video sequences from Class A to Class E at two QPs {22, 37} using the LDP configuration. In order to validate the performance of the proposed scheme, all simulations were carried out on windows 10 OS platform with Intel R core TM i7-3770 @ 3.4 GHz CPU and 16 GB RAM. We also use the NVIDIA GeForce GTX 480 GPU to dramatically improve speed during the training phase of the network model.", "cite_spans": [], "ref_spans": [], "section": "Experimental Results"}, {"text": "The Tensorflow-GPU deep learning framework was used in the training process. We first adopt a batch mode learning method with a batch size of 64 where the momentum of the stochastic gradient descent algorithm optimization is set to 0.9. Second, the learning rate was set to 0.01, changing every 2,000 iterations to train the LSTM model. Then, the LSTM length was set to T = 20. Finally, the trained model can be used to predict the inter-mode CU partition for HEVC.", "cite_spans": [], "ref_spans": [], "section": "Experimental Results"}, {"text": "For the test, to further enhance the RD performance and the complexity reduction at inter-mode, the bi-threshold decision scheme was adopted at three levels. Note that the upper and lower thresholds at level l represents by {\u03b3 l } 3 l=1 and {\u03b3 l } 3 l=1 . The predicted CU partition probability is output by the LSTM model at different levels (P l (CU )). Therefore, the CU decides to be split when P l (CU ) > \u03b3 l ; if P l (CU ) < \u03b3 l , the CU is not split. In this way, this considerably reduces the HEVC complexity by skipping the most redundant checking of RD cost.", "cite_spans": [], "ref_spans": [], "section": "Experimental Results"}, {"text": "The RD performance analysis is performed on the basis of the average PSNR ( P SNR) gain and the average BitRate ( BitRate) reduction. Additionally, the complexity reduction is the critical metric for the performance evaluation at HEVC inter-mode. Let T the encoding time reduction. All performance metrics are written as: Table 1 demonstrates the performance comparison of the proposed scheme and three other state-of-the-arts schemes.", "cite_spans": [], "ref_spans": [{"start": 322, "end": 329, "text": "Table 1", "ref_id": "TABREF0"}], "section": "Experimental Results"}, {"text": "From this table, we can conclude that the proposed scheme is better in terms of computational complexity reduction than other state-of-the-arts schemes. Specifically, the time saving of our approach is 60.43% on average, which exceeds the 55.26% obtained by [12] , the 44.64% achieved by [13] , and 54.70% of [14] , respectively. On the other hand, the proposed approach can reduce the PSNR performance by \u22120.046 dB, which is better than \u22120.085 dB of [12] , \u22120.092 dB of [13] and \u22120.048 of [14] . Furthermore, the approaches [12] achieve better value of BitRate 0.350% than ours. Meanwhile, the proposed approach outperforms the existing approaches [13, 14] in terms of BitRate by 0.797%.", "cite_spans": [{"start": 258, "end": 262, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 288, "end": 292, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 309, "end": 313, "text": "[14]", "ref_id": "BIBREF13"}, {"start": 451, "end": 455, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 471, "end": 475, "text": "[13]", "ref_id": "BIBREF12"}, {"start": 490, "end": 494, "text": "[14]", "ref_id": "BIBREF13"}, {"start": 525, "end": 529, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 649, "end": 653, "text": "[13,", "ref_id": "BIBREF12"}, {"start": 654, "end": 657, "text": "14]", "ref_id": "BIBREF13"}], "ref_spans": [], "section": "Experimental Results"}, {"text": "As shown in this table, the proposed approach can reduce the complexity reduction by 70.85% for class E video sequences, since these sequences have low motion activities and homogeneous regions, where the blocks CU partition is larger. From the overall performance assessment, our proposed fast scheme provides competitive HEVC coding efficiency tradeoffs compared to state-ofthe-art approaches. Figure 3 shows the comparison between the CU partition predicted by the proposed deep learning model and the ground truth partition when QP equals 37 under the LDP configuration.", "cite_spans": [], "ref_spans": [{"start": 396, "end": 404, "text": "Figure 3", "ref_id": "FIGREF2"}], "section": "Experimental Results"}, {"text": "This paper proposed a deep learning approach to predict the CU partition, which combines the CNN-LSTM network to reduce inter-mode HEVC complexity. To train the proposed model, the inter database was built. According to the temporal correlation of the CU partition of neighboring frames, we developed a new LSTM architecture to learn the long and short-term dependencies of the CU partition across frames, instead of brute-force RDO search. In summary, the proposed scheme saves a significant encoding complexity compared to other state-of-the-art works.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Overview of the high efficiency video coding", "authors": [{"first": "G", "middle": ["J"], "last": "Sullivan", "suffix": ""}, {"first": "J", "middle": ["R"], "last": "Ohm", "suffix": ""}, {"first": "W", "middle": ["J"], "last": "Han", "suffix": ""}, {"first": "T", "middle": [], "last": "Wiegand", "suffix": ""}], "year": 2012, "venue": "IEEE Trans. Circuits Syst. Video Technol", "volume": "22", "issn": "", "pages": "1649--1668", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Optimisation of HEVC motion estimation exploiting SAD and SSD GPU-based implementation", "authors": [{"first": "R", "middle": [], "last": "Khemiri", "suffix": ""}, {"first": "H", "middle": [], "last": "Kibeya", "suffix": ""}, {"first": "F", "middle": ["E"], "last": "Sayadi", "suffix": ""}, {"first": "N", "middle": [], "last": "Bahri", "suffix": ""}, {"first": "M", "middle": [], "last": "Atri", "suffix": ""}, {"first": "N", "middle": [], "last": "Masmoudi", "suffix": ""}], "year": 2017, "venue": "IET Image Process", "volume": "12", "issn": "2", "pages": "243--253", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Fast Motion Estimation's Configuration Using Diamond Pattern and ECU, CFM, and ESD, Modes for Reducing HEVC Computational Complexity", "authors": [{"first": "R", "middle": [], "last": "Khemiri", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "1--17", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Fast CU splitting and pruning for suboptimal CU partitioning in HEVC intra coding", "authors": [{"first": "S", "middle": [], "last": "Cho", "suffix": ""}, {"first": "M", "middle": [], "last": "Kim", "suffix": ""}], "year": 2013, "venue": "IEEE TCSVT", "volume": "23", "issn": "", "pages": "1555--1564", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Adaptive inter-mode decision for HEVC jointly utilizing inter-level and spatio-temporal correlations", "authors": [{"first": "L", "middle": [], "last": "Shen", "suffix": ""}, {"first": "Z", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Liu", "suffix": ""}], "year": 2014, "venue": "IEEE Trans. Circuits Syst. Video Technol", "volume": "24", "issn": "", "pages": "1709--1722", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Adaptive inter CU partitioning based on a look-ahead stage for HEVC", "authors": [{"first": "G", "middle": [], "last": "Cebri\u00e1n-M\u00e1rquez", "suffix": ""}, {"first": "J", "middle": ["L"], "last": "Martinez", "suffix": ""}, {"first": "P", "middle": [], "last": "Cuenca", "suffix": ""}], "year": 2019, "venue": "Sig. Process. Image Commun", "volume": "76", "issn": "", "pages": "97--108", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "A fast HEVC inter CU selection method based on pyramid motion divergence", "authors": [{"first": "J", "middle": [], "last": "Xiong", "suffix": ""}, {"first": "H", "middle": [], "last": "Li", "suffix": ""}, {"first": "Q", "middle": [], "last": "Wu", "suffix": ""}, {"first": "F", "middle": [], "last": "Meng", "suffix": ""}], "year": 2014, "venue": "IEEE Trans. Multimed", "volume": "16", "issn": "", "pages": "559--564", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "CU splitting early termination based on weighted SVM. EURASIP J. Image Video Process", "authors": [{"first": "X", "middle": [], "last": "Shen", "suffix": ""}, {"first": "L", "middle": [], "last": "Yu", "suffix": ""}], "year": 2013, "venue": "", "volume": "4", "issn": "", "pages": "1--11", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Fuzzy SVM based coding unit decision in HEVC", "authors": [{"first": "L", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "Y", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "S", "middle": [], "last": "Kwong", "suffix": ""}, {"first": "X", "middle": [], "last": "Wang", "suffix": ""}, {"first": "T", "middle": [], "last": "Zhao", "suffix": ""}], "year": 2017, "venue": "IEEE Trans. Broadcast", "volume": "64", "issn": "", "pages": "681--694", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "Fast CU depth decision for HEVC using neural networks", "authors": [{"first": "K", "middle": [], "last": "Kim", "suffix": ""}, {"first": "W", "middle": [], "last": "Ro", "suffix": ""}], "year": 2018, "venue": "IEEE Trans. Circuits Syst. Video Technol", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1109/TCSVT.2018.2839113"]}}, "BIBREF10": {"ref_id": "b10", "title": "Reinforcement learning based coding unit early termination algorithm for high efficiency video coding", "authors": [{"first": "N", "middle": [], "last": "Li", "suffix": ""}, {"first": "Y", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "L", "middle": [], "last": "Zhu", "suffix": ""}, {"first": "W", "middle": [], "last": "Luo", "suffix": ""}, {"first": "S", "middle": [], "last": "Kwong", "suffix": ""}], "year": 2019, "venue": "J. Visual Commun. Image R", "volume": "60", "issn": "", "pages": "276--286", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Fast CU partition based machine learning approach for reducing HEVC complexity", "authors": [{"first": "S", "middle": [], "last": "Bouaafia", "suffix": ""}, {"first": "R", "middle": [], "last": "Khemiri", "suffix": ""}, {"first": "F", "middle": ["E"], "last": "Sayadi", "suffix": ""}, {"first": "M", "middle": [], "last": "Atri", "suffix": ""}], "year": 2019, "venue": "J. Real-Time Image Process", "volume": "7", "issn": "", "pages": "185--196", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "CNN based CU partition mode decision algorithm for HEVC inter coding", "authors": [{"first": "Y", "middle": [], "last": "Li", "suffix": ""}, {"first": "Z", "middle": [], "last": "Liu", "suffix": ""}, {"first": "X", "middle": [], "last": "Ji", "suffix": ""}, {"first": "D", "middle": [], "last": "Wang", "suffix": ""}], "year": 2018, "venue": "25th IEEE International Conference on Image Processing (ICIP)", "volume": "", "issn": "", "pages": "993--997", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Reducing complexity of HEVC: a deep learning approach", "authors": [{"first": "M", "middle": [], "last": "Xu", "suffix": ""}, {"first": "T", "middle": [], "last": "Li", "suffix": ""}, {"first": "Z", "middle": [], "last": "Wang", "suffix": ""}, {"first": "X", "middle": [], "last": "Deng", "suffix": ""}, {"first": "R", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Z", "middle": [], "last": "Guan", "suffix": ""}], "year": 2018, "venue": "IEEE Trans. Image Process", "volume": "27", "issn": "10", "pages": "5044--59", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Common test conditions and software reference configurations. Document JCTVC-L1100, Joint Collaborative Team on Video Coding", "authors": [{"first": "F", "middle": [], "last": "Bossen", "suffix": ""}], "year": 2013, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "Xiph.org Video Test Media", "authors": [{"first": "", "middle": [], "last": "Xiph", "suffix": ""}, {"first": "", "middle": [], "last": "Org", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Temporal similarity of CTU partition across HEVC video frames.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Framework of the proposed algorithm.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "CU partition result of BasketballPass with QP = 37. frame = 20. LDP configuration.", "latex": null, "type": "figure"}, "TABREF0": {"text": "Performance comparison between the proposed scheme and the state-of-theart approaches", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Class </td><td>Sequence </td><td>Approaches </td><td>\u0394BR (%) </td><td>\u0394PSNR(dB) </td><td>\u0394T (%)\n</td></tr><tr><td>A </td><td>Traffic </td><td>[12] </td><td>\u22120.458 </td><td>\u22120.059 </td><td>\u221256.66\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[13] </td><td>3.25 </td><td>\u22120.081 </td><td>41.8\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>1.990 </td><td>\u22120.052 </td><td>\u221259.01\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[Proposed Scheme] </td><td>0.376 </td><td>\u22120.101 </td><td>\u221261.27\n</td></tr><tr><td>B </td><td>BasketballDrive </td><td>[12] </td><td>1.335 </td><td>\u22120.031 </td><td>\u221250.43\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[13] </td><td>2.01 </td><td>\u22120.049 </td><td>44.7\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>2.268 </td><td>\u22120.052 </td><td>\u221253.92\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[Proposed Scheme] </td><td>1.528 </td><td>\u22120.022 </td><td>\u221252.05\n</td></tr><tr><td>C </td><td>PartyScene </td><td>[12] </td><td>\u22120.436 </td><td>\u22120.076 </td><td>\u221251.51\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[13] </td><td>3.12 </td><td>\u22120.131 </td><td>41.4\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>1.011 </td><td>\u22120.039 </td><td>\u221248.27\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[Proposed Scheme] </td><td>0.494 </td><td>\u22120.029 </td><td>\u221258.48\n</td></tr><tr><td>D </td><td>BQSquare </td><td>[12] </td><td>\u22122.012 </td><td>\u22120.128 </td><td>\u221253.27\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[13] </td><td>4.15 </td><td>\u22120.149 </td><td>46.6\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>0.770 </td><td>\u22120.028 </td><td>\u221248.85\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[Proposed Scheme] </td><td>0.219 </td><td>\u22120.050 </td><td>\u221259.52\n</td></tr><tr><td>E </td><td>Johnny </td><td>[12] </td><td>\u22120.181 </td><td>\u22120.134 </td><td>\u221264.43\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[13] </td><td>0.82 </td><td>\u22120.052 </td><td>48.7\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>1.691 </td><td>\u22120.038 </td><td>\u221263.48\n</td></tr><tr><td>Average </td><td>[Proposed Scheme] </td><td>1.371 </td><td>\u22120.028 </td><td>\u221270.85\n</td></tr><tr><td>[12] </td><td>\u22120.350 </td><td>\u22120.085 </td><td>\u221255.26\n</td></tr><tr><td>[13] </td><td>2.67 </td><td>\u22120.092 </td><td>44.64\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[14] </td><td>1.546 </td><td>\u22120.048 </td><td>\u221254.70\n</td></tr><tr><td>\u00a0</td><td>\u00a0</td><td>[Proposed Scheme] </td><td>0.797 </td><td>\u22120.046 </td><td>\u221260.43\n</td></tr></table></body></html>"}}, "back_matter": []}