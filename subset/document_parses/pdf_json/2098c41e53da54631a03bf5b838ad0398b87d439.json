{"paper_id": "2098c41e53da54631a03bf5b838ad0398b87d439", "metadata": {"title": "Bio-JOIE: Joint Representation Learning of Biological Knowledge Bases", "authors": [{"first": "Junheng", "middle": [], "last": "Hao", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of California", "location": {"postCode": "90095", "settlement": "Los Angeles", "country": "USA"}}, "email": "jhao@cs.ucla.edu"}, {"first": "Chelsea", "middle": ["J"], "last": "", "suffix": "", "affiliation": {}, "email": ""}, {"first": "-T", "middle": [], "last": "Ju", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Muhao", "middle": [], "last": "Chen", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of California", "location": {"postCode": "90095", "settlement": "Los Angeles", "country": "USA"}}, "email": ""}, {"first": "Yizhou", "middle": [], "last": "Sun", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of California", "location": {"postCode": "90095", "settlement": "Los Angeles", "country": "USA"}}, "email": ""}, {"first": "Carlo", "middle": [], "last": "Zaniolo", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of California", "location": {"postCode": "90095", "settlement": "Los Angeles", "country": "USA"}}, "email": ""}, {"first": "Wei", "middle": [], "last": "Wang", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of California", "location": {"postCode": "90095", "settlement": "Los Angeles", "country": "USA"}}, "email": ""}]}, "abstract": [{"text": "The widespread of Coronavirus has led to a worldwide pandemic with a high mortality rate. Currently, the knowledge accumulated from different studies about this virus is very limited. Leveraging a wide-range of biological knowledge, such as gene ontology and protein-protein interaction (PPI) networks from other closely related species presents a vital approach to infer the molecular impact of a new species. In this paper, we propose the transferred multi-relational embedding model Bio-JOIE to capture the knowledge of gene ontology and PPI networks, which demonstrates superb capability in modeling the SARS-CoV-2-human protein interactions. Bio-JOIE jointly trains two model components. The knowledge model encodes the relational facts from the protein and GO domains into separated embedding spaces, using a hierarchy-aware encoding technique employed for the GO terms. On top of that, the transfer model learns a nonlinear transformation to transfer the knowledge of PPIs and gene ontology annotations across their embedding spaces. By leveraging only structured knowledge, Bio-JOIE significantly outperforms existing state-of-the-art methods in PPI type prediction on multiple species. Furthermore, we also demonstrate the potential of leveraging the learned representations on clustering proteins with enzymatic function into enzyme commission families. Finally, we show that Bio-JOIE can accurately identify PPIs between the SARS-CoV-2 proteins and human proteins, providing valuable insights for advancing research on this new disease.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "The outbreak of COVID-19 (Coronavirus Disease-2019) has infected over 8,000,000 people and caused death for over 430,000 since the end of 2019 1 . Tremendous efforts have been made to discover the infection mechanism of the causative agent, named SARS-CoV-2. One important and urgent task is to understand the mechanism in which viral proteins interact with human proteins. The new findings will enrich the annotation of viral genomes [12] in biomedical knowledge bases (KBs). Constructing and populating such biomedical KBs can significantly improve our understanding of the processes by which SARS-CoV-2 affects different cells in human body and will serve as the foundation for many important downstream applications such as vaccine development [17] , drug repurposing [12, 36] and drug side effect detection [37] . In general, biological KBs, often stored as knowledge graphs (KGs) , consist of various biological entities, their properties and relations. These KBs can be categorized in different domains, such as gene annotation, functional proteomic analysis, and transcriptomic profiling. Specifically, gene ontology (GO) [10, 16] is the most widely used resource for gene function annotation; STRING [29] , PDB [2] and neXtProt [19] collect the knowledge accumulated from functional proteomic analysis; Expression Atlas [25] is a database facilitating the retrieval and analysis of gene expression studies. While those KBs provide the essential sources of knowledge for in silico research in the corresponding domains, such domain-specific knowledge is often sparse and costly to apprehend [21, 30] . For example, PPI networks can be far from complete given the information supported by experimental results or suggested by computational inference [14, 21] . Makrodimitris et al. [21] indicate that the numbers of protein-protein interactions in BIOGRID [24] for non-model organisms are far less than expected, specifically, there are only 107 interactions for tomato (Solanum lycopersicum) and 80 interactions for pig (Sus scrofa). Evidently, relying on the KG from a single domain presents the risk of learning from limited and scarce information. The stored knowledge is often interrelated across different perspectives. Hence, the missing knowledge in certain KBs can be transferred from other KBs, and thus provide a more comprehensive representation of the biological entities. Taking the protein-protein interaction (PPI) examples of the new SARS-CoV-2 proteins as illustrated in Figure 1 , SARS-CoV-2 M protein interacts with a list of human proteins, and five of them are involved in the endoplasmic reticulum (ER) morphology process as suggested by the gene ontology annotation (GO:0005783). Similarly, the SARS-CoV-2 ORF3a also interacts with a list of human proteins. Among these proteins, VSP39 and VSP11 are the core subunits of HOPS complex, presenting a binding action as suggested by the STRING database. While aligning the gene ontology annotations of the SARS-CoV-2 M protein as demonstrated in Figure 2 , the SARS-CoV M protein presents a similar set of gene ontology annotations, such as \"host immune mitigation\" and \"virion membrane\", suggesting that the side knowledge of gene ontology annotations can facilitate the inference of interactions for related proteins. More generally, the sparse domain information can always benefit from the supplementary knowledge from other relevant domains, therefore calling upon a plausible method to support the fusion and transfer of knowledge across multiple biological domains.", "cite_spans": [{"start": 435, "end": 439, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 748, "end": 752, "text": "[17]", "ref_id": "BIBREF16"}, {"start": 772, "end": 776, "text": "[12,", "ref_id": "BIBREF11"}, {"start": 777, "end": 780, "text": "36]", "ref_id": "BIBREF35"}, {"start": 812, "end": 816, "text": "[37]", "ref_id": "BIBREF36"}, {"start": 1130, "end": 1134, "text": "[10,", "ref_id": "BIBREF9"}, {"start": 1135, "end": 1138, "text": "16]", "ref_id": "BIBREF15"}, {"start": 1209, "end": 1213, "text": "[29]", "ref_id": "BIBREF28"}, {"start": 1220, "end": 1223, "text": "[2]", "ref_id": "BIBREF1"}, {"start": 1237, "end": 1241, "text": "[19]", "ref_id": "BIBREF18"}, {"start": 1329, "end": 1333, "text": "[25]", "ref_id": "BIBREF24"}, {"start": 1599, "end": 1603, "text": "[21,", "ref_id": "BIBREF20"}, {"start": 1604, "end": 1607, "text": "30]", "ref_id": "BIBREF29"}, {"start": 1757, "end": 1761, "text": "[14,", "ref_id": "BIBREF13"}, {"start": 1762, "end": 1765, "text": "21]", "ref_id": "BIBREF20"}, {"start": 1789, "end": 1793, "text": "[21]", "ref_id": "BIBREF20"}, {"start": 1863, "end": 1867, "text": "[24]", "ref_id": "BIBREF23"}], "ref_spans": [{"start": 2496, "end": 2504, "text": "Figure 1", "ref_id": "FIGREF0"}, {"start": 3023, "end": 3031, "text": "Figure 2", "ref_id": "FIGREF1"}], "section": "Introduction"}, {"text": "Regardless of the importance and advantages of knowledge fusion across different domains [3, 5] , fewer efforts have been devoted to incorporating knowledge from different domains for a specific task in computational biology studies. Onto2vec [27] presents one state-of-the-art learning approach that successfully bridges gene ontology annotations with the protein representation. However, the known PPI information is neglected and not encoded in the obtained protein embeddings.", "cite_spans": [{"start": 89, "end": 92, "text": "[3,", "ref_id": null}, {"start": 93, "end": 95, "text": "5]", "ref_id": "BIBREF4"}, {"start": 243, "end": 247, "text": "[27]", "ref_id": "BIBREF26"}], "ref_spans": [], "section": "Introduction"}, {"text": "To combine multiple domain-specific biological knowledge, and facilitate knowledge transfer across different domains, we purpose Bio-JOIE, a JoInt Embedding learning framework for multiple domains of Biological KBs. In Bio-JOIE, two model components are jointly learned, i.e., a knowledge model characterizes different domain-specific KGs in separate low-dimensional embedding spaces, and a transfer model captures the cross-domain knowledge association. More specifically, the knowledge model encodes the relational facts of entities in each view into the corresponding embedding space separately, with a hierarchy-aware technique designated for the hierarchically-layered domains. Besides, the transfer model seeks to transfer the knowledge between pairs of domains by employing a weighted non-linear transformation across their embedding spaces. In evaluation, we apply the Bio-JOIE on several PPI networks with Gene Ontology annotations and the entire gene ontology and evaluate by PPI predictions. We compare Bio-JOIE with that of the state-of-the-art representation learning approaches on multiple species, including SARS-CoV-2-Human PPIs, with different model settings. Our best Bio-JOIE outperforms alternative approaches by 7.4% in PPI prediction.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "Our contributions are 4-fold. First, we construct a general framework for learning representations across different domain-specific KBs, including the dynamically changing SARS-CoV-2 KB. Second, we emphasize and demonstrate that cross-domain representation learning by the proposed Bio-JOIE can improve the inference in one domain by leveraging the complementary knowledge from another domain. Extensive experiments on different species confirm the effectiveness of crossdomain representation learning. Third, Bio-JOIE also demonstrates cross-species transferability to improve PPI predictions among multiple species by knowledge population from gene ontology. Fourth, the protein representations learned from Bio-JOIE can be leveraged for different tasks. Specifically, we show that the protein embeddings trained on PPI network and gene ontology present the potential to better group enzymes into different enzyme commission families.", "cite_spans": [], "ref_spans": [], "section": "Introduction"}, {"text": "In this section, we present the proposed method to support representation learning and cross-domain knowledge transfer on biological KBs. Without loss of generality and aligned with the evaluation of the proposed Bio-JOIE, we refer two domain-specific KGs in the following section to PPI networks and the gene ontology graph. We begin with the formalized descriptions of the materials and tasks.", "cite_spans": [], "ref_spans": [], "section": "Materials and Method"}, {"text": "Materials. A typical biological KB can be viewed as relational data that are presented as an edge-labeled directed graph G, which is formed with a set of entities (e.g. proteins) E and a set of relations (e.g. interaction types) R. A triple (s, r, t) \u2208 G represents a r \u2208 R typed relation between the source and target entities s, t \u2208 E, As stated, we continue with the modeling on KGs of two domains, PPI and gene ontology. For example, in the PPI network, a triple (FBgn0011606, binding, FBgn0260855) simply states the fact that two proteins (from fly) have binding interaction; and in gene ontology, a triple (GO:0008152, is a, GO:0008150) similarly represents that GO:0008152 (a unique identifier of \"metabolic process\") is one subclass of GO:0008150 (a unique identifier of \"biological process\"). Our model seeks to capture the protein information in the triples (s p , r p , t p ) of PPI graph G p in a k p -dimensional embedding space, where we use boldfaced notations such as s p , r p , t p \u2208 R kp to denote the embedding representation. Similarly, gene ontology is another graph G o formed with a set of GO terms E o and a set of semantic relations R o . The triple (s o , r o , t o ) \u2208 G o identifies a semantic relation of GO terms, while we also observe hierarchical substructures formed by \"subclass\" or \"is a\" relation as the aforementioned example. The gene ontology is embedded in another space R ko , such that k p and k o may not be equivalent. We use (o, p) \u2208 A to denote a GO term annotation where a GO term o \u2208 E o describes a protein p \u2208 E p of its corresponding functionality, and A denotes the set of such associations. As introduced in Section 1, we consider SARS-CoV-2-Human interaction as a similar (but significantly smaller) KBs with the same structures as G p , which serves as an extension of human PPI networks. Tasks. To validate the learned embedding of biological entities (proteins and GO terms in this context), we address the following two tasks. (i) PPI type prediction aims at predicting the interaction type between two interacting proteins, including SARS-CoV-2 related PPIs; (ii) Protein clustering and family identification aims at clustering the existing proteins and helps identify the clusters based on Enzyme Commission (EC) numbers.", "cite_spans": [], "ref_spans": [], "section": "Preliminary"}, {"text": "Methods. The model architecture of Bio-JOIE is shown in Figure 3 . The proposed Bio-JOIE jointly learns two types of model components to connect the two views of structured knowledge. Knowledge models are responsible for representing the relational knowledge of PPI and that of GO term into two separate embedding spaces R kp and R ko by using KG embedding and hierarchy-aware regularization. On top of that, a transfer model learns a transformation to connect between the representations of GO term relation facts and PPI based on partially provided GO term assignments. In particular, we investigate weighted transfer techniques to better capture the knowledge transfer, for which the weights reflect the specificity of the assigned GO term to a protein. The following of this section describes the model components and the learning objective of Bio-JOIE in detail. ", "cite_spans": [], "ref_spans": [{"start": 56, "end": 64, "text": "Figure 3", "ref_id": "FIGREF3"}], "section": "Preliminary"}, {"text": "The knowledge models seek to characterize the semantic relations of GO terms and PPI information into separate embedding spaces. In each embedding space, the inference of relations or interactions is modeled as specific algebraic vector operations. As mentioned, the two views of gene ontology and PPI are embedded to separate embedding spaces.", "cite_spans": [], "ref_spans": [], "section": "Knowledge Model"}, {"text": "To capture a triple (s, r, t) from either of the two domains, a cost function f r (s, t) is provided to measure its plausibility. A lower score indicates a more plausible triple. We can adopt multiple vector operations in the defined embedding space with three representative examples defined as follows, i.e. translations (TransE [4] ), Hadamard product [33] and circular correlation (HolE [23] ). The cost functions are given as follows, where the symbol \u2022 denotes Hadamard product, and :", "cite_spans": [{"start": 331, "end": 334, "text": "[4]", "ref_id": "BIBREF3"}, {"start": 355, "end": 359, "text": "[33]", "ref_id": "BIBREF32"}, {"start": 391, "end": 395, "text": "[23]", "ref_id": "BIBREF22"}], "ref_spans": [], "section": "Knowledge Model"}, {"text": "Since most of the relations in PPI networks are symmetric (such as binding and catalysis), we apply the Hadamard product based function. The learning objective of a knowledge model on a graph G is to minimize the following margin ranking loss,", "cite_spans": [], "ref_spans": [], "section": "Knowledge Model"}, {"text": "where \u03b3 G is a positive margin, and a negative sample (s , r, t ) / \u2208 G is created by randomly substituting either s or t using Bernoulli negative sampling [32] . With regard to the two domains of relational knowledge (proteins and gene ontology) G p and G o , we denote the learning objective losses as L Gp K and L Go K . Hierarchy-aware Encoding Regularization As mentioned in Section 2.1, it is observed that some ontological knowledge can form hierarchies [8] , which is typically constituted by a relation with the implicit hierarchical property, such as \"subclass of\", as substructures. In gene ontology, more than 50% of the triples have such relations. To better characterize such hierarchies, we model such substructures differently from the aforementioned DistMult and many others by adding hierarchy regularization. More specifically, given entity pairs (e l , e h ) \u2208 S where e l is a subclass of e h , we model such hierarchies by minimizing the distance between coarser concepts and associated finer concepts in embedding space. Hence, the loss is simply defined as", "cite_spans": [{"start": 156, "end": 160, "text": "[32]", "ref_id": "BIBREF31"}, {"start": 461, "end": 464, "text": "[8]", "ref_id": "BIBREF7"}], "ref_spans": [], "section": "Knowledge Model"}, {"text": "where [x] + = max{x, 0} and \u03b3 HA is also a positive margin parameter. This penalizes the case where the embedding of e l falls out the \u03b3 HA -radius neighborhood centered at the embedding of e h .", "cite_spans": [], "ref_spans": [], "section": "Knowledge Model"}, {"text": "Relation Inference Given the learned embeddings and a pair of query proteins ((p 1 , p 2 )), we can predict the most plausible interaction type r by selecting the optimal f r (p 1 , p 2 ) score. We can also provide predictions for possible protein targets given the query of the subject protein and specific interaction type (p, r, ?t) by populating the selection proteins with top score f r (p, t) from the knowledge model. Details about each task are curated in Section 3.3 and 3.5.", "cite_spans": [], "ref_spans": [], "section": "Knowledge Model"}, {"text": "The transfer model learns to connect between the above two relational embedding spaces via a non-linear transformation. The transformation is induced based on the GO term assignments, towards the goal to collocate the associated GO terms and proteins in an embedding space after transformation. Hence, the affinity of embedding structures of gene ontology and PPIs can be captured. This allows the relational knowledge to transfer across and complement the learning and inference on both domains.", "cite_spans": [], "ref_spans": [], "section": "Transfer Model"}, {"text": "Given each GO term assignment (o, p) \u2208 A, following function f T (o, p) measures the plausibility of the transformation that is favored to be minimized.", "cite_spans": [], "ref_spans": [], "section": "Transfer Model"}, {"text": "thereof is a weight matrix and b T \u2208 R kp is a bias vector. \u03c3 is either the identify function, or a non-linear function as tanh, the latter thereof aim at smoothing the transformation with additional non-linearity.", "cite_spans": [], "ref_spans": [], "section": "Transfer Model"}, {"text": "The basic strategy to learn the transfer model is to treat each GO term assignment evenly, and thereby minimizing the following learning objective loss.", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "is a negative sample by randomly substituting p , and \u03b3 A is a positive margin.", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "Weighed Transfer Model Since some ontological knowledge, such as gene ontology, may form hierarchical structures, where GO terms in lower levels typically describe more specified gene functionality. During the characterization of associations between GO terms and proteins, in contract to general GO terms, more specified GO terms necessarily carry more precise descriptions to the proteins. Hence, an improved transfer model weights among GO term associations to a protein for the purpose of more attentively capturing those with more specific GO terms. Let \u03c9(o) be a weight is specifically assigned to o, the objective of the weighted transfer model is to minimize the following loss,", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "where C is a normalizing constant to constrain that (o,p) \u03c9(o) C = 1 for a specific proteinp. Exemplarily, there could be several ways to calculate the association weight. Level-based weight. The level of the node in one hierarchical taxonomy is a natural indicator of its specificity. Accordingly, the weight can be defined as,", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "where l is the term's current depth and l max is the maximum length of the associated branch in the gene ontology DAG. Degree centrality weight. A small node's degree centrality in the graph roughly reflects its specialty and we apply", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "as the balance factor for different GO term specialty.", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "In practice, incorporating a specificity-based weight to the transfer model essentially enhances the inference in the protein domain, as we have observed in the evaluation in Section 3. However, the above weight options generally yield similar performance gain, and we fix the weight option as the level-based weight in our experimental setting.", "cite_spans": [], "ref_spans": [], "section": "Basic Transfer Model"}, {"text": "Bio-JOIE jointly learns two knowledge models respectively for GO term relations and PPIs, and a transfer model to support knowledge transfer between these two. Therefore, the joint learning objective minimizes the following loss: \u03bb p and \u03bb t are two positive hyperparameters. We use Adam [18] to optimize the learning objective loss. The learning process uses orthogonal initialization [26] to initialize the weight matrix, and Xavier normal initialization [11] for vector parameters. A normalization constraint is enforced to keep all embedding vectors of GO terms and proteins on unit hyper-spherical surfaces, which is to prevent the non-convex optimization process from collapsing to a trivial solution where all vectors shrink to zero [4, 13, 20, 33] .", "cite_spans": [{"start": 288, "end": 292, "text": "[18]", "ref_id": "BIBREF17"}, {"start": 386, "end": 390, "text": "[26]", "ref_id": "BIBREF25"}, {"start": 457, "end": 461, "text": "[11]", "ref_id": "BIBREF10"}, {"start": 740, "end": 743, "text": "[4,", "ref_id": "BIBREF3"}, {"start": 744, "end": 747, "text": "13,", "ref_id": "BIBREF12"}, {"start": 748, "end": 751, "text": "20,", "ref_id": "BIBREF19"}, {"start": 752, "end": 755, "text": "33]", "ref_id": "BIBREF32"}], "ref_spans": [], "section": "Joint Learning Objectives"}, {"text": "Note that Bio-JOIE is suitable for joint representation learning on proteomic knowledge of different species. In this protein-GO example, the proteins of these species are significantly different from each other. However, they share the same set of annotations in the GO domain. Therefore, More specifically, if we have multiple PPI networks G i , i = 1, 2, . . . , m where m denotes the number of independent species, n knowledge models are trained respectively. Consequently, one unique transfer model is also trained to facilitate the protein-GO knowledge transfer regarding each species. The learning objective on the multi-species setting is changed accordingly as,", "cite_spans": [], "ref_spans": [], "section": "Joint Learning Objectives"}, {"text": "with the assumption that the knowledge model for gene ontology remains unchanged.", "cite_spans": [], "ref_spans": [], "section": "Joint Learning Objectives"}, {"text": "In addition to joint learning on multiple species, Bio-JOIE can also be re-trained from new observations of PPIs. For example, suppose newly discovered SARS-CoV-2-Human PPI knowledge extends the original human PPI networks, we can fine-tune the Bio-JOIE from the saved model and obtained embeddings, by only optimizing the Bio-JOIE on the new triples and hence fast obtain representations for all new proteins, without a long time for retraining the Bio-JOIE from scratch.", "cite_spans": [], "ref_spans": [], "section": "Joint Learning Objectives"}, {"text": "In this section, we evaluate the embeddings learned from Bio-JOIE with two groups of tasks: PPI type prediction (Section 3.3) and protein clustering based on enzymatic functions (Section 3.4). Furthermore, we provide an extensive case study in Section 3.5 on SARS-CoV-2 related PPI prediction and classification.", "cite_spans": [], "ref_spans": [], "section": "Results"}, {"text": "The protein-protein interactions for yeast (Saccharomyces cerevisiae), fly (Drosophila melanogaster ), and human (Homo sapiens) are collected from the STRING [29] database. There are seven types of interactions annotated in the STRING database. To preserve a balanced and sufficient number of cases in each class, we randomly choose the protein pairs from four types of interaction: activation, binding, catalysis, and reaction. In total, there are 21704, 10000, 36400 pairs of proteins for yeast, fly, and human, respectively; each type contains roughly the same number of interactions. Table 1 summarizes the PPI information for each species. Note that, the human PPI dataset does not contain the virus-generated proteins, but the set partially overlaps with the virus-human pan-PPI networks.", "cite_spans": [{"start": 158, "end": 162, "text": "[29]", "ref_id": "BIBREF28"}], "ref_spans": [{"start": 588, "end": 595, "text": "Table 1", "ref_id": "TABREF0"}], "section": "Dataset"}, {"text": "The gene ontology annotations for each protein are extracted from gene ontology Consortium [10] , including all three biological aspects: biological process (BP), cellular components (CC), and molecular function (MF). Table 2 summarizes the number of relations between proteins and GO terms. The relations between GO terms include is-a, part-of, has-part, regulates, positively-regulates, and negatively-regulates. For the SARS-CoV-2 dataset, we collect the latest virus-protein interaction from BioGrid 2 and the limited GO annotations for SARS-CoV-2 from Gene Ontology Consortium 3 , as last updated on early April. In summary, there are 26 SARS-CoV-2 generated proteins and 332 human proteins presenting the evidence of viral-human protein interactions as suggested by Gordon et al. [12] . The selection is based on a high MIST score and a low SAINTexpress BFDR from Affinity Capture-MS.", "cite_spans": [{"start": 91, "end": 95, "text": "[10]", "ref_id": "BIBREF9"}, {"start": 786, "end": 790, "text": "[12]", "ref_id": "BIBREF11"}], "ref_spans": [{"start": 218, "end": 225, "text": "Table 2", "ref_id": "TABREF1"}], "section": "Dataset"}, {"text": "Out of the same experiment, we select 1131 viral-human protein pairs with MIST scores lower than 0.01 as our negative samples. The 26 SARS-CoV-2 generated proteins are annotated with 282 GO terms. In addition to SARS-CoV-2, BioGrid also includes 30 viral proteins from SARS-CoV and MERS-CoV, which are two similar contagious viruses causing respiratory infection. These 30 viral proteins are annotated with 630 GO terms, and display 326 interactions with human proteins. All processed datasets are available at https://www.haojunheng.com/project/goterm.", "cite_spans": [], "ref_spans": [], "section": "Dataset"}, {"text": "We compare Bio-JOIE with the most applicable state-of-the-art approach, Onto2Vec [27] , on learning the representation of proteins. Onto2Vec considered the annotation from gene ontology for representation learning. In addition, we compare Bio-JOIE with a simpler setting, Bio-JOIE-NonGO, where we only consider the single-domain knowledge of PPI. Onto2Vec, Onto2Vec-Parent, Onto2Vec-Ancestor. Onto2Vec utilizes the annotation information from gene ontology to create pairwise context and apply Word2Vec [22] to generate protein and GO term embeddings. Its schema allows the model to learn the representation of proteins and GO terms simultaneously. The proposed setting of Onto2Vec only includes the direct relationship between a protein and a GO term. In this experiment, we explicitly include the relationship between a protein and the parents of the annotated GO terms, named Onto2Vec-Parent, and the ancestors of the annotated GO terms, named Onto2Vec-Ancestor. Onto2Vec-Sum, Onto2Vec-Mean. To examine the effect of Onto2Vec on learning the protein representation from a single domain, i.e. gene ontology, we remove the relations between proteins and GO terms during the learning process. The representation of a protein is then computed by either summing up the embeddings of all the associated GO terms (Onto2Vec-Sum), or taking the average of the embeddings of those GO terms (Onto2Vec-Mean). OPA2Vec Based on Onto2Vec, OPA2Vec further learns the protein and GO term embeddings by leveraging meta-data (labels, synonyms, etc), which better characterize GO terms.", "cite_spans": [{"start": 81, "end": 85, "text": "[27]", "ref_id": "BIBREF26"}, {"start": 503, "end": 507, "text": "[22]", "ref_id": "BIBREF21"}], "ref_spans": [], "section": "Baselines"}, {"text": "Bio-JOIE (NonGO). As opposed to considering the knowledge from a single domain of gene ontology, we adopt Bio-JOIE to consider only the knowledge from Protein-Protein Interaction. In this approach, all the gene ontology annotations and the gene ontology graph are neglected, and thus is reduced to a knowledge model. We only use the knowledge model in Section 2.2, where the protein embeddings are solely learned from PPI networks by the original KG embedding technique, DistMult. We refer to this approach as \"Non-GO\".", "cite_spans": [], "ref_spans": [], "section": "Baselines"}, {"text": "It is worth mentioning that the goal of Onto2Vec and OPA2Vec is to learn the protein representation; therefore, to adapt for the task of PPI prediction, we concatenate the embeddings of each pair of proteins and train a multi-class classifier to predict the PPI type for a given pair of query proteins. We examine the performance with four different classifiers: logistic regression (LR), support vector machine (SVM), random forest (RF), and neural networks (MLP). The evaluation is conducted with five-fold cross-validation. Similar settings apply to all Onto2Vec variants and OPA2Vec. On the contrary, our proposed model equips with relational modeling and outputs PPI predictions by selecting the most plausible relation type. As a result, we do not need an additional classifier for Bio-JOIE and Bio-JOIE-NonGO.", "cite_spans": [], "ref_spans": [], "section": "Baselines"}, {"text": "We examine how effectively Bio-JOIE leverages gene ontology to predict protein-protein interaction types. To do so, we first evaluate the performance on three organisms separately: human, yeast, and fly. Then we study the contribution of the three aspects in gene ontology, i.e. biological process (BP), cellular component (CC), and molecular function (MF), on predicting the type of PPI. Specifically, we provide an analysis on how the knowledge from Gene Ontology contributes to PPIs in different species. Experimental setting. We first separate the PPI triples into approximately 70% for training, 10% for validation and 20% for testing. For hyperparameters with the best performance from the validation set, we select dimension d p = d o = 300 and margin parameters \u03b3 G = 0.25, \u03b3 A = 1.0 and \u03b3 HA = 1.0. Two weight factors in the joint learning objective are set as \u03bb p = 1.0, \u03bb t = 1.0. We use DistMult for the knowledge model in Section 2.2, with hierarchy-aware regularization and the levelweighted transfer model (Section 2.3) deployed. For simplicity, the reported Bio-JOIE adopt the same settings if not specifically explained. The number of epochs in training on all settings is limited to 150. For evaluation, we aim at predicting the correct interaction type, given pairs of proteins in the test set. We conduct a 5-fold cross validation for Bio-JOIE and all baselines, and report the average and standard deviation of accuracy. The best-performing classifier is RF for OPA2Vec and most of the Onto2Vec variants. The only exception is to apply MLP for Onto2Vec-Ancestor on fly. Results. The results for PPI type prediction are shown in Table 3 . We observe that our best Bio-JOIE variant outperforms Bio-JOIE-NonGO by 7.4% on average for all three species. This observation directly shows that gene ontology KG provides complementary knowledge for proteins. Subsequently, Gene Ontology annotations benefit the learning of protein representations and better predict the interaction types between proteins. Compared to other baselines, it is observed that Bio-JOIE notably outperforms Onto2Vec-Ancestor with an average increase of 7.4% on the prediction accuracy, and a relative gain of 9.0% on average of all three species. This observation is due to the advantage that Bio-JOIE better leverages the complementary knowledge from PPI to enhance the PPI prediction. As mentioned in Section 3.2, Onto2Vec does not utilize the PPI information into protein embedding learning. Instead, it obtains embeddings based on the aggregated semantic representations of GO terms. It requires additional classifiers for PPI type prediction given pre-trained protein embeddings. In contrast, Bio-JOIE jointly learns protein representations from both the knowledge model that captures the structured information of known PPIs, and the transfer model that delivers the annotations of GO terms. Also, we observe that Bio-JOIE-Weighted achieves better results than Bio-JOIE, with a relative performance gain of 2.5%. We hypothesize that such gain is attributed to specificity modeling in the transfer model which distinguishes more specific and informative GO terms from other general GO terms and assigns a higher weight, which selectively learns the alignments between two domains. In terms of different species, we also observe that Bio-JOIE achieves a higher PPI prediction accuracy on yeast compared to human and fly. The possible reason is that the yeast interaction network is denser, such that 0.30% of the protein pairs are known to interact, compared to human (0.13%) and fly (0.11%), which indicates that yeast is possibly well studied. OPA2Vec claims to be an improved version of Onto2Vec. Similar to Onto2Vec, it only considers the direct relationship between a protein and a GO term, without parents and ancestors. We find that OPA2Vec performs slightly better than Onto2Vec on Yeast and Fly, but worse on Human. In addition, OPA2Vec falls short when compared to any of the Bio-JOIE variants, indicating that incorporating the metadata of GO terms is insufficient for protein representation learning.", "cite_spans": [], "ref_spans": [{"start": 1649, "end": 1656, "text": "Table 3", "ref_id": "TABREF2"}], "section": "PPI Type Prediction on Multiple Species"}, {"text": "It is noteworthy that unlike Onto2Vec, which achieves its best performance with the help of full gene ontology (i.e. Onto2Vec-Ancestor), our Bio-JOIE model can utilize only the GO terms that are directly annotated with the proteins to accomplish the highest accuracy score. This also makes Bio-JOIE training processes more time efficient. We hypothesize that for Bio-JOIE in the PPI type prediction task, GO terms that are directly related to associated proteins with high specificity are sufficient for the transfer model to model the protein-GO association in the embedding spaces. In contrast, Onto2Vec needs entire structured information of GO terms for its word2vec module to construct an exhaustive context of protein features. We further explore the effects of three different aspects of gene ontology in predicting the types of PPIs. To achieve this, we train Bio-JOIE in settings where only specific aspects of gene ontology annotations are used. Results are shown in Table 4 , in which BP, CC and MF respectively refer to the cases where GO terms of biological processes, cellular components and molecular functions are used. \"BP + CC\" denotes that the GO terms from both biological processes and cellular components are included in training. We observe that Bio-JOIE performs the best with GO terms from all aspects (full gene ontology). This phenomenon is consistent among all three species, indicating that the protein representations are more robust when learning from a more enhanced knowledge graph. It is also interesting to see that the accuracy of the task is generally higher when we include the GO terms from biological processes. This leads to 2.61% improvement in accuracy over CC, and at least 2.13% of improvement over MF when evaluating individually. In the two-aspect evaluation, \"BP+CC\" is in average leads to 0.7% better accuracy than \"CC+MF\". This is attributed to the fact that BP is the largest group in the gene ontology, containing more entities and relational facts. Consequently, Bio-JOIE achieves the best performance with all three aspects of gene ontology annotations incorporated. This indicates that the characterization of PPIs benefits from more comprehensive gene ontology annotations.", "cite_spans": [], "ref_spans": [{"start": 977, "end": 984, "text": "Table 4", "ref_id": "TABREF3"}], "section": "PPI Type Prediction on Multiple Species"}, {"text": "In addition to joint learning from two different domains (i.e. GO terms and PPIs), as mentioned in Section 2.4, Bio-JOIE can be trained to capture PPIs for multiple species with several speciesspecific knowledge models, along with transfer models that bridge the universal gene ontology. To validate the benefit of joint learning on multiple species together, we consider three following configurations of Bio-JOIE: (i) the \"multi-way\" setting uses one unique knowledge model and one transfer model to the universal gene ontology for each species; (ii) the \"concat\" setting uses one unified knowledge model to capture all species of PPIs, together with one transfer model to learn protein-GO alignments, that is, simply concatenate all PPI triples and all gene ontology annotations of proteins in multiple species; (iii) the \"single\" setting trains separately on each species, which is exactly the same as in the setting in Table 3 . We summarize the results in Table 5 . It is observed that the \"multi-way\" setting can slightly improve PPI performance in comparison to the \" single\" setting that trains separately on each species. Also in the \"concat\" setting with one shared transfer model and knowledge model, the performance significantly drops with a 2.8% decrease of accuracy on average compared to the \"single\" setting. Such results suggest that each species has unique patterns of PPIs, such differences are better differentiated in separate embedding spaces. Hence, the multi-way setting better encodes the species-specific knowledge and model, which helps the type prediction of PPIs for each species by Bio-JOIE that are jointly trained on multiple species.", "cite_spans": [], "ref_spans": [{"start": 924, "end": 931, "text": "Table 3", "ref_id": "TABREF2"}, {"start": 962, "end": 969, "text": "Table 5", "ref_id": "TABREF4"}], "section": "PPI Type Prediction on Multiple Species"}, {"text": "Besides inferring PPI types, the embedding representations of proteins can also be used to identify potential protein families based on their functions. This can be achieved by performing clustering algorithms on the learned protein embeddings.", "cite_spans": [], "ref_spans": [], "section": "Identifying Protein Families And Enzyme Commission Based Clustering"}, {"text": "The Enzyme Commission number (EC number) defines a hierarchical classification scheme that provides the enzyme nomenclature based on enzyme-catalyzed reactions. The top-level EC numbers contain seven classes: oxidoreductases, transferases, hydrolases, lyases, isomerases, ligases, and translocases. In this experiment, we select 1340 yeast proteins in total with enzymatic functions. We learn the protein representations using all the triples of PPI networks and the annotation from gene ontology and evaluate the learned representations of these proteins by performing the k-means clustering algorithm to group them into seven non-overlapping clusters. These clusters are compared with the top-level of enzyme commission classification. Purity score is reported as evaluation metrics.", "cite_spans": [], "ref_spans": [], "section": "Identifying Protein Families And Enzyme Commission Based Clustering"}, {"text": "The evaluation of the clustering results is shown in Table 6 . Bio-JOIE achieves the best clustering performance on yeast by a relative increase of 9.7%, which demonstrates that Bio-JOIE has the good model capability to representation learning and empirically show the validity of the learned embeddings to measure the similarity. We hypothesize that Bio-JOIE better incorporates protein annotation resource and utilizes the complementary knowledge in the gene ontology domain, while Bio-JOIE also captures PPI information and encode it into protein embeddings. This in the end results in comprehensive representations for proteins and helps to identify protein EC classes by clustering.", "cite_spans": [], "ref_spans": [{"start": 53, "end": 60, "text": "Table 6", "ref_id": "TABREF5"}], "section": "Identifying Protein Families And Enzyme Commission Based Clustering"}, {"text": "The COVID-19 pandemic requires many efforts and attentions from scientists of different fields. However, there is very limited knowledge of the molecular details of SARS-CoV-2. In this subsection, we apply Bio-JOIE to gain more insights of the PPI network between SARS-CoV-2 and human proteins. Specifically, we explore the potential of Bio-JOIE on predicting whether a pair of human and SARS-CoV-2 proteins interact or not. This is modeled as a binary prediction task. Correspondingly, results from the binary predictions can serve as a guide to identify the targeted proteins by SARS-CoV-2. We first use the known interactions between these two species to validate the effectiveness of Bio-JOIE. These interactions are experimentally verified as described in Section 3.1. In this setting, we particularly study the contribution of the knowledge of other closely related viruses (SARS-CoV and MERS) on supporting PPI prediction. We also show the high-confidence candidates of targeted human proteins predicted by Bio-JOIE for four selected SARS-CoV-2 proteins. Experimental setting. In this experiment, we randomly split the known positive human-virus PPIs into train and test sets with a ratio of 80% and 20%. We train Bio-JOIE on this train set along with human PPIs. For evaluation, positive test samples and selected negative samples, mentioned in Section 3.1 are used to perform binary prediction. We adopt F1-score as the evaluation metric. Table 4 in Section 3.3, we adopt eight options, i.e. one without gene ontology information (NonGO), three using a single aspect of GO terms (BF, CC, MF), three options using two of the aspects (BF+CC, etc) and one using all three aspects (AllGO).", "cite_spans": [], "ref_spans": [{"start": 1448, "end": 1455, "text": "Table 4", "ref_id": "TABREF3"}], "section": "Case Study: SARS-CoV-2-Human Protein Target Prediction"}, {"text": "The results are summarized in Table 7 . In terms of gene ontology aspects, we observe that CC contributes the most compared to other aspects of gene ontology annotations, and the best performance is achieved by adopting CC+MF in Bio-JOIE learning. One explanation is that most of the SARS-CoV-2 proteins have CC annotations and these annotations make up over 70% of all currently available annotations on average. However, less than 5 proteins (such as NSP and ORF 1a) have BF and MF annotations, possibly due to insufficient knowledge on understanding SARS-CoV-2 biological mechanism. As for the input fields, we find that the performance drastically increases with the expansion of input from S1 to S2, which indicates that interactions of 2-hop neighbor proteins can benefit SARS-CoV-2 PPI prediction. However, such a trend is not clearly observed when expanding the input field from S2 to S3. We hypothesize that proteins that are not within 2-hop neighbors may not be very related to SARS-CoV-2 or provide beneficial insights. Interestingly, when adding interactions of two related coronaviruses (SARS-CoV/MERS-CoV) that cause respiratory infection, the performance continues to improve with a relative gain of 3.4%. As shown in Figure. 2, viruses that are closely related to SARS-CoV-2 tend to share important properties. This strongly suggests that it is crucial to leverage their interactions and gene ontology annotations as augmented knowledge for drastically emerging SARS-CoV-2. Besides providing PPI prediction, the proposed model can help by identifying high-confidence candidates for potential human protein targets; this is considered as a link prediction task. When a viral protein (such as SARS-CoV-2 M protein) is given as the query, along with a specific relation (such as \"binding\" under the experiment system type of \"Affinity Capture-MS\"), Bio-JOIE can output a list of most likely protein targets by enumerating the triples with top f r (h, t) scores. The predictions are listed in Table 8 . It is our observation, Bio-JOIE can successfully predict the high-confidence human protein targets in the test set from by [12] among its top predictions (marked as boldfaced entities). Other than the proteins in the test set, Bio-JOIE can also provide a list of reasonable candidates that possess a relatively high MIST score. For example, P62834 is one of the top-ranked protein targets of SARS-CoV-2 NSP7 by our Bio-JOIE, which has a MIST score of 0.658. Diving deep into the facts for P62834, though P62834 is not considered as a high-confidence target by [12] , we observe that both P62834 (RAB1A HUMAN) and SARS-CoV-2 NSP7 interacts with protein P62820 (RAB1A HUMAN). Besides, they are both annotated with the cellular component GO:0016020 (membrane) and enables molecular function GO:0000166 (nucleotide binding), which are possibly the reasons for Bio-JOIE making such prediction with a high rank. Furthermore, Bio-JOIE's predictions include proteins that are not covered by [12] , which inspires further scientific research to verify.", "cite_spans": [{"start": 2139, "end": 2143, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 2576, "end": 2580, "text": "[12]", "ref_id": "BIBREF11"}, {"start": 2999, "end": 3003, "text": "[12]", "ref_id": "BIBREF11"}], "ref_spans": [{"start": 30, "end": 37, "text": "Table 7", "ref_id": "TABREF6"}, {"start": 1234, "end": 1241, "text": "Figure.", "ref_id": null}, {"start": 2006, "end": 2013, "text": "Table 8", "ref_id": "TABREF7"}], "section": "Case Study: SARS-CoV-2-Human Protein Target Prediction"}, {"text": "We further investigate how the information sufficiency of SARS-CoV-2 related PPIs in training set affect the performance. We define the train-set ratio parameter as means the proportions of the SARS-CoV-2-Human PPIs that are used for training Bio-JOIE and follow the aforementioned evaluation protocol on \"NonGO/S3\", \"CC/S3\", \"CC+MF/S3\" and \"CC+MF/S4\" as input other than the control of SARS-CoV-2-Human PPIs part. We plot the PPI results in Figure 6 . As expected, when the proportion of SARS-CoV-2-Human PPIs used for training increases from 20% to 80%, the F1 score improves from 0.2-0.3 to around 0.8, which strongly confirms that the known SARS-CoV-2-Human PPIs serve as one significant factor to the PPI prediction. Moreover, the more knowledge we know about existing SARS-CoV-2 interaction, the more powerful the model is to predict SARS-CoV-2. We also observe that the performance is not saturated when the training ratio is approaching 100%, which possibly results from the fact that as a novel coronavirus, the current known interactions are still very limited. This encourages the scientific communities to unearth more knowledge on SARS-CoV-2; moreover, Bio-JOIE has the potential of bringing about significant advances based on new discoveries.", "cite_spans": [], "ref_spans": [{"start": 442, "end": 450, "text": "Figure 6", "ref_id": "FIGREF10"}], "section": "Case Study: SARS-CoV-2-Human Protein Target Prediction"}, {"text": "In the past decade, much attention has been paid to representation learning of KBs. Methods along this line of research typically encode entities into low dimensional embedding spaces, where the relational inference [32] , proximity measures and alignment [6] of those entities can be supported in the form of vector algebras. Therefore, they provide efficient and versatile methods to incorporate the symbolic knowledge of KGs into statistical learning and inference. Some existing approaches focus specifically on computational biology studies [1, 9, 15, 27, 34] , which similarly embed features of biological entities within low-dimensional representations. One representative work related to ours is Onto2Vec [27] , in which protein representations are learned by incorporating the full semantic content of gene ontology in the feature learning using Word2Vec [22] . However, Onto2Vec replies on the ontology information, while falls short of capturing the multi-relational semantic facts that are important to characterize the proximity of biological entities. For example, regarding the protein and GO terms, the PPI knowledge and the non-hierarchical relationships between gene ontology entities (such as \"regulates\") are not considered. Another thread of related work is joint representation learning for multiple KGs, where embedding models are learned to bridge multiple relational structures for tasks such as entity alignment and type inference. MTransE [6] jointly learns a transformation across two separate translational embedding spaces based on one-to-one seed alignment of entities. Later extensions of this model family, such as KDCoE [7] and JAPE [28] , require additional information of literal descriptions [7] and numerical attributes of entities [28, 31, 35] that are generally not available for biological KB. Our recent development on this line of research, i.e. JOIE [13] learns a many-to-one mapping between entity embeddings and ontological concept embeddings, and aims at resolving the entity type inference task using the latent space of the type ontology. One of the caveats is that JOIE does not specifically incorporate the specificity of concepts in the ontology in the transfer process, for which we find to be particularly beneficial in this problem setting. Besides, the aforementioned methods are mostly for general encyclopedia KBs (such as Wikidata, DBpedia) and have not been adapted for the purpose the modeling biological KBs. More specifically, in contrast to these methods, our method features the characterization of more complicated many-to-many associations between proteins and GO terms. Besides, instead of predicting the alignment of entities, we focus on transferring relational knowledge from one domain to enhance the prediction on the other.", "cite_spans": [{"start": 216, "end": 220, "text": "[32]", "ref_id": "BIBREF31"}, {"start": 256, "end": 259, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 546, "end": 549, "text": "[1,", "ref_id": "BIBREF0"}, {"start": 550, "end": 552, "text": "9,", "ref_id": "BIBREF8"}, {"start": 553, "end": 556, "text": "15,", "ref_id": "BIBREF14"}, {"start": 557, "end": 560, "text": "27,", "ref_id": "BIBREF26"}, {"start": 561, "end": 564, "text": "34]", "ref_id": "BIBREF33"}, {"start": 713, "end": 717, "text": "[27]", "ref_id": "BIBREF26"}, {"start": 864, "end": 868, "text": "[22]", "ref_id": "BIBREF21"}, {"start": 1466, "end": 1469, "text": "[6]", "ref_id": "BIBREF5"}, {"start": 1654, "end": 1657, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 1667, "end": 1671, "text": "[28]", "ref_id": "BIBREF27"}, {"start": 1729, "end": 1732, "text": "[7]", "ref_id": "BIBREF6"}, {"start": 1770, "end": 1774, "text": "[28,", "ref_id": "BIBREF27"}, {"start": 1775, "end": 1778, "text": "31,", "ref_id": "BIBREF30"}, {"start": 1779, "end": 1782, "text": "35]", "ref_id": "BIBREF34"}, {"start": 1894, "end": 1898, "text": "[13]", "ref_id": "BIBREF12"}], "ref_spans": [], "section": "Related Work"}, {"text": "In this paper, we present a novel model Bio-JOIE, that enables end-to-end representation learning for cross-domain biological knowledge bases. Our approach utilizes the knowledge model to capture structural and relational facts within each domain and motivates the knowledge transfer by alignments among domains. Extensive experiments on the tasks of PPI type prediction and clustering demonstrate that Bio-JOIE can successfully leverage complementary knowledge from one domain to another and therefore enable learning entity representation in multiple interrelated and transferable domains in biology. More importantly, Bio-JOIE also provides interaction type predictions on dramatically changing SARS-CoV-2 with human protein targets, which potentially brings reliable computational methods seeking new directions on drug design and disease mitigation.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}, {"text": "In our main directions of future research, we plan to enhance and extend entity representations by systematically incorporating important multimodal features and annotations. For example, primary sequence information and secondary geometric folding features can be modeled simultaneously in protein networks and their combined representation can lead to a comprehensive understanding that will greatly benefit many downstream applications.", "cite_spans": [], "ref_spans": [], "section": "Conclusion"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Neuro-symbolic representation learning on biological knowledge graphs", "authors": [{"first": "Mona", "middle": [], "last": "Alshahrani", "suffix": ""}, {"first": "Omar", "middle": [], "last": "Mohammad Asif Khan", "suffix": ""}, {"first": "", "middle": [], "last": "Maddouri", "suffix": ""}, {"first": "R", "middle": [], "last": "Akira", "suffix": ""}, {"first": "N\u00faria", "middle": [], "last": "Kinjo", "suffix": ""}, {"first": "Robert", "middle": [], "last": "Queralt-Rosinach", "suffix": ""}, {"first": "", "middle": [], "last": "Hoehndorf", "suffix": ""}], "year": 2017, "venue": "Bioinformatics", "volume": "33", "issn": "17", "pages": "2723--2730", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "The worldwide protein data bank (wwpdb): ensuring a single, uniform archive of pdb data", "authors": [{"first": "Helen", "middle": [], "last": "Berman", "suffix": ""}, {"first": "Kim", "middle": [], "last": "Henrick", "suffix": ""}, {"first": "Haruki", "middle": [], "last": "Nakamura", "suffix": ""}, {"first": "John L", "middle": [], "last": "Markley", "suffix": ""}], "year": 2007, "venue": "Nucleic acids research", "volume": "35", "issn": "1", "pages": "301--303", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Translating embeddings for modeling multi-relational data", "authors": [{"first": "Antoine", "middle": [], "last": "Bordes", "suffix": ""}, {"first": "Nicolas", "middle": [], "last": "Usunier", "suffix": ""}], "year": 2013, "venue": "NIPS", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Learning conflict resolution strategies for cross-language wikipedia data fusion", "authors": [{"first": "Volha", "middle": [], "last": "Bryl", "suffix": ""}, {"first": "Christian", "middle": [], "last": "Bizer", "suffix": ""}], "year": 2014, "venue": "WWW", "volume": "", "issn": "", "pages": "1129--1134", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Multilingual knowledge graph embeddings for cross-lingual knowledge alignment", "authors": [{"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Yingtao", "middle": [], "last": "Tian", "suffix": ""}, {"first": "Mohan", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Carlo", "middle": [], "last": "Zaniolo", "suffix": ""}], "year": 2017, "venue": "IJCAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment", "authors": [{"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Yingtao", "middle": [], "last": "Tian", "suffix": ""}, {"first": "Kai-Wei", "middle": [], "last": "Chang", "suffix": ""}, {"first": "Steven", "middle": [], "last": "Skiena", "suffix": ""}, {"first": "Carlo", "middle": [], "last": "Zaniolo", "suffix": ""}], "year": 2018, "venue": "In IJCAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "On2vec: Embeddingbased relation prediction for ontology population", "authors": [{"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Yingtao", "middle": [], "last": "Tian", "suffix": ""}, {"first": "Xuelu", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Zijun", "middle": [], "last": "Xue", "suffix": ""}, {"first": "Carlo", "middle": [], "last": "Zaniolo", "suffix": ""}], "year": 2018, "venue": "SDM", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Multifaceted protein-protein interaction prediction based on siamese residual rcnn", "authors": [{"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "J-T", "middle": [], "last": "Chelsea", "suffix": ""}, {"first": "Guangyu", "middle": [], "last": "Ju", "suffix": ""}, {"first": "Xuelu", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Tianran", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Kai-Wei", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Carlo", "middle": [], "last": "Chang", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Zaniolo", "suffix": ""}, {"first": "", "middle": [], "last": "Wang", "suffix": ""}], "year": 2019, "venue": "Bioinformatics", "volume": "35", "issn": "14", "pages": "305--314", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "The gene ontology resource: 20 years and still going strong", "authors": [{"first": "Gene", "middle": [], "last": "Ontology Consortium", "suffix": ""}], "year": 2018, "venue": "Nucleic acids research", "volume": "47", "issn": "D1", "pages": "330--338", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Understanding the difficulty of training deep feedforward neural networks", "authors": [{"first": "Xavier", "middle": [], "last": "Glorot", "suffix": ""}, {"first": "Yoshua", "middle": [], "last": "Bengio", "suffix": ""}], "year": 2010, "venue": "Proceedings of the thirteenth international conference on artificial intelligence and statistics", "volume": "", "issn": "", "pages": "249--256", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "A sars-cov-2 protein interaction map reveals targets for drug repurposing", "authors": [{"first": "Gwendolyn", "middle": ["M"], "last": "David E Gordon", "suffix": ""}, {"first": "Mehdi", "middle": [], "last": "Jang", "suffix": ""}, {"first": "Jiewei", "middle": [], "last": "Bouhaddou", "suffix": ""}, {"first": "Kirsten", "middle": [], "last": "Xu", "suffix": ""}, {"first": "Kris", "middle": ["M"], "last": "Obernier", "suffix": ""}, {"first": "", "middle": [], "last": "White", "suffix": ""}, {"first": "J", "middle": [], "last": "Matthew", "suffix": ""}, {"first": "", "middle": [], "last": "O&apos;meara", "suffix": ""}, {"first": "V", "middle": [], "last": "Veronica", "suffix": ""}, {"first": "Jeffrey", "middle": ["Z"], "last": "Rezelj", "suffix": ""}, {"first": "Danielle", "middle": ["L"], "last": "Guo", "suffix": ""}, {"first": "", "middle": [], "last": "Swaney", "suffix": ""}], "year": 2020, "venue": "Nature", "volume": "", "issn": "", "pages": "1--13", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts", "authors": [{"first": "Junheng", "middle": [], "last": "Hao", "suffix": ""}, {"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Wenchao", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Yizhou", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Wang", "suffix": ""}], "year": 2019, "venue": "Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery and data mining", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Completing sparse and disconnected protein-protein network by deep learning", "authors": [{"first": "Lei", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Li", "middle": [], "last": "Liao", "suffix": ""}, {"first": "Cathy", "middle": ["H"], "last": "Wu", "suffix": ""}], "year": 2018, "venue": "BMC bioinformatics", "volume": "19", "issn": "1", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Using weighted sparse representation model combined with discrete cosine transformation to predict protein-protein interactions from protein sequence", "authors": [{"first": "Yu-An", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Zhu-Hong", "middle": [], "last": "You", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Gao", "suffix": ""}, {"first": "Leon", "middle": [], "last": "Wong", "suffix": ""}, {"first": "Lirong", "middle": [], "last": "Wang", "suffix": ""}], "year": 2015, "venue": "BioMed research international", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "The goa database: gene ontology annotation updates for", "authors": [{"first": "P", "middle": [], "last": "Rachael", "suffix": ""}, {"first": "Tony", "middle": [], "last": "Huntley", "suffix": ""}, {"first": "Prudence", "middle": [], "last": "Sawford", "suffix": ""}, {"first": "Aleksandra", "middle": [], "last": "Mutowo-Meullenet", "suffix": ""}, {"first": "Carlos", "middle": [], "last": "Shypitsyna", "suffix": ""}, {"first": "Maria", "middle": ["J"], "last": "Bonilla", "suffix": ""}, {"first": "Claire O&apos;", "middle": [], "last": "Martin", "suffix": ""}, {"first": "", "middle": [], "last": "Donovan", "suffix": ""}], "year": 2015, "venue": "Nucleic acids research", "volume": "43", "issn": "D1", "pages": "1057--1063", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Risk-based bioengineering strategies for reliable bacterial vaccine production", "authors": [{"first": "Tjerko", "middle": [], "last": "Kamminga", "suffix": ""}, {"first": "Simen-Jan", "middle": [], "last": "Slagman", "suffix": ""}, {"first": "A", "middle": ["P"], "last": "Vitor", "suffix": ""}, {"first": "Jetta", "middle": ["Je"], "last": "Martins Dos Santos", "suffix": ""}, {"first": "Peter", "middle": ["J"], "last": "Bijlsma", "suffix": ""}, {"first": "", "middle": [], "last": "Schaap", "suffix": ""}], "year": 2019, "venue": "Trends in biotechnology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Adam: A method for stochastic optimization", "authors": [{"first": "P", "middle": [], "last": "Diederik", "suffix": ""}, {"first": "Jimmy", "middle": [], "last": "Kingma", "suffix": ""}, {"first": "", "middle": [], "last": "Ba", "suffix": ""}], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "nextprot: a knowledge platform for human proteins", "authors": [{"first": "Lydie", "middle": [], "last": "Lane", "suffix": ""}, {"first": "Ghislaine", "middle": [], "last": "Argoud-Puy", "suffix": ""}, {"first": "Aurore", "middle": [], "last": "Britan", "suffix": ""}, {"first": "Isabelle", "middle": [], "last": "Cusin", "suffix": ""}, {"first": "Paula", "middle": ["D"], "last": "Duek", "suffix": ""}, {"first": "Olivier", "middle": [], "last": "Evalet", "suffix": ""}, {"first": "Alain", "middle": [], "last": "Gateau", "suffix": ""}, {"first": "Pascale", "middle": [], "last": "Gaudet", "suffix": ""}, {"first": "Anne", "middle": [], "last": "Gleizes", "suffix": ""}, {"first": "Alexandre", "middle": [], "last": "Masselot", "suffix": ""}], "year": 2012, "venue": "Nucleic acids research", "volume": "40", "issn": "D1", "pages": "76--83", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Hierarchical taxonomy aware network embedding", "authors": [{"first": "Jianxin", "middle": [], "last": "Ma", "suffix": ""}, {"first": "Peng", "middle": [], "last": "Cui", "suffix": ""}, {"first": "Xiao", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Wenwu", "middle": [], "last": "Zhu", "suffix": ""}], "year": 2018, "venue": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining", "volume": "", "issn": "", "pages": "1920--1929", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Sparsity of protein-protein interaction networks hinders function prediction in non-model species. bioRxiv", "authors": [{"first": "Stavros", "middle": [], "last": "Makrodimitris", "suffix": ""}, {"first": "Marcel", "middle": [], "last": "Roeland Van Ham", "suffix": ""}, {"first": "", "middle": [], "last": "Reinders", "suffix": ""}], "year": 2019, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Distributed representations of words and phrases and their compositionality", "authors": [{"first": "Tomas", "middle": [], "last": "Mikolov", "suffix": ""}, {"first": "Ilya", "middle": [], "last": "Sutskever", "suffix": ""}, {"first": "Kai", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Greg", "middle": ["S"], "last": "Corrado", "suffix": ""}, {"first": "Jeff", "middle": [], "last": "Dean", "suffix": ""}], "year": 2013, "venue": "Advances in neural information processing systems", "volume": "", "issn": "", "pages": "3111--3119", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "Holographic embeddings of knowledge graphs", "authors": [{"first": "Maximilian", "middle": [], "last": "Nickel", "suffix": ""}, {"first": "Lorenzo", "middle": [], "last": "Rosasco", "suffix": ""}], "year": 2016, "venue": "AAAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "The biogrid interaction database: 2019 update", "authors": [{"first": "Rose", "middle": [], "last": "Oughtred", "suffix": ""}, {"first": "Chris", "middle": [], "last": "Stark", "suffix": ""}, {"first": "Bobby-Joe", "middle": [], "last": "Breitkreutz", "suffix": ""}, {"first": "Jennifer", "middle": [], "last": "Rust", "suffix": ""}, {"first": "Lorrie", "middle": [], "last": "Boucher", "suffix": ""}, {"first": "Christie", "middle": [], "last": "Chang", "suffix": ""}, {"first": "Nadine", "middle": [], "last": "Kolas", "suffix": ""}, {"first": "O&apos;", "middle": [], "last": "Lara", "suffix": ""}, {"first": "Genie", "middle": [], "last": "Donnell", "suffix": ""}, {"first": "Rochelle", "middle": [], "last": "Leung", "suffix": ""}, {"first": "", "middle": [], "last": "Mcadam", "suffix": ""}], "year": 2019, "venue": "Nucleic acids research", "volume": "47", "issn": "D1", "pages": "529--541", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Expression atlas update: from tissues to single cells", "authors": [{"first": "Irene", "middle": [], "last": "Papatheodorou", "suffix": ""}, {"first": "Pablo", "middle": [], "last": "Moreno", "suffix": ""}, {"first": "Jonathan", "middle": [], "last": "Manning", "suffix": ""}, {"first": "Alfonso Mu\u00f1oz-Pomer", "middle": [], "last": "Fuentes", "suffix": ""}, {"first": "Nancy", "middle": [], "last": "George", "suffix": ""}, {"first": "Silvie", "middle": [], "last": "Fexova", "suffix": ""}, {"first": "A", "middle": [], "last": "Nuno", "suffix": ""}, {"first": "Anja", "middle": [], "last": "Fonseca", "suffix": ""}, {"first": "Matthew", "middle": [], "last": "F\u00fcllgrabe", "suffix": ""}, {"first": "Ni", "middle": [], "last": "Green", "suffix": ""}, {"first": "", "middle": [], "last": "Huang", "suffix": ""}], "year": 2020, "venue": "Nucleic acids research", "volume": "48", "issn": "D1", "pages": "77--83", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "authors": [{"first": "M", "middle": [], "last": "Andrew", "suffix": ""}, {"first": "James", "middle": ["L"], "last": "Saxe", "suffix": ""}, {"first": "", "middle": [], "last": "Mcclelland", "suffix": ""}], "year": 2014, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Onto2vec: joint vector-based representation of biological entities and their ontology-based annotations", "authors": [{"first": "Fatima", "middle": ["Zohra"], "last": "Smaili", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Gao", "suffix": ""}, {"first": "Robert", "middle": [], "last": "Hoehndorf", "suffix": ""}], "year": 2018, "venue": "Bioinformatics", "volume": "34", "issn": "13", "pages": "52--60", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Cross-lingual entity alignment via joint attributepreserving embedding", "authors": [{"first": "Zequn", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Chengkai", "middle": [], "last": "Li", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF28": {"ref_id": "b28", "title": "Peer Bork, et al. The string database in 2017: quality-controlled protein-protein association networks", "authors": [{"first": "Damian", "middle": [], "last": "Szklarczyk", "suffix": ""}, {"first": "H", "middle": [], "last": "John", "suffix": ""}, {"first": "Helen", "middle": [], "last": "Morris", "suffix": ""}, {"first": "Michael", "middle": [], "last": "Cook", "suffix": ""}, {"first": "Stefan", "middle": [], "last": "Kuhn", "suffix": ""}, {"first": "Milan", "middle": [], "last": "Wyder", "suffix": ""}, {"first": "Alberto", "middle": [], "last": "Simonovic", "suffix": ""}, {"first": "", "middle": [], "last": "Santos", "suffix": ""}, {"first": "T", "middle": [], "last": "Nadezhda", "suffix": ""}, {"first": "Alexander", "middle": [], "last": "Doncheva", "suffix": ""}, {"first": "", "middle": [], "last": "Roth", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report", "authors": [{"first": "D", "middle": [], "last": "Paul", "suffix": ""}, {"first": "Valerie", "middle": [], "last": "Thomas", "suffix": ""}, {"first": "", "middle": [], "last": "Wood", "suffix": ""}, {"first": "J", "middle": [], "last": "Christopher", "suffix": ""}, {"first": "Suzanna", "middle": ["E"], "last": "Mungall", "suffix": ""}, {"first": "Judith", "middle": ["A"], "last": "Lewis", "suffix": ""}, {"first": "Gene", "middle": ["Ontology"], "last": "Blake", "suffix": ""}, {"first": "", "middle": [], "last": "Consortium", "suffix": ""}], "year": 2012, "venue": "PLoS computational biology", "volume": "8", "issn": "2", "pages": "", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "Entity alignment between knowledge graphs using attribute embeddings", "authors": [{"first": "Jianzhong", "middle": [], "last": "Bayu Distiawan Trsedya", "suffix": ""}, {"first": "Rui", "middle": [], "last": "Qi", "suffix": ""}, {"first": "", "middle": [], "last": "Zhang", "suffix": ""}], "year": 2019, "venue": "AAAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Knowledge graph embedding by translating on hyperplanes", "authors": [{"first": "Zhen", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Jianwen", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Jianlin", "middle": [], "last": "Feng", "suffix": ""}, {"first": "Zheng", "middle": [], "last": "Chen", "suffix": ""}], "year": 2014, "venue": "AAAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "Embedding entities and relations for learning and inference in knowledge bases", "authors": [{"first": "Bishan", "middle": [], "last": "Yang", "suffix": ""}, {"first": "Wen-Tau", "middle": [], "last": "Yih", "suffix": ""}, {"first": "Xiaodong", "middle": [], "last": "He", "suffix": ""}], "year": 2015, "venue": "ICLR", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "Predicting protein-protein interactions from primary protein sequences using a novel multi-scale local feature representation scheme and the random forest", "authors": [{"first": "Zhu-Hong", "middle": [], "last": "You", "suffix": ""}, {"first": "C", "middle": ["C"], "last": "Keith", "suffix": ""}, {"first": "Pengwei", "middle": [], "last": "Chan", "suffix": ""}, {"first": "", "middle": [], "last": "Hu", "suffix": ""}], "year": 2015, "venue": "PloS one", "volume": "10", "issn": "5", "pages": "", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Multiview knowledge graph embedding for entity alignment", "authors": [{"first": "Qingheng", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Zequn", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Wei", "middle": [], "last": "Hu", "suffix": ""}, {"first": "Muhao", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Lingbing", "middle": [], "last": "Guo", "suffix": ""}, {"first": "Yuzhong", "middle": [], "last": "Qu", "suffix": ""}], "year": 2019, "venue": "IJCAI", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "Networkbased drug repurposing for novel coronavirus 2019-ncov/sars-cov-2", "authors": [{"first": "Yadi", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "Yuan", "middle": [], "last": "Hou", "suffix": ""}, {"first": "Jiayu", "middle": [], "last": "Shen", "suffix": ""}, {"first": "Yin", "middle": [], "last": "Huang", "suffix": ""}, {"first": "William", "middle": [], "last": "Martin", "suffix": ""}, {"first": "Feixiong", "middle": [], "last": "Cheng", "suffix": ""}], "year": 2020, "venue": "Cell discovery", "volume": "6", "issn": "1", "pages": "1--18", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Modeling polypharmacy side effects with graph convolutional networks", "authors": [{"first": "Marinka", "middle": [], "last": "Zitnik", "suffix": ""}, {"first": "Monica", "middle": [], "last": "Agrawal", "suffix": ""}, {"first": "Jure", "middle": [], "last": "Leskovec", "suffix": ""}], "year": 2018, "venue": "Bioinformatics", "volume": "34", "issn": "13", "pages": "457--466", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Two examples of SARS-CoV-2-human protein interactions: M protein (left) and ORF3a protein (right). The purple diamonds refers to the viral proteins and the orange circles refer to the high-confidence human protein target. Proteins highlighted in blue are involved in certain biological processes, and proteins highlighted in yellow are arranged in a protein complex.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "Examples of gene ontology annotation enrichment on three representative SARS-CoV or SARS-CoV-2 proteins, which possess multiple properties across three biological aspects: biological processes, cellular components and molecular functions.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Model architecture of Bio-JOIE. The Knowledge Model seeks to encode relational facts in each domain respectively (such as proteins and gene ontology). Meanwhile, the Transfer Model learns to connect both domains and enable knowledge transfer across protein and gene ontology.", "latex": null, "type": "figure"}, "FIGREF5": {"text": "Explanation of weighted transfer model for modeling hierarchical gene ontology.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "", "latex": null, "type": "figure"}, "FIGREF7": {"text": "SARS-CoV2 PPIs + All Human PPIsS4: S3 + SARS-CoV/MERS PPIs", "latex": null, "type": "figure"}, "FIGREF8": {"text": "Different scopes of input to train Bio-JOIE for SARS-CoV-2 PPI prediction.Results. As in Section 3.3, we first evaluate Bio-JOIE on SARS-CoV-2 PPI prediction. From the observation in Section 3.3, two important factors are considered: three aspects in the gene ontology domain and the scope of input SARS-CoV-2-Human PPIs. More specifically, we define increasingly four scopes of input PPIs, as shown inFigure 5, i.e. (1) S1: Only using the train folds of SARS-CoV-2-Human PPIs; (2) S2: Using SARS-CoV-2-Human PPIs with the 2-hop neighbor proteins from SARS-CoV-2 viral proteins, i.e. including the ones which also interact with any proteins that", "latex": null, "type": "figure"}, "FIGREF9": {"text": "SARS-CoV-2 interacts; (3) S3: SARS-CoV-2-Human PPIs with all other protein interactions on human; (4) S4: SARS-CoV-2-Human PPIs with all protein interactions in S3 plus all SARS-CoV and MERS PPIs. As for the aspects of the gene ontology domain, similar to", "latex": null, "type": "figure"}, "FIGREF10": {"text": "Bio-JOIE performance on different train-set ratios of SARS-CoV-2-Human PPIs.", "latex": null, "type": "figure"}, "TABREF0": {"text": "Statistics of PPI networks and associated GO annotations.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Species </td><td># Proteins </td><td># PPI Triples </td><td># GO Annotations\n</td></tr><tr><td>Yeast </td><td>3,736 </td><td>21,704 </td><td>191,801\n</td></tr><tr><td>Fly </td><td>3,826 </td><td>10,000 </td><td>87,807\n</td></tr><tr><td>Human </td><td>8,204 </td><td>36,400 </td><td>102,759\n</td></tr></table></body></html>"}, "TABREF1": {"text": "Statistics of three aspects in the gene ontology: biological processes (BP), cellular components (CC) and molecular functions (MF).", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Aspects </td><td>BP </td><td>CC </td><td>MF\n</td></tr><tr><td># GO entities </td><td>5744 </td><td>1,147 </td><td>1,764\n</td></tr><tr><td># GO triples </td><td>19,021 </td><td>2,116 </td><td>2,190\n</td></tr><tr><td># Protein-GO annotations (yeast) </td><td>72,956 </td><td>58,729 </td><td>60,116\n</td></tr><tr><td># Protein-GO annotations (fly) </td><td>44,605 </td><td>24,550 </td><td>18,652\n</td></tr><tr><td># Protein-GO annotations (human) 4</td><td>2,899 </td><td>32,929 </td><td>26,931\n</td></tr></table></body></html>"}, "TABREF2": {"text": "PPI type prediction accuracy (%) evaluated on yeast, fly and human species. Bio-JOIE-Weighted 90.12 \u00b1 1.21 85.55 \u00b1 1.57 83.89 \u00b1 0.92", "latex": null, "type": "table"}, "TABREF3": {"text": "Comparison of PPI prediction accuracy of Bio-JOIE on three different aspects of gene ontology.", "latex": null, "type": "table", "html": "<html><body><table><tr><td># </td><td>Aspects </td><td>Yeast </td><td>Fly </td><td>Human\n</td></tr><tr><td>\u00a0</td><td>BP </td><td>0.8794 </td><td>0.8402 </td><td>0.8153\n</td></tr><tr><td>1\n</td><td>CC </td><td>0.8499 </td><td>0.8272 </td><td>0.8054\n</td></tr><tr><td>\u00a0</td><td>MF </td><td>0.8539 </td><td>0.8386 </td><td>0.8165\n</td></tr><tr><td>\u00a0</td><td>BP+CC </td><td>0.8717 </td><td>0.8473 </td><td>0.8271\n</td></tr><tr><td>2\n</td><td>BP+MF </td><td>0.8673 </td><td>0.8471 </td><td>0.8163\n</td></tr><tr><td>\u00a0</td><td>CC+MF </td><td>0.8569 </td><td>0.8466 </td><td>0.8170\n</td></tr><tr><td>3 </td><td>All-GO </td><td>0.9012 </td><td>0.8555 </td><td>0.8389\n</td></tr></table></body></html>"}, "TABREF4": {"text": "PPI type prediction accuracy on different configurations of multi-species joint learning.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Model </td><td>Yeast </td><td>Fly </td><td>Human\n</td></tr><tr><td>Bio-JOIE (single) </td><td>0.9012 </td><td>0.8555 </td><td>0.8389\n</td></tr><tr><td>Bio-JOIE (concat) </td><td>0.8795 </td><td>0.8282 </td><td>0.8028\n</td></tr><tr><td>Bio-JOIE (multi-way) </td><td>0.9062 </td><td>0.8638 </td><td>0.8426\n</td></tr></table></body></html>"}, "TABREF5": {"text": "Results of top-level EC clustering by K-means on learning selected yeast protein embeddings.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Model </td><td>Purity Score\n</td></tr><tr><td>Onto2Vec </td><td>0.2339\n</td></tr><tr><td>Onto2Vec-Parent </td><td>0.2452\n</td></tr><tr><td>Onto2Vec-Ancestor </td><td>0.3224\n</td></tr><tr><td>Onto2Vec-Sum </td><td>0.3022\n</td></tr><tr><td>Onto2Vec-Mean </td><td>0.2616\n</td></tr><tr><td>Bio-JOIE (KM only) </td><td>0.2514\n</td></tr><tr><td>Bio-JOIE </td><td>0.3306\n</td></tr></table></body></html>"}, "TABREF6": {"text": "F-1 score on SARS-CoV-2-Human PPI interaction classification.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Input </td><td>S1 </td><td>S2 </td><td>S3 </td><td>S4\n</td></tr><tr><td>NonGO </td><td>0.6737 </td><td>0.7004 </td><td>0.6918 </td><td>0.6997\n</td></tr><tr><td>BP </td><td>0.7103 </td><td>0.7353 </td><td>0.7348 </td><td>0.7492\n</td></tr><tr><td>CC </td><td>0.7188 </td><td>0.7383 </td><td>0.7380 </td><td>0.7675\n</td></tr><tr><td>MF </td><td>0.6737 </td><td>0.7016 </td><td>0.7022 </td><td>0.7365\n</td></tr><tr><td>BP+CC </td><td>0.7257 </td><td>0.7570 </td><td>0.7499 </td><td>0.7813\n</td></tr><tr><td>BP+MF </td><td>0.7252 </td><td>0.7479 </td><td>0.7486 </td><td>0.7713\n</td></tr><tr><td>CC+MF </td><td>0.7317 </td><td>0.7622 </td><td>0.7692 </td><td>0.7917\n</td></tr><tr><td>AllGO </td><td>0.7307 </td><td>0.7537 </td><td>0.7500 </td><td>0.7885\n</td></tr></table></body></html>"}, "TABREF7": {"text": "Top target proteins predicted by Bio-JOIE. Known interactions from training set are excluded. Proteins that are considered as high-confidence targets are boldfaced.SARS-CoV-2 Proteins Targeted proteins in human", "latex": null, "type": "table"}, "TABREF8": {"text": "Table 3: PPI type prediction accuracy (%) evaluated on yeast, fly and human species.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Model </td><td>Yeast </td><td>Fly </td><td>Human\n</td></tr><tr><td>Onto2Vec </td><td>76.41 \u00b1 0.73 </td><td>70.85 \u00b1 0.85 </td><td>77.97 \u00b1 0.46\n</td></tr><tr><td>Onto2Vec-Parent </td><td>80.79 \u00b1 0.66 </td><td>75.46 \u00b1 1.11 </td><td>74.90 \u00b1 0.46\n</td></tr><tr><td>Onto2Vec-Ancestor </td><td>86.31 \u00b1 0.42 </td><td>80.31 \u00b1 0.92 </td><td>78.73 \u00b1 0.46\n</td></tr><tr><td>Onto2Vec-Sum Onto2Vec-Mean </td><td>76.38 \u00b1 0.83 77.95 \u00b1 0.81 </td><td>72.84 \u00b1 1.13 74.38 \u00b1 1.13 </td><td>72.53 \u00b1 0.73 73.47 \u00b1 0.80\n</td></tr><tr><td>OPA2Vec </td><td>79.88 \u00b1 0.74 </td><td>74.45 \u00b1 0.97 </td><td>72.04 \u00b1 0.58\n</td></tr><tr><td>Bio-JOIE-NonGO Bio-JOIE </td><td>83.65 \u00b1 0.92 87.15 \u00b1 1.15 </td><td>77.58 \u00b1 1.07 84.56 \u00b1 0.81 </td><td>76.10 \u00b1 0.87 81.42 \u00b1 0.62\n</td></tr><tr><td>Bio-JOIE-Weighted </td><td>90.12 \u00b1 1.21 </td><td>85.55 \u00b1 1.57 </td><td>83.89 \u00b1 0.92\n</td></tr></table></body></html>"}, "TABREF9": {"text": "Table 8: Top target proteins predicted by Bio-JOIE. Known interactions from training set are excluded. Proteins that are considered as high-confidence targets are boldfaced.", "latex": null, "type": "table", "html": "<html><body><table><tr><td>SARS-CoV-2 Proteins ORF8 </td><td>Targeted proteins in human P05556, P61019, Q9Y4L1, P17858, Q92769, Q9BQE3, Q9NQC3,\n</td></tr><tr><td>NSP13 </td><td>Q9NXK8, P33527, P61106\nQ99996, P67870, P35241, O60885, P26358, Q9UHD2, Q12923,\n</td></tr><tr><td>M </td><td>Q86YT6, Q04726, P61106 P26358, Q9NR30, O75439, Q15056, P61962, P49593, P33993, O60885,\n</td></tr><tr><td>NSP7 </td><td>Q9Y312, P78527 P62834, P51148, P62070, P67870, O14578, Q8WTV0, P53618,\n</td></tr><tr><td>Q9BS26, O94973, Q7Z7A1\n</td></tr></table></body></html>"}}, "back_matter": []}