{
    "paper_id": "08687b31e7eca10e98d3aafbbb12f4e8a5149e0b",
    "metadata": {
        "title": "The Monte Carlo Transformer: a stochastic self-attention model for sequence prediction",
        "authors": [
            {
                "first": "Alice",
                "middle": [],
                "last": "Martin",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Charles",
                "middle": [],
                "last": "Ollion",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Florian",
                "middle": [],
                "last": "Strub",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Sylvain",
                "middle": [],
                "last": "Le Corff",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Olivier",
                "middle": [],
                "last": "Pietquin",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Brain Team. \u22a5 DeepMind",
                    "location": {}
                },
                "email": ""
            },
            {
                "first": "\u2213",
                "middle": [
                    "\u2020"
                ],
                "last": "Samovar",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "T\u00e9l\u00e9com",
                "middle": [],
                "last": "Sudparis",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "This paper introduces the Sequential Monte Carlo Transformer, an original approach that naturally captures the observations distribution in a recurrent architecture. The keys, queries, values and attention vectors of the network are considered as the unobserved stochastic states of its hidden structure. This generative model is such that at each time step the received observation is a random function of these past states in a given attention window. In this general state-space setting, we use Sequential Monte Carlo methods to approximate the posterior distributions of the states given the observations, and then to estimate the gradient of the log-likelihood. We thus propose a generative model providing a predictive distribution, instead of a single-point estimate.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "While neural networks excel at predicting a single-point estimate of a given target for complex machine learning problems, an open research question is the design of neural generative models able to output a predictive distribution, that can capture the inherent variability of the observations or the model's level of confidence in its predictions. The main motivation behind uncertainty quantification is the design of AI systems for critical applications that are safe, and are mitigating risks while automatizing decision-making. On one hand, Bayesian statistics offer a mathematically grounded framework to reason about uncertainty; however, such models generally require prohibitive computational costs, which make them not widely used in practice. On the other hand, frequentist methods and metrics have been developed for confidence estimation in neural networks, in particular in the classification setting [Brosse et al., 2020] , [Corbi\u00e8re et al., 2019] . Such works address the issue of neural networks calibration [Guo et al., 2017] and detection of out-of-distribution samples [Lee et al., 2018] . But few works focus on generative models based on recurrent neural networks.",
            "cite_spans": [
                {
                    "start": 916,
                    "end": 937,
                    "text": "[Brosse et al., 2020]",
                    "ref_id": null
                },
                {
                    "start": 940,
                    "end": 963,
                    "text": "[Corbi\u00e8re et al., 2019]",
                    "ref_id": null
                },
                {
                    "start": 1026,
                    "end": 1044,
                    "text": "[Guo et al., 2017]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1090,
                    "end": 1108,
                    "text": "[Lee et al., 2018]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "On another note, the Transformer model introduced in [Vaswani et al., 2017] has achieved impressive results on sequential data problems. In the field of Natural Language Processing (NLP), Transformers have indeed repeatedly outperformed recurrent neural networks (RNNs), and are now the go-to network architectures to solve complex tasks such as Machine Translation or Language Modeling. The Transformer model is based on a self-attention mechanism, that computes dot-product attention for every element of a sequence with respect to all others to model their dependency. By computing in parallel multiple heads of self-attention and by stacking layers of such multi-head attention, the model learns long-range dependencies better than previous state-ofthe-art models for sequential data.",
            "cite_spans": [
                {
                    "start": 53,
                    "end": 75,
                    "text": "[Vaswani et al., 2017]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Since the release of \"Attention is all you need\" [Vaswani et al., 2017] , the Deep Learning community have been eager to seize the nuts and bolts of the model to improve its training algorithm or to adapt its architecture to new use-cases and types of sequential data, see for instance BERT and its variants ( [Devlin et al., 2019] , [Radford et al., 2018] , [Radford et al., 2019] , [Raffel et al., 2019] ) and [Chen et al., 2018] , [Hao et al., 2019] . Yet, few publications actually focus on the dependency structure at the heart of the Transformer architecture which provides a promising approach to model sequential data. We think that designing a recurrent network inspired from the original Transformer with statistical priors in its architecture could provide a powerful statistical model for capturing the distribution of the observations for sequence prediction problems.",
            "cite_spans": [
                {
                    "start": 49,
                    "end": 71,
                    "text": "[Vaswani et al., 2017]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 310,
                    "end": 331,
                    "text": "[Devlin et al., 2019]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 334,
                    "end": 356,
                    "text": "[Radford et al., 2018]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 359,
                    "end": 381,
                    "text": "[Radford et al., 2019]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 384,
                    "end": 405,
                    "text": "[Raffel et al., 2019]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 412,
                    "end": 431,
                    "text": "[Chen et al., 2018]",
                    "ref_id": null
                },
                {
                    "start": 434,
                    "end": 452,
                    "text": "[Hao et al., 2019]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To that end, we introduce the Sequential Monte Carlo (SMC) recurrent Transformer which presupposes that the keys, queries, values and self-attention parameters are unobserved latent states evolving randomly through time. The model relies on a dynamical system inspired from the Transformer, capturing the uncertainty by replacing deterministic self-attention sequences by latent trajectories. The combination of self-attention through time with unobserved model noise allows to generate observations with a complex statistical structure. Self-attention vectors being unobserved stochastic variables, the log-likelihood of the observations is intractable and needs to be estimated. In this paper, we propose to use particle filtering and smoothing methods to draw samples from the distribution of hidden states given observations. The proposed algorithm is based on the auxiliary particle filter of [Liu and Chen, 1998, Pitt and Shephard, 1999] , the most widely used particle filtering method and a generalization of previous approaches such as the algorithms proposed in [Gordon et al., 1993] and [Kitagawa, 1996] . The theoretical properties of such methods to estimate the unknown distributions of the internal states and observations have been widely studied, usually in the context of hidden Markov models, see for instance [Del Moral, 2004] , [Capp\u00e9 et al., 2005] , [Del Moral et al., 2010] , [Del Moral et al., 2015] , [Douc et al., 2011] , [Dubarry and Le Corff, 2013] , [Olsson et al., 2017] , [Nguyen et al., 2017] .",
            "cite_spans": [
                {
                    "start": 898,
                    "end": 906,
                    "text": "[Liu and",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 907,
                    "end": 927,
                    "text": "Chen, 1998, Pitt and",
                    "ref_id": null
                },
                {
                    "start": 928,
                    "end": 943,
                    "text": "Shephard, 1999]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1072,
                    "end": 1093,
                    "text": "[Gordon et al., 1993]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1098,
                    "end": 1114,
                    "text": "[Kitagawa, 1996]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1329,
                    "end": 1346,
                    "text": "[Del Moral, 2004]",
                    "ref_id": null
                },
                {
                    "start": 1349,
                    "end": 1369,
                    "text": "[Capp\u00e9 et al., 2005]",
                    "ref_id": null
                },
                {
                    "start": 1372,
                    "end": 1396,
                    "text": "[Del Moral et al., 2010]",
                    "ref_id": null
                },
                {
                    "start": 1399,
                    "end": 1423,
                    "text": "[Del Moral et al., 2015]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1426,
                    "end": 1445,
                    "text": "[Douc et al., 2011]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1448,
                    "end": 1476,
                    "text": "[Dubarry and Le Corff, 2013]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1479,
                    "end": 1500,
                    "text": "[Olsson et al., 2017]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1503,
                    "end": 1524,
                    "text": "[Nguyen et al., 2017]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Fitting the Transformer approach to general state space modeling provides a new promising and interpretable statistical framework for sequential data and recurrent neural networks. From a statistical point of view, the SMC Transformer provides an efficient way of writing each observation as a sophisticated mixture of previous data, while the approximated posterior distribution of the unobserved states captures the states dynamics. We evaluate our model on a series of experiments that first assess the model's ability to predict accurately a known distribution of observations on synthetic datasets, and then apply it to uncertainty quantification in a time-series forecasting problem. The results show that the SMC Transformer manages to capture efficiently the known observation models in the synthetic setting. When performing the task of time-series forecasting on a critical dataset (daily deaths from the Covid-19), the SMC Transformer allows to maintain accurate mean predictions with satisfactory confidence intervals, that take in account the variability of the observations found in each test example.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The Transformer model has been originally developed to propose a new sequence transduction model without recurrence or convolution, and as an alternative to recurrent neural networks for sequence modeling, [Vaswani et al., 2017] . This approach relies entirely on the self-attention mechanism ([Lin et al., 2017] ) to model global dependencies regardless of their distance in input or output sequences. Let (X s ) s 1 be a sequence of observations indexed by N. Transformer models are designed to predict an output X s , for a given index s, from input data X \u2212s . Each input data X s is associated with a query q s and a set of key-value (k s , v s ) computed from linear transformations of the input. From the set of keys and queries, a softmax score function is first computed, which determines how much focus to place on each input in X \u2212s as X s is processed. Transformer models use a scaled dot product attention to compute this score \u03c0: \u03c0 s = softmax(Q s K T s / \u221a r), where each line of Q s (resp. K s ) contains an input query (resp. keys) and r denotes the dimensionality of keys and queries. Then, this softmax score is used to compute a weighted sum of the values vectors. The final attention is written as:",
            "cite_spans": [
                {
                    "start": 206,
                    "end": 228,
                    "text": "[Vaswani et al., 2017]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 293,
                    "end": 312,
                    "text": "([Lin et al., 2017]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "The Transformer model"
        },
        {
            "text": "where V s is the matrix whose rows are the values associated with each input data. The Transformer uses multihead self-attention: the data hidden representations are linearly projected in h subspaces where the attention is computed in parallel, leading to h outputs then concatenated back together.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The Transformer model"
        },
        {
            "text": "In real-world machine learning applications, the auxiliary states (queries, keys, values) as well as the observations used to train the neural network are prone to be very noisy. The use of a generative model replacing these deterministic states by random variables evolving according to a dynamical model allows to take into account the uncertainty in the estimation procedure instead of choosing fixed deterministic states. However, considering queries, keys and values as unobserved random variables leads to an intractable likelihood function as the log-likelihood of the observed data X 1:T , where X u1:u2 stands for (X u1 , . . . , X u2 ) for u 1 u 2 , is obtained by integrating out all latent variables which cannot be done analytically. The exact computation of the likelihood function is therefore not possible in general state spaces. Maximum likelihood estimation cannot be performed directly but a gradient descent algorithm may still be defined using Fisher's identity, see for instance [Capp\u00e9 et al., 2005] :",
            "cite_spans": [
                {
                    "start": 1002,
                    "end": 1022,
                    "text": "[Capp\u00e9 et al., 2005]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Sequential Monte Carlo Methods"
        },
        {
            "text": "where \u03b8 denotes the unknown parameters of the model, \u03b6 1:T denotes all the unobserved states, p \u03b8 the joint probability distribution of the observations X 1:T and the latent states and E \u03b8 the expectation under p \u03b8 . In this paper, we propose to estimate the gradient of the log-likelihood of such general state space model using Sequential Monte Carlo methods, i.e. by a set of random samples associated with non negative importance weights. These particle filters and smoothers approximations combine sequential importance sampling steps to recursively update conditional expectations of the form (1) and importance resampling steps to duplicate or discard particles according to their importance weights. By (1), \u2207 \u03b8 log p \u03b8 (X 1:T ) is then approximated by a weighted sample mean of the form",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential Monte Carlo Methods"
        },
        {
            "text": "where (\u03c9 m n ) 1 m M are nonnegative importance weights such that M m=1 \u03c9 m T = 1 and where \u03be m 1:T are trajectories approximately sampled from the posterior distribution of \u03b6 1:T given X 1:T when the parameter is \u03b8. This approximation of the score function can be plugged into any stochastic gradient algorithm to find local minima of \u03b8 \u2192 \u2212 log p \u03b8 (X 1:T ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Sequential Monte Carlo Methods"
        },
        {
            "text": "In the specific case of sequential data, Transformers-based approaches may be introduced to provide a model of the conditional distribution of X t given \u2206 past observations X t\u2212\u2206:t\u22121 where 1 \u2206 t.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "In a SMC Transformer with a unique layer, for all 1 s t and all 1 h n heads , define,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "Finally, self-attention of the input data is computed, for all 1 s \u2206, as,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "where \u03c0 h s (t) denotes the s-th component of \u03c0 h (t) (i.e. the self attention weight of the observation t\u2212s), (\u03a3 h,z ) 1 h n heads are unknown semi definite-positive matrices and (\u03b5 h z ) 1 h n heads are independent standard Gaussian random vectors in R r . Therefore, z h (t) is a Gaussian random variable with mean",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "The reparametrization trick is used to write z h (t) as a deterministic function of \u00b5 h (t) and \u03a3 h with \u03b5 h a random variable that does not depend on the parameters. Such trick provides a differentiable transition for the optimization process, see [Kingma and Welling, 2014] . The output r t is then computed with layer normalization and residual connection steps depending on a parameter \u03b7 state .",
            "cite_spans": [
                {
                    "start": 249,
                    "end": 275,
                    "text": "[Kingma and Welling, 2014]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "In a classification setting, the observation model provides a probability vector G \u03b7 obs (r t ) on the finite observation space based on the self-attention vectors. In a regression framework, the observation model is given by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "where G \u03b7 obs is a FFNN with linear ouput layer and \u03b5 t is a centered noise, for instance a centered Gaussian random vector with unknown variance \u03a3 obs . Let \u03b8 be the vector that contains all the unknown parameters of the model:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Generative model"
        },
        {
            "text": "By Section 3.1, the unobserved state at time t is \u03b6 t = {z(t), q(t), \u03ba(t), v(t)} and the complete-data likelihood may be written",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "where by convention if t \u2212 \u2206 1 then u t\u2212\u2206:s = u 1:s . The associated probability density functions are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "in a classification setting, and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "in a regression setting, where \u03d5 \u00b5,\u03a3 is the Gaussian probability density function with mean \u00b5 and covariance matrix \u03a3. By (1) and (2), the sequential Monte Carlo algorithm approximates \u2207 \u03b8 log p \u03b8 (X 1:T ) by a weighted sample mean:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "where the importance weights (\u03c9 m T ) 1 m M and the trajectories \u03be m 1:T are sampled according to the particle filter described below. In this paper, we propose to estimate all the parameters of the recurrent architecture based on a gradient descent using S M \u03b8,T . All parameters related to the noise (the covariance matrices) are estimated using an explicit Expectation Maximization (EM) update [Dempster et al., 1977] each time a batch of observations is processed, see the appendix materials for all details.",
            "cite_spans": [
                {
                    "start": 397,
                    "end": 420,
                    "text": "[Dempster et al., 1977]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "Particle filtering/smoothing algorithm. For all t 1, once the observation X t is available, the weighted particle sample {(\u03c9 m t , \u03be m 1:t )} N m=1 is transformed into a new weighted particle sample. This update step is carried through in two steps, selection and mutation, using the auxiliary sampler introduced in [Pitt and Shephard, 1999] . New indices and particles {(I m t+1 , \u03be m t+1 )} N m=1 are simulated independently as follows:",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 341,
                    "text": "[Pitt and Shephard, 1999]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "2. Sample \u03be m t+1 using the model introduced in Section 3.1 with the resampled trajectories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "For any m \u2208 {1, . . . , N }, the ancestral line \u03be 1:t+1 is updated as follows \u03be m 1:t+1 = (\u03be I m t+1 1:t , \u03be m t+1 ) and is associated with the importance weight defined by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "Therefore, in a classification setting, \u03c9 m t+1 \u221d [G \u03b7 obs (r m t+1 )] Xt+1 , and in a regression setting, \u03c9 m t+1 \u221d exp{\u2212 X t+1 \u2212 G \u03b7 obs (r m t+1 ) 2 \u03a3 obs /2}, where for any vector u, u 2 \u03a3 obs = u T \u03a3 \u22121 obs u. This smoother introduced in [Kitagawa, 1996] (see also [Del Moral, 2004 ] for a discussion) approximates the joint smoothing distributions of the latent states given the observations using the genealogy of the particles produced by the auxiliary particle filter. The genealogical trajectories are defined recursively and updated at each time step with the particles and indices (\u03be m k+1 , I m k+1 ). As a result, at each time step, the algorithm selects an ancestral trajectory by choosing its last state at time k which is extended using the newly sampled particle \u03be m k+1 . As explained for instance in [Kitagawa, 1996, Kitagawa and Sato, 2001] , [Fearnhead et al., 2010] and [Poyiadjis et al., 2011] , this algorithm suffers from the path degeneracy issue. At each time t 1, the first step to build a new trajectory is to select an ancestral trajectory chosen among M existing trajectories, as the number of resampling steps increases, the number of ancestral trajectories which are likely to be discarded increases. There are many solutions to improve the approximation S M \u03b8,T ; in this paper, we propose to use the fixed-lag smoother of [Olsson et al., 2008] , which means that for each 1 t n, the trajectories \u03be m t\u2212\u2206:t\u22121 involved in S M \u03b8,T are only resampled up to a few time steps after t.",
            "cite_spans": [
                {
                    "start": 243,
                    "end": 259,
                    "text": "[Kitagawa, 1996]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 270,
                    "end": 286,
                    "text": "[Del Moral, 2004",
                    "ref_id": null
                },
                {
                    "start": 820,
                    "end": 849,
                    "text": "[Kitagawa, 1996, Kitagawa and",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 850,
                    "end": 861,
                    "text": "Sato, 2001]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 864,
                    "end": 888,
                    "text": "[Fearnhead et al., 2010]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 893,
                    "end": 917,
                    "text": "[Poyiadjis et al., 2011]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1358,
                    "end": 1379,
                    "text": "[Olsson et al., 2008]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "Inference and predictive distribution. Based on the generative model proposed in this paper, usual objectives are the state estimation problem, which aims at recovering the latent attention parameter z t at time t given the observations X 1:t and the inference problem which aims at approximating the distribution of X t given X 1:t\u22121 . After a training phase which produces an estimate \u03b8 of \u03b8, the state estimation problem is usually solved by approximating the posterior mean of z t given the observations X 1:t when the model is driven by the parameter \u03b8:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "which may be approximated using the weighted samples at time t \u2212 1 by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "This distribution may be computed using the states dynamics which implies that p \u03b8 (z t |\u03be m 1:t\u22121 , X 1:t\u22121 ) is a Gaussian probability density function. A Monte Carlo approximation of the predictive probability p M \u03b8 (X t |X 1:t\u22121 ) may be obtained straightforwardly by sampling from p \u03b8 (z t |\u03be m 1:t\u22121 , X 1:t\u22121 ). This Monte Carlo estimate can be extended straightforwardly to predictions at future time steps.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The training algorithm"
        },
        {
            "text": "Consider first an experimental setting where the observations model is known to assess the ability of our model to capture the distributions of the observations. To that end, we designed two synthetic auto-regressive time-series with a sequence length of 24 observations. For model I, one data sample X = (X 0 , X 1 , ..., X 24 ) is drawn as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results on synthetic datasets"
        },
        {
            "text": "where (\u03b5 t ) 1 t 24 are i.i.d standard Gaussian variables independent of X 0 . For model II, the law of a new observation given the past is multimodal and drawn as follows: where (\u03b5 t ) 1 t 24 are i.i.d standard Gaussian variables independent of X 0 and (U t ) 1 t 24 are i.i.d Bernoulli random variables variables with parameter p independent of X 0 and of (\u03b5 t ) 1 t 24 . In the first experiment, the dataset is sampled with \u03b1 = 0.8 and \u03c3 2 = 0.5. In the second experiment, the dataset is sampled with \u03b1 = 0.9, \u03b2 = 0.6\u03b1, p = 0.7 and \u03c3 2 = 0.3. More details on the hyperparameters used for such experiments are provided in the appendix. Here, all covariance matrices of the SMC Transformer are assumed to be scalar. Table 1 displays the loss values and their associated standard deviations at the end of training over a 5-fold cross-validation. The displayed losses are the mean squared errors between the predictions (resp. weighted mean of the output particles) and the true observations for the LSTM (resp. the SMC Transformer).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 717,
                    "end": 724,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Results on synthetic datasets"
        },
        {
            "text": "The main interest of our generative model and our estimation procedure is displayed in Figure 1, Table 2 and Figure 2 . For each test example, at each time step t, 1000 samples are drawn from the SMC estimate of the law of X t+1 given X 0:t . A MC-Dropout approach as described in [Gal and Ghahramani, 2015, Section 4] is also used to estimate the uncertainty of X t+1 from 1000 stochastic forward passes through the LSTM network with dropout. In this table, dropout is added after the output of the LSTM layer. Figure 1 illustrates that the samples from the SMC estimate match the true distribution at each time step while the dropout samples highly underestimate its variability. These samples are compared in Figure 1 to the true 95% confidence interval at each time step which is available in this synthetic setting. Our generative model captures the probability distribution of the observations while the LSTM models fail to estimate the known variance of the observations. Based on these 1000 samples, Table 2 provides the empirical estimate of the mean squared error of the predictive distribution of X t+1 given the past for all time steps t. For Model I, it is given by E[(X t+1 \u2212 \u03b1X t ) 2 |X t ] (and the true value is \u03c3 2 = 0.5) and by",
            "cite_spans": [
                {
                    "start": 281,
                    "end": 318,
                    "text": "[Gal and Ghahramani, 2015, Section 4]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 87,
                    "end": 104,
                    "text": "Figure 1, Table 2",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 109,
                    "end": 117,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 512,
                    "end": 520,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 712,
                    "end": 720,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1008,
                    "end": 1015,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Results on synthetic datasets"
        },
        {
            "text": "for Model II. The means and standard deviations over the all time steps and all test examples illustrate how the SMC samples capture the true variability of the law of a new observation given the past. In this table, LSTM with dropout also in the LSTM layer are displayed. Dropout networks highly underestimate the variability which yields a predictive MSE too small for both the monomodal distribution (Model I) and the multimodal distribution (Model II). This is confirmed by Figure 2 which shows histograms over the 100 test examples and over all time steps of the frequency of the 1000 samples which fall in the true confidence interval. Over all test samples and time steps, 78.4% (resp. 93.6%) of the SMC with M = 30 (resp. LSTM with d = 64 and dropout = 0.5) samples fall into the 80% confidence interval. Additional results are available in the appendix. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 478,
                    "end": 486,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Results on synthetic datasets"
        },
        {
            "text": "The performance of the stochastic Transformer is analyzed using Covid-19 data 1 which gathers daily deaths from the Covid-19 disease in 3261 US cities. Cities with less than 100 deaths over the time period considered were discarded from the dataset: all algorithms are thus trained on 886 cities decomposed into 80% for training and 20% for test and validation. Figure 3 displays the 20 days ahead predictions, where the true observation is not available after day 40 and replaced by a sample from the estimated model, for three cities in the test dataset. Here, the variability of the observations is different for every sample: for our model, we first estimated a global variance of the observations at training time, and then fine-tuned the estimated noise per test sample at inference, using 30 iterations of an EM algorithm on the first 40 days. As the time horizon increases, the variability of our predictions increases, thus maintaining a satisfactory combination of mean prediction and error bars: the latter are crucial to model both the uncertainty in the observations measurements (e.g potential errors in data collection), and the natural randomness found in such problem, where daily death rates depend on complex dynamics and a multitude of external factors. On the other hand, the underestimation of the output variability given by the MC-Dropout samples for a rate of 0.2 is highlighted as it leads in some test examples to drifted predictions (see Maryland example on the graph). When increasing the dropout rate up to 0.5, the increase in variability comes at the cost of performance's degradation (see Fairfax example and the training table): this suggests that the confidence interval given by MC-Dropout is ill-calibrated, and that there is no easy tuning of the dropout rate that could give satisfactory error bars. Additional graph, results and full details about the hyper-parameters used for training are available in the appendix. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 362,
                    "end": 370,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Covid-19 data"
        },
        {
            "text": "The SMC Transformer is part of an emerging line of research which focuses on reconciling traditional model-based approaches and model-free ones that arose from the development of Deep Learning. One such approach similar to the SMC Transformer is the Particle Filter Recurrent Neural Network (PF-RNN) from [Ma et al., 2019] . Our work differs in several ways. First, the importance weights of the PF-RNN do not depend directly on the output of the RNN model, i.e. on an observation model estimated thanks to the SMC approach, but on a exterior learned function. The SMC Transformer uses Fisher's Identity to estimate the gradient of the likelihood of the observations, while the PF-RNN directly optimizes the classic cross-entropy loss and adds an evidence lower bound term in the objective function. The prediction algorithm of the PF-RNN only leverages the SMC algorithm to improve performance at training time and outputs a single-point estimate, thus failing to capture the observations distribution, which is the focus of our paper. On this topic, our work is related to Bayesian Deep Learning: two popular Bayesian methods to quantify uncertainty are MC-Dropout from [Gal and Ghahramani, 2015] and Bayes by Backprop from [Blundell et al., 2015] and its extension to RNNs [Fortunato et al., 2017] . By introducing randomness in the network's parameters or in the training algorithm, they both train an ensemble of neural networks giving a predictive distribution which tends to be overconfident (as illustrated in Section 4); while our method, based on stochastic states, learns directly an observation model almost able to capture perfectly the true variability of the observations.",
            "cite_spans": [
                {
                    "start": 305,
                    "end": 322,
                    "text": "[Ma et al., 2019]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1172,
                    "end": 1198,
                    "text": "[Gal and Ghahramani, 2015]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1226,
                    "end": 1249,
                    "text": "[Blundell et al., 2015]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1276,
                    "end": 1300,
                    "text": "[Fortunato et al., 2017]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "In this paper, we proposed the SMC Transformer, a novel recurrent network naturally capturing the observations distribution. The model maintains a distribution of self-attention parameters as latent states, estimated by a set of particles. It then outputs a distribution of predictions instead of a single-point estimate, and our inference method gives a flexible framework to quantify the observations variability.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The number of particles of the embedded algorithm is a hyper-parameter that can be tuned depending on the complexity of the task and dataset considered, and by taking in account the trade-off between training time and precision. To our knowledge, this is the first method dedicated to estimate uncertainty in the newly-developed Transformer model, and one of the few focusing on uncertainty quantification in the context of sequence prediction. This SMC Transformer layer could be used as a \"plug-and-play\" layer for uncertainty quantification in a deeper neural network representing sequential data: the data could be first encoded in a multi-layer neural network before being processed sequentially by the SMC Transformer layer. We specifically chose to focus on the Transformer model by having in mind future applications in the NLP field. We are indeed particularly interested in the diversity in language generation that could arise from the particle filter algorithm at inference. For such task, the distributions of words created by the SMC Transformer could naturally mimic the diversity and richness found in natural language.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The unobserved state at time t is \u03b6 t = {z(t), q(t), \u03ba(t), v(t)} and the complete-data likelihood may be written p \u03b8 (X 1:T , \u03b6 1:T ) = T t=1 p \u03b8 (\u03b6 t |\u03b6 t\u2212\u2206:t\u22121 , X t\u2212\u2206:t\u22121 )p \u03b8 (X t |\u03b6 t\u2212\u2206:t , X t\u2212\u2206:t\u22121 ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A SMC Transformer and the training algorithm"
        },
        {
            "text": "In the regression framework of this paper, the associated probability density functions is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A SMC Transformer and the training algorithm"
        },
        {
            "text": "where \u03d5 \u00b5,\u03a3 is the Gaussian probability density function with mean \u00b5 and covariance matrix \u03a3. A graphical representation of our model which describes the dependency between states and observations is proposed in Figure A .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 212,
                    "end": 220,
                    "text": "Figure A",
                    "ref_id": null
                }
            ],
            "section": "A SMC Transformer and the training algorithm"
        },
        {
            "text": "Hidden layer",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "Cell input",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "Output layer Figure 4 : Graphical representation of the SMC transformer for sequential data.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 13,
                    "end": 21,
                    "text": "Figure 4",
                    "ref_id": null
                }
            ],
            "section": "SMC Transformer"
        },
        {
            "text": "Particle filtering/smoothing algorithm. For all t 1, once the observation X t is available, the weighted particle sample {(\u03c9 m t , \u03be m 1:t )} N m=1 is transformed into a new weighted particle sample. This update step is carried through in two steps, selection and mutation, using the auxiliary sampler introduced in [Pitt and Shephard, 1999] . New indices and particles {(I m t+1 , \u03be m t+1 )} N m=1 are simulated independently as follows:",
            "cite_spans": [
                {
                    "start": 316,
                    "end": 341,
                    "text": "[Pitt and Shephard, 1999]",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "2. Sample \u03be m t+1 using the model with the resampled trajectories.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "In the regression framework of the paper, for any m \u2208 {1, . . . , N }, the ancestral line \u03be 1:t+1 is updated as follows \u03be m 1:t+1 = (\u03be I m t+1 1:t , \u03be m t+1 ) and is associated with the importance weight defined by The algorithm is illustrated in Figure 5 : particles at the last time step are in blue and pink particles are the ones which appear in the genealogy of at least one blue particle. White particle have not been selected to give birth to a path up to the last time. In Figure 5 , the N = 3 genealogical trajectories are \u03be 1 0:4 = (\u03be 3 0 , \u03be 2 1 , \u03be 2 2 , \u03be 3 3 , \u03be 1 4 ), \u03be 2 0:4 = (\u03be 3 0 , \u03be 1 1 , \u03be 3 2 , \u03be 2 3 , \u03be 2 4 ), \u03be 3 0:4 = (\u03be 3 0 , \u03be 2 1 , \u03be 2 2 , \u03be 3 3 , \u03be 3 4 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 247,
                    "end": 255,
                    "text": "Figure 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 481,
                    "end": 489,
                    "text": "Figure 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "SMC Transformer"
        },
        {
            "text": "The training algorithm The sequential Monte Carlo algorithm approximates \u2207 \u03b8 log p \u03b8 (X 1:T ) by a weighted sample mean:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "where the importance weights (\u03c9 m T ) 1 m M and the trajectories \u03be m 1:T are sampled according to the particle filter described below. Thanks to Fisher's identity, this approximation only requires to compute the gradient of the state model loglikelihood \u03b8 \u2192 log p \u03b8 (\u03be m t |\u03be m t\u2212\u2206:t\u22121 , X t\u2212\u2206:t\u22121 ) and the gradient of the observation model loglikelihood \u03b8 \u2192 log p \u03b8 (X t |\u03be m t\u2212\u2206:t , X t\u2212\u2206:t\u22121 ). There is no need to compute the gradient of the weights \u03c9 m T which depend on the parameter \u03b8. Using TensorFlow function tf.stop gradient on these weights, this allows to train the model with the following loss function:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "log p \u03b8 (\u03be m t |\u03be m t\u2212\u2206:t\u22121 , X t\u2212\u2206:t\u22121 ) + log p \u03b8 (X t |\u03be m t\u2212\u2206:t , X t\u2212\u2206:t\u22121 ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "In this paper, we propose to estimate all the parameters of the recurrent architecture based on a gradient descent using S M \u03b8,T . All parameters related to the noise (the covariance matrices) are estimated using an explicit Expectation Maximization (EM) update [Dempster et al., 1977] each time a batch of observations is processed. For each sequence of observations, the EM update relies on the approximation of the intermediate quantity",
            "cite_spans": [
                {
                    "start": 262,
                    "end": 285,
                    "text": "[Dempster et al., 1977]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "log p \u03b8 (\u03b6 t |\u03b6 t\u2212\u2206:t\u22121 , X t\u2212\u2206:t\u22121 ) + log p \u03b8 (X t |\u03b6 t\u2212\u2206:t , X t\u2212\u2206:t\u22121 )|X 1:T ] by the following particle-based estimator:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "log p \u03b8 (\u03be m t |\u03be m t\u2212\u2206:t\u22121 , X t\u2212\u2206:t\u22121 ) + log p \u03b8 (X t |\u03be m t\u2212\u2206:t , X t\u2212\u2206:t\u22121 ) .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "Then, Q M \u03b8,T may be maximized with respect to all covariances to obtain the new estimates. This is a straightforward update which yields for instance for \u03a3 obs for the p-th update:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "where r m t are the resampled particles at time t. The estimate \u03a3 obs of \u03a3 obs is then updated as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "where \u03b7 p is a learning rate chosen by the user (\u03b7 p = p \u22120.6 in the experiments).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "Inference and predictive distribution used in the experiments. To solve the inference problem, note that p \u03b8 (X t |X 1:t\u22121 ) = p \u03b8 (X t , z 1:t |X 1:t\u22121 )dz 1:t ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "which may be approximated using the weighted samples at time t \u2212 1 by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "A Monte Carlo approximation of the integral involved in the predictive probability p M \u03b8 (X t |X 1:t\u22121 ) may be obtained straightforwardly. In the experiments, p M \u03b8 was approximated as follows. For all 1 k N (with N = 1000 in our experiments), sample independently I k in {1, . . . , M } with weights proportional to (\u03c9 m t\u22121 ) 1 m M and then z k t from p \u03b8 (z t |\u03be I k 1:t\u22121 , X 1:t\u22121 ), i.e. from our transformer model with the selected past trajectory of hidden states \u03be I k 1:t\u22121 . Finally r k t can be computed from z k t and p M \u03b8 is approximated by N \u22121 N k=1 \u03d5 G\u03b7 obs (r k t ), \u03a3 obs (X t ) i.e. by a mixture of Gaussian distributions with means given by (r k t ) 1 k N and variance \u03a3 obs .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "SMC Transformer"
        },
        {
            "text": "The synthetic datasets were generated with 1000 samples: we used 800 of them for training and 100 of them for test and validation. For training the models, we used a batch size of 32, a number of epochs equal to 50, and the ADAM algorithm with a learning rate of 0.001 and the original custom schedule found in [Vaswani et al., 2017] . Table 4 displays the loss values and their associated standard deviations at the end of training over a 5-fold cross-validation. The displayed losses are the mean squared errors between the predictions (resp. weighted mean of the output particles) and the true observations for the LSTM (resp. the SMC Transformer). Additional dropout rates and a Transformer with d = 8 were considered to complete the experiments given in the main part of the paper. These neural networks were also considered in Table 5 .",
            "cite_spans": [
                {
                    "start": 311,
                    "end": 333,
                    "text": "[Vaswani et al., 2017]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [
                {
                    "start": 336,
                    "end": 343,
                    "text": "Table 4",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 833,
                    "end": 840,
                    "text": "Table 5",
                    "ref_id": "TABREF5"
                }
            ],
            "section": "B.1 Additional results on synthetic datasets"
        },
        {
            "text": "The hyper-parameters used for training the SMC Transformer and the LSTM with dropout were the following: the models were trained during 50 epochs with a batch size of 32, with a learning rate of 0.001 for the LSTM and the original learning rate with custom schedule from [Vaswani et al., 2017] . The LSTM with dropout include a dropout layer inside the LSTM layer, and before the output layer. Figure 6 displays another example of 20 days ahead predictions, where the true observation is not available after day 40 and replaced by a sample from the estimated model, for two cities in the test dataset. The figure shows that the confidence intervals given by the SMC Transformer capture almost entirely the true sequence of predictions for these two cities with high variability in daily death rates, which is not the case for the two LSTM with dropout. Figure 6 : 20 days ahead predictions of covid-19 daily deaths for 2 cities. The black lines represent the true predictions, and the colored areas represent the confidence interval given by a SMC Transformer with 10 particles, while the grey stripped (resp. dotted) areas represent the confidence intervals given by a LSTM with a dropout rate equal to 0.2 (resp. to 0.5). ",
            "cite_spans": [
                {
                    "start": 271,
                    "end": 293,
                    "text": "[Vaswani et al., 2017]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [
                {
                    "start": 394,
                    "end": 402,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 853,
                    "end": 861,
                    "text": "Figure 6",
                    "ref_id": null
                }
            ],
            "section": "B.2 Additional results on the Covid-19 data"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Weight uncertainty in neural networks",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "References",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Blundell",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 32nd International Conference on Machine Learning (ICML)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Uniform stability of a particle approximation of the optimal filter derivative",
            "authors": [
                {
                    "first": "Del",
                    "middle": [],
                    "last": "Moral",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "SIAM Journal on Control and Optimization",
            "volume": "53",
            "issn": "3",
            "pages": "1278--1304",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Maximum likelihood from incomplete data via the EM algorithm",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Dempster",
                    "suffix": ""
                }
            ],
            "year": 1977,
            "venue": "Journal of the Royal Statistical Society: Series B",
            "volume": "39",
            "issn": "1",
            "pages": "1--38",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Bert: Pretraining of deep bidirectional transformers for language understanding",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Devlin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
            "volume": "",
            "issn": "",
            "pages": "4171--4186",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Sequential monte carlo smoothing for general state space hidden markov models",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Douc",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The Annals of Applied Probability",
            "volume": "21",
            "issn": "6",
            "pages": "2109--2145",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Non-asymptotic deviation inequalities for smoothed additive functionals in nonlinear state-space models",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Dubarry",
                    "suffix": ""
                },
                {
                    "first": "Le",
                    "middle": [],
                    "last": "Corff ; Dubarry",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Le Corff",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Bernoulli",
            "volume": "19",
            "issn": "5B",
            "pages": "2222--2249",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A sequential smoothing algorithm with linear computational cost",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Fearnhead",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Biometrika",
            "volume": "97",
            "issn": "2",
            "pages": "447--464",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Bayesian recurrent neural networks",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Fortunato",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "authors": [
                {
                    "first": "Ghahramani ;",
                    "middle": [],
                    "last": "Gal",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gal",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Ghahramani",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 33rd International Conference on Machine Learning (ICML)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Novel approach to nonlinear/non-Gaussian bayesian state estimation",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Gordon",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "IEE Proc. F, Radar Signal Process",
            "volume": "140",
            "issn": "",
            "pages": "107--113",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "On calibration of modern neural networks",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 34th International Conference on Machine Learning",
            "volume": "70",
            "issn": "",
            "pages": "1321--1330",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Modeling recurrence for transformer",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Hao",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference of the North",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Auto-encoding variational bayes",
            "authors": [
                {
                    "first": "Welling ;",
                    "middle": [],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Welling",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Monte-Carlo filter and smoother for non-Gaussian nonlinear state space models",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kitagawa ; Kitagawa",
                    "suffix": ""
                }
            ],
            "year": 1996,
            "venue": "Journal of Computational and Graphical Statistics",
            "volume": "1",
            "issn": "",
            "pages": "1--25",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Monte carlo smoothing and selforganizing state-space model",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Kitagawa",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sato ; Kitagawa",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sato",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Sequential Monte Carlo methods in Practice",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Training confidence-calibrated classifiers for detecting out-of-distribution samples",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "6th International Conference on Learning Representations",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "A structured self-attentive sentence embedding",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Sequential Monte Carlo methods for dynamic systems",
            "authors": [
                {
                    "first": "Chen",
                    "middle": [
                        ";"
                    ],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Journal of the American Statistical Association",
            "volume": "93",
            "issn": "",
            "pages": "1032--1044",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Particle filter recurrent neural networks. CoRR, abs/1905.12885",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "On the two-filter approximations of marginal smoothing distributions in general state-space models",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Advances in Applied Probability",
            "volume": "50",
            "issn": "1",
            "pages": "154--177",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Sequential monte carlo smoothing with application to parameter estimation in nonlinear state space models",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Olsson",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Bernoulli",
            "volume": "14",
            "issn": "1",
            "pages": "155--179",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Efficient particle-based online smoothing in general hidden markov models: the paris algorithm",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Olsson",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Bernoulli",
            "volume": "23",
            "issn": "3",
            "pages": "1951--1996",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Filtering via simulation: Auxiliary particle filters",
            "authors": [
                {
                    "first": "Shephard ;",
                    "middle": [],
                    "last": "Pitt",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Pitt",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Shephard",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Journal of the American Statistical Association",
            "volume": "94",
            "issn": "446",
            "pages": "590--599",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Particle approximations of the score and observed information matrix in state space models with application to parameter estimation",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Poyiadjis",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Biometrika",
            "volume": "98",
            "issn": "",
            "pages": "65--80",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Improving language understanding by generative pre-training",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Radford",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Language models are unsupervised multitask learners",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Radford",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "OpenAI Blog",
            "volume": "",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Raffel",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1910.10683"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Attention is all you need",
            "authors": [
                {
                    "first": "[",
                    "middle": [],
                    "last": "Vaswani",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "5998--6008",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Samples distribution from each approach on a test example (Model I).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Frequency of the 1000 samples in the true 95% (right) and 80% (left) confidence intervals (Model I).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "20 days ahead predictions given by a SMC Transformer (d = 8, M = 10), and 2 MC-Dropout LSTM (d = 64, dropout rate of 0.2 and 0.5). The black lines correspond to the ground truth. The colored (resp. grey stripped and grey dotted) areas correspond to the variability of the SMC Transformer (resp. 2 MC-Dropout LSTM with dropout of 0.2 and 0.5) predictions, i.e an interval of mean \u00b1 std over the 1000 samples at each time step.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Particle filter: N = 3, n = 4.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Brosse et al., 2020]  Brosse, N., Riquelme, C., Martin, A., Gelly, S., and Moulines,\u00c9. (2020). On last-layer algorithms for classification: Decoupling representation from uncertainty estimation. arXiv preprint arXiv:2001.08049.[Capp\u00e9 et al., 2005] Capp\u00e9, O., Moulines, E., and Ryd\u00e9n, T. (2005). Inference in Hidden Markov Models. Springer. [Chen et al., 2018] Chen, M. X., Firat, O., Bapna, A., Johnson, M., Macherey, W., Foster, G., Jones, L., Parmar, N., Schuster, M., Chen, Z., et al. (2018). The best of both worlds: Combining recent advances in neural machine translation. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), 1:76-86. [Corbi\u00e8re et al., 2019] Corbi\u00e8re, C., Thome, N., Bar-Hen, A., Cord, M., and P\u00e9rez, P. (2019). Addressing failure prediction by learning model confidence. In Advances in Neural Information Processing Systems, pages 2898-2909. [Del Moral, 2004] Del Moral, P. (2004). Feynman-Kac Formulae. Genealogical and Interacting Particle Systems with Applications. Springer. [Del Moral et al., 2010] Del Moral, P., Doucet, A., and Singh, S. S. (2010). A backward particle interpretation of feynman-kac formulae. ESAIM: Mathematical Modelling and Numerical Analysis, 44(5):947-975.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Train and validation losses (\u00d710 \u22122 ) for synthetic data.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Mean squared error of the predictive distribution over 1000 samples on 100 test examples. The symbol separates between dropout only after the output of the LSTM layer (left) and full dropout (right). E t \u03b1",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Train and validation losses for covid data.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "displays the training results for different LSTM with Dropout and SMC Transformer architectures.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Train and validation losses (\u00d710 \u22122 ) for synthetic data. = 32, drop = 0.1 49.91 (0.10) 50.24 (0.58) 32.21 (0.09) 32.28 (0.69) d = 32, drop = 0.2 50.43 (0.04) 50.79 (0.73) 32.49 (0.10) 32.50 (0.65) d = 32, drop = 0.3 50.93 (0.26) 51.13 (0.54) 32.87 (0.07) 32.88 (0.65) d = 32, drop = 0.4 51.89 (0.29) 51.98 (1.17) 34.11 (0.15) 34.02 (0.87) d = 32, drop = 0.5 52.78 (0.36) 53.26 (1.10) 34.75 (0.18) 34.81 (0.90) d = 64, drop = 0.1 49.76 (0.10) 50.14 (0.66) 32.06 (0.10) 32.17 (0.58) d = 64, drop = 0.2 50.02 (0.13) 50.39 (0.70) 32.21 (0.13) 32.37 (0.67) d = 64, drop = 0.3 50.37 (0.11) 50.81 (0.55) 32.40 (0.14) 32.46 (0.68) d = 64, drop = 0.4 50.77 (0.36) 51.07 (1.15) 33.39 (0.23) 33.34 (0.90) d = 64, drop = 0.5 51.33 (0.41) 51.59 (1.29) 33.70 (0.24) 33.99 (0.79)",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Mean squared error of the predictive distribution over 1000 samples on 100 test examples. The symbol separates between dropout only after the output of the LSTM layer (left) and full dropout (right).E t \u03b1 = E[(X t+1 \u2212 \u03b1X t ) 2 |X t ] and E t \u03b2 = E[(X t+1 \u2212 \u03b2X t ) 2 |X t ].",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}