{
    "paper_id": "d4e164dcbb27d8429f5fe61d9dd3540eecadb755",
    "metadata": {
        "title": "Wearable and Continuous Prediction of Passage of Time Perception for Monitoring Mental Health",
        "authors": [
            {
                "first": "Lara",
                "middle": [],
                "last": "Orlandic",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Embedded Systems Laboratory (ESL)",
                    "institution": "Swiss Federal Institute of Technology Lausanne (EPFL)",
                    "location": {
                        "country": "Switzerland"
                    }
                },
                "email": "[lara.orlandic@epfl.ch"
            },
            {
                "first": "Adriana",
                "middle": [
                    "Arza"
                ],
                "last": "Valdes",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Embedded Systems Laboratory (ESL)",
                    "institution": "Swiss Federal Institute of Technology Lausanne (EPFL)",
                    "location": {
                        "country": "Switzerland"
                    }
                },
                "email": ""
            },
            {
                "first": "David",
                "middle": [],
                "last": "Atienza",
                "suffix": "",
                "affiliation": {
                    "laboratory": "Embedded Systems Laboratory (ESL)",
                    "institution": "Swiss Federal Institute of Technology Lausanne (EPFL)",
                    "location": {
                        "country": "Switzerland"
                    }
                },
                "email": "david.atienza]@epfl.ch"
            }
        ]
    },
    "abstract": [
        {
            "text": "A person's passage of time perception (POTP) is strongly linked to their mental state and stress response, and can therefore provide an easily quantifiable means of continuous mental health monitoring. In this work, we develop a custom experiment and Machine Learning (ML) models for predicting POTP from biomarkers acquired from wearable biosensors. We first confirm that individuals experience time passing slower than usual during fear or sadness (p = 0.046) and faster than usual during cognitive tasks (p = 2 \u00d7 10 \u22125 ). Then, we group together the experimental segments associated with fast, slow, and normal POTP, and train a ML model to classify between these states based on a person's biomarkers. The classifier had a weighted average F-1 score of 79%, with the fast-passing time class having the highest F-1 score of 93%. Next, we classify each individual's POTP regardless of the task at hand, achieving an F-1 score of 77.1% when distinguishing time passing faster rather than slower than usual. In the two classifiers, biomarkers derived from the respiration, electrocardiogram, skin conductance, and skin temperature signals contributed most to the classifier output, thus enabling real-time POTP monitoring using noninvasive, wearable biosensors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "The way in which humans perceive the passage of time is a psychological and neurological phenomenon linked to emotions, memory, attention, and the body's response to stress [1] , [2] . When people are busy, amused or excited, they experience time passing faster than it truly does. Conversely, when people are afraid or under stress, time seems to slow down [1] - [3] . Furthermore, during the recent COVID-19 pandemic lockdown, it was found that the experience of time passing slowly was associated with increased stress, decreased task load, and decreased satisfaction with one's amount of social interactions [4] . Moreover, a person's passage of time perception (POTP) is a quantifiable measure that is intricately linked to their mental state [3] .",
            "cite_spans": [
                {
                    "start": 173,
                    "end": 176,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 179,
                    "end": 182,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 358,
                    "end": 361,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 364,
                    "end": 367,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 612,
                    "end": 615,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 748,
                    "end": 751,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Along with distortions in POTP, various emotions also induce changes in physiological processes such as heart rate, blood pressure, muscular contraction and respiration [3] , [5] . This phenomenon illustrates the notion that our perception of time is related to our homeostatic state, and thus, to our physiological stress response that our body triggers to deal with a disturbance in homeostatic balance [6] .",
            "cite_spans": [
                {
                    "start": 169,
                    "end": 172,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 175,
                    "end": 178,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 405,
                    "end": 408,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Physiological monitoring through noninvasive biosensors has previously been used as a means of monitoring mental health conditions including depression, anxiety, bipolar dis-orders, and many more [7] . These sensors enable continuous measurements and online estimations of a person's emotions [8] , thereby providing real-time insights into their mental state and facilitating timely interventions in the case of deteriorating mental health. Biomarkers computed from such sensors have been previously used to classify a person's stress response [8] , [9] , cognitive load [10] , and emotions on the arousal-valence scale [11] . However, no study has thus far has used unobtrusively measured biosignals to predict individuals' POTP, which provides additional insights into their mental state.",
            "cite_spans": [
                {
                    "start": 196,
                    "end": 199,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 293,
                    "end": 296,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 545,
                    "end": 548,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 551,
                    "end": 554,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 572,
                    "end": 576,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 621,
                    "end": 625,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this study, we assess the hypothesis that a person's POTP relates to their stress-related physiological processes, as these relate to their mental state. Thus, we aim to use noninvasive biosignal monitoring and Machine Learning (ML) tools to predict a person's POTP, both directly through binary classification, and indirectly through multi-class prediction of activities that elicit significant changes in POTP. We first investigate the correlations between different induced emotions and their effects on subjects' POTP. Then, we propose a ML model training and optimization procedure for predicting the experimental segment -and its corresponding POTP -a subject experienced given their physiological features. Next, we use this ML technique to distinguish periods of fast time perception from those of slow time perception across all experimental segments. Finally, we investigate the influence of individual biomarkers in the POTP and emotion classification outcome to determine which features affect each model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The set of contributions of this work, namely, the quantification and classification of POTP, is presented in Fig. 1 . First, various emotional states are induced in the subject through a custom-designed experimental protocol. Since the physiological stress response has been associated with different levels of cognitive workload, job performance, emotions, and optimal physical states [8] , [9] , we investigate multiple biosignals and the correlation of their changes with the perception of passage of time during a variety of stimuli that elicit different emotions, cognitive loads, and stress levels. Thus, we induce emotions and cognitive states on a set of participants as they perform specific tasks and watch emotional short films while we measure their response to these stimuli, as well as their sense of the passage of time.",
            "cite_spans": [
                {
                    "start": 387,
                    "end": 390,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 393,
                    "end": 396,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [
                {
                    "start": 110,
                    "end": 116,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "II. METHODS"
        },
        {
            "text": "Throughout the experiment, five biosignals are measured -electrocardiogram (ECG), skin temperature (SKT), electro- dermal activity (EDA), respiration (RSP), and photoplethysmography (PPG) -for their proven contribution to emotion and psychological stress monitoring [8] , [9] . Next, we develop a ML optimization procedure to select the ML model and hyperparameters that perform the best classification of emotional states and time perceptions based on the subjects' physiological features. Finally, the models are tested to predict subjects' emotional states and time perceptions.",
            "cite_spans": [
                {
                    "start": 266,
                    "end": 269,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 272,
                    "end": 275,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "II. METHODS"
        },
        {
            "text": "In order to investigate the relationship between subjects' emotional state and their POTP, we designed an experiment to elicit various emotions in healthy volunteers using films, cognitive tasks, and intermittent rest states. The exact experimental protocol and the groupings of segments for statistical analysis are displayed in Table I : The video clips were selected from the Emotional Movie [12] and the FilmStim Databases [13] , which are two validated databases containing footage to induce specific emotions. The mathematics activity consists of solving arithmetic tasks given time constraints with startling negative feedback [14] . The Stroop Color Test is a color-word reading exercise used to measure cognitive flexibility and working memory [15] .",
            "cite_spans": [
                {
                    "start": 395,
                    "end": 399,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 427,
                    "end": 431,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 634,
                    "end": 638,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 753,
                    "end": 757,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [
                {
                    "start": 330,
                    "end": 337,
                    "text": "Table I",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "A. Induced Emotional States: Experimental Protocol Design"
        },
        {
            "text": "Between experimental segments, the subject completes a questionnaire including a visual analogue scale for stress (VASS), in which they select their stress level at that moment from 0 to 100 [16] . Also, the subjects estimate the duration of the past experimental segment using a time scale ranging from 0 to 5 minutes in increments of 30 seconds. Rest phases are included between experimental phases to give the subject time to reset their emotional state to its baseline. During the experiment, the Shimmer Node3 ECG [17] and Empatica E4 wristband [18] , which are two lightweight and unobtrusive sensing devices, are used to measure the 5 biosignals.",
            "cite_spans": [
                {
                    "start": 191,
                    "end": 195,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 519,
                    "end": 523,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 550,
                    "end": 554,
                    "text": "[18]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A. Induced Emotional States: Experimental Protocol Design"
        },
        {
            "text": "There were 18 participants recruited for this study: 13 males and 5 females between the ages of 22 and 31. Each experiment was conducted in one sitting using a custom-made Android application to display the instructions and tasks. The ethical approval for this study was obtained from the Cantonal Ethics Commissions for Human Research Vaud (ID 2019-00321).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Induced Emotional States: Experimental Protocol Design"
        },
        {
            "text": "The body's physiological response to emotions and stress is characterized by the combination of several biometric variables [9] . These variables can be monitored through parameters derived from biosignals that are unobtrusively measured and continuously monitored. After preprocessing each signal (i.e., filtering and delineation), various parameters are extracted. The preprocessing algorithms and primary parameters obtained from each time series signal are computed as in [8] , [10] , and [19] . Next, 80 physiological features in the time and frequency domains are extracted from the parameters in segmentation windows of 45s. Previous works have used windows of length 60s [8] , [9] , [20] , but learning curves indicated that this produced insufficient data for training. Therefore, we reduced the window length for feature extraction to 45s as a data augmentation technique. These features capture the subject's physiological response during each emotional state. Several key biosignal parameters and features from were the biomarkers are selected, are described as follows:",
            "cite_spans": [
                {
                    "start": 124,
                    "end": 127,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 476,
                    "end": 479,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 482,
                    "end": 486,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 493,
                    "end": 497,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 679,
                    "end": 682,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 685,
                    "end": 688,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 691,
                    "end": 695,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "B. Biosignal Measurement and Analysis"
        },
        {
            "text": "1) SKT: For the SKT signal, we compute the gradient (SKT gradient) and total power, (SKT power) of its power spectral density (PSD).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Biosignal Measurement and Analysis"
        },
        {
            "text": "2) EDA: The EDA signal is divided into two main components: the skin conductance level (SCL) and the skin conductance response (SCR) as the driver phasic signal (SCR power). The gradient and mean of the SCL (SCL gradient, SCL mean) are obtained.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Biosignal Measurement and Analysis"
        },
        {
            "text": "3) RSP: We compute respiration rate and period (RSP Rate,RSP P rd), duration of air inhaled (InspT ime) and exhaled (ExpT ime) and compute statistics based on these parameters. In the frequency domain, we compute the PSD in four different bands of equal bandwidth between 0-1 Hz (RSP P SD 1\u22124 ). Additionally, we consider the normalized band power in these four bands (RSP nP SD 1\u22124 ), as well as in 5 fine-grained bands in 0.08-0.6 Hz (RSP pBF 1\u22125 ). Then, we extract RSP F 1pond, which is the mean frequency of a Gaussian distribution used to fit the PSD estimated in the HF band (0.15 \u2212 0.5Hz). Moreover, we applied the method proposed in [21] to compute the estimated respiratory frequency, as the largest peak power (RSP P k) of the Lomb-Scargle PSD of respiration using a Welch periodogram. Finally, we compute the average signal power across all windows (RSP power). [22] , and then features are extracted based on the Heart Rate Variability (HRV) analysis [23] , such as its mean (ECG RR mean), median (ECG RR median) and standard deviation (ECG RR SDN N ). Additionally, we compute its normalized bandpower in the very low frequency (ECG RR nV LF ), low frequency (ECG RR nLF ), and high frequency (ECG RR nHF ) bands centered at 0.04 Hz, 0.15 Hz, and 0.4 Hz, respectively. Non-linear features are also extracted from Poincar\u00e9 plot indicating vagal and sympathetic function. They are the following: the length of the transverse axis (ECG RR T ), the length of the longitudinal axis (ECG RR L), and their ratio, called Cardiac Sympathetic Index (ECG RR CSI), as well as the modified CSI (ECG RR CSI modif ied) [20] .",
            "cite_spans": [
                {
                    "start": 642,
                    "end": 646,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 874,
                    "end": 878,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 964,
                    "end": 968,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 1618,
                    "end": 1622,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "B. Biosignal Measurement and Analysis"
        },
        {
            "text": "We compute several PPG parameters, including the pulse period (P P G P P ), pulse wave rising time (P P G P RT ), pulse wave decreasing time (P P G P DT ), pulse width until reflected wave (P P G P W ). We then extract ensemble statistics from each parameter, as well as the same frequency analysis as for the RR intervals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "5) PPG:"
        },
        {
            "text": "In order to quantify subjects' POTP, we define the relative time estimation error metric t rel . This metric is calculated based on the correct segment time t correct and the subjects' estimation of the passed time t perceived , as shown in Equation 1. A positive t rel means that the person experienced time as passing faster than it truly did, whereas a negative t rel corresponds to the perception of time passing slower.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Passage of Time Perception Assessment"
        },
        {
            "text": "The segments are grouped into three categories, as displayed in Table I : emotional, cognitive, and neutral. Neutral segments are placed after the initial rest period to avoid bias by any previous experimental segment or sensor placement. We then test the statistical significance in the difference of means of t rel for each category to confirm previous hypotheses that each segment corresponds to a given POTP.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 64,
                    "end": 71,
                    "text": "Table I",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "C. Passage of Time Perception Assessment"
        },
        {
            "text": "Next, we train ML models to predict a person's POTP based on their physiological features. Hence, we perform two classification tasks: a binary classification to determine when each person determines that time is passing faster rather than slower than usual, as well as a multiclass classification of the experimental state of the user (emotional, cognitive, neutral), as these states each correspond to a different POTP.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. ML Model of Emotional State and Time Passage"
        },
        {
            "text": "We compare 8 state-of-the art ML classification algorithms to perform the inference: Logistic Regression (LogReg), Decision Tree Classifier (DTC), k Nearest Neighbor (KNN), Linear Discriminant Analysis (LDA), Gaussian Naive Bayes (GNB), Support Vector Machines (SVM), Random Forest (RF) and eXtreme Gradient Boosting (XGB). A ML model development pipeline is implemented to ensure generalizability of the chosen model across all subjects, as displayed in Fig. 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 455,
                    "end": 461,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "D. ML Model of Emotional State and Time Passage"
        },
        {
            "text": "First, every biosignal for each experimental segment is divided into 45 s non-overlapping segments. The signals are then preprocessed and the aforementioned features are extracted. Features with multiple NaN values are removed as they may be unstable. Then, all features are scaled by subtracting the mean and dividing by the standard deviation of each feature using the training dataset. In both classification tasks, the same randomly-selected 22% of subjects is designated as the testing set to assess the generalizability of the trained model. No samples belonging to the same subject appear in both the testing and training sets, nor the training and validation sets of each cross-validation (CV) fold.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. ML Model of Emotional State and Time Passage"
        },
        {
            "text": "Next, we train all eight ML models and perform 10fold Leave-n-Subjects-Out CV, thereby ensuring that signal segments belonging to the same subject are not used for training and validation at a given CV fold. 20% of the subjects are used for validation in each fold. The utilized metric is the F-1 score in the case of binary classification, and weighted average F-1 score in the multi-label case. The selected model is the one with the highest mean F-1 score across the training folds. In the case that multiple algorithms produce similar mean F-1 scores, the learning curves of the algorithms are analyzed to examine the bias-variance tradeoff. The model with the higher variance than bias is selected, as the subsequent hyperparameter optimization and feature elimination steps intend to reduce overfitting [24] .",
            "cite_spans": [
                {
                    "start": 809,
                    "end": 813,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "D. ML Model of Emotional State and Time Passage"
        },
        {
            "text": "Once the algorithm is selected, its hyperparameters are tuned using Tree-structured Parzen Estimators (TPE) [25] with the objective of maximizing the mean CV F-1 score. Next, Recursive Feature Elimination with Cross-Validation (RFECV) is performed to remove features that do not contribute to the classification outcome [24] . Following RFECV, the aforementioned TPE procedure is performed to re-optimize the model to its new feature set.",
            "cite_spans": [
                {
                    "start": 108,
                    "end": 112,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 320,
                    "end": 324,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "D. ML Model of Emotional State and Time Passage"
        },
        {
            "text": "First, we analyze the results of the statistical analysis of relative time errors in the feature set to determine which experimental segments truly produce significant POTP distortions. We use this information, along with the distribution of t rel ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "III. RESULTS"
        },
        {
            "text": "The average t rel across all subjects for each segment are displayed in Fig. 3 . We can see that the most positive t rel occurs for the mathematics test, whereas the most negative one occurs for the fear clip.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 72,
                    "end": 78,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "A. Passage of Time Perception"
        },
        {
            "text": "Next, we performed one-sample, one-tailed t-tests to determine whether or not these time errors deviated significantly from zero during each experimental segment. Tasks corresponding to the same hypothesized POTP direction were grouped together, as described in Section I. The null hypothesis for neutral (rest and neutral clip) and emotional (fear and sadness) tasks is that the time error is less than zero, since people typically perceive time as passing slower when they are bored or afraid. Conversely, for the cognitive (mathematics and Stroop) tasks, we ran a right-tailed t-test, since people normally perceive time as passing faster when they are busy. This grouping leads to a nearly balanced sample of neutral, emotional, and cognitive segments.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Passage of Time Perception"
        },
        {
            "text": "The results of the t-tests are summarized in Table II . The neutral segments showed no significant deviation from zero (p = 0.942). Conversely, the cognitive tasks and the emotional tasks were significantly higher than zero (p = 2.01\u00d710 \u22125 ) and lower than zero (p = 0.0456), respectively. The sadness clip showed significant variance in t rel and no significant deviation from zero by itself, perhaps due to the short duration of the clip and subjectivity in individuals' perceptions of sadness. The reported VASS stress levels were highest during the mathematics task (63 \u00b1 26) and fear clips (38 \u00b1 20). There Finally, to facilitate classification based directly on POTP, we define thresholds on t rel to identify biosignal segments during which the individual subjects experience time passing significantly fast and slowly. Fig. 4 shows a histogram of all t rel values in the training dataset. We notice a bi-modal distribution of positive and negative time errors, so we fit Gaussian curves to the positive and negative t rel values. The upper threshold is located two standard deviations to the right of the mean of negative t rel values, while the lower threshold is two standard deviations to the left of the positive t rel mean. This process provides an empirical estimation of statistically significant low and high values of t rel .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 45,
                    "end": 53,
                    "text": "Table II",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 827,
                    "end": 833,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "A. Passage of Time Perception"
        },
        {
            "text": "Therefore, our final classification labels for the passage of time are as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Passage of Time Perception"
        },
        {
            "text": "This grouping leads to an imbalanced sample of the two classes, since there are about twice as many segments in which time passes faster rather than slower.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Passage of Time Perception"
        },
        {
            "text": "Once we determined which experimental states corresponded to a faster, slower, or normal POTP, we built a ML model to classify these states. We first use the procedure described in Fig. 2 to train a ML model to determine whether a person was in the emotional, cognitive, or neutral phases of the experiment based on their physiological features. The algorithm selection procedure is shown in Fig. 5 , which displays the CV F-1 scores of each model. We note from Fig. 5 that SVM exhibits the highest mean F-1 score, but its standard deviation is much larger than that of RF, which has a similar mean. To finalize our model selection, we examine the learning curves, as shown in Fig. 6 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 181,
                    "end": 187,
                    "text": "Fig. 2",
                    "ref_id": null
                },
                {
                    "start": 392,
                    "end": 398,
                    "text": "Fig. 5",
                    "ref_id": null
                },
                {
                    "start": 462,
                    "end": 468,
                    "text": "Fig. 5",
                    "ref_id": null
                },
                {
                    "start": 677,
                    "end": 683,
                    "text": "Fig. 6",
                    "ref_id": null
                }
            ],
            "section": "B. POTP Classification"
        },
        {
            "text": "We can see that the training and CV accuracies of the SVM model converge quickly to around 0.7, implying low variance and high bias, and in the RF there remains a large gap between the training and validation accuracies, implying high variance. We therefore select the RF model for further analysis because its variance can be reduced using TPE and RFECV. Following TPE, the average CV score of the RF model increased by 7.2%, as shown in Table III . Then, RFECV revealed that the optimal number of features was 45. The final model is then tested on new, unseen data from four subjects. The results are displayed in the confusion matrix in Fig. 7 , as well as the F-1 scores in Table IV . We can see that the \"Fast POTP\" class is the easiest for the classifier to distinguish, with a 100% precision and highest F-1 score of 93%. Most of the misclassifications are due to the \"No Change in POTP\" signals being classified as \"Slow POTP\" signals. The weighted average of the F-1 scores of all classes with respect to the number of data points per class is 79%. Finally, we compute the Shapley (SHAP) values of the model, which are measures of the relative importance of the features in the model's classification decision [26] . The features and their relative importances to each class are displayed in Fig. 8 The way a person perceives the passage of time is a quantifiable metric that indicates their mental state. Therefore, continuous monitoring of subjects' POTP may provide insights into their mental well-being. In this work, we have developed an experiment to induce certain emotions that have known effects on the passage of time. Our results have confirmed our hypotheses that people consistently interpret time as passing slower during fear or sadness (p = 0.046), and faster during mentally taxing tasks (p = 2\u00d710 \u22125 ). Then, we have developed a classifier to predict which experimental state, which is correlated to a change or lack thereof in POTP, a subject experienced based on physiological features extracted from unobtrusively measured biosignals. This classifier obtained a weighted average F-1 score of 79%, with fast POTP tasks being the easiest to distinguish with an F-1 score of 93%.",
            "cite_spans": [
                {
                    "start": 1219,
                    "end": 1223,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 439,
                    "end": 448,
                    "text": "Table III",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 640,
                    "end": 646,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 678,
                    "end": 686,
                    "text": "Table IV",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1301,
                    "end": 1307,
                    "text": "Fig. 8",
                    "ref_id": null
                }
            ],
            "section": "B. POTP Classification"
        },
        {
            "text": "Next, we classify the POTP directly by identifying segments with significantly high and low t rel values regardless of the task at hand. We obtain a 77.1% F-1 score in distinguishing time passing fast rather than slow, meaning that is possible to determine a person's POTP based solely on their physiological signals. When we analyzed the feature importance of the two models, the emotion classifier used more diverse biosignals than the POTP classifier, the latter of which did not heavily weigh features derived from SCL or SKT. Both classifiers place heavy importance on the ECG RR median, ECG RR mean, ECG RR SDN N , and RSP InspT ime mean biomarkers. These results indicate that by monitoring a few biosignals with simple, wearable sensors, it is possible to unobtrusively monitor POTP and mental state on a continuous basis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. POTP Classification"
        },
        {
            "text": "In the future, these preliminary results may be enhanced by using a larger, more diverse sample of subjects for testing and training, as well as longer experimental segments. These factors may help overcome the high variance seen in t rel of the sadness clip, as well as the class imbalance in the binary classification task. With more individuals and longer biosignal durations, Deep Learning analysis may be employed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. POTP Classification"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "How emotions colour our perception of time",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Droit-Volet",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Meck",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "Trends in Cognitive Sciences",
            "volume": "11",
            "issn": "12",
            "pages": "504--513",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "The influence of social stress on time perception and psychophysiological reactivity",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Van Hedger",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Psychophysiology",
            "volume": "54",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "The emotional body and time perception",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Droit-Volet",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gil",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Cognition and Emotion",
            "volume": "30",
            "issn": "4",
            "pages": "687--699",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "The passage of time during the UK Covid-19 lockdown",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Ogden",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "PLoS ONE",
            "volume": "15",
            "issn": "7",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Human emotion recognition using heart rate variability analysis with spectral bands based on respiration",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "T"
                    ],
                    "last": "Valderas",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
            "volume": "",
            "issn": "",
            "pages": "6134--6137",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "From psychological stress to the emotions: a history of changing outlooks",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "S"
                    ],
                    "last": "Lazarus",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Annual review of psychology",
            "volume": "44",
            "issn": "",
            "pages": "1--21",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Automatic stress detection in working environments from smartphones' accelerometer data: A first step",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Garcia-Ceja",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Osmani",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Mayora",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Journal of Biomedical and Health Informatics",
            "volume": "20",
            "issn": "4",
            "pages": "1053--1060",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Multi-modal acute stress recognition using offthe-shelf wearable devices",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Montesinos",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society",
            "volume": "",
            "issn": "",
            "pages": "2196--2201",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Measuring acute stress response through physiological signals: towards a quantitative assessment of stress",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Arza",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical and Biological Engineering and Computing",
            "volume": "8",
            "issn": "",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Self-aware machine learning for multimodal workload monitoring during manual labor on edge wearable sensors",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Masinelli",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Design and Test",
            "volume": "2356",
            "issn": "c",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMI-GOS)",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Santamaria-Granados",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Access",
            "volume": "7",
            "issn": "",
            "pages": "57--67",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "The emotional movie database (EMDB): A self-report and psychophysiological study",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Carvalho",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Applied Psychophysiology Biofeedback",
            "volume": "37",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Schaefer",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Cognition and Emotion",
            "volume": "24",
            "issn": "7",
            "pages": "1153--1172",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Encyclopedia of Social Psychology",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Baumeister",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Vohs",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "The Stroop color and word test",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Scarpina",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Tagini",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Frontiers in Psychology",
            "volume": "8",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Clinical stress assessment using a visual analogue scale",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "X"
                    ],
                    "last": "Lesage",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Berjot",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Deschamps",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Occupational Medicine",
            "volume": "62",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Shimmer",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Ecg Unit",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "SPARE: A spectral peak recovery algorithm for PPG signals pulsewave reconstruction in multimodal wearable devices",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Masinelli",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Sensors",
            "volume": "21",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Cognitive workload monitoring in virtual reality based rescue missions with drones",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Dell&apos;agnola",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "12th International Conference on Virtual, Augmented and Mixed Reality",
            "volume": "7",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Inclusion of respiratory frequency information in heart rate variability analysis for stress assessment",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hernando",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Journal of Biomedical and Health Informatics",
            "volume": "20",
            "issn": "4",
            "pages": "1016--1025",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Reward: Design, optimization, and evaluation of a real-time relative-energy wearable r-peak detection algorithm",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Orlandic",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)",
            "volume": "",
            "issn": "",
            "pages": "3341--3347",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Heart rate variability: standards of measurement, physiological interpretation and clinical use",
            "authors": [],
            "year": 1996,
            "venue": "Task Force of the European Society of Cardiology and the North American Society of Pacing and Electrophysiology",
            "volume": "93",
            "issn": "",
            "pages": "1043--1065",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "On feature selection, bias-variance, and bagging",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Munson",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Caruana",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Lecture Notes in Computer Science",
            "volume": "5782",
            "issn": "2",
            "pages": "144--159",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Algorithms for hyper-parameter optimization",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bergstra",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Neural Information Processing Systems (NIPS 2011)",
            "volume": "24",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "An efficient explanation of individual classifications using game theory",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "\u0160trumbelj",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kononenko",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Journal of Machine Learning Research",
            "volume": "11",
            "issn": "",
            "pages": "1--18",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Overall methodology of the POTP statistical analysis and classification",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Average t rel (blue), with standard deviations (black), for each experimental segment values, to set up the emotion classification procedure and determine thresholds for the POTP classification. ML models are trained to perform each classification task based on the extracted biomarkers and subsequently analyze each model's generalization capabilities.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Classification thresholds for t rel was no significant correlation (\u03b1 = 0.05) between the stress levels and either the signed or absolute value of t rel .",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "CV mean and st. dev. F-1 scores for each ML model Learning curves of the SVM and RF algorithms",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "SHAP values of the time perception classifier IV. DISCUSSION AND FUTURE WORK",
            "latex": null,
            "type": "figure"
        },
        "TABREF1": {
            "text": "Experimental protocol",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Fig. 2: Pipeline for machine learning model selection and testing 4) ECG: From the ECG, the RR intervals are obtained as in",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Statistical Analysis Results",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "ML Optimization Step-by-Step Results",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Emotion Classifier Results on Unseen data",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": ". We can see that by far, the most important featuresFig. 7: Confusion matrix for the emotion classifier are the SCL gradient and SKT power. The remaining features relate to the ECG, RSP, SKT, SCR, and SCL signals. The SHAP values of the passage of time perception classifier are displayed in Fig. 9. In this case, the two most important features are PSD features of the ECG and RSP inspiration time. Other important features are derived from the ECG and RSP signals. All of the important RSP features relate to the time-domain inspiration time parameter, whereas the important ECG features are computed using the time and frequency domain of the R-R interval signal. |SHAP value|) (average impact on model output magnitude) Fig. 8: SHAP values indicating the feature importance to the output of the emotion classifier",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}