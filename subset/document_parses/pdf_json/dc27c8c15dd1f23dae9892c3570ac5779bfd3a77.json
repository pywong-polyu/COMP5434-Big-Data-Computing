{
    "paper_id": "dc27c8c15dd1f23dae9892c3570ac5779bfd3a77",
    "metadata": {
        "title": "Comparison of Red versus Blue Laser Light for Accurate 3D Measurement of Highly Specular Surfaces in Ambient Lighting Conditions",
        "authors": [
            {
                "first": "Arpita",
                "middle": [],
                "last": "Dawda",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Auckland University of Technology",
                    "location": {
                        "postCode": "1010",
                        "settlement": "Auckland",
                        "country": "New Zealand"
                    }
                },
                "email": ""
            },
            {
                "first": "Minh",
                "middle": [],
                "last": "Nguyen",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Auckland University of Technology",
                    "location": {
                        "postCode": "1010",
                        "settlement": "Auckland",
                        "country": "New Zealand"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Inspection or Quality Control is an essential stage of the production line. For some products, their accurate three-dimensional (3D) reconstructions are necessary for inspection [1] . The type of surface of the product plays a critical part in choosing a suitable 3D reconstruction method. The inspection of highly specular surfaces is still a limitation of most of the state-of-art 3D measurement techniques. Most of the available commercial solutions cannot inspect specular surfaces in ambient lighting conditions. This research paper focuses on a simple and accurate 3D measurement technique using laser and stereo cameras for the inspection of reflective surface objects. In this technique, a single laser line is projected onto the surface, and its stereo images are captured and processed for 3D reconstruction. The method overcomes the limitation of traditional methods and works robustly in ambient lighting conditions. As our experiments are performed in ambient lighting conditions, it is essential to project the right type of laser light on the object. Two different colours (Red and Blue) of laser lights are considered. Here, we reconstructed 3D profiles of three different shapes and estimated sizes of these objects using these two lights. This research article compares the output 3D profiles obtained using red laser light with which achieved using blue laser light. The results are quantitatively evaluated in terms of accuracy with the ground truth 3D model of the acquitted objects for accuracy evaluation. We also discuss the dependency on the specularity of the surface.",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 181,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "For customer satisfaction, reliable inspection and quality control of the product is necessary. It also assures confidence to the manufacturer and reduces manu- facturing cost by eliminating scrap losses. The quality results help to simulate failure modes and verify strength criteria to validate functional product design [4] . Same as the manufacturing process, the quality checking process also needs to be fast, accurate, simple, cost-effective and automatic. \"Machine vision is the technology and methods used to provide imaging-based automatic inspection and analysis [3] .\" This research has been carried out in collaboration with Facteon Intelligent Technology Limited. Facteon manufactures different parts of consumer appliances such as drums, doors and panels, cabinets and cases, water heater cases and refrigeration foaming lines [5] . The base material of most of the products is stainless steel which makes the surface highly specular in the presence of light.",
            "cite_spans": [
                {
                    "start": 323,
                    "end": 326,
                    "text": "[4]",
                    "ref_id": null
                },
                {
                    "start": 574,
                    "end": 577,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 842,
                    "end": 845,
                    "text": "[5]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As seen in Fig. 1 , any slight variations in the viewing plane, the angle of view, and camera position; they can significantly affect the appearing colour. In general, the more direct the reflection, the brighter the colour and vice versa. Also, the ambient lighting conditions of the working environment cause significant difficulty for quality inspection. A significant number of 3D shape measurement techniques have been proposed in the last few decades. Time-of-flight, stereo vision, laser range scanning and structured lighting are some example of the surface non-contact techniques used for high-speed inspection of objects [6] . These techniques provide accurate results for non-reflective surfaces. Structured lighting and stereo vision are considered as the most effective techniques for specular surfaces. However, the shape or curvature of the specular surface will cause reflection in ambient lighting conditions. Even by using structured lighting or stereo vision techniques, it is challenging to observe every small feature of the object in the region of reflection [7] . Therefore, we use the method which combines the concepts of sheet-of-light and stereo vision for the inspection of highly specular surface.",
            "cite_spans": [
                {
                    "start": 631,
                    "end": 634,
                    "text": "[6]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1081,
                    "end": 1084,
                    "text": "[7]",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [
                {
                    "start": 11,
                    "end": 17,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "Here, a narrow band of light is projected onto a 3D surface. \"The projection produces a distorted line of illumination, which represents the profile of an object [2] .\" Stereo cameras capture the image of the distorted laser line in a calibrated environment. An algorithm is developed to detect the laser line accurately in both photos. After accurately detecting the laser line in both images, stereo matching is performed for 3D reconstruction of the laser profile in World Coordinate System (WCS).",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 165,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The output accuracy mainly depends on the detection of projected laser line. To get accurate results in ambient lighting conditions, it is important that the projected narrow band of laser line is sharp and it should resemble the shape of the product. Here, we have used red and blue light lasers as a source of light. A laser emits coherent light. As a result, the laser beam stays narrow and focused over a great distance [8] . The effect of the projected narrow band of light onto the accuracy of the output 3D profile is studied here. The wavelength of Redlight laser diode is generally 638 nm, 650 nm or 670 nm. On the other hand, the wavelength of Blue-light laser diode is normally 450 nm, 473 nm or 488 nm [12] . All these wavelengths come under the visible light region of the electromagnetic radiation spectrum [13] . The visible-beam lasers are classified into four classes based on its maximum output power: Class 2, Class 3R, Class 3B and Class 4 [14]. Figure 2 shows that the eye injury hazard increases as the laser's power increases [15] . As the experiments are performed in an open working environment, we have used class 2 lasers for this research. In this paper, we projected a narrow band of red and blue laser line onto three different shapes of objects. The first object is the drum of washing machine manufactured by Facteon. The drum is made of stainless steel which makes its surface highly specular. The other two items are a cube and a prism. They are wrapped in an aluminium foil to create the effect of reflective surfaces. The 3D profiles of each object are created for red and blue laser lights using the abovespecified technique. For each object, the output 3D profile obtained using red laser light is compared with the output 3D profile obtained using blue laser light. Later, they are also compared with the ground truth three-dimensional model of the acquired objects for accuracy evaluation.",
            "cite_spans": [
                {
                    "start": 424,
                    "end": 427,
                    "text": "[8]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 714,
                    "end": 718,
                    "text": "[12]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 821,
                    "end": 825,
                    "text": "[13]",
                    "ref_id": null
                },
                {
                    "start": 1049,
                    "end": 1053,
                    "text": "[15]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 966,
                    "end": 974,
                    "text": "Figure 2",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Introduction"
        },
        {
            "text": "The remainder of this paper is structured as follows: Sect. 2 briefly describes the reviewed literature and shows a comparison of commercial solutions for Red vs Blue laser light. Section 3 explains our 3D measurement technique in detail and illustrates the dependency of the type of laser light on the specularity of the surface. All steps of our approach with experimental results are shown in Sect. 4. Section 5 concludes the paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this section, the commercial solutions which use Red-light laser are compared with the commercial solutions which use Blue-light laser. Table 1 compares products which are based on the concept of sheet-of-light. A trade-off between the accuracy of the output and the field of view (FOV) covered by the system is seen in all these solutions. Also, the FOV covered by these products is very small for higher resolution. Therefore, multiple laser profilers are required to inspect large objects. This increases the cost of the inspection process. Another disadvantage is that most of the solutions do not work in the ambient lighting conditions of the working environment. Moreover, the resolution of the red-light laser is low compared to the blue-light laser. Also, some of the red-light laser profilers do not work for highly specular surfaces. Therefore, blue-light laser profilers are considered as a better choice for the inspection of small specular objects.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 139,
                    "end": 146,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Commercial Solutions"
        },
        {
            "text": "The flow chart in Fig. 3 , represents our suggested approach for the inspection of reflective surfaces. A narrow band of light is projected on the surface of the object. The stereo cameras capture the images of the product in the calibrated environment. These captured images are first rectified using calibration parameters. To generate the Region of Interest (ROI) automatically, we have used the concept of two-dimensional (2D) shape matching. In Fig. 4 , the Red curve depicts the intensity distribution of the projected laser line for the first row. As we can see, the intensity distribution for the projected laser profile resembles a bell-shaped curve. The first step of the detection algorithm is to smooth the curve using a Gauss function [17] . The blue curve shows the smoothed function. The next step is to find local maximums for the blue curve [18] . Also, we find the location of the pixel with the highest grey value intensity for the red curve. Now, we compare the pixel location of each local maximum with the location of the highest grey value pixel. We try to find the area which is nearest to the location of the highest grey value pixel. The nearest local maximum would be considered as the detected point of the laser line. In the case of multiple values, an algorithm is developed to choose the best suitable amount. This algorithm also considers the grey value intensity at each local maximum point for the accurate decision-making process.",
            "cite_spans": [
                {
                    "start": 748,
                    "end": 752,
                    "text": "[17]",
                    "ref_id": null
                },
                {
                    "start": 858,
                    "end": 862,
                    "text": "[18]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 18,
                    "end": 24,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 450,
                    "end": 456,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Methodology"
        },
        {
            "text": "However, we can not repeat the same process for each row. If the ROI contains highlights caused by ambient light, the distribution of intensity would be affected [2] . As we can see in Fig. 5 , there are two possible circumstances. In the first case, the highlight is separate from the projected laser line. The second case is where the highlight is merged with the laser line by making the intensity distribution a wide bell-shaped curve. In Fig. 5a , the first peak is the peak of the highlight. The same method will assume the highest intensity of highlight as a projected laser profile. Therefore, the location of the detected laser point in the previous row is taken as a reference for the next row. \"If the location of the detected laser profile is (x, y), then in the next row, we search pixel locations (x+1, y-10 ) to (x+1, y+10 ) for finding the pixel with the highest grey value [2] .\" Now, we repeat the process used for the first line to detect the laser line.",
            "cite_spans": [
                {
                    "start": 162,
                    "end": 165,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 890,
                    "end": 893,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 185,
                    "end": 191,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 443,
                    "end": 450,
                    "text": "Fig. 5a",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Methodology"
        },
        {
            "text": "The problem of detecting the laser line when it is merged with the highlight is solved in the next stage of the experiment. Here, we compare the detected laser line in both images. Typically, the highlights caused by ambient lighting conditions will not be visible in both photos. Therefore, the highlights which are present in the left image will not be present in the right image and vice versa. For the case where the laser line is merged with the highlight in one shot, we would still be able to detect the laser line accurately in the other image. By comparing, we can specify the region which has inaccurate output because of the reflection.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methodology"
        },
        {
            "text": "Another critical factor of the detection process is that the reflected region should not be considered as a part of the projected laser profile because of its high intensities. The red-light laser penetrates deeper into the target surface compared to the blue-light laser. Therefore, the red-light laser light looks blurry and diffused and merges with the reflected region. On the other hand, the bluelight laser generates a much more focused laser band when projected on to the surface [19] . Figure 6 show the images of the projected red-light and bluelight lasers on the washing machine drum in ambient lighting conditions. Here, both the lasers have the same maximum output power. As seen in Fig. 6 , the red-light laser has low intensities compared to the blue-light laser. Therefore, while trying to detect the red-light laser in the highlighted region, the reflected region is detected as a part of the laser line. In contrast, the projected blue-light laser is detected accurately, even in the presence of the reflected area. This is one of the advantages of using blue-light laser instead of red-light laser for 3D reconstruction of highly specular surfaces.",
            "cite_spans": [
                {
                    "start": 487,
                    "end": 491,
                    "text": "[19]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 494,
                    "end": 502,
                    "text": "Figure 6",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 696,
                    "end": 702,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF8"
                }
            ],
            "section": "Methodology"
        },
        {
            "text": "The setup of the experiment is shown in Fig. 7 . In this experiment, we are using red and blue light lasers of class 2M. The maximum output power of both lasers is 20 mW. Both single-line lasers have the same fan angle of 45 degrees. Now, the position of the laser is one of the most critical parameters of this technique. To understand the concept, we projected a narrow band of a horizontal laser line on to a flat surface. Figure 8 shows the captured image of the projected laser line. As seen in Fig. 8 , the intensity of the laser decreases as the distance from the centre of the image increases. Also, the laser line diffuses and causes reflection when it is projected directly in the centre of the image. However, if the laser line is projected too far from the centre of the image, then the intensity of the laser line is low, and it merges with the background. Therefore, we need to choose the position of the laser in such a way that it does not cause any reflection and does not get merged with the background in both images.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 40,
                    "end": 46,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF9"
                },
                {
                    "start": 426,
                    "end": 434,
                    "text": "Figure 8",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 500,
                    "end": 506,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "Experiments and Results"
        },
        {
            "text": "For the cameras, we are using two Genie Nano M4020 monochrome camera, which has 4112 \u00d7 3008 resolution. The focal lengths of both cameras are identical. Also, the stereo cameras are placed in Canonical Stereo Geometry, which means their optic axes are parallel. The baseline distance, which is the distance between the optical axes of two cameras is 130 mm for this experiment [16] . The setup is the same for both lasers. The experiment is first performed using red-light laser and afterwards using blue-light laser. Moreover, HALCON software is used to perform image processing tasks.",
            "cite_spans": [
                {
                    "start": 377,
                    "end": 381,
                    "text": "[16]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Experiments and Results"
        },
        {
            "text": "The stereo cameras are calibrated using Halcon calibration plate, which has a pattern of hexagonally arranged black marks printed on white background. A narrow band of the red-light laser line is projected on the object after calibrating stereo cameras. Figure 9 show images of different shaped objects with a projected laser band. Stereo cameras capture the images of the object with a projected laser line. The next step is to rectify the captured stereo images. After rectification, we use the fundamentals of 2D shape matching to get the Region of Interest (ROI) automatically. Now, we apply the algorithm to detect the projected laser line in both images. The left and right ROI images with detected laser profiles are shown in Fig. 10 . Stereo matching is performed only on the detected laser profiles to calculate its disparity. We can reconstruct the projected laser line in the World Coordinate System (WCS) using the calculated disparity value and calibration parameters. \"For a full 3D reconstruction of the object, the object is rotated at specific intervals. At each interval, the projected laser profile is reconstructed. By merging these reconstructed laser profiles, we can reconstruct the shape of the object in 3D for accurate measurements [2] .\" For each object, we repeat the whole process by replacing the red-light laser with the blue-light laser. No changes have been made in the setup for bluelight laser. Figure 11 shows the left and right ROI images with detected laser profiles for blue-light laser. In Fig. 12 , we compare the output reconstructed 3D profiles by red-light laser with the output reconstructed 3D profiles by blue-light laser. The accuracy of the output mainly depends on the detection of the laser profile. The Table 2 shows the number of scan required to reconstruct each object using red and blue light laser. Here, false positive specifies how many times the reflection is falsely detected as a part of a laser line. From the deviation results, we can tell that the detected red-light laser is quite noisy. On the other hand, the detected blue-light laser is quite sharp, and it detects all small features of the object accurately.",
            "cite_spans": [
                {
                    "start": 1258,
                    "end": 1261,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [
                {
                    "start": 254,
                    "end": 262,
                    "text": "Figure 9",
                    "ref_id": "FIGREF12"
                },
                {
                    "start": 733,
                    "end": 740,
                    "text": "Fig. 10",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1430,
                    "end": 1439,
                    "text": "Figure 11",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1530,
                    "end": 1537,
                    "text": "Fig. 12",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 1755,
                    "end": 1762,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experiments and Results"
        },
        {
            "text": "To conclude, blue-light laser is proven to be more accurate compared to redlight laser for the 3D shape measurement of highly specular surfaces in identical conditions. Also, the projected beam of red-light laser diffuses and merges with the reflection caused by ambient light. On the other hand, the blue-light laser does not penetrate the surface. It provides a sharp narrow beam when projected onto a highly specular surface. Therefore, we can accurately detect the blue-light laser even in the presence of reflection. The accuracy of the output is improved by using the blue-light laser. Moreover, the proposed method is proven to be a simple, fast, feasible, accurate and cost-effective solution for the inspection of reflective objects even in ambient lighting conditions. Unlike commercial laser profilers, there is no trade-off between the field of view and the accuracy of the output.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Computer vision for quality control in automated manufacturing systems",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Asoudegi",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Comput. Ind. Eng",
            "volume": "21",
            "issn": "1-4",
            "pages": "141--145",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Accurate 3D measurement of highly specular surface using laser and stereo reconstruction",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Dawda",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Klette",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 International Conference on Image and Vision Computing New Zealand (IVCNZ)",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Wisdom IT Services India Pvt",
            "authors": [],
            "year": 2019,
            "venue": "Machine Vision",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Flexible & Intelligent manufacturing solutions",
            "authors": [],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Review and comparison of high-dynamic range three-dimensional shape measurement techniques",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Sens",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Overview of three-dimensional shape measurement using optical methods",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Brown",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "Opt. Eng",
            "volume": "39",
            "issn": "1",
            "pages": "10--22",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "LMI Technologies Inc",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Laser",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Laser scanners for 2D/3D profile measurements",
            "authors": [],
            "year": 2019,
            "venue": "-sight Laser Profiler",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Visible spectrum",
            "authors": [],
            "year": 2020,
            "venue": "Eye injury hazard",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Concise Computer Vision",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Klette",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "MVTec Software GmbH",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Intelligent Technology Ltd.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Springer Nature Switzerland AG 2021 M. Nguyen et al. (Eds.): ISGV 2021, CCIS 1386, pp. 300-312, 2021. https://doi.org/10.1007/978-3-030-72073-5_23",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Specular, diffuse reflection, and the degrees of reflection glossiness. (Color figure online)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Laser classes and eye injury hazard [15].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Overall approach for 3D inspection.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Intensity distribution for region without highlights. (Color figure online)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Intensity distribution for region with highlights.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Detection of laser light in the presence of highlight.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Setup of experiment.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Change in the intensity of laser.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "Objects with projected laser profile.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "ROIs with detected laser profiles using Red-light laser. (Color figure online)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF15": {
            "text": "ROIs with detected laser profiles using Blue-light laser. (Color figure online)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "3D reconstructed laser profiles.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Comparision of laser profilers.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Output accuracy for red and blue light laser.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Supported by Facteon Intelligent Technology Ltd.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgment."
        }
    ]
}