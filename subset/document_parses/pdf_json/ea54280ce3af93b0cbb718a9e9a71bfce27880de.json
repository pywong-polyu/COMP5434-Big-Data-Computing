{
    "paper_id": "ea54280ce3af93b0cbb718a9e9a71bfce27880de",
    "metadata": {
        "title": "Human Activity Analysis and Recognition from Smartphones using Machine Learning Techniques",
        "authors": [
            {
                "first": "Jakaria",
                "middle": [],
                "last": "Rabbi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khulna University of Engineering & Technology Khulna-9203",
                    "location": {
                        "country": "Bangladesh"
                    }
                },
                "email": "jakariarabbi@cse.kuet.ac.bd"
            },
            {
                "first": "Hasan",
                "middle": [],
                "last": "Tahmid",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khulna University of Engineering & Technology Khulna-9203",
                    "location": {
                        "country": "Bangladesh"
                    }
                },
                "email": "mdtahmidhasanfuad@gmail.com"
            },
            {
                "first": "",
                "middle": [
                    "Abdul"
                ],
                "last": "Fuad",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khulna University of Engineering & Technology Khulna-9203",
                    "location": {
                        "country": "Bangladesh"
                    }
                },
                "email": ""
            },
            {
                "first": "",
                "middle": [],
                "last": "Awal",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khulna University of Engineering & Technology Khulna-9203",
                    "location": {
                        "country": "Bangladesh"
                    }
                },
                "email": "awal@cse.kuet.ac.bd"
            }
        ]
    },
    "abstract": [
        {
            "text": "Human Activity Recognition (HAR) is considered a valuable research topic in the last few decades. Different types of machine learning models are used for this purpose, and this is a part of analyzing human behavior through machines. It is not a trivial task to analyze the data from wearable sensors for complex and high dimensions. Nowadays, researchers mostly use smartphones or smart home sensors to capture these data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "In our paper, we analyze these data using machine learning models to recognize human activities, which are now widely used for many purposes such as physical and mental health monitoring. We apply different machine learning models and compare performances. We use Logistic Regression (LR) as the benchmark model for its simplicity and excellent performance on a dataset, and to compare, we take Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), and Artificial Neural Network (ANN). Additionally, we select the best set of parameters for each model by grid search. We use the HAR dataset from the UCI Machine Learning Repository as a standard dataset to train and test the models. Throughout the analysis, we can see that the Support Vector Machine performed (average accuracy 96.33%) far better than the other methods. We also prove that the results are statistically significant by employing statistical significance test methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Human beings can realize others' psychological state and personality by observing their daily activities. Following this pattern, the researchers want to predict human behavior using machines, and Human Behavior Recognition (HAR) comes as an active research topic. This has become one of the important research topics in machine learning and computer vision. Though motion data collection was hard in previous days, current technological developments help researchers capture the data as they can now use portable devices, including smartphones, music players, smartwatches, or smart home sensors. Especially, motion sensor embedded smartphones, like accelerometers, gyroscope, etc. bring a new era for activity recognition. Researchers use various machine learning and deep learning techniques including Naive Bayes (NB) [1] , Decision Tree [2] , Support Vector Machine (SVM) [3] [4] , Nearest Neighbor (NN) [5] , Hidden Markov Model (HMM) [6] Convolutional Neural Network (CNN) [7] etc. to analyze the sensor data and recognize human activity.",
            "cite_spans": [
                {
                    "start": 822,
                    "end": 825,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 842,
                    "end": 845,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 877,
                    "end": 880,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 881,
                    "end": 884,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 909,
                    "end": 912,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 941,
                    "end": 944,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 980,
                    "end": 983,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "HAR is the problem of classifying day-to-day human activity using data collected from smartphone sensors. Data are continuously generated from the accelerometer and gyroscope, and these data are instrumental in predicting our activities such as walking or standing. There are lots of datasets and ongoing research on this topic. In [8] , the authors discuss wearable sensor data and related works of predictions with machine learning techniques. Wearable devices can predict an extensive range of activities using data from various sensors. Deep Learning models are also being used to predict various human activities [9] . Nowadays, people use smartphones almost all the time and use many wearable devices. Through these devices, physical and mental health can be monitored by predicting human activity without specialized and costly medical equipment, and nowadays, it is an efficient, cheap, and safe way to do this as the COVID-19 (Coronavirus disease 2019) pandemic is ongoing.",
            "cite_spans": [
                {
                    "start": 332,
                    "end": 335,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 618,
                    "end": 621,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "In this paper, we have selected a dataset from the UCI machine learning repository [10] to calculate the accuracy of five machine learning models and to perform some statistical significance tests. We use the Decision Tree (DT), Random Forest (RF), LR, SVM, and Artificial Neural Network (ANN) with a hidden layer to predict human activity from mobile data. In the dataset, the human activities are classified into six categories: walking, walking upstairs, walking downstairs, sitting, standing, and laying, and the data were collected from two different smartphone sensors, which are accelerometer and gyroscope. We ran experiments to see the performance of the models based on classification results and tried to get the highest possible accuracy from these models. Here, we tried to get the highest possible performance by these algorithms by parameter tuning, cross-validation, and finally, comparing the result with two statistical significance tests to get the winner algorithm.",
            "cite_spans": [
                {
                    "start": 83,
                    "end": 87,
                    "text": "[10]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The remainder of this paper is organized as follows. Section II describes the related works, and section III discusses the dataset. Section IV discusses the machine learning models used in this paper, section V describes the experimental methods, and section VI presents the experimental results. Eventually, section VII concludes the paper. [11] . A Anjum et al. [12] use smartphone sensors over detectable physical activities, including walking, running, climbing, cycling, driving, etc. They compare Naive Bayes, Decision Tree, KNN (K Nearest Neighbours), and SVM to calculate accuracy. They achieve a greater than 95% true positive rate and less than 1.5% false positives rate.",
            "cite_spans": [
                {
                    "start": 342,
                    "end": 346,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 364,
                    "end": 368,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Z Chen et al. [13] propose a robust HAR system based on coordinate transformation and PCA (CT-Principal Component Analysis) and online SVM. CT-PCA scheme is used to reduce the effect of orientation variations. Their presented OSVM is independent, which uses a tiny portion of data from the unseen placement. Sun et al. [14] propose a HAR approach with varying position and orientation through smartphone accelerometer data. They use their acceleration magnitude as the fourth data dimension. They also use generic SVM and location-specific SVM in the model.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 18,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 319,
                    "end": 323,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "Deep Learning approaches require a considerable amount of training data; therefore, many researchers mainly use generic machine learning approaches [15] . Hence, in our paper, we focus on the generic approaches to analyze and detect human activity.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 152,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "I. INTRODUCTION"
        },
        {
            "text": "The dataset is taken from UCI machine learning repository [10] . The dataset contains the information from 30 volunteers within the age range: 19-48. Each volunteer performs six activities:",
            "cite_spans": [
                {
                    "start": 58,
                    "end": 62,
                    "text": "[10]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "A. Data Exploration and Exploratory Visualization"
        },
        {
            "text": "\u2022 Walking \u2022 Walking upstairs \u2022 Walking downstairs \u2022 Sitting \u2022 Standing \u2022 Laying Hence, the dataset has six labels to predict. The dataset consists of 561 feature vectors with time and frequency domain variables. These features come from the following data:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Data Exploration and Exploratory Visualization"
        },
        {
            "text": "\u2022 Gravitational acceleration for x, y, and z axes \u2022 Body acceleration data files for x, y, and z axes \u2022 Body gyroscope data files for x, y, and z axes We also have the ID of an individual volunteer for each record. A total of 10299 records and training and test dataset splits are 70% and 30%. The 6 classes are converted to numerical values sequentially: [1, 2, 3, 4, 5, 6]. Figure 1 shows the total number of different human activities in training data, and figure 2 shows the distribution of two types of activity (static: sitting, standing, and layingdynamic: walking, walking downstairs, and walking upstairs) using tBodyAccMag-mean() feature, which is taken from the accelerometer of smartphones. It is clear that the two types of activities are easily separable. There are no missing and duplicate values. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 376,
                    "end": 384,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "A. Data Exploration and Exploratory Visualization"
        },
        {
            "text": "Support Vector Machine (SVM) is used as one of the selected algorithms. SVM is a discriminative classifier determined by a separating hyperplane. If training data is fed to the SVM, it gives an optimal hyperplane that classifies new data. This hyperplane is simply a line dividing a plane into two parts in two-dimensional space wherein each class lay on either side [16] . There are SVM variants, and one is Support Vector Classifier (SVC) for more than two classes. In this paper, we use SVC with 'linear,' 'rbf' [17] and 'sigmoid' kernel. SVM usually provides good accuracy when the number of features is large. In our dataset, the number of features is large; hence we selected this algorithm. ",
            "cite_spans": [
                {
                    "start": 367,
                    "end": 371,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 515,
                    "end": 519,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "A. Support Vector Machine"
        },
        {
            "text": "A Decision tree is a tree-like formation of decisions and possibilities. It differentiates instances by sorting from root to leaves. Here, we check impurity using Gini and gain information from entropy. These measures the quality of the split. We use various max depths (0 to 8), which is the maximum depth of the tree. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Decision Tree"
        },
        {
            "text": "Random Forest (RF) model is an ensemble of some decision trees. It combines the learning methods and increases the overall result. Here criterion measures the quality of a split. We use Gini for impurity checks, and the information is gained from entropy. We use N estimators and max depth as the parameter. N estimators are the number of trees in the generated forest, and max depth is the tree's maximum depth. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Random Forest"
        },
        {
            "text": "An artificial Neural Network having a single hidden layer and the sigmoid activation function is used for our experiment. Adam, a stochastic gradient-based optimizer [18] , is used for weight optimization. The maximum epoch is 200, and the dataset is shuffled between each epoch. The ANN is selected because it is currently used in many learning problems.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 170,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "D. Artificial Neural Network"
        },
        {
            "text": "We used Logistic Regression (LR) as a benchmark model, and it focuses to maximize the probability of the data. This is a basic model without much complexity like neural networks. The performance of LR improves if the data lies on the correct side of the separating hyperplane. We used the kernel trick and 'lbfgs' optimizer to compare the performance. Some previous research has some good results with that combination of LR [19] . Hence, we used this algorithm because LR, and its variants are the right choice for benchmarking.",
            "cite_spans": [
                {
                    "start": 425,
                    "end": 429,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "E. Benchmark Model"
        },
        {
            "text": "Dataset has a train and test portion. There are no duplicate and missing values. Train and Test data are stored in the data frame initially. We tried to remove some features to reduce the feature space. We tried to select features by computing ANOVA F-value [20] for the dataset. We selected top 100, 200, 400, and 500 features with top ANOVA F-values. Nevertheless, each time we increased the features, the accuracy increased significantly for all five algorithms and the trend is depicted in figure 3 . Therefore, we use all the features for training and testing. The learning is divided into two parts. Initially, the best parameters for all the algorithms are learned. Then, in the second step, the algorithms are compared. The dataset is evaluated by a K-fold cross-validation set, and we used k=5 for cross-validation. The data splitting is done by stratified sampling. We use 70% training data for crossvalidation purposes without touching the test data.",
            "cite_spans": [
                {
                    "start": 258,
                    "end": 262,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [
                {
                    "start": 494,
                    "end": 502,
                    "text": "figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "A. Data preprocessing"
        },
        {
            "text": "A cross-validation dataset is used for an exhaustive grid search to find the best hyperparameters. The models learn from the dataset for all combinations of the listed parameters. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Implementation"
        },
        {
            "text": "After finding the best parameters, we evaluated the five algorithms on test data. Test data is divided into 10 random sets, and every set consists of 50% of the data. Hence, we have 10 runs for every algorithm and calculated the mean and variance for these runs. The learning process to find the best parameters used only training data. Hence, we got an unbiased estimation for cross algorithm comparisons.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Refinement"
        },
        {
            "text": "The best parameters for the five algorithms are found after an exhaustive grid search. All combination of the given parameters is used to find the best parameters After 5-fold cross-validation (stratified), we got the best parameters in table VI. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "C. Refinement"
        },
        {
            "text": "We used hypothesis testing for this paper. A hypothesis is examined by estimating and inspecting a random sample of the population selected to be analyzed. We examined specific hypotheses using a random population pattern: one is the null and another one is the alternative hypothesis. The null hypothesis related to the equality between population parameters, and as an example, a null hypothesis assumes that the population mean return is the same to zero. Alternatively, the alternative hypothesis is efficaciously the reverse of a null hypothesis, and as an instance, the population mean return is not identical to zero. Therefore, they can not happen simultaneously, and only one hypothesis can be correct. We tested all hypotheses using the following four-step process:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "D. Refinement with Statistical Significance Test"
        },
        {
            "text": "\u2022 At first, the we have to state the two hypotheses so that only one can be accurate. \u2022 Then, there is a plan to outline how the data are determined. \u2022 After that, the plan is carried out, and the sample data are analyzed. \u2022 Finally, the result is analyzed and take a decision whether to reject the null hypothesis, or state that the null hypothesis can be possible with the given data [26] . The algorithms are compared using Welch's t-test [27] method because the algorithms' variances are different. We can find output from the t-test that shows whether the algorithms have significant changes in their performance measurements. The t-test show the importance of the differences between groups. It can explain whether the differences measured in means, could have happened by chance. The two-tailed t-test is done pairwise for every algorithm with H 0 : \u00b5 0 = \u00b5 1 and significance level \u03b1 = 0.05 [28] to produce a ranking between the algorithms and for finding the winner algorithm. Here, H 0 is the null hypothesis, and \u00b5 0 and \u00b5 1 are the means of two groups of population. Also, the algorithms are compared using 5 times 2-fold cross-validated paired t-test [29] as suggested by the researchers in [30] .",
            "cite_spans": [
                {
                    "start": 386,
                    "end": 390,
                    "text": "[26]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 899,
                    "end": 903,
                    "text": "[28]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1164,
                    "end": 1168,
                    "text": "[29]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1204,
                    "end": 1208,
                    "text": "[30]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "D. Refinement with Statistical Significance Test"
        },
        {
            "text": "We used 5-fold stratified cross-validation and grid search to find the best hyperparameters. Then run the models with the best parameters on test data and finally run the statistical significance test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VI. EXPERIMENTAL RESULTS"
        },
        {
            "text": "Accuracy is calculated by dividing the number of correct predictions by the total number of predictions. This metric is fundamental as we want to know whether a human is walking or sitting correctly. Accuracy is the primary metric to distinguish between our models. In equation 1, we get an accuracy score using True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Evaluation Metrics"
        },
        {
            "text": "Additionally, we use Precision, Recall, and F1 score as the evaluation metrics. The equation of these three metrics is given in equations 2, 3, and 4.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Evaluation Metrics"
        },
        {
            "text": "P recision = T P T P + F P",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Evaluation Metrics"
        },
        {
            "text": "Recall = T P T P + F N ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "A. Evaluation Metrics"
        },
        {
            "text": "Using the derived best parameters, the best model for each algorithm is formulated. Then the models are evaluated on the test data. Test data is divided into 5 random folds (stratified), and each fold contains the whole dataset. We got the average accuracy for the five different models using the data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Model Evaluation & Validation"
        },
        {
            "text": "In Table VII , we can see the accuracies for the algorithms. Decision Tree and Random forest have low accuracy compared to the other five algorithms. ANN performs well but has less accuracies compare to the other two algorithms. We can see the average precision, recall, and F1 score per class from tables VIII, IX, X, XI, and XII. There are 6 classes, and all scores per class are in the tables. We also understand that SVM and LR perform better than DT, RF, and ANN by inspecting the results from the tables mentioned above. We also tried multiple hidden layers with more hidden nodes, but the accuracy dropped and the phenomenon is depicted in figure  4 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 12,
                    "text": "Table VII",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 647,
                    "end": 656,
                    "text": "figure  4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "B. Model Evaluation & Validation"
        },
        {
            "text": "Hence, we did not include that model for comparison. We used the kernel trick implementation for logistic Regression, but the accuracy is not significantly sufficient, and it takes more time than simple LR. Therefore, for simplicity, we did not include kernels in the LR. Both SVM and LR have closer accuracy and precision-recall scores per class. Nevertheless, we cannot decide the best model without a statistical significance test.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "B. Model Evaluation & Validation"
        },
        {
            "text": "Test data is divided into 10 random folds (stratified), and each fold contains 50% of the data. Then we run the top three best models with the best parameters. After getting the result from 10 runs for each of the three models, we ran a two-tailed Welch's t-test on the results from the top three models. We got the result for the three models and shown in table XIII. From Table XIII , we understand that SVM is the winner algorithm. Our hypothesis H 0 : \u00b5 0 = \u00b5 1 has \u03b1 = 0.05 and from this table we see that every p-value is less than alpha. Therefore, we can reject the hypothesis. So, we can conclude that the results are significantly different. Hence, SVM is the best algorithm here. We also tested with a 5 by 2-fold cross-validation t paired test to confirm the winner algorithm. In several research papers [31] [32] [33] , we found this as a recommended test. In this test, the whole dataset (training and test data) is divided into two random folds and run 5 times. Then the results are collected, and the t statistic is calculated. In table XIV, the statistic is shown. It is clearly visible that the hypothesis is rejected every time, and the results are significantly different according to the test. Table 9 shows that the t-value | p-value pair is different for the same pair if the order is different. Because 5 times 2-fold cross-validation makes the outcome different. We can conclude that the SVM algorithm is the winner for this dataset.",
            "cite_spans": [
                {
                    "start": 816,
                    "end": 820,
                    "text": "[31]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 826,
                    "end": 830,
                    "text": "[33]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [
                {
                    "start": 374,
                    "end": 384,
                    "text": "Table XIII",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 1215,
                    "end": 1222,
                    "text": "Table 9",
                    "ref_id": null
                }
            ],
            "section": "C. Statistics for Justification"
        },
        {
            "text": "In conclusion, it is evident that SVM performs better than the other two algorithms, though LR is the closer in case of accuracy. ANN cannot compete with SVM for this dataset. In most of the classification problems, ANN and deep ANN performs well. For this dataset, deep neural network architectures or convolutional neural network might increase the performance. We think we will explore the path in the near future. We also want to explore the performance of other machine learning algorithms in the future. In this experiment, we understand that simple machine learning algorithms can do well with proper parameter tuning, and we can determine the significance of the result by the statistical testing.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "VII. CONCLUSION"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Activity recognition from user-annotated acceleration data",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Intille",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "International conference on pervasive computing",
            "volume": "",
            "issn": "",
            "pages": "1--17",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Activity recognition in the home using simple and ubiquitous sensors",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "M"
                    ],
                    "last": "Tapia",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "S"
                    ],
                    "last": "Intille",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Larson",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "International conference on pervasive computing",
            "volume": "",
            "issn": "",
            "pages": "158--175",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Context-aware activity recognition and anomaly detection in video",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Nayak",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Roy-Chowdhury",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE Journal of Selected Topics in Signal Processing",
            "volume": "7",
            "issn": "1",
            "pages": "91--101",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Faster human activity recognition with svm",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "M"
                    ],
                    "last": "Chathuramali",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Rodrigo",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "International Conference on Advances in ICT for Emerging Regions (ICTer2012)",
            "volume": "",
            "issn": "",
            "pages": "197--203",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Classification accuracies of physical activities using smartphone motion sensors",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Dasgupta",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "E"
                    ],
                    "last": "Ramirez",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Peterson",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Norman",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Journal of medical Internet research",
            "volume": "14",
            "issn": "5",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Activity recognition and abnormality detection with the switching hidden semi-markov model",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "V"
                    ],
                    "last": "Duong",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "H"
                    ],
                    "last": "Bui",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "Q"
                    ],
                    "last": "Phung",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Venkatesh",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)",
            "volume": "1",
            "issn": "",
            "pages": "838--845",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Human activity recognition with convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bevilacqua",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Macdonald",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rangarej",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Widjaya",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Caulfield",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Kechadi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases",
            "volume": "",
            "issn": "",
            "pages": "541--552",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A survey on human activity recognition using wearable sensors",
            "authors": [
                {
                    "first": "O",
                    "middle": [
                        "D"
                    ],
                    "last": "Lara",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Labrador",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "IEEE communications surveys & tutorials",
            "volume": "15",
            "issn": "3",
            "pages": "1192--1209",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Deep learning for human activity recognition in mobile computing",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pl\u00f6tz",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Computer",
            "volume": "51",
            "issn": "5",
            "pages": "50--59",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Human activity recognition using neural networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Oniga",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "S\u00fct\u0151",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Proceedings of the 2014 15th International Carpathian Control Conference (ICCC)",
            "volume": "",
            "issn": "",
            "pages": "403--406",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Activity recognition using smartphone sensors",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Anjum",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "U"
                    ],
                    "last": "Ilyas",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "914--919",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Robust human activity recognition using smartphone sensors via ct-pca and online svm",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "C"
                    ],
                    "last": "Soh",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "IEEE Transactions on Industrial Informatics",
            "volume": "13",
            "issn": "6",
            "pages": "3070--3080",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Activity recognition on an accelerometer embedded mobile phone with varying positions and orientations",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "International conference on ubiquitous intelligence and computing",
            "volume": "",
            "issn": "",
            "pages": "548--562",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Applying machine learning techniques to transportation mode recognition using mobile phone sensor data",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Jahangiri",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "A"
                    ],
                    "last": "Rakha",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "IEEE transactions on intelligent transportation systems",
            "volume": "16",
            "issn": "5",
            "pages": "2406--2417",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Chapter 2 : Svm (support vector machine) -theory",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Patel",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Radial basis function kernel",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Adam: A method for stochastic optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Efficient approximate leave-oneout cross-validation for kernel logistic regression",
            "authors": [
                {
                    "first": "G",
                    "middle": [
                        "C"
                    ],
                    "last": "Cawley",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "L"
                    ],
                    "last": "Talbot",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Machine Learning",
            "volume": "71",
            "issn": "",
            "pages": "243--264",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Decision tree",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Random forest",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Available",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Support vector classifier",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "How hypothesis testing works",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Majaski",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Welch's t-test",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "27",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Null hypothesis",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "K-fold cross-validated paired t test",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Raschka",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Approximate statistical tests for comparing supervised classification learning algorithms",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "G"
                    ],
                    "last": "Dietterich",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Neural computation",
            "volume": "10",
            "issn": "7",
            "pages": "1895--1923",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Evaluating the replicability of significance tests for comparing learning algorithms",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Bouckaert",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Frank",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
            "volume": "",
            "issn": "",
            "pages": "3--12",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Approximate statistical tests for comparing supervised classification learning algorithms",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "G"
                    ],
                    "last": "Dietterich",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Neural computation",
            "volume": "10",
            "issn": "7",
            "pages": "1895--1923",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Combined 5\u00d7 2 cv f test for comparing supervised classification learning algorithms",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Alpaydm",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Neural computation",
            "volume": "11",
            "issn": "8",
            "pages": "1885--1892",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Different human activities with their count in the training dataset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Static and dynamic activity pattern",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Increasing accuracy of the five algorithms by increasing features.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Decreasing accuracy of ANN by increasing the number of hidden layers.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "II. RELATED WORKS Since HAR becomes an important research topic, the researchers use different Machine Learning methods, such as Naive Bayes, Logistic Regression, Decision Trees, Support Vector Machines, Nearest Neighbor, Hidden Markov Model, CNN, RNN (Recurrent Neural Network), etc. for recognizing human activities. D. Singh et al. used RNN in their work for human activity recognition. They use smart home sensors to collect data and applied a Long Short Term Memory (LSTM) RNN. ANN is used for prototyping data acquisition module",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Parameters for DT",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Parameters for RF Estimators [10, 30, 60, 90, 120, 150] Number of trees in",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Parameters for SVM",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Parameters for ANN",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Parameters for LR",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Best parameters for the selected models",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Accuracies for all algorithms",
            "latex": null,
            "type": "table"
        },
        "TABREF8": {
            "text": "for DT), Table II (for RF), Table III (for SVM), Table IV (for ANN), and Table V (for LR) have the parameter list that we use to get the best combination of parameters. The parameters are chosen from a range of values that work well in many problems. Accuracy is used as the scoring method. We use the python Scikit-learn library for the implementation. A detailed explanation of all parameters can be found in [21] [22] [23] [24] [25].",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "Average scores per class for DT",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Average scores per class for RF",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Average scores per class for ANN",
            "latex": null,
            "type": "table"
        },
        "TABREF12": {
            "text": "Average scores per class for SVM",
            "latex": null,
            "type": "table"
        },
        "TABREF13": {
            "text": "Average scores per class for LR",
            "latex": null,
            "type": "table"
        },
        "TABREF14": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF15": {
            "text": "",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}