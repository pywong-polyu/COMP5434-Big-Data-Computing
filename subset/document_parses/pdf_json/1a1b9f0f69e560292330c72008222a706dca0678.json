{
    "paper_id": "1a1b9f0f69e560292330c72008222a706dca0678",
    "metadata": {
        "title": "Triage of Potential COVID-19 Patients from Chest X-ray Images using Hierarchical Convolutional Networks",
        "authors": [
            {
                "first": "Kapal",
                "middle": [],
                "last": "Dev",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Trinity College Dublin",
                    "location": {
                        "country": "Ireland"
                    }
                },
                "email": ""
            },
            {
                "first": "Sunder",
                "middle": [
                    "Ali"
                ],
                "last": "Khowaja",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Sindh",
                    "location": {
                        "settlement": "Jamshoro",
                        "country": "Pakistan"
                    }
                },
                "email": ""
            },
            {
                "first": "Aman",
                "middle": [],
                "last": "Jaiswal",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Ankur",
                "middle": [],
                "last": "Singh Bist",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Signy Advanced Technologies. Gurugram",
                    "location": {
                        "region": "Haryana",
                        "country": "India"
                    }
                },
                "email": ""
            },
            {
                "first": "Vaibhav",
                "middle": [],
                "last": "Saini",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Surbhi",
                "middle": [],
                "last": "Bhatia",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Faisal University",
                    "location": {
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "The current COVID-19 pandemic has motivated the researchers to use artificial intelligence techniques for potential alternatives to reverse transcriptionpolymerase chain reaction (RT-PCR) due to the limited scale of testing. The chest X-ray (CXR) is one of the alternatives to achieve fast diagnosis but the unavailability of largescale annotated data makes the clinical implementation of machine learning-based COVID detection methods difficult. Another important issue is the usage of ImageNet pretrained networks which does not guarantee to extract reliable feature representations.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "In this paper, we propose the use of hierarchical convolutional network (HCN) architecture to naturally augment the data along with diversified features. The HCN uses the first convolution layer from COVIDNet followed by the convolutional layers from wellknown pre-trained networks to extract the features. The use of the convolution layer from COVIDNet ensures the extraction of representations relevant to the CXR modality. We also propose the use of ECOC for encoding multiclass problems to binary classification for improving the recognition performance. Experimental results show that HCN architecture is capable of achieving better results in comparison to the existing studies. The proposed method can accurately triage potential COVID-19 1 Corresponding author: Kapal Dev (email address: kdev@tcd..ie ) patients through CXR images for sharing the testing load and increasing the testing capacity.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "multiple ways for COVID-19 diagnosis but the reverse transcription-polymerase chain reaction (RT-PCR) remains the gold standard that detects the viral nucleic acid from the throat and nasopharyngeal swabs. However, the diagnosis using RTPCR takes more than 4-6 hours and has a low viral load which refers to the amount of virus found in the sputum. Moreover, due to the limited number of test kits, machines, and human experts, the scale of testing is marginally low for developing countries. South",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Korea is the first one to opt for massive testing but a lot of developed as well as developing countries cannot follow the same strategy due to the above limitations (Engelberg, Song and Dipillis, 2020; Bedingfield, 2020; McCurry, 2020; Sakellaropoulou , 2020) . Therefore, a fast way for COVID-19 diagnosis is in need for the timely trace, test, and treat (3T) strategy. Antigen testing is considered to be a fast way of COVID-19 diagnosis but yields poor sensitivity, therefore is not recommended (Oh, Park and Ye, 2020 ). An alternative to conventional testing is the analysis of chest computed tomography (CT) scans for COVID-19 diagnosis as it belongs to the family of pneumonia. As per the 10th revision of the International Statistical Classification of Diseases and Related Health Problems (ICD-10) COVID-19, SARS, and MERS fall under the category of viral pneumonia whereas the Streptococcus and Pneumocystis belong to the bacterial and fungal pneumonia, respectively (Fang, 2020) . The radiological examination through CT scans has shown better sensitivity in comparison to RT-PCR Ai, 2020) and can detect COVID-19 from weakly-positive or negative cases declared by RT-PCR. However, despite the better diagnostics, CT-scan has some of the problems similar to that of RT-PCR testing as they are limited in numbers and are too expensive for general masses. Moreover, the CT suites can get contaminated with the regular visits from COVID-19 patients and unlike nasal swabs used in RT-PCR the CT-suites are not disposable, thus, they require extensive cleansing, which put the radiologists and the patients at greater risk (Oh, 2020) .As an alternate modality to CT-scans the chest X-rays (CXRs) have been given a lot of attention for a fast COVID-19 diagnosis. The ground glass opacities, peripheral, and bilateral consolidation, described by CT-scans can also be reflected by CXR findings (Fang, 2020; Ai, 2020) . The authors (Wong et al, 2020) showed that the COVID19 can be diagnosed using CXRs but yield low sensitivity in comparison to RT-PCR testing.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 202,
                    "text": "(Engelberg, Song and Dipillis, 2020;",
                    "ref_id": null
                },
                {
                    "start": 203,
                    "end": 221,
                    "text": "Bedingfield, 2020;",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 222,
                    "end": 236,
                    "text": "McCurry, 2020;",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 237,
                    "end": 260,
                    "text": "Sakellaropoulou , 2020)",
                    "ref_id": null
                },
                {
                    "start": 499,
                    "end": 521,
                    "text": "(Oh, Park and Ye, 2020",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 977,
                    "end": 989,
                    "text": "(Fang, 2020)",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1091,
                    "end": 1100,
                    "text": "Ai, 2020)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1629,
                    "end": 1639,
                    "text": "(Oh, 2020)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1897,
                    "end": 1909,
                    "text": "(Fang, 2020;",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1910,
                    "end": 1919,
                    "text": "Ai, 2020)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1934,
                    "end": 1952,
                    "text": "(Wong et al, 2020)",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "However, there have been some cases (i.e. 9%) where CXRs were able to detect the abnormalities while the RT-PCR tests for those patients were declared negative. It has been established that the CXRs cannot replace the RT-PCR diagnosis at this instance but both of the diagnosing mechanisms can be used to reduce the strain on healthcare systems worldwide. CXR can potentially be used for patient triage as the indication of pneumonia can be detected with higher accuracy. Furthermore, the triage can be extended by distinguishing between bacterial and viral pneumonia so that the RT-PCR resources can be spared, substantially. The use of deep learning approaches in this pandemic has been quite welcoming, let it be for automatic skin temperature detection, mask detection, social distancing measures, RNA strain analysis, and so forth.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Researchers are actively working on improving the CXR diagnostics for COVID-19 classification. The researchers recently proposed COVIDNet from CXR images and have been shown to achieve 91% sensitivity. However, there are a few problems associated with the existing methods. First, the volume of the dataset which is quite limited due to the current public health emergency. Second, the features are either extracted from hand-crafted methods or a single end-to-end deep learning architecture pre-trained on ImageNet which limits the actual representation. Third, due to the high data imbalance, achieving good sensitivity, precision, and accuracy for COVID-19 diagnosis using multiclass classification is quite hard. Fourth, the system is limited in a sense such that it only deals with a few labels, however, the current recognition systems are unable to elevate COVID-19 patients from the patients having flu only. The methods are not capable of determining the severity of the case. Therefore, considering a standalone solution for COVID19 detection is not possible at this instance. To overcome the above-limitations, we proposed a hierarchical convolutional network (HCN). We solve the data distribution problem by extracting feature maps from multiple pretrained networks which is a natural way of augmenting images. We explore both the feature-level and decision-level fusion strategies for the augmentation tasks. The feature representation problem is addressed by using the first convolutional layer of COVIDNet-CXR3C (Wang and Wong, 2020) cascading with the initial layers of some of the well-known pre-trained networks to extract the features. We propose the use of ECOC conjunct with HCN to transform the multiclass into a binary classification problem for improving the classification accuracy and sensitivity. The advantage of using HCN is that it works well with a relatively small dataset and the data augmentation compels the network to avoid overfitting. We present a way to triage potential COVID-19 patients through CXR images with other ways of testing to speed and scale up the testing process. We further extend our analysis to compare the performance of HCN variants with the existing works. The class activation maps are also used to show the interpretation of the classification results. The contributions of this study are stated as follows:",
            "cite_spans": [
                {
                    "start": 1527,
                    "end": 1548,
                    "text": "(Wang and Wong, 2020)",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "\uf0b7 We propose HCN to classify COVID-19 from CXR images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "\uf0b7 We propose the use of a unique method, i.e. using the first layer of COVID-19 cascaded with the initial layers of pre-trained networks, to augment the data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "\uf0b7 We propose the ECOC encoding scheme to transform the multiclass into the binary classification problem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "\uf0b7 We present a potential triage strategy for speeding and scaling up the testing process.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "\uf0b7 Comparative analysis with the existing works and interpretability of the classification results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The rest of the paper is structured as follows. Section 2 provides a literature review of existing works. Section 3 describes the proposed methodology. Section 4 presents the experimental results and comparison with the existing works. This section also proposes a strategy to triage COVID-19 patients. Section 5 concludes the paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "There are a lot of research involved for practicing computer assisted systems in the domain of healthcare. Those researches include almost all the areas of medicine and obtain efficacious results especially when dealing with the images that are produced in the domain of medicine. For this purpose, a number of deep learning architectures were analyzed before employing certain known neural nets. Many studies have explored CXRimages as a surveillance tool for diagnosing and screening COVID-19 using deep learning techniques. With relevance to the proposed work, we divide the related works section into three divisions. The first subsection will highlight the studies using deep learning techniques specifically on the CXR modality. The second subsection consolidate the works using CXR images for COVID-19 diagnosis, and the third present the works focusing on feature and decision-level fusion strategies for COVID-19 diagnosis using CXR images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "CXRImages using Deep Learning: The researchers (Rajpurkar et al, 2017) developed an algorithm for multiclass classification on CT scan (CXRdataset) i.e.",
            "cite_spans": [
                {
                    "start": 47,
                    "end": 70,
                    "text": "(Rajpurkar et al, 2017)",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "ChestX-ray14 dataset. They built a 121 layers CNN architecture to classify the features of the given input x-ray images to one of the 14 different classes. The algorithm was named as CheXNet reporting an accuracy ranging from 0.73 to 0.93 for all 14 classes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "The DeepRadiology Team (Team TD, 2018) described an approach to pneumonia detection in chest radiographs. Their method used an open-source deep-learning object detection based on CoupleNet (a fully connected CNN). The local and global features were extracted with the intent to classify pneumonia. The model's accuracy was improved further using ensemble algorithm. The authors (Jakhar, Bajaj and Gupta, 2020 ) focused on diagnosing the presence of Pneumothorax using the frontal view of CXRimages. The segmentation techniques have been used to extract the features and predict an output mask correspondingly. U-Net and PretrainedResNet weights were used to achieve detection at a very fast and accurate way with promising results. The authors (Ranjan et al, 2018) used interpolation techniques by down-sampling the high dimensional medical images and further feeding them into the deep learning architecture. An autoencoder is created which includes an encoder, decoder and a CNN classifier to reconstruct the input images. A combination of MSE and BCE loss were used at last to predict the thoracic disease in the compressed domain obtained after autoencoders. Xiaosong Wang et al. (Wang et al, 2017) studied ChestX-ray8 dataset with 8 different classes of disease as atelectasis, cardiomegaly, effusion, infiltration, mass, nodule, pneumonia, and pneumothorax using deep CNN based on unified weakly-supervised multi-label image classification and disease localization formulation. This dataset was trained and tested on different pre-trained networks like AlexNet, VGG-16, GoogleNet, and ResNet-50.",
            "cite_spans": [
                {
                    "start": 23,
                    "end": 38,
                    "text": "(Team TD, 2018)",
                    "ref_id": "BIBREF55"
                },
                {
                    "start": 378,
                    "end": 408,
                    "text": "(Jakhar, Bajaj and Gupta, 2020",
                    "ref_id": null
                },
                {
                    "start": 744,
                    "end": 764,
                    "text": "(Ranjan et al, 2018)",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1184,
                    "end": 1202,
                    "text": "(Wang et al, 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Background"
        },
        {
            "text": "The authors (Basu and Mitra, 2020) demonstrated a novel technique using transfer learning for diagnosing COVID cases with chest X-rays. Their algorithm was named as Domain Extension Transfer Learning (DETL) that used the Gradient Class Activation Map for finding the characteristic features from the large dataset from different sources of radiology. The model with visual pattern was efficient for distinguishing between classes of COVID. Ozturk et al. (Ozturk et al, 2020) discussed the method using DarkNet model and used YOLO object detection system. The codes were created for assisting the radiologist for initial testing and screening for COVID cases. A deep model using X-ray images was proposed with accuracy reported for two findings as (binary) 98.08% and for multiclass cases as 87.02%. The authors (Farooq and Hafeez, 2020) studied the differentiation of the COVID-19 cases from that of the pneumonia cases using the CXRimages. A pre-trained ResNet-50 architecture was evaluated on the two publicly available datasets by using a three step technique. Their work includes the preprocessing steps on images as progressive resizing, cyclical learning rate findings and descriptive learning rate findings. The researchers (Kumar et al, 2020) presented the use of ResNet152 and machine learning classifiers distinguishing between cases of COVID-19 and non COVID-19 on CXRimages. Different classifiers were used for evaluating the performance with an accuracy of 0.973 with Random Forest and 0.977 with XGBoost is reported in the paper. The authors (Salman et al, 2020) proposed a model based on deep CNN using a pre-trained Inception V3 model for detecting chest X-rays. A dataset of total 260 images were tested and evaluated with 50% COVID-19 and 50% Normal x-rays. The authors ) developed a deep-learning model which was composed of a backbone network, a classification head, and an anomaly detection head.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 34,
                    "text": "(Basu and Mitra, 2020)",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 454,
                    "end": 474,
                    "text": "(Ozturk et al, 2020)",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 811,
                    "end": 836,
                    "text": "(Farooq and Hafeez, 2020)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1231,
                    "end": 1250,
                    "text": "(Kumar et al, 2020)",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1556,
                    "end": 1576,
                    "text": "(Salman et al, 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "COVID-19 Diagnosis with CXR images:"
        },
        {
            "text": "High-level features were generated from images using the backbone network and further these features were passed onto the heads to extract the classification score and anomaly score. Binary cross-entropy loss was used for classification score and deviation loss for anomaly score. The paper (Mukherjee et al, 2020) The uniqueness of the proposed work can be highlighted from both fronts, i.e. learning representations and network design. We propose a way to naturally augment the data by using first convolutional layer from COVID-19 followed by the well-known pre-trained networks. We show that the resultant representations are more diverse than the ones used in existing studies. Moreover, the proposed way of extracting features uses the ImageNet pre-trained networks effectively in compliance with the transfer learning dynamics. We also propose the use of ECOC for label encoding in order to transform the multiclass into binary classification problem which to the best of our knowledge has not been explored yet. Furthermore, this study explores various fusion strategies using the proposed learning representations and the network architecture so that the strategy attaining best results can be selected for comparative analysis.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 314,
                    "text": "(Mukherjee et al, 2020)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "COVID-19 Diagnosis with CXR images:"
        },
        {
            "text": "The proposed architecture for HCN is shown in Fig 1. As mentioned earlier, we use the first convolutional layer of pre-trained COVIDNet followed by the initial layers of well-known pre-trained networks to extract the feature maps. The pooling layers are designed such that they down-sample and up-sample the feature maps depending on the stage they are employed and selects a single response by performing convolution-sum fusion. The maps are then encoded for their labels using the ECOC technique for transforming the multiclass to the binary classification problem. The feature maps along with their encoded labels are then trained using DarkNet19 network architecture. The details for each of the blocks in Fig 1 are provided in the subsequent sections.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 46,
                    "end": 52,
                    "text": "Fig 1.",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 710,
                    "end": 719,
                    "text": "Fig 1 are",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Proposed Method"
        },
        {
            "text": "We employ the COVIDx dataset proposed to evaluate the COVID detection performance using HCN. The dataset comprises of 13,975 CXR images obtained from 13,870 patients. The COVIDx dataset is the combination of five publicly available dataset repositories such as COVID-19 radiography database (Rahman et al, 2020) , RSNA Pneumonia detection challenge dataset (R. S of N America, 2020), ActualMed COVID-19 CXR dataset initiative (ActualMed, 2020), COVID-19 CXR dataset initiative (Chung, 2020) and COVID-19 image data collection (Cohen et al, 2020) . All the above-mentioned datasets are open to the public and are continuously updated constantly. Most of the images representing COVID-19 patients were acquired from (Rahman, Chowdhury and Khandakar, 2020) whereas the normal patients and the ones with non-COVID Pneumonia are obtained using (Cohen et al, 2020) . One of the motivations of this work was to deal with the low volume of CXR images representing COVID patients. The COVIDx dataset has around 5,5328 and 8,066 CXR images for Normal and Bacterial Pneumonia, respectively, whereas only 358 CXR images are available for COVID-19 patients (Viral Pneumonia). The high data imbalance justifies our motivation for using activation maps from multiple pretrained networks to increase the volume of COVID positive CXR images. We adopt the dataset generation method from (Wang and Wong, 2020) . We used the same number of training and testing images as of COVID-19 so that a fair comparative analysis could be carried out.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 311,
                    "text": "(Rahman et al, 2020)",
                    "ref_id": null
                },
                {
                    "start": 477,
                    "end": 490,
                    "text": "(Chung, 2020)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 526,
                    "end": 545,
                    "text": "(Cohen et al, 2020)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 714,
                    "end": 753,
                    "text": "(Rahman, Chowdhury and Khandakar, 2020)",
                    "ref_id": null
                },
                {
                    "start": 839,
                    "end": 858,
                    "text": "(Cohen et al, 2020)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1369,
                    "end": 1390,
                    "text": "(Wang and Wong, 2020)",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "Dataset"
        },
        {
            "text": "We made our basis earlier that using the networks pre-trained on ImageNet might not provide us better feature representations that are supported by the research community. The authors (Cheplygina, 2019) conducted a study to provide a stance on whether the use of ImageNet pre-training is useful in medical imaging studies or not.",
            "cite_spans": [
                {
                    "start": 184,
                    "end": 202,
                    "text": "(Cheplygina, 2019)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Convolutional Layer from COVIDNet"
        },
        {
            "text": "The conclusion of the said study was: \"it depends\" suggesting that if the volume of the data is small then it's better to use a pre-trained network rather than initializing the weights randomly, however, if the volume of data is enough then the network should be trained on medical images from scratch. The authors (Raghu et al, 2019 ) also conducted a similar study and suggested that although the ImageNet pre-training is not beneficial in terms of accuracy and precision it does provide faster convergence. In compliance with the existing studies, we use the first convolutional layer from COVIDNet (Wang and Wong, 2020) the feature maps. The first layer has a convolutional filter size of 7x7 with a stride of 1x1. The feature dimensions are set to be 48 but the subsequent pooling layer will select a single response (as discussed in the next subsection). As the COVIDNet model was designed by GenSynth, the authors do not provide the architecture code directly. Therefore, we used the checkpoint utilities from tensorflow python training package, along with the index and the pre-trained model (.data) file provided by the authors of COVIDNet (Wang and Wong, 2020) to obtain the weights of the first convolutional layer (conv1-conv/kernel).",
            "cite_spans": [
                {
                    "start": 315,
                    "end": 333,
                    "text": "(Raghu et al, 2019",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 1149,
                    "end": 1170,
                    "text": "(Wang and Wong, 2020)",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "Convolutional Layer from COVIDNet"
        },
        {
            "text": "Intuitively, we assume that using the first convolutional layer from COVIDNet provides a better justification of transfer learning than by using standalone network architectures pre-trained on ImageNet (natural and colorful images). As the COVIDNet leverages the principles of residual network architecture, we compare the feature maps extracted from the first convolutional layer of well-known networks designed with residual connections such as ResNet50, DenseNet201, GoogleNet, and SqueezeNet pre-trained on ImageNet and the one extracted from the first convolutional layer of COVIDNet as shown in Fig 2. To get a single response, we use the max pooling layer for the aforementioned convolutional layers, accordingly. The visual difference in the feature maps is quite apparent. The feature map from the pre-trained networks extract some low-level information based on intensity levels which is beneficial for natural and colorful images but does not contribute much to the medical images, whereas the feature map from the COVIDNet's convolution layer focuses on the lung areas which is the cornerstone to detect COVID-19. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 601,
                    "end": 607,
                    "text": "Fig 2.",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Convolutional Layer from COVIDNet"
        },
        {
            "text": "In the proposed HCN-FM architecture, the first pooling layer is responsible for two operations. The first is the max pooling from the convolutional layer of COVIDNet and the second is the reversible downsampling of the feature maps into three sub-images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Pooling Layer"
        },
        {
            "text": "Subsequently, the tensor l of size W \u00d7 H/3 \u00d7C is formed and provided as an input to the initial layers of well-known convolutional networks pre-trained on ImageNet where l refers to the feature map, and W, H, and C represent the width, height, and channel, respectively. Zero-padding is performed to keep the size of the feature map compliant with the input size of pre-trained convolutional networks. Similarly, the second pooling layer also comprises of two operations. The first is the fusion of feature maps to provide a single feature response. Studies working on image analysis have extensively applied multiple fusion strategies to improve the recognition performance (Feichtenhofer, Pinz and Zisserman, 2016; Khowaja and Lee, 2020) which include sum, convolution, convolution-sum, and so forth. As suggested in (Feichtenhofer, Pinz and Zisserman, 2016; Khowaja and Lee, 2020) , the convolution-sum strategy performs better than both the sum and convolution fusion strategies, therefore, in this study, we use the convolution-sum strategy in our second pooling layer. Let ld\u2208 R H\u00d7W\u00d7D represent the d th feature map where d = 1, . . . , D. The convolution-sum fusion function f performs four steps: (1) concatenation, (2) convolution, (3) dimension reduction, and (4) summation.",
            "cite_spans": [
                {
                    "start": 675,
                    "end": 716,
                    "text": "(Feichtenhofer, Pinz and Zisserman, 2016;",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 717,
                    "end": 739,
                    "text": "Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 819,
                    "end": 860,
                    "text": "(Feichtenhofer, Pinz and Zisserman, 2016;",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 861,
                    "end": 883,
                    "text": "Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Pooling Layer"
        },
        {
            "text": "The feature map ld and ld-1 will be concatenated at spatial locations. The convolutional operation is performed through the filter banks which are defined in equation (1). The summation function is just the summation of feature maps with respect to their spatial locations. The convolution operation is applied through the filter banks and biases such that filt \u2208 R1\u00d71\u00d72w\u00d7h and bias \u2208 R h , respectively. A weighted combination of feature maps is generated through the convolution operation at spatial location w \u00d7 h followed by the reduction in dimension therefore the resultant feature representation will retain the actual size of the map. The second operation executed at this pooling layer is upscaling of feature map performed by the reverse operator from the first pooling layer to produce the map with the same W, H, and C as the input.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Pooling Layer"
        },
        {
            "text": "We use initial convolution layers from multiple network architectures pre-trained on ImageNet. Naturally, the question arises as to why we do not use COVIDNet layers as feature extraction? This work aims to extract diverse features to augment the data and in turn increasing the data volume. The problem with using COVIDNet layers as feature extraction is that we lose the diversification of feature maps. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Initial Convolutional Layers from pre-trained networks"
        },
        {
            "text": "The extracted feature maps will be assigned an encoded label using error-correcting output code (ECOC) in the form of { -1, 0, +1} where 0 represents the non-participating class, -1 and +1 refers to the negative and positive class, respectively. An example of encoded labels for CXR images is shown in Fig 4. The encoded labels will be assigned to each image for each hierarchy. For instance, a feature map will first be assigned either -1 or +1 for the first hierarchy and the darknet19 architecture will be trained on the encoded labels, accordingly. Similarly, the same feature map will undergo the second hierarchy and assigned a label amongst 0, -1, or +1 followed by the darknet19",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 302,
                    "end": 308,
                    "text": "Fig 4.",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Label Encoder"
        },
        {
            "text": "training. This is how the multi-class problem is transformed into a binary class. Let c define the number of classes and k be the length of the coding matrix, then the encoding matrix z for the ECOC will be of the size { -1, 0, +1 } c*k . The underlying assumption for using the coding matrix is that each column of z will have k classifiers (binary) which implies that the feature maps zck comprising of +1 or -1, i.e. positive or negative label, trains k classifiers based on c-th label and the zck having 0 encoded value will not participate in the training of k-th classifier. We are only interested in the encoded labels assigned to the feature maps by the k-th classifier instead of directly classifying them, the idea is to optimize the separation of feature maps based on their class labels through encodings to represent a binary classification problem. The hierarchical assignment of encoded values will be continued until a leaf node occurs. The weights and biases are characterized as W and B, respectively. We adopt the joint binary classifier learning (JCL) framework and the optimization method from the studies (Gao and Koller , 2011; Khowaja, Yahya and Lee, 2017) . The principle optimization problem is shown in equation (2). The variable \u03b4 refers to the mismatch loss between the actual encoded label and the predicted encoding. The notation n refers to the number of training samples, specifically the number of feature maps used for training. The first constraint in equation 2 refers to the coding variable \u03d1 which can take the values {-1,0,+1} representing the label c.",
            "cite_spans": [
                {
                    "start": 1127,
                    "end": 1150,
                    "text": "(Gao and Koller , 2011;",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1151,
                    "end": 1180,
                    "text": "Khowaja, Yahya and Lee, 2017)",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Label Encoder"
        },
        {
            "text": "The variables W, B, \u03b1 are the optimizable parameters that define the decision boundary as presented in the second constraint. The third constraint represents the hinge loss. The term \u03c4 in the fourth constraint refers to the tolerance level which is introduced to maintain the balance. The last constraint ensures that there is at least one positive and one negative class available. Equation 2 is optimized for the label encodings such that the labels are separable through a decision hyperplane. In the training phase, the label encodings are provided based on the categorization in Fig 3, but the equation 2 is optimized for the testing phase so that the images are assigned the label encodings so that the specific trained model could be activated for classification. For more details regarding the optimization problem, refer to the study (Khowaja, Yahya and Lee, 2017) .",
            "cite_spans": [
                {
                    "start": 843,
                    "end": 873,
                    "text": "(Khowaja, Yahya and Lee, 2017)",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [
                {
                    "start": 584,
                    "end": 590,
                    "text": "Fig 3,",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Label Encoder"
        },
        {
            "text": "The reason for choosing DarkNet19 architecture is that it is as accurate as ResNet architectures but takes 4x less time to train (Joseph, 2020) . It is apparent from the recent studies on COVID-19 diagnosis that the volume of viral pneumonia CXR images are less in number. Therefore, to balance the distribution of data we use the bootstrapping method with sample replacement at the batch level. We fine-tune the DarkNet19 network pre-trained on ImageNet with ADAM optimizer (Kingma and Ba, 2014) having an initial learning rate of 0.003, batch size of 32, and an exponential decay rate of 0.00005 after every 3 epochs. We train the network for 40 epochs. We used the rotation, translation, flipping, and zoom augmenting strategies for fine-tuning the network.",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 143,
                    "text": "(Joseph, 2020)",
                    "ref_id": null
                },
                {
                    "start": 475,
                    "end": 496,
                    "text": "(Kingma and Ba, 2014)",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "DarkNet19 architecture"
        },
        {
            "text": "The image analysis studies use fusion strategies extensively to improve recognition performance. We evaluate four different kinds of strategies that vary based on computational complexity and the number of parameters. We evaluate decision-level fusion strategy with meta-learning, decision-level fusion strategy with weighted averaging, feature-level fusion, and without fusion. The strategies are listed in their descending order suggesting that the decision-level fusion strategy with meta-learning comprises a large number of parameters and high computational complexity whereas the training without fusion has the lowest number of parameters and lower computational complexity amongst all the strategies. The decision-level fusion needs separate streams to be trained for encoded labels in a hierarchical fashion suggesting that a separate DarkNet19 network will be trained on features extracted from ResNet50 and so forth. The probabilities from each of the streams will be combined either using a meta-learning strategy (Khowaja, Yahya and Lee, 2017) or weighted averaging (Khowaja and Lee, 2020) The feature-level fusion combines the feature maps using gradient-sum pooling (Khowaja and Lee, 2020) and trains a single DarkNet19 architecture for the encoded labels in the proposed hierarchy. The use of the aforementioned fusion strategies with reference to the proposed architecture is shown in Fig 5. The HCN-FM represents a cross-modal training architecture (Khowaja and Lee, 2020) where the diverse features are trained using a single-stream. On the other hand, HCN-DML, and HCN-DWA takes an opposite approach by training an individual stream for a single modality. We adopt the implementation of HCN-DML from (Khowaja, Yahya and Lee, 2017) , HCN-DWA, and HCN-FLF from (Khowaja and Lee, 2020) , respectively. ",
            "cite_spans": [
                {
                    "start": 1026,
                    "end": 1056,
                    "text": "(Khowaja, Yahya and Lee, 2017)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1079,
                    "end": 1102,
                    "text": "(Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1181,
                    "end": 1204,
                    "text": "(Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1467,
                    "end": 1490,
                    "text": "(Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1720,
                    "end": 1750,
                    "text": "(Khowaja, Yahya and Lee, 2017)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1779,
                    "end": 1802,
                    "text": "(Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 1402,
                    "end": 1408,
                    "text": "Fig 5.",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Fusion Strategies"
        },
        {
            "text": "This section provides the quantitative and qualitative analysis for evaluating the effectiveness of the proposed HCN. We also perform ablation studies to select the best fusion strategy, accordingly. Furthermore, this section presents an implication of the proposed work in the form of a strategy for the triage of COVID-19 patients to support other testing approaches.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Results"
        },
        {
            "text": "As the proposed hierarchical classification network employs various fusion strategies, it is essential to evaluate each of the strategies quantitatively. This will allow us to investigate not only the test accuracy but also the trade-off between the accuracy and computational complexity. We evaluate HCN-DML, HCN-DWA, HCN-FLF, and HCN-FM using sensitivity, precision, and accuracy metric on test set images from the COVIDx dataset. The results are shown in Table I . The results show that the HCN-DML achieves the best result in terms of sensitivity, precision, and accuracy, accordingly. It makes sense as the HCN-DML has the highest computational complexity in comparison to the other strategies. An interesting finding here is that the HCN-FM performs better than the HCN-DWA which performs a weighted averaging on the probabilities obtained using four different network streams. Additionally, the HCN-DWA has the second-highest computational complexity whereas the HCN-FM has the lowest one and the least number of parameters. We assume that the resultant classification probabilities are quite close to each other for individual streams which makes it difficult for a weighted averaging scheme to differentiate them. On the other hand, the HCN-FM represents a cross-modal learning strategy but in this case, the cross-modality is represented at the input level, i.e. the feature maps. It has been shown in the literature that cross-modal learning in some cases benefits from the diverse representations and might achieve better results than the multi-stream networks (Khowaja and Lee, 2020) . The lowest recognition rate is obtained using HCN-FLF which is apparent as it uses a single response for training the network stream. The HCN-FLF does not leverage the natural way of data augmentation as proposed in this study.",
            "cite_spans": [
                {
                    "start": 1573,
                    "end": 1596,
                    "text": "(Khowaja and Lee, 2020)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 458,
                    "end": 465,
                    "text": "Table I",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Ablation Study"
        },
        {
            "text": "However, the results obtained using HCN-FLF are on par with the COVIDNet, respectively. It should also be noted that the HCN networks also use a bootstrapping technique to balance the distribution of the samples as well as the ECOC technique to transform the multiclass to the binary class classification problem. has proved to be beneficial in improving the performance with a large number of labels classifier (Khowaja, Yahya and Lee, 2017) , although, the increase in performance is not significant using 3 labels with respect to the HCN-DML but still the encodings improve the performance rather than degrading it. It is also to be noted that the use of ECOC and bootstrapping is supported by the results from HCN-FM where the absence of these techniques results in reduced sensitivity, i.e. 83.00$\\%$ for viral pneumonia.",
            "cite_spans": [
                {
                    "start": 412,
                    "end": 442,
                    "text": "(Khowaja, Yahya and Lee, 2017)",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Ablation Study"
        },
        {
            "text": "The results highlight that the ECOC and bootstrapping technique complement each other for improving the recognition performance and both the techniques are more effective with the less complex network designs. It should also be noted that the sensitivity for almost all the HCN variants is above 90% which is quite acceptable considering that the clinical experts achieved 69% for the same when diagnosing COVID-19 from CXR images. Moreover, the sensitivity of RT-PCR which is currently the gold standard has been recorded to be 91% (Wong et al, 2020) .",
            "cite_spans": [
                {
                    "start": 533,
                    "end": 551,
                    "text": "(Wong et al, 2020)",
                    "ref_id": "BIBREF56"
                }
            ],
            "ref_spans": [],
            "section": "Ablation Study"
        },
        {
            "text": "We illustrate the visualization of saliency maps using the Grad-CAM method (Selvaraju et al, 2017) in Fig 6 and 7 , respectively. The Fig. 6 and Fig.7 shows the broad main lesion learned by the network to classify COVID-19 patients, correctly. It was noticed that the particular map is only activated in COVID-19 CXR images whereas no saliency map was observed with Bacterial or Normal CXR images as shown in Fig 8. The images support our previous analysis where HCN achieves better sensitivity analysis than the gold standard. Moreover, the Grad-CAM maps can also be used for the interpretability of the CXR images while providing insights to the radiologists through main lesions which might be helpful for clinical diagnosis. The left image represents the original CXR whereas the right image represents the saliency map along with classification probabilities.",
            "cite_spans": [
                {
                    "start": 75,
                    "end": 98,
                    "text": "(Selvaraju et al, 2017)",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 102,
                    "end": 113,
                    "text": "Fig 6 and 7",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 134,
                    "end": 140,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 145,
                    "end": 150,
                    "text": "Fig.7",
                    "ref_id": null
                },
                {
                    "start": 409,
                    "end": 415,
                    "text": "Fig 8.",
                    "ref_id": "FIGREF9"
                }
            ],
            "section": "Qualitative Analysis"
        },
        {
            "text": "All of the experiments reported in this study have been conducted on a GPU NVIDIA GeForce GTX 1080Ti with 32GB RAM and Intel Core i7 clocked at 3.4 GHz.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison with the existing works"
        },
        {
            "text": "The COVID pandemic is recent therefore, the studies centered towards diagnosing COVID-19 from a limited amount of annotated images. We compare the proposed HCN architecture with three of the studies that are considered to be state-of-the-art approaches. The first one is the COVIDNet whereas the second and third are proposed in (Oh, Park and Y, 2020) and (Apostolopoulos and Mpesiana, 2020) . The comparison between the HCN architecture and the state-of-the-art approaches is shown in Table III .",
            "cite_spans": [
                {
                    "start": 329,
                    "end": 351,
                    "text": "(Oh, Park and Y, 2020)",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 356,
                    "end": 391,
                    "text": "(Apostolopoulos and Mpesiana, 2020)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 486,
                    "end": 495,
                    "text": "Table III",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Comparison with the existing works"
        },
        {
            "text": "It should be noted that we used the same dataset along with the same training and testing protocols to perform a fair comparison. The overall accuracy achieved by HCN-FM and HCN-DLM is 96.6\\% and 95.33% which outperforms the results reported in (Oh, Park and Ye, 2020; Apostolopoulos and Mpesiana, 2020) and COVIDNet, i.e. 91.9%, 94.72%, and 93.33$\\%$, respectively. Furthermore, the proposed method shows significant improvement in terms of both, the sensitivity and the precision, accordingly.",
            "cite_spans": [
                {
                    "start": 245,
                    "end": 268,
                    "text": "(Oh, Park and Ye, 2020;",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 269,
                    "end": 303,
                    "text": "Apostolopoulos and Mpesiana, 2020)",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Comparison with the existing works"
        },
        {
            "text": "The training time for HCN-FM and HCN-DLM was noted to be 1055, and 2926 seconds, whereas the testing time for both the networks, was noted to be 3, and 8 seconds, respectively. We do agree that the proposed HCN architecture is more computationally complex than that of in (Oh, Park and Ye, 2020; Apostolopoulos and Mpesiana, 2020) , and COVIDNet but considering the inference time, reliability of clinical diagnosis, and the ongoing pandemic situation, we believe that the accuracy weighs more than the computational complexity. Some studies proposed the COVID-19 detection from CXR images using the COVIDx dataset but their evaluation is either based on the same protocol as of (Wang and Wong, 2020) (Wong and Wang, 2020) 93.33% EfficientNet (Chung, 2020) 69.95% ConfiNet (Chung, 2020) 68.08% AnoDet (Chung, 2020) 73.24% CAAD (Chung, 2020) 72.77% DeTraC-ResNet18 (Cohen, 2020) 95.12% VGG19 (Cheplygina , 2019) 90.00% DenseNet201 (Cheplygina, 2019) 90.00% MobileNetv2 (ActualMed, 2020) 94.72% Hall (Raghu et al, 2019) 89.20%",
            "cite_spans": [
                {
                    "start": 272,
                    "end": 295,
                    "text": "(Oh, Park and Ye, 2020;",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 296,
                    "end": 330,
                    "text": "Apostolopoulos and Mpesiana, 2020)",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 679,
                    "end": 700,
                    "text": "(Wang and Wong, 2020)",
                    "ref_id": "BIBREF56"
                },
                {
                    "start": 701,
                    "end": 722,
                    "text": "(Wong and Wang, 2020)",
                    "ref_id": "BIBREF56"
                },
                {
                    "start": 743,
                    "end": 756,
                    "text": "(Chung, 2020)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 773,
                    "end": 786,
                    "text": "(Chung, 2020)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 801,
                    "end": 814,
                    "text": "(Chung, 2020)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 827,
                    "end": 840,
                    "text": "(Chung, 2020)",
                    "ref_id": "BIBREF59"
                },
                {
                    "start": 864,
                    "end": 877,
                    "text": "(Cohen, 2020)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 891,
                    "end": 910,
                    "text": "(Cheplygina , 2019)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 930,
                    "end": 948,
                    "text": "(Cheplygina, 2019)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 998,
                    "end": 1017,
                    "text": "(Raghu et al, 2019)",
                    "ref_id": "BIBREF40"
                }
            ],
            "ref_spans": [],
            "section": "Comparison with the existing works"
        },
        {
            "text": "HCN-FM 95.33% HCN-DML 96.67%",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Comparison with the existing works"
        },
        {
            "text": "As discussed earlier in this study, the limitation of the gold standard testing, i.e. RT-PCR is due to the shortage of testing kits and expert resources especially in the developing countries. Keeping in view the current spread of the COVID pandemic, the developed countries will also face the shortage of testing kits and medical capacity. It is therefore a need to explore all possible resources and distribute them based on 'triage'. The patients with cough or mild fever rush to the testing facility to get themselves diagnosed. It has been explored by existing studies that people with such symptoms mostly suffer from bacterial pneumonia (Brown and Lerner, 1998) . The study (Brown and Lerner, 1998) also suggests that viral pneumonia stands at the third common cause of pneumonia preceded by the S. pneumonia and H. influenza, respectively. For some geological regions, tuberculosis is also considered to be a common cause of pneumonia (Brown and Lerner, 1998) . The takeaway from the study (Brown and Lerner, 1998) is that the major portion of patients suffering from the flu, cough, or mild fever might have bacterial pneumonia or tuberculosis rather than COVID-19. Conducting their tests through the gold standard RT-PCR will be a waste of time as well as resources that can be effectively managed through the CXR image diagnosis.",
            "cite_spans": [
                {
                    "start": 644,
                    "end": 668,
                    "text": "(Brown and Lerner, 1998)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 681,
                    "end": 705,
                    "text": "(Brown and Lerner, 1998)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 943,
                    "end": 967,
                    "text": "(Brown and Lerner, 1998)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 998,
                    "end": 1022,
                    "text": "(Brown and Lerner, 1998)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Triage of HCN for COVID-19"
        },
        {
            "text": "Based on the HCN architecture, we present a triage workflow that could help distribute and manage the limited resources during this pandemic in Fig 9. The diagnosis through CXR images is much faster than that of RT-PCR which could be leveraged using HCN architecture. Specifically, the proposed method can distinguish between patients having normal, bacterial, and viral pneumonia. The ones diagnosed with viral pneumonia can be considered for further testing through RT-PCR or CT scans to double-check or validate the diagnosis. This will not only save the medical resources but will also help in speeding up the diagnosis and early isolation of the suspected cases, hence slowing down the spread of COVID-19. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 150,
                    "text": "Fig 9.",
                    "ref_id": "FIGREF10"
                }
            ],
            "section": "Triage of HCN for COVID-19"
        },
        {
            "text": "With the current spread of COVID-19 pandemic, the efficient utilization of medical resources is an important issue. The gold standard RT-PCR testing at a large scale is not possible for developing or developed countries. The patient management based on triage is the only option to test the patients and early isolation of the suspects. The CXR and CT scans are potential alternatives to RT-PCR testing. Unfortunately, CT scans suffer from the same problem as of RT-PCR which leaves us with CXR images. To make the diagnosis faster, the use of artificial intelligence can be leveraged by analyzing the CXR images in an automated way. However, the use of artificial intelligence requires a high volume of annotated data which is currently the main problem related to CXR image diagnosis.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        },
        {
            "text": "In this regard, we proposed the HCN architecture which uses the first convolution layer from COVIDNet followed by the well-known pre-trained architectures to extract the feature representations. This is a natural way to augment the annotated data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        },
        {
            "text": "Furthermore, we proposed the use of ECOC to transform the multiclass into a binary classification problem for improving the recognition performance. We also performed an in-depth analysis based on the fusion strategies to select the HCN variant with the best recognition performance. The results from the proposed HCN architecture were also verified through qualitative analysis (Grad-CAM) which showed that the activations in the saliency maps are triggered only in the COVID-19 patients' CXR.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        },
        {
            "text": "Furthermore, we compared the proposed work with existing state-of-the-art works and showed that the HCN yields better recognition performance. Finally, a triage workflow has also been laid out for showing the real-world applicability of the proposed work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        },
        {
            "text": "Even though we report the state-of-the-art results, the proposed work has some limitations for its applicability to the real-world setting. The first limitation is regarding the availability of the limited labeled dataset. Although, this work proposes a natural way of augmenting the data still the dataset is too small to be applied to real-world settings. The second limitation is the label constraints with respect to the dataset. The images are labeled as normal, bacterial, and viral pneumonia, however, there are many classifications within these three labels. For instance, bacterial pneumonia includes Streptococcus, Legionella, Pneumocystis, Klebsiella, and more whereas viral pneumonia includes SARS, MERS, COVID-19, and ARDS. The current system is not designed either to elevate COVID-19 patients from the ones having flu or to classify the severity of the cases. It is in line with the previous limitation, i.e. limited labeled data, accordingly.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        },
        {
            "text": "One of the benefits of using HCN is the ability to deal with multiple labels by leveraging the concepts of ECOC. As per the medical community, the diseases such as Pleural effusion, Pulmonary edema, Pulmonary fibrosis, and Chronic obstructive pulmonary disease (COPD) yield the same characteristics of lung shrinking in terms of CXR visualization, which can be added to the bacterial variant of pneumonia. However, the point is, there is a need for large-scale annotation with extended labels. As the proposed HCN uses ECOC, it can be helpful to build a recognition system with a large set of labels for differentiating amongst several diseases. As our future work, we want to coordinate with experts to build a database of such diseases to not only detect the disease but also to rate the severity of each disease through CXR images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussions and Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Abbas",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Abdelsamea",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Gaber",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.13815"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "COVID-19 Chest X-ray Dataset Initiative",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Actualmed",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Epidemiology, causes, clinical manifestation and diagnosis, prevention and control of coronavirus disease (COVID-19) during the early outbreak period: a scoping review. Infectious diseases of poverty",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "P"
                    ],
                    "last": "Adhikari",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Meng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "J"
                    ],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "P"
                    ],
                    "last": "Mao",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "X"
                    ],
                    "last": "Ye",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [
                        "Z"
                    ],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sylvia",
                    "suffix": ""
                },
                {
                    "first": "Rozelle",
                    "middle": [
                        "S"
                    ],
                    "last": "Raat",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "1--2",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lv",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Texture Analysis Algorithm for Digital Test of COVID-19 Patients",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "ICD-10-CM 2019 The Complete Official Codebook",
            "authors": [],
            "year": null,
            "venue": "American Medical Association",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks. Physical and Engineering Sciences in Medicine",
            "authors": [
                {
                    "first": "I",
                    "middle": [
                        "D"
                    ],
                    "last": "Apostolopoulos",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Mpesiana",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep Learning for Screening COVID-19 using Chest X-Ray Images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Basu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mitra",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.10507"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "What the world can learn from South Korea's coronavirus strategy",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Bedingfield",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Community-acquired pneumonia. The Lancet",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "D"
                    ],
                    "last": "Brown",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Lerner",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "352",
            "issn": "",
            "pages": "1295--302",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Cats or CAT scans: transfer learning from natural or medical image source data sets?. Current Opinion in Biomedical Engineering",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Cheplygina",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "9",
            "issn": "",
            "pages": "21--28",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "COVID-19 chest x-ray data initiative",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Chung",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Covid-19 image data collection: Prospective predictions are the future",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Morrison",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Dao",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "Q"
                    ],
                    "last": "Duong",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2006.11988"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "How South Korea Scaled Coronavirus Testing While the U.S. Fell Dangerously Behind",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Engelberg",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Depillis",
                    "middle": [
                        "L"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "13",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Sensitivity of chest CT for COVID-19: comparison to RT-PCR",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Ying",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Pang",
                    "suffix": ""
                },
                {
                    "first": "Ji",
                    "middle": [
                        "W"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Covid-resnet: A deep learning framework for screening of covid19 from radiographs",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Farooq",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hafeez",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.14395"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Convolutional two-stream network fusion for video action recognition",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Feichtenhofer",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Pinz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "InProceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1933--1941",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Discriminative learning of relaxed hierarchy for large-scale visual recognition",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Koller",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "In2011 international conference on computer vision",
            "volume": "",
            "issn": "",
            "pages": "2072--2079",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Finding covid-19 from chest x-rays using deep learning on a small dataset",
            "authors": [
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "B"
                    ],
                    "last": "Goldgof",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "M"
                    ],
                    "last": "Goldgof",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.02060"
                ]
            }
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "InProceedings of the IEEE conference on computer vision and pattern recognition",
            "authors": [],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Covidx-net: A framework of deep learning classifiers to diagnose covid-19 in x-ray images",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "E"
                    ],
                    "last": "Hemdan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Shouman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "E"
                    ],
                    "last": "Karar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.11055"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Van Der Maaten",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "Q"
                    ],
                    "last": "Weinberger",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "InProceedings of the IEEE conference on computer vision and pattern recognition 2017",
            "volume": "",
            "issn": "",
            "pages": "4700--4708",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "N"
                    ],
                    "last": "Iandola",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "W"
                    ],
                    "last": "Moskewicz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Ashraf",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "J"
                    ],
                    "last": "Dally",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Keutzer",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Squeezenet",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1602.07360"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Deep Learning Image Segmentation to predict Pneumothorax",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Jakhar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bajaj",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gupta",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Pneumothorax Segmentation",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1912.07329"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Open Source Neural Networks in C, 2020",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Joseph",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Darknet",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Khowaja",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Neural Computing and Applications",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Hierarchical classification method based on selective learning of slacked hierarchy for activity recognition systems. Expert Systems with Applications",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "A"
                    ],
                    "last": "Khowaja",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "N"
                    ],
                    "last": "Yahya",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "88",
            "issn": "",
            "pages": "165--77",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "A method for stochastic optimization",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Kingma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ba",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Adam",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1412.6980"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Accurate Prediction of COVID-19 using Chest X-Ray Images through Deep Feature Learning model with SMOTE and Machine Learning Classifiers. medRxiv",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Kumar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Arora",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Bansal",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [
                        "J"
                    ],
                    "last": "Sahayasheela",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Buckchash",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Imran",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Narayanan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "N"
                    ],
                    "last": "Pandian",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Raman",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "YOLO3: A Huge Improvement",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Mc",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Test, Trace, contain: How South Korea flattened its coronavirus curve",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mccurry",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "30",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Multi-Channel Transfer Learning of Chest X-ray Images for Screening of COVID-19",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Misra",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Jeon",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Managuli",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2005.05576.2020"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Shallow Convolutional Neural Network for COVID-19 Outbreak Screening using Chest X-rays",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ghosh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Dhar",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Obaidullah",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Santosh",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roy",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Deep learning covid-19 features on cxr using limited training data sets",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Oh",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Ye",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Medical Imaging",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Automated detection of COVID-19 cases using deep neural networks with X-ray images",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "B"
                    ],
                    "last": "Baloglu",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computers in Biology and Medicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bertolini",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "O"
                    ],
                    "last": "Teixeira",
                    "suffix": ""
                },
                {
                    "first": "Silla",
                    "middle": [],
                    "last": "Jr",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "N"
                    ],
                    "last": "Costa",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [
                        "M"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Computer Methods and Programs in Biomedicine",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Transfusion: Understanding transfer learning for medical imaging. InAdvances in neural information processing systems",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Raghu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kleinberg",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "3347--3357",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "A New Modified Deep Convolutional Neural Network for",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Rahimzadeh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Attar",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Detecting COVID-19 from X-ray Images",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.08052"
                ]
            }
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "COVID-19 Radiography Database",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Rahman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chowdhury",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khandakar",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Radiologist-level pneumonia detection on chest x-rays with deep learning",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rajpurkar",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Irvin",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bagul",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Langlotz",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Shpanskaya",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Lungren",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Chexnet",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1711.05225"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Jointly Learning Convolutional Representations to Compress Radiological Images and Classify Thoracic Diseases in the Compressed Domain",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Ranjan",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kapoor",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Kar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sethuraman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sheet",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "InProceedings of the 11th Indian Conference on Computer Vision",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "RSNA Pneumonia Detection Challenge",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "America",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Accessed",
            "volume": "30",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Research in the time of a pandemic: Korea's COVID-19 success story",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sakellaropoulou",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF48": {
            "ref_id": "b48",
            "title": "Coronavirus disease 2019 (COVID-19): a systematic review of imaging findings in 919 patients",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Salehi",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Abedi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Balakrishnan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gholamrezanezhad",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "American Journal of Roentgenology",
            "volume": "14",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF50": {
            "ref_id": "b50",
            "title": "Visual explanations from deep networks via gradient-based localization. InProceedings of the IEEE international conference on computer vision 2017",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "R"
                    ],
                    "last": "Selvaraju",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cogswell",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Vedantam",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Batra",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Grad-Cam",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "618--626",
            "other_ids": {}
        },
        "BIBREF52": {
            "ref_id": "b52",
            "title": "Severe acute respiratory syndrome (SARS): a year in review",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Babiuk",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "Annu. Rev. Med",
            "volume": "56",
            "issn": "",
            "pages": "357--81",
            "other_ids": {}
        },
        "BIBREF53": {
            "ref_id": "b53",
            "title": "From SARS to MERS, thrusting coronaviruses into the spotlight",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bao",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Qu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Viruses",
            "volume": "11",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF54": {
            "ref_id": "b54",
            "title": "Going deeper with convolutions",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Szegedy",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sermanet",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Reed",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Erhan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vanhoucke",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Rabinovich",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "InProceedings of the IEEE conference on computer vision and pattern recognition",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF55": {
            "ref_id": "b55",
            "title": "Pneumonia detection in chest radiographs",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "D"
                    ],
                    "last": "Team",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1811.08939"
                ]
            }
        },
        "BIBREF56": {
            "ref_id": "b56",
            "title": "COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-Ray Images",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.09871"
                ]
            }
        },
        "BIBREF57": {
            "ref_id": "b57",
            "title": "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bagheri",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Summers",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "InProceedings of the IEEE conference on computer vision and pattern recognition 2017",
            "volume": "",
            "issn": "",
            "pages": "2097--2106",
            "other_ids": {}
        },
        "BIBREF59": {
            "ref_id": "b59",
            "title": "Frequency and distribution of chest radiographic findings in COVID-19 positive patients",
            "authors": [
                {
                    "first": "Chung",
                    "middle": [
                        "T"
                    ],
                    "last": "Kw",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF60": {
            "ref_id": "b60",
            "title": "World Health Organization. Coronavirus disease (COVID-19) pandemic. 2020. Acessado em",
            "authors": [],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF61": {
            "ref_id": "b61",
            "title": "Chest CT for typical 2019-nCoV pneumonia: relationship to negative RT-PCR testing",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF62": {
            "ref_id": "b62",
            "title": "Covid-19 screening on chest x-ray images using deep learning based anomaly detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.12338"
                ]
            }
        },
        "BIBREF63": {
            "ref_id": "b63",
            "title": "Covid-19 screening on chest x-ray images using deep learning based anomaly detection",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xia",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2003.12338"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "proposed lightweight CNN architecture for classifying COVID positive chest X-ray cases. This model was trained on 260 CXR of COVID positive and tested on 130 COVID-19 x-ray images. They have used batch-size of 25, 50, 75, 100, 125, and 150. The advantage of this method was reduced parameters than other deep learning methods and less computational time. The researchers (Abbas et al, 2020) proposed a DeTraC CNN architecture for the classification of the CXRimages as COVID-19. DeTraC is an acronym for Decompose, Transfer and Compose which deals with any irregularities with the help of class boundary obtained by class decomposition method. The extra decomposition layer for adding more flexibility to their decision boundaries was added with the motive to decompose each class into subclasses and assigning labels to the new set of class for getting final results. The shallow tuning mode for feature extraction was employed. The model gave high accuracy of 95.12% with comprehensive dataset of images. The authors (Basu and Mitra, 2020) proposed Domain Extension Transfer Learning (DETL) for the screening of COVID-19 with the help of feature extraction from the x-ray images. They give a Grad-CAM concept to examine the detection transparency with the help of region detection where the model paid more attention during the classification. The authors (Misra et al, 2020) presented a multi-channel transfer learning model based on ResNet architecture on different sets of dataset composition. 3 classes as normal, pneumonia and COVID were used as the target values. So, they used 3 subnetwork model of binary classification for them similar as one vs all classification. Further, a fine-tuning with another model to do to achieve the classification output. The authors (Wang et al, 2020) investigated COVID-Net to makes predictions using an explain ability method based on Deep Neural Network-based architecture for detection of the COVID disease. The customized lightweight designpattern was an added advantage with reduced computational complexity. Adam optimizer was used using a learning rate policy on different set of datasets, namely publicly available dataset and COVIDx dataset. This dataset was generated which contains 358 COVID-19 affected X-ray images, 8066 normal x-rays and 5538 pneumonia affected x-rays. Both quantitative and qualitative analysis was conducted on the above dataset with good score of about 93.3% test accuracy.Feature and Decision Level fusion strategies for COVID-19 diagnosis:The authors(Pereira etal, 2020)  discussed features and decision level fusion method by proposing resampling algorithms for detecting COVID on CXR images. Texture descriptions were used for extracting multiple features with CNN and several fusion techniques were used for strengthening the texture descriptions for final classification.The results of the research tested in RYDLS-20 gave an average results of 0.65 with macro average F-score metric using a multi-class labelled data samples and 0.89, as F-1 score for classifying COVID-19 in the hierarchical classification case. The paper(Al-  Karawi etal, 2020)  proposed and demonstrated novel approach of extracting features from the LBP-transformed CXR images of different types of Chest infections, with the aim of developing an automatic CAD system to be used for distinguishing between COVID-19 and Non COVID-19. The findings resulted an accuracy of 94.43%. The authors(Rahimzadeh and Attar, 2020)  proposed the concatenated neural network by capturing the features extracted from Xception and ResNet50V2 and then fusing it to a convolutional layer that is connected to the classifier. The dataset included 180 CXRof COVID patients, 6054 pneumonia affected X-rays and 8851 normal x-ray images. The fine-tuned ResNet50V2 and Xception network predicts the result with the average accuracy as 99.56%.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The Proposed HCN-FM Architecture",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Feature maps extracted from the first convolutional layer of COVIDNet and well known pre-trained networks such as ResNet50, GoogleNet, DenseNet201, SqueezeNet, pre-trained on ImageNet.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Furthermore, the characteristics of COVIDNet in the feature maps are retained from each pre-trained network architecture as the forward pass of the CXR image is propagated through the first convolution layer of the said network. The size of the extracted feature map from each pre-trained network is kept constant by branching off the networks at a specific layer. For instance, ResNet50, DenseNet201, GoogleNet, and SqueezeNet(Huang et   al, 2017;Iandola et al, 2016; He et al, 2016; Szegedy etal, 2015)  are branched off at 38 th , 54 th , 28 th , and 29 th layer, respectively, to get a 28x28x128 feature responses with added zero-padding to maintain the consistency in image size. The diversified feature maps from the first convolutional layer of the aforementioned pre-trained networks preceding the first convolution layer of COVIDNet is shown inFig 3.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Feature maps from the first convolutional network of the pretrained networks preceded by the COVIDNet convolutional layer.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The ECOC method for label encodings for converting multi-class to binary classification problem where +1 and -1 represent the positive and negative class, and the 0 refers to the confusing class ought to be ignored in the training and at the inferential stage",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Application of fusion strategies with reference to the proposed architecture.HCN-FM \u2192 CN without fusion, HCN-FLF \u2192 HCN with feature-level fusion, the feature maps are fused using gradient-sum pooling(Khowaja and Lee, 2020), HCN-DML \u2192 HCN with meta-learning based decisionlevel fusion, the probabilities of the classified labels are trained using a shallow-learning classifier(Khowaja, Yahya and Lee, 2017), and HCN-DWA \u2192 HCN with weighted averaging based decision-level fusion, the probabilities of the classified labels are combined through weighted averaging and the class with maximum probability is selected.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Example of an activation map for Viral Pneumonia patient using Grad-CAM.The left image represents the original CXR whereas the right image represents the saliency map along with classification probabilitiesFig. 7. Example of an activation map for Viral Pneumonia patient using Grad-CAM.The left image represents the original CXR whereas the right image represents the saliency map along with classification probabilities.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Example of an activation map for Bacterial Pneumonia patient using Grad-CAM.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Triage workflow using HCN architecture",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Quantitative results for the fusion strategies using hierarchical classification network",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "bootstrapping and ECOC technique to get a deeper understanding. The results are reported inTable II. The results show that the transformation to binary class problem plays a vital role in improving the COVID recognition performance from CXR images.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "or they perform the binary classification, i.e. COVID-19 and non-COVID-19 patients. We compare the performance of HCN with the other recent studies in terms of accuracy inTable IV. It is evident that the proposed HCN architecture outperforms the recent studies for detecting COVID-19 from CXR images.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Comparison of proposed HCN Architecture with state-of-the-art methods",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Comparison with the recent studies in terms of Accuracy",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}