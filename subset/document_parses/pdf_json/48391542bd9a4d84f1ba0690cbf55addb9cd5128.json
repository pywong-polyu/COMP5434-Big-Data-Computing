{
    "paper_id": "48391542bd9a4d84f1ba0690cbf55addb9cd5128",
    "metadata": {
        "title": "CPSC: Conformal prediction with shrunken centroids for efficient prediction reliability quantification and data augmentation, a case in alternative herbal medicine classification with electronic nose",
        "authors": [
            {
                "first": "Li",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Xianghao",
                "middle": [],
                "last": "Zhan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Xikai",
                "middle": [],
                "last": "Yang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Shanghai Jiao Tong University",
                    "location": {
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Xiaoqing",
                "middle": [],
                "last": "Guan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Rumeng",
                "middle": [],
                "last": "Wu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Zhan",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Zhiyuan",
                "middle": [],
                "last": "Luo",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of London",
                    "location": {
                        "postCode": "TW20 0EX",
                        "settlement": "Egham Hill, Egham",
                        "region": "Surrey",
                        "country": "UK"
                    }
                },
                "email": ""
            },
            {
                "first": "You",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            },
            {
                "first": "Guang",
                "middle": [],
                "last": "Li",
                "suffix": "",
                "affiliation": {
                    "laboratory": "The State Key Laboratory of Industrial Control Technology",
                    "institution": "Zhejiang University",
                    "location": {
                        "postCode": "310027",
                        "settlement": "Hangzhou",
                        "country": "China"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "In machine learning applications, the reliability of predictions is significant for assisted decision and risk control. As an effective framework to quantify the prediction reliability, conformal prediction (CP) was developed with the CPKNN (CP with kNN). However, the conventional CPKNN suffers from high variance and bias and long computational time as the feature dimensionality increases. To address these limitations, a new CP frameworkconformal prediction with shrunken centroids (CPSC) is proposed. It regularizes the class centroids to attenuate the irrelevant features and shrink the sample space for predictions and reliability quantification. To compare CPKNN and CPSC, we employed them in the classification of 12 categories of alternative herbal medicine with electronic nose as a case and assessed them in two tasks: 1) offline prediction: the training set was fixed and the accuracy on the testing set was evaluated; 2) online prediction with data augmentation: they filtered unlabeled data to augment the training data based on the prediction reliability and the final accuracy of testing set was compared. The result shows that CPSC significantly outperformed CPKNN in both two tasks: 1) CPSC reached a significantly higher accuracy with lower computation cost, and with the same credibility output, CPSC generally achieves a higher accuracy; 2) the data augmentation process with CPSC robustly manifested a statistically significant improvement in prediction accuracy with different reliability thresholds, and the augmented data were more balanced in classes. This novel CPSC provides higher prediction accuracy and better reliability quantification, which can be a reliable assistance in decision support. 2",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "In machine learning applications, the reliability of predictions is significant for assisted decision and risk control. As an effective framework to quantify the prediction reliability, conformal prediction (CP) was developed with the CPKNN (CP with kNN). However, the conventional CPKNN suffers from high variance and bias and long computational time as the feature dimensionality increases. To address these limitations, a new CP frameworkconformal prediction with shrunken centroids (CPSC) is proposed. It regularizes the class centroids to attenuate the irrelevant features and shrink the sample space for predictions and reliability quantification. To compare CPKNN and CPSC, we employed them in the classification of 12 categories of alternative herbal medicine with electronic nose as a case and assessed them in two tasks: 1) offline prediction: the training set was fixed and the accuracy on the testing set was evaluated; 2) online prediction with data augmentation: they filtered unlabeled data to augment the training data based on the prediction reliability and the final accuracy of testing set was compared. The result shows that CPSC significantly outperformed CPKNN in both two tasks: 1) CPSC reached a significantly higher accuracy with lower computation cost, and with the same credibility output, CPSC generally achieves a higher accuracy; 2) the data augmentation process with CPSC robustly manifested a statistically significant improvement in prediction accuracy with different reliability thresholds, and the augmented data were more balanced in classes. This novel CPSC provides higher prediction accuracy and better reliability quantification, which can be a reliable assistance in decision support.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Machine learning classification algorithms have enabled many successful applications in the field of biomedicine such as patient outcome prediction [1] and free-text clinical note mining [2] . For classification applications in biomedicine, besides the metrics like accuracy, precision and recall, the reliability of the predictions is of great significance, as the misclassification can lead to delayed treatment and tremendous physiological and mental burden [3] . For instance, in the case of cancer diagnosis, the risky prediction with unclear reliability can either lead to undetected carcinoma and even metastasis, or the false positives which may lead the patient to suffer from costly and harmful chemotherapy and radiotherapy. On the contrary, if the reliability of predictions could be quantified, additional and complementary diagnostic approaches can be taken in time to improve the diagnosis reliability.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 151,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 187,
                    "end": 190,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 461,
                    "end": 464,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To quantify the prediction reliability in machine learning, Platts method [4] , probably approximately correct learning (PAC) [5] , Bayesian learning [6] , have been proposed. However, those methods typically require the data to be in large quantities or under normal distribution to estimate a prior probability. These assumptions are hard to satistfy in real-world applications due to factors like measurement limitations, such as inadequate training samples, measurement noises, sensor drifts. Therefore, a more robust and precise reliability quantification method without strong assumptions is in need. Conformal prediction (CP), proposed by Shafer and Vovk [7] , has proved a computational framework effective in prediction reliability quantification. It is featured by generating accurate confidence levels of predictions: with a given significance level \u03b5, it outputs a set of region predictions which contains the true label with confidence at least 1-\u03b5.",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 77,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 126,
                    "end": 129,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 150,
                    "end": 153,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 662,
                    "end": 665,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Without the requirements of distributional or model assumptions , CP can work with any underlying algorithm to calculate nonconformity measurement [8] , which is used to measure the conformity of a prediction with the training data. The k-nearest neighbor (kNN) was initially proposed as an underlying algorithm. In previous research, CP is frequently combined with kNN [3, [9] [10] [11] [12] , and the approach is usually referred to as CPKNN, which quantifies the nonconformity of a new sample via the ratios of the sums of Euclidean distances from k nearest observations with same/different potential labels. However, multiple issues arise when CPKNN is used: firstly, when dealing with high-dimensional data, CPKNN suffers from the curse of dimensionality: the sparsely scattered points in high-dimensional space may lead the pairs of samples close in Euclidean distance to be not similar in their classes, particularly when many dimensions do not contain relevant classification information, which may finally lead to high variance and high bias. [13] . Secondly, to get the k nearest observations, CPKNN needs to iteratively compute the distances on the entire training set. Therefore, CPKNN is computationally expensive. Compared with the kNN, shrunken centroid (SC) classifier, as a regularized version of the nearest centroid (NC) classifier and with the additional attenuation of noisy and uninformative dimensions, has been shown effective in fast computation and in dealing with high-dimensional data. Proposed by Tibshirani et al. [14] , SC simplifies the distance computation process by taking class centroids as the reference points rather than all the scattered sample points. Therefore, SC only needs to compute the Euclidean distances with the time in an order of the number of classes rather than the number of training samples. Additionally, SC can make the high-dimensional feature space more compact by shrinking the class centroids and attenuating the irrelevant features for classification, which is meaningful to the real-world application of measurement technology, as higher dimensions of features are frequently observed in machine learning modeling, particularly in the field of biomedicine (e.g., the high-dimensional gene data and biomedical sensor measurements). Considering the prediction reliability of the high-dimensional data, it is worthwhile to develop and investigate conformal prediction based on shrunken centroids (CPSC).",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 150,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 370,
                    "end": 373,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 374,
                    "end": 377,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 378,
                    "end": 382,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 383,
                    "end": 387,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 388,
                    "end": 392,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1052,
                    "end": 1056,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1544,
                    "end": 1548,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As a appropriate case with the issue of high dimensionality in the field of biomedical research and the significance of reliability quantification, the classification of alternative herbal medicine with the electronic nose is worthwhile to be investigated [15, 16] . Different categories herbal medicines are valuable in medical research and patient treatment, but even the categories close in species can bring about diverse treatment effect [17] . The different treatment values and varying prices of herbal medicines lead to the fraud and inferior herbal medicine products. These facts call for an effective way to identify different herbal medicines for better patient treatment. However, many of the herbal medicines are hard to classify due to their similar appearance, especially when they are pulverized. Electronic nose system (e-nose), has proved its effectiveness in solving this task. However, in previous publications, high-dimensional engineered features are extracted from e-nose signals, contributing to the potential curse of dimensionality [9, 16, [18] [19] [20] . It can not only bring high variance and bias in getting accurate and reliable prediction, but also high computational cost before we get the predictions and reliability quantification with the conventional CPKNN. Therefore, it is meaningful to develop an efficient mechanism with e-nose system to further optimize the prediction reliabiltiy quantification and computational speed.",
            "cite_spans": [
                {
                    "start": 256,
                    "end": 260,
                    "text": "[15,",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 261,
                    "end": 264,
                    "text": "16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 443,
                    "end": 447,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1058,
                    "end": 1061,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1062,
                    "end": 1065,
                    "text": "16,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1066,
                    "end": 1070,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1071,
                    "end": 1075,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1076,
                    "end": 1080,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "2/22"
        },
        {
            "text": "In this study, a new CP framework, CPSC, is developed, and its effectiveness is compared with the conventional CPKNN on the classification task of 12 categories of herbal medicines, where both computational cost and prediction reliability were compared in two scenarios: 1) offline prediction, where the training data were fixed and three metrics on testing set were evaluated: the runtime, the prediction accuracy and the quantified reliability, 2) online prediction with data augmentation, where the training data were augmented with samples filtered by the CP in an on-going manner, and the prediction dynamics of both CP frameworks and their respective influences on the classifier's accuracy were compared. As a result, this study reveals that CPSC contributes to better reliability quantification, higher classification accuracy, more effective data augmentation and an remarkable advantage of computational speed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "2/22"
        },
        {
            "text": "In machine learning classification problems, the classifiers leverage the knowledge from an observed training set Z:((x 1 , y 1 ) , . . . , (x n\u22121 , y n\u22121 )) to learn the mapping of a new sample x n from the sample space X (also known as feature space) to its label y n in the label space Y [7, 11] . With an additional parameter, the significance level \u03b5, conformal predictor can give the new sample x n a prediction region \u0393 \u03b5 which is a subset of label space Y , with a confidence level 1 \u2212 \u03b5. This confidence level indicates how much confidence one has for that the true label is included in the prediction region \u0393 \u03b5 [12, 21, 22] . With this quantified probability, conformal prediction enables the users to make reasonable decisions with better risk control.",
            "cite_spans": [
                {
                    "start": 291,
                    "end": 294,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 295,
                    "end": 298,
                    "text": "11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 622,
                    "end": 626,
                    "text": "[12,",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 627,
                    "end": 630,
                    "text": "21,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 631,
                    "end": 634,
                    "text": "22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "In the process of modeling prediction regions, conformal predictors employ a mechanism called nonconformity measurement to evaluate how conformed or strange a sample is when compared with other observations already seen. For each example in z i (i = 1, 2, . . . , n) \u2208 Z, the nonconformity measurement presents as a real number \u03b1 i (i = 1, 2, . . . , n) \u2208 R, which is calculated by a measurable function A:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "3/22",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "For a new sample x n , P-values are computed based on the nonconformity measurement, which then enables the construction of the prediction region according to the following formula:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "where p y is the P-value of a potential label y (y \u2208 Y ) for the new sample x n . It indicates how well this new sample (with the predicted label of y) conforms to observations already seen. With every potential label y for x n , the nonconformity measurement \u03b1 y n is computed, and corresponding p y is defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "What must be mentioned is that unlike the predicted probability with a softmax function in the multi-class classification, the sum of P-values for one sample over the label space does not necessarily equal 1 because the conformal predictor does not directly model the conditional probability P (Y |X), but focuses on the conformity with the set of training observations. Therefore, the nonconformity measurement of each possible label in the label space is calculated as an independent attempt based on the training observations. If CP was forced to output one prediction y based on the largest P-value (also referred to as forced prediction), two reliability metrics for the prediction can be given: 1) credibility: the largest P-value, which indicates how reliable the best choice of prediction y in the label space Y is, based on its conformity to the training observations; 2) confidence: 1 -the second largest P-value, which indicates how reliable the best prediction y is, based on the exclusion of other possible choice of prediction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal Prediction"
        },
        {
            "text": "As a regularized version of the nearest centroid classifier [23] , shrunken centroid (SC) classifier attenuates the irrelevant features and shrink the class centroids to the overall centroid [14] , which alleviates the negative influences on classification exerted by noises. For a test sample x, SC finds its nearest 'denoised' centroid based on the Euclidean distance and outputs the predicted label based on the label associated with the centroid. In this process, the new sample only needs to be compared with K class centroids, instead of being compared with all the individual observations as what is done in kNN classifier. Furthermore, SC shrinks the reference sample space covered by the training samples to be more compact as a form of regularization, and therefore alleviates the curse of dimensionality intrinsic in many Euclidean-distance-based methods such as KNN. To model the posterior probabilities of a potential predicted label k: P (Y = k|X), SC works with observed training set Z in following steps: 1) Compute the prototype centroidsx k of each class (1,2,...,K) and the overall centroid \u00b5 of all observations (Z:((x 1 , y 1 ) , . . . , (x n , y n ))) as (5), (6) shows, where C k denotes the set of samples with label k, and n k denotes the quantity of samples with label k.x",
            "cite_spans": [
                {
                    "start": 60,
                    "end": 64,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 191,
                    "end": 195,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 1182,
                    "end": 1185,
                    "text": "(6)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "2) Calculate the pooled within-class standard deviation, and standardize the bias between class centroids and the overall centroid:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "3) Shrink the biases with a threshold \u2206:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "Note that the centroidsx k , \u00b5, the standard deviation s, and biases d k are all vectors, which contain the information of all p features j=1,2,...,p. As 9 shows, on the one hand, if d jk , the bias of a j-th feature of class k, has an absolute value which is smaller than the threshold \u2206, the corresponding feature will be considered not informative enough for classification. Therefore, this bias in this feature will be shrunken to zero and the noisy feature is therefore removed, which also lowers the data dimensionality. On the other hand, if d jk has an absolute value larger than the threshold \u2206, the bias will be shrunken towards the overall means, shrinking the sample space as a form of regularization. 4) Update the class centroids with the shrunken biases:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "5) Compare the new sample with shrunken centroids:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "This discrimination score \u03b4 k (x * ) measures how close the new sample is to the shrunken centroids. Its result consists of two terms: the first term log \u03c0 k is the prior probability of class k, defined by the portion of the samples in class k in overall observations. The second term is the standardized squared distance between k-th centroids and this new sample. Therefore, the posterior probability of a given class k, P (Y = k|X) is decided by both the prior class distribution and sample's proximity to different centroids. 6) Compute the probability of that a new sample belongs to class k:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "To convert the probabilities into the range [0,1] and aggregates to 1, the softmax method is adopted. Additionally, a scale parameter T was innovatively added, which may shrink the value of \u03b4 k (x * ) and make the predicted probability distribution softer. We borrowed the idea of temperature from knowledge distillation in this design because the softmax function with a higher temperature generally leads to a more balanced distribution across different labels and therefore maintain the information of those less possible labels as well as avoid overfitting to some extent [24, 25] .",
            "cite_spans": [
                {
                    "start": 576,
                    "end": 580,
                    "text": "[24,",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 581,
                    "end": 584,
                    "text": "25]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Shrunken centroids"
        },
        {
            "text": "Conformal predictor leverages a measurable function A (2) as the nonconformity measurement. For SC, inspired by the previous works [21, 26] , the function A was defined as:",
            "cite_spans": [
                {
                    "start": 131,
                    "end": 135,
                    "text": "[21,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 136,
                    "end": 139,
                    "text": "26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Conformal prediction with Shrunken Centroids (CPSC)"
        },
        {
            "text": "where y i denotes the label for x i . For a sample among the training observations Z, the nonconformity measurement is a real number because its label is known. However, for a",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal prediction with Shrunken Centroids (CPSC)"
        },
        {
            "text": "new sample x * , its \u03b1 * is a vector with a length of K which is the number of potential labels. This vector contains all the \u03b1 * k for all the potential labels y k = 1, 2, ..., K in Y . With the nonconformity measurement \u03b1 * , the P-value p * of x * is given as (4) shows. Note that p * is also a vector, including the P-values for all potential labels of x * . The labels with P-values higher than the significance level \u03b5 will be output in the prediction region, and the largest P-value indicates the most reliable label based on the nonconformity measurement.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 266,
                    "text": "(4)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "5/22"
        },
        {
            "text": "In CPKNN, the function A for nonconformity measurement of x i is defined as [27] :",
            "cite_spans": [
                {
                    "start": 76,
                    "end": 80,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Conformal prediction with kNN (CPKNN)"
        },
        {
            "text": "To compute it, firstly, the distances between x i and other observations in",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal prediction with kNN (CPKNN)"
        },
        {
            "text": "Secondly, the k num nearest observations which have the same/different labels with x i are ranked respectively. Here x y m denotes the observations with the same label as x i , and the x !y denotes the observations with a different label. Then, the sums of the distances from k num nearest observations with same/different label are divided. Under this scheme, the closer a sample locates to its homogeneous groups and farther to its heterogeneous groups, the lower nonconformity measurement it gets. The way CPKNN converts \u03b1 to P-value follows (4), with the same rule as CPSC to give prediction outputs based on P-value.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conformal prediction with kNN (CPKNN)"
        },
        {
            "text": "In this study, CPSC and CPKNN were applied to the classification of 12 categories of alternative herbal medicines based on a self-assembled e-nose system. This e-nose system has been shown effective in the classification of herbal medicines in our previous publications [19, [28] [29] [30] [31] . The system includes 16 TGS (Taguchi Gas Sensors) type metal-oxide semi-conductive (MOS) sensors by Figaro Engineering Inc, Osaka, Japan. The details of the sensors are listed in Table 1 .",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 274,
                    "text": "[19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 275,
                    "end": 279,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 280,
                    "end": 284,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 285,
                    "end": 289,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [
                {
                    "start": 475,
                    "end": 482,
                    "text": "Table 1",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experiment and dataset"
        },
        {
            "text": "This self-assembled e-nose system consisted of four major components: the gas transporting system, the sensors reaction chamber, the data acquisition unit, and the data processing and pattern recognition algorithms. The brief description of e-nose system is illustrated in Fig. 1 . The gas transporting system controls the flow of the standard gas (dry and clean air) and the objective gas with two gas pumps and a three-way valve. The entire process of collecting a sample lasted for 400 seconds, and the sensors' reactions are recorded by data acquisition unit (DAQ) with a sampling rate of 100 Hz, as is shown in Fig. 2 . During the intervals between the sensor reaction time periods for two different samples, the standard gas was pumped in to reset the sensors. This baseline-setting period took up 20 s with a flow rate of 1 L/minutes. The objective gas, which was the 10 mL headspace air collected from each individual sample, was then injected into the sensors reaction chamber to react with the sensor panel (shown as ascending curve in the sensor reaction signals). The objective gas stayed in the chamber for 180 s, and then it was pumped out with the input of the standard gas again (shown as descending curve in the sensor reaction signals).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 273,
                    "end": 279,
                    "text": "Fig. 1",
                    "ref_id": null
                },
                {
                    "start": 616,
                    "end": 622,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Experiment and dataset"
        },
        {
            "text": "The experiment was done at the State Key Laboratory of Industrial Control Technology, Zhejiang University in 2017 [28] . The environment temperature was 22 -27 \u2022 C, and the humidity was kept in an interval of 50% -70 %. Figure 1 . The brief description of the electronic nose system. The e-nose system consists of four sub-systems: 1) the gas transporting system to control the flow, 2) the reaction chamber where the objective gas reacts with the sensor panel, 3) the data acquisition unit to record the signals, and 4) the computer system for signal processing and classification. For each type of the medicines, 50 samples were collected with the following process: 1. Used an electrical pulverizer to grind the medicines into powders. 2. For each medicine sample (all-together 12x50=600 samples) , took 8 grams of its powder into a 125 ml glass container, and seal the container with a para-film.",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 118,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [
                {
                    "start": 220,
                    "end": 228,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Experiment and dataset"
        },
        {
            "text": "3. Heated the sample powders in a thermostatic chamber (50 \u2022 C) for 10 hours, and waited for another 10 hours to let the volatile gases diffuse in the glass container.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiment and dataset"
        },
        {
            "text": "4. Took 10 mL gas mixtures in the headspace of each glass container as the objective gas, ready to be injected into sensors reaction chamber.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experiment and dataset"
        },
        {
            "text": "The primitive data are the temporal signals from 16 sensors, in the form of voltage changes in 16 channels. First, the signals was calibrated by subtracting each sensors' baselines:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "Here V s denotes the recorded response of sensors, and V 0 denotes the baseline of sensors. According to the previous research, 8 commonly used features for each sensor were extracted, which turned out to be effective in pattern recognition with e-nose systems [32] . This feature extraction process output 128 features for a single sample:",
            "cite_spans": [
                {
                    "start": 261,
                    "end": 265,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "1. The maximum value of V:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "2. The area under the curve of V:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "where T takes 340s, the same long as data recording period. 3-8. Exponential moving average of the derivative of V:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "E a (V ) = [min(y(k)), max(y(k))], 2000 < k < 34, 000",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "where the discrete sampling exponential moving average and parameter \u03b1 are set to be:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "where SR represents the sampling rate (100 Hz in this study), and E a (V ) denotes a vector of the smallest and largest values of y(k). After performing the feature engineering, a feature matrix with size of (600 x 128) was extracted as our dataset, which constructed the sample space for 12 categories of herbal medicines in this study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data processing and Feature Engineering"
        },
        {
            "text": "In this study, two tasks to compare the two CP frameworks (CPSC and CPKNN) were designed: 1) offline prediction and 2) online prediction with data augmentation, as shown in Fig. 3 . The offline prediction task is the most prevalence machine learning application scenario. The dataset was randomly split into training set, validation set and testing set for 30 times, with a ratio of 4:1:1. First, training set was used to train the model (CPSC and CPKNN) , and the hyperparameters were tuned according to the classification accuracy on the validation set. The hyperparameters included the shrink threshold \u2206 and temperature T in CPSC, and the K num of kNN. In this offline task, three metrics were investigated to compare the CPSC and CPKNN performances: the classification accuracy on the testing set, the prediction credibility (as the major reliability information) given by the CPSC and CPKNN for the test predictions, and their runtime. Ideally, a CP framework should reach a high accuracy when the prediction credibility is high. Therefore, to compare the reliability of CPSC and CPKNN, the prediction accuracy with different intervals of credibility thresholds were calculated.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 173,
                    "end": 179,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 438,
                    "end": 454,
                    "text": "(CPSC and CPKNN)",
                    "ref_id": null
                }
            ],
            "section": "Study pipeline"
        },
        {
            "text": "Another application of the reliability given by conformal prediction is in the online prediction, where the data augmentation can be performed based on the reliability of the unlabeled data. In the online task, the dataset was partitioned into training set, active set (unlabelled data), validation set, and testing set, with a ratio of 1:2:1:1. The validation set is used for hyperparameter tuning, and the active set was the assumed unlabeled data available for online augmentation process. The online augmentation process follows the same pattern as our previous research [16] . As Fig. 3 (b) shows, Linear Discriminant Analysis (LDA) [33] is adopted as the basic classifier to predict testing set, as LDA generally performed better with the data augmentation process according to our previous research [16] and we aimed to only compare the influence of CPSC and CPKNN on data augmentation process. CPSC and CPKNN are applied in the data augmentation process. First, CPSC and CPKNN are trained with the initial training set, and then the 4 batches of active set were predicted and augmented into the training set in a batch-wise manner with these two CP frameworks. According to the previous research [21] , in the augmentation process, only the sample satisfying two criteria can be chosen: the credibility of its label prediction (the largest P-value) should be 1) larger than the threshold . 2) three times larger than the second-max P-value. These two criteria ensure that the predictions are with high credibility and that the prediction confidence is not too low. In this study, the effectiveness of data augmentation was evaluated by the improvement of LDA's classification accuracy on testing set. Furthermore, because CPSC and CPKNN output prediction regions which can be comprised of singleton predictions, empty predictions and multiple predictions, to observe the prediction dynamics of online prediction and compare the prediction characteristics of CPSC and CPKNN, the output of the region predictions were counted, and the following metrics were visualized: the accumulative counts of singleton predictions, the multiple predictions, the empty prediction, and the accepted samples in the augmentation process. Furthermore, to qualitatively compare the class balance in the augmentation process, we plotted the distribution of the predicted classes among the augmented data.",
            "cite_spans": [
                {
                    "start": 575,
                    "end": 579,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 638,
                    "end": 642,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 806,
                    "end": 810,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1204,
                    "end": 1208,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 585,
                    "end": 595,
                    "text": "Fig. 3 (b)",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Study pipeline"
        },
        {
            "text": "To test the statistical significance of the performance difference between CPSC and CPKNN in two tasks (each task for 30 times), several statistical tests are leveraged: 1) Shapiro Wilk test for evaluating the normality of data, 2) Wilcoxon signed rank test or t-test for statistically comparing the prediction performance metrics (e.g. accuracy) from two groups, depending on the result of Shapiro Wilk test. While the Shapiro Wilk test rejected the normality assumption, Wilcoxon signed rank test is adopted rather than t-test. The process of online prediction with data augmentation: first employing CPKNN and CPSC to predict the active set and augment training set, and then comparing their effectiveness on improving prediction accuracy on testing set before/after data augmentation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Statistical tests"
        },
        {
            "text": "The accuracy of CPSC and CPKNN in offline prediction is illustrated in Fig. 4 , which shows that CPSC reaches a higher prediction accuracy (median: 0.854) than CPKNN (median: 0.763) with statistical significance (p \u2264 0.05) and runs much faster than CPKNN (p \u2264 0.05, and the computational cost analysis will be done in the last result subsection).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 71,
                    "end": 77,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Offline prediction"
        },
        {
            "text": "As one important characteristic of CP is that this computational framework can provide the reliability of predictions [7, 22] , to verify the CP validity and test whether the predictions with high credibility are indeed more likely to be correct prediction, and to investigate how reliable the offline predictions CPKNN and CPSC make, a statistical comparison of the accuracy of the predictions with credibility values in different credibility intervals was done. According to the results shown in Fig. 5 , with a higher credibility (c) interval, the prediction accuracy of CPSC and CPKNN both increases. This indicates that 1) in CP framework, the credibility information c is effective in assisting in decision making: if the prediction credibility is higher, the prediction is more likely to be true; 2) with the same credibility interval, predictions made by CPSC are more accurate than CPKNN, as CPSC generally achieves a higher prediction accuracy. These properties of CPSC enables the users to better leverage the credibility information to aid in decision making when compared with the conventional CPKNN.",
            "cite_spans": [
                {
                    "start": 118,
                    "end": 121,
                    "text": "[7,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 122,
                    "end": 125,
                    "text": "22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [
                {
                    "start": 498,
                    "end": 504,
                    "text": "Fig. 5",
                    "ref_id": null
                }
            ],
            "section": "Offline prediction"
        },
        {
            "text": "In addition to giving reliability information besides the predictions themselves for better decision making in offline scenarios, another major application of CP is for online prediction with data augmentation, where the augmented data can be filtered by the prediction reliability to improve the quality of augmented data [9, 10] . The accuracy of online prediction with data augmentation under different credibility thresholds (from 0.1-0.9) is displayed in Fig. 6 . The result shows that CPSC robustly achieved a statistically significantly higher accuracy (p \u2264 0.05) after data augmentation with all (the credibility threshold that enables the prediction to be added into the training set) setting. Although both CPSC and CPKNN generally led to higher classification accuracy after data augmentation, however, CPKNN only showed accuracy improvement (p \u2264 0.05) in a subset of settings (0.4-0.7), and even showed statistically significantly decreases in accuracy when was set to be 0.9. The results shown in Fig. 6 manifests that in a proper subset of settings (such as 0.2-0.7), a higher in data augmentation enables CPKNN to gain a lager accuracy improvement. However, when the threshold was set to be close to 1 (such as 0.8-0.9), CPKNN suffers an accuracy decline after data augmentation. In contrast, CPSC performed robustly with improved accuracy after data augmentation under all settings.",
            "cite_spans": [
                {
                    "start": 323,
                    "end": 326,
                    "text": "[9,",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 327,
                    "end": 330,
                    "text": "10]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [
                {
                    "start": 460,
                    "end": 466,
                    "text": "Fig. 6",
                    "ref_id": null
                },
                {
                    "start": 1010,
                    "end": 1016,
                    "text": "Fig. 6",
                    "ref_id": null
                }
            ],
            "section": "Online prediction with data augmentation"
        },
        {
            "text": "To better evaluate the prediction types given by CPSC and CPKNN, the prediction dynamics of online augmentation process is illustrated in Fig.7 , which presents the classification accuracy after each batch of data augmentation in Fig.7 (a) and (b) , and the accumulative counts of specific types of predictions: accepted prediction (the predictions which satisfy the reliability requirements in Section 2.7), singleton predictions (the predictions with only one predicted label in the region predictions), multiple predictions (the predictions with more than one predicted labels in the region predictions), and empty predictions (the predictions with no label in the region predictions) in Fig. 7 (c) and (d). Here, three are taken as examples: 0.1, 0.5, and 0.9, and the results are displayed in (Fig. S1 ), including the result of from 0.1, 0.3, 0.5, 0.7 and 0.9. For the prediction accuracy, in cases where the final accuracy was improved (CPSC ((a1)-(a3)) and CPKNN cases ((b1)-(b2))), the accuracy dynamics manifest a similar pattern: when the first batch was augmented, the accuracy slightly declined, possibly because the models did not learn a robust relationship based on the initial training data. When more active data were added into the training set via augmentation, the accuracy increased to the initial level and finally outperformed the baseline (p \u2264 0.05). However, in (b3) (CPKNN with 0.9), the accuracy was gradually declining with the addition of every batch of active data. Based on the accumulative counts of various types of predictions, when was fixed, CPKNN generally output much more multiple predictions (i.e. more than one predicted labels in the prediction region) while CPSC generally output more singleton predictions. As for the empty predictions, CPSC output more empty predictions when was lower than 0.5, but CPKNN gave more of them when is higher than 0.5. As for the accepted predictions, CPSC generally took in more augmented samples than CPKNN, especially when comes to 0.9. To better investigate the augmentation process when was 0.9, the distribution of the predicted classes of augmented samples from CPSC and CPKNN was illustrated in Fig. 8 . In general, CPSC tends to be more certain in making predictions: the predicted labels are with high credibility values. Therefore, its prediction region \u0393 \u03b5 always includes only a singleton prediction, and with the same credibility threshold , CPSC generally accepts more samples than CPKNN does. Besides, compared with CPKNN, CPSC kept a more balanced distribution in predicted class when augmenting data. Fig. 4 (b) displays the box plot of runtime for training model and classifying 120 cases in offline task with CPKNN and our proposed CPSC, where the median runtime of CPKNN and CPSC over 30 trials are about 7.5s and 0.05s, respectively. We used a personal computer ( Intel(R) Core(TM) i7-8550U CPU@1.80GHz 2.00 GHz, and a RAM with 16.0 GB) to train the models. It is obvious that, compared with CPKNN, the computational cost of CPSC decreases considerably. Furthermore, the runtime of CPKNN ranges over 5.5-9.5s, which is clearly larger than the runtime variance in terms of the CPSC. Figure 6 . The online prediction accuracy on the testing set with data augmentation under a series of settings. The accuracy is calculated with LDA classifier after the entire data augmentation process has been done. Each group of accuracy results (with 30 times of random dataset partition) are compared with those given by the baseline (without augmentation). The statistical significance is tested by Wilcoxon signed-rank test. 14/22 Figure 8 . The distribution of the augmentation classes predicted by CPKNN and CPSC when is 0.9.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 138,
                    "end": 143,
                    "text": "Fig.7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 230,
                    "end": 247,
                    "text": "Fig.7 (a) and (b)",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 691,
                    "end": 697,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 798,
                    "end": 806,
                    "text": "(Fig. S1",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 2179,
                    "end": 2185,
                    "text": "Fig. 8",
                    "ref_id": null
                },
                {
                    "start": 2595,
                    "end": 2605,
                    "text": "Fig. 4 (b)",
                    "ref_id": null
                },
                {
                    "start": 3180,
                    "end": 3188,
                    "text": "Figure 6",
                    "ref_id": null
                },
                {
                    "start": 3617,
                    "end": 3625,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Online prediction with data augmentation"
        },
        {
            "text": "Theoretically, the computational cost of CPKNN is dominated by the calculation of nonconformaity measurement \u03b1 i . Based on the (14), the computational complexity of CPKNN can be stated as O(pn), where p denotes the overall feature number of collected samples, n represents the size of training dataset. On the other hand, the computational time of CPSC mainly depends on the standard deviation update and the distance computation between new sample with , which are indicated as to (7), (11) , respectively. And the total computational complexity of CPSC is supposed to be O(n + pK), where K denotes the class number. Normally, the size of training dataset (n) surpasses the number of overall categories (K) extremely. Therefore, training CPKNN model consumes several times as long as the CPSC model.",
            "cite_spans": [
                {
                    "start": 488,
                    "end": 492,
                    "text": "(11)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "13/22"
        },
        {
            "text": "In this study, CPSC is proposed as a novel conformal predictor, and it is compared against the conventional CP framework CPKNN which has already been proved to be effective in many classification tasks for reliability quantification and data augmentation, in such application fields as herbal medicine classification [16, 27, 28, 31] and lung cancer detection [3] . This study investigates CPSC and CPKNN in classifying 12 categories of herbal medicines with the e-nose system, where two tasks are designed: offline prediction (to compare the accuracy and verify the ability of reliability quantification), and online prediction with data augmentation (to compare the effectiveness of data augmentation with CPSC/CPKNN in improving classificaiton accuracy). In these two tasks, several metrics are studied: the accuracy and reliability of offline prediction, the effectiveness of data augmentation in online prediction, and the computational cost. In task 1 (offline prediction), CPSC achieves a higher accuracy with a much faster speed with statistical significance. In task 2 (online prediction with data augmentation), CPSC stably improves the prediction accuracy with a series of credibility thresholds. Furthermore, the augmentation effect tends to be better with the increase of , as the threshold of filtering the predictions is getting stricter. However, CPKNN suffers a decline when reaches 0.9. According to Fig. 8 , most of the augmented samples filtered by CPKNN belong to class 6 or 2, which shows an unbalanced distribution of the augmentation classes predicted by CPKNN. This may be because of the more evident feature dissimilarities of class 6 from other classes, which is also shown in the heatmap in our previous publications [16] . In contrast, CPSC filters the augmented samples in a much more balanced manner with more cases in diverse classes, which may finally lead 15/22 to the better performances after data augmentation with CPSC.",
            "cite_spans": [
                {
                    "start": 317,
                    "end": 321,
                    "text": "[16,",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 322,
                    "end": 325,
                    "text": "27,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 326,
                    "end": 329,
                    "text": "28,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 330,
                    "end": 333,
                    "text": "31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 360,
                    "end": 363,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1745,
                    "end": 1749,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1890,
                    "end": 1895,
                    "text": "15/22",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 1418,
                    "end": 1424,
                    "text": "Fig. 8",
                    "ref_id": null
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "As for the reasons why CPSC generally outperforms CPKNN in both the offline and online prediction tasks, we believe that it may be attributed to the fact that CPSC attenuates the negative influences of relatively irrelevant features via the shrunken centroids, and the fact that CPSC better summarizes the classification information with the representative centroids for each class. Therefore, the variance and bias caused by curse of dimensionality could be alleviated as the feature space is more compact. The reason for CPSC's advantage on the computational cost is that CPSC 1) attenuates the irrelevant features thus reduces dimensionality ; 2) makes predictions based on the distance with regularized class centroids. Therefore, the times of Euclidean distance calculation for a test sample is proportional to the number of centroids. On the contrary, CPKNN calculates and sorts the Euclidean distance between a test sample and each training sample in a pair-wise manner. The optimization in Euclidean distance calculation (both the shrunken feature space and reduced computational cost) enables CPSC to perform faster, especially when dealing with high dimensional data. Furthermore, the parameters (temperature and shrinkage) in CPSC help users with the freedom to adjust the regularization strength of prediction and calibrate the reliability given by CPSC with expert knowledge. To be exact, the newly proposed parameter T in CPSC makes the probabilities distribution among class more balanced, and the shrinking threshold \u03b4 controls the extent of dimensionality reduction and noise attenuation. When these parameters were set in a proper interval, they have little impact on prediction accuracy but may optimize the reliability of the predictions where the users can calibrate the reliability quantified by CPSC with their field experience and expertise.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "The CPSC proposed by us is one component in the broad category of conformal prediction (CP) algorithms, which is featured with the ability to provide the reliability information related to the classification prediction [7] in a distribution-free manner. This important characteristic can help users to make a decision with additional consideration of reliability and prediction confidence, which can also be referred to as the prediction mindset of the classifier. For example, over the past years, machine learning and deep learning have shown their great potential in assisting in medical diagnosis, such as the COVID-19 patient outcome prediction, lung cancer diagnosis and traumatic brain injury monitoring [3, 28, 34] . However, an incorrect decision made by machine learning models in medical diagnosis might result in disastrous consequence. For example, in cancer detection, a patient receiving a false negative diagnosis result might miss the best period for treatment. On the contrary, a false positive diagnosis result might lead the patient to suffer from unnecessary chemotherapy, which does harm to the patient's normal tissues. Therefore, to improve the reliability of machine learning applications in medical diagnosis, the credibility, as one type of the reliability information provided by CP, can be used to facilitate more reliable medical diagnosis: a high prediction credibility indicates that the results are generally more reliable for the user to trust. However, a low credibility informs that the prediction may not be reliable enough so that the doctors may need to consider other diagnostic approaches to confirm the decision output by the machine learning system, instead of drawing an arbitrary conclusion. In addition to ensure the reliability in decision, CP has manifested its effectiveness in online prediction with data augmentation. With proper thresholds on credibility, CP filters and predicts the unlabeled samples that have high conformity with initial training set. In this way, the CP leverages the reliability as the \"prediction mindset\" and utilizes it to filter the predictions for data augmentation with higher quality. As a result, with the CP and the reliability thresholding, the classifiers can learn to be more powerful and accurate with the increasing number of samples.",
            "cite_spans": [
                {
                    "start": 219,
                    "end": 222,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 711,
                    "end": 714,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 715,
                    "end": 718,
                    "text": "28,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 719,
                    "end": 722,
                    "text": "34]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Although CP has lots of unique benefits which are mentioned above, it still has something worth attention from the users to ensure online prediction with data augmentation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "First, the threshold should stay in a proper interval to balance the quality and quantity of the augmented data. As Fig. 6 and Fig. 7 show, when is above 0.7, the quantity of augmented samples declines and the data augmentation can not always ensure a statistically significant improvement on prediction accuracy. This is because the higher is, although the samples filtered by a stricter criteria can be more reliable (i.e., the predictions with higher credibility values are with higher prediction accuracy, as shown in Fig. 5) , the fewer samples can be added in the training set, and the distribution of the augmentation classes is more likely to be unbalanced (which is shown in using CPKNN in Fig. 8 , where the majority of the augmented samples have the predicted class as 6 or 2) as CP more readily picks up the easy-to-predict classes. In this case, the augmentation with high might have directly led the model to overfit the training data. However, a low might further regularize the model by allowing many less reliable augmented samples to be added to the training set. We suppose the reason why more augmented samples matter in this case is: the initial training set may not enable the models to learn a robust pattern for each class and a robust decision boundary between each pair of classes, while the augmented samples aid in the expansion of the feature space covered by the training samples and add in more information related to the data distribution. As a result, the larger quantities of unlabelled data may facilitate the modeling process. Therefore, the balance between augmentation's quality and quantity is important, which requires a proper setting. Second, the parameters ( K num in CPKNN, T and \u03b4 in CPSC) should be tuned based on the need of users, which has been illustrated in the previous discussion paragraphs.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 116,
                    "end": 122,
                    "text": "Fig. 6",
                    "ref_id": null
                },
                {
                    "start": 127,
                    "end": 133,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 522,
                    "end": 529,
                    "text": "Fig. 5)",
                    "ref_id": null
                },
                {
                    "start": 699,
                    "end": 705,
                    "text": "Fig. 8",
                    "ref_id": null
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Although the novel CPSC proposed in this paper outperformed the conventional CPKNN in many aspects in the offline and online tasks, there are still limitations in our research which must be mentioned. First, there lacks a comparison between CPSC and other more complicated CP framework, such as CPSVM and CP-LSTM [26] , which may be able to perform better than CPKNN. In this study, we focused on the comparison with CPKNN. This is because CPKNN is the first proposed CP framework, which has been proved effective by many datasets. Therefore, it can be regarded as a proper baseline to be compared with. Another reason is that we presume that CPSVM and CP-LSTM are more flexible models driven by the data which take even more time on computation when compared with CPKNN due to the optimization problem setting. Second, for each dataset, only one type of feature engineering method is adopted. We chose the feature engineering approahces which have shown effective or the most effective in terms of classification accuracy in the previous publications [28, 32] . However, we believe that CPSC can display even more of its advantages when facing high dimensional dataset if we change the feature sets, such as using down-sample and FFT features [35] (the number of features is more than 318). Therefore, as for future work, CPSC will be compared with other types of CP framework and applied on dataset with even higher dimensionality to further validate the model's advantage. 18/22",
            "cite_spans": [
                {
                    "start": 313,
                    "end": 317,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1052,
                    "end": 1056,
                    "text": "[28,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1057,
                    "end": 1060,
                    "text": "32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1244,
                    "end": 1248,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Ai-based analysis of ct images for rapid triage of covid-19 patients",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "NPJ digital medicine",
            "volume": "4",
            "issn": "1",
            "pages": "1--11",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Structuring clinical text with ai: old vs. new natural language processing techniques evaluated on eight common cardiovascular diseases",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Humbert-Droz",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Mukherjee",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gevaert",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "An electronic nose-based assistive diagnostic prototype for lung cancer detection with conformal prediction",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Measurement",
            "volume": "158",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Platt",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Advances in large margin classifiers",
            "volume": "10",
            "issn": "3",
            "pages": "61--74",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Probably approximately correct learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Haussler",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Bayesian learning for neural networks",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Neal",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "118",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "A tutorial on conformal prediction",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Shafer",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vovk",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "Journal of Machine Learning Research",
            "volume": "9",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "A gentle introduction to conformal prediction and distribution-free uncertainty quantification",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "N"
                    ],
                    "last": "Angelopoulos",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Bates",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2107.07511"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Feature engineering in discrimination of herbal medicines from different geographical origins with electronic nose",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 IEEE 7th International Conference on Bioinformatics and Computational Biology (ICBCB)",
            "volume": "",
            "issn": "",
            "pages": "56--62",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Boost ai power: Data augmentation strategies with unlabelled data and conformal prediction, a case in alternative herbal medicine discrimination with electronic nose",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "IEEE Sensors Journal (Accepted",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Inductive conformal prediction: Theory and application to neural networks",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Papadopoulos",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Regression conformal prediction with nearest neighbours",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Papadopoulos",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vovk",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gammerman",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Artificial Intelligence Research",
            "volume": "40",
            "issn": "",
            "pages": "815--840",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "The elements of statistical learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Hastie",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tibshirani",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Springer series in statistics New York",
            "volume": "1",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Diagnosis of multiple cancer types by shrunken centroids of gene expression",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tibshirani",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Hastie",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Narasimhan",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chu",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Proceedings of the National Academy of Sciences",
            "volume": "99",
            "issn": "10",
            "pages": "6567--6572",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Application of electronic nose systems for assessing quality of medicinal and aromatic plant products: A review",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kiani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Minaei",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ghasemi-Varnamkhasti",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of Applied Research on Medicinal and Aromatic Plants",
            "volume": "3",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Boost ai power: Data augmentation strategies with unlabelled data and conformal prediction, a case in alternative herbal medicine discrimination with electronic nose",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2102.03088"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Herbal medicine: current status and the future",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Pal",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Shukla",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Asian pacific journal of cancer prevention",
            "volume": "4",
            "issn": "4",
            "pages": "281--288",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Classifying herbal medicine origins by temporal and spectral data mining of electronic nose",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2104.06640"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Feature engineering in discrimination of herbal medicines from different geographical origins with electronic nose",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "2019 IEEE 7th International Conference on Bioinformatics and Computational Biology (ICBCB)",
            "volume": "",
            "issn": "",
            "pages": "56--62",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "The curse of dimensionality in data mining and time series prediction",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Verleysen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Fran\u00e7ois",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "758--770",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Inductive conformal prediction for silent speech recognition",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of neural engineering",
            "volume": "17",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Conformal prediction for reliable machine learning: theory, adaptations and applications",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Balasubramanian",
                    "suffix": ""
                },
                {
                    "first": "S.-S",
                    "middle": [],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Vovk",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "A local mean-based k-nearest centroid neighbor classifier",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gou",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yi",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Du",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Xiong",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "The Computer Journal",
            "volume": "55",
            "issn": "9",
            "pages": "1058--1071",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Knowledge distillation: A survey",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Gou",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Maybank",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Tao",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "International Journal of Computer Vision",
            "volume": "129",
            "issn": "6",
            "pages": "1789--1819",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Towards understanding knowledge distillation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Phuong",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Lampert",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "5142--5151",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Speech neuromuscular decoding based on spectrogram images using conformal predictors with bi-lstm",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Neurocomputing",
            "volume": "451",
            "issn": "",
            "pages": "25--34",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Conformal prediction based on k-nearest neighbors for discrimination of ginsengs by a home-made electronic nose",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Sensors",
            "volume": "17",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Discrimination between alternative herbal medicines from different categories with the electronic nose",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sensors",
            "volume": "18",
            "issn": "9",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Conformal prediction based on k-nearest neighbors for discrimination of ginsengs by a home-made electronic nose",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Sensors",
            "volume": "17",
            "issn": "8",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Valid probabilistic predictions for ginseng with venn machines using electronic nose",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Lyu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Sensors",
            "volume": "16",
            "issn": "7",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "An optimized deep convolutional neural network for dendrobium classification based on electronic nose",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Diao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sensors and Actuators A: Physical",
            "volume": "307",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Chemical gas sensor drift compensation using classifier ensembles",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vergara",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Vembu",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ayhan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Ryan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "L"
                    ],
                    "last": "Homer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Huerta",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Sensors and Actuators B: Chemical",
            "volume": "166",
            "issn": "",
            "pages": "320--329",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Linear discriminant analysis-a brief tutorial",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Balakrishnama",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Ganapathiraju",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Institute for Signal and information Processing",
            "volume": "18",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Rapid estimation of entire brain strain using deep learning models",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "J"
                    ],
                    "last": "Raymond",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "V"
                    ],
                    "last": "Alizadeh",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Domel",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Gevaert",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zeineh",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Grant",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "B"
                    ],
                    "last": "Camarillo",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Transactions on Biomedical Engineering",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Classifying herbal medicine origins by temporal and spectral data mining of electronic nose",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Duan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Guan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2104.06640"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "The description of the data collection process for an individual sample. For each sample, the experiment process took 400s, and the data recording period (denoted by the red line) lasted for 340s. The experiment contained 4 steps: 1) T0-T1: the sensors get initialized using clean air, with the baseline values recorded. 2) T1-T2: the reaction of objective gas and the sensor panel. 3) T2-T3: the outflow of the objective gas and the cleaning of the reaction chamber. 4) T3-T4: the sensors get reset.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "The study pipeline of the two designed prediction tasks.(a) The process of offline prediction: comparing the prediction accuracy of CPKNN and CPSC on testing set. (b)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "The offline prediction performance of CPSC and CPKNN, with 30 times of random dataset partition.(a) The box plots of prediction accuracy of CPSC and CPKNN. (b) The box plots of the time cost for training model and making predictions with CPSC and CPKNN. The offline prediction accuracy among the predictions within 5 credibility information intervals (each takes a span of 0.2), with 30 times of random dataset partition.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "The prediction dynamics of online prediction with data augmentation. (a) and (b) respectively denotes the accuracy dynamics of CPSC and CPKNN. (c) and (d) denotes their accumulative counts of prediction indices. Index 1-3 denotes different settings: 0.1, 0.5, and 0.9.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "and X. Zhan contributed equally to this work. The work is supported by the Natural Science Foundation of China (Grant No. 61773342) and the Science Fund for Creative Research Groups of NSFC (Grant No.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "The prediction dynamics of online prediction with data augmentation. (a) and (b) respectively denotes the accuracy dynamics of CPSC and CPKNN. (c) and (d) denotes their accumulative counts of prediction indices. Index 1-5 denotes different settings: 0.1, 0.3, 0.5, 0.7 and 0.9.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "The categories of herbal medicines are: Astragalus, Liquorice, Chinese Angelica, Saposhnikovia Divaricata, Radix Angelicae 6/22",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Let in clean air to wash the sensors. 2.Start recording data. 1.Let out the objective gas. 2.Input clean air. End of a sample's collection. 1.Stop recording data. 2.Wait the sensors till they reset.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "The particular high-sensitivity volatile organic compounds for different sensors used in the study.Pubescentis, Radix Angelicae Dahuricae, Notopterygium Incisum, Codonopsis Pilosula, Radix Bupleuri, Ligusticum Chuanxiong Hort, Radix Peucedani, and Pueraria Lobata.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Accumulative counts (\u03b5=0.10)",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The work is supported by the Natural Science Foundation of China (Grant No. 61773342) and the Science Fund for Creative Research Groups of NSFC (Grant No.61621002). In this study, the data was collected at Zhejiang University. The authors appreciate the research equipment and assistance from the State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        },
        {
            "text": "The authors declare no conflict of interests.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interests"
        }
    ]
}