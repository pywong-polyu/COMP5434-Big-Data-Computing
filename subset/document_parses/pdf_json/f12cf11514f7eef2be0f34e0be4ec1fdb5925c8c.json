{
    "paper_id": "f12cf11514f7eef2be0f34e0be4ec1fdb5925c8c",
    "metadata": {
        "title": "Event-based clinical findings extraction from radiology reports with pre-trained language model",
        "authors": [
            {
                "first": "Wilson",
                "middle": [],
                "last": "Lau",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Washington",
                    "location": {
                        "settlement": "Seattle",
                        "region": "WA"
                    }
                },
                "email": ""
            },
            {
                "first": "Kevin",
                "middle": [],
                "last": "Lybarger",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Washington",
                    "location": {
                        "settlement": "Seattle",
                        "region": "WA"
                    }
                },
                "email": ""
            },
            {
                "first": "Martin",
                "middle": [
                    "L"
                ],
                "last": "Gunn",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Washington",
                    "location": {
                        "settlement": "Seattle",
                        "region": "WA"
                    }
                },
                "email": ""
            },
            {
                "first": "M",
                "middle": [
                    "B"
                ],
                "last": "Chb",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Meliha",
                "middle": [],
                "last": "Yetisgen",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of Washington",
                    "location": {
                        "settlement": "Seattle",
                        "region": "WA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Radiology reports contain a diverse and rich set of clinical abnormalities documented by radiologists during their interpretation of the images. Comprehensive semantic representations of radiological findings would enable a wide range of secondary use applications to support diagnosis, triage, outcomes prediction, and clinical research. In this paper, we present a new corpus of radiology reports annotated with clinical findings. Our annotation schema captures detailed representations of pathologic findings that are observable on imaging (\"lesions\") and other types of clinical problems (\"medical problems\"). The schema used an event-based representation to capture fine-grained details, including assertion, anatomy, characteristics, size, count, etc. Our gold standard corpus contained a total of 500 annotated computed tomography (CT) reports. We extracted triggers and argument entities using two state-of-the-art deep learning architectures, including BERT. We then predicted the linkages between trigger and argument entities (referred to as argument roles) using a BERT-based relation extraction model. We achieved the best extraction performance using a BERT model pre-trained on 3 million radiology reports from our institution: 90.9%-93.4% F1 for finding triggers 72.0%-85.6% F1 for arguments roles. To assess model generalizability, we used an external validation set randomly sampled from the MIMIC Chest X-ray (MIMIC-CXR) database. The extraction performance on this validation set was 95.6% for finding triggers and 79.1%-89.7% for argument roles, demonstrating that the model generalized well to the cross-institutional data with a different imaging modality. We extracted the finding events from all the radiology reports in the MIMIC-CXR database and provided the extractions to the research community.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "facilitate many secondary use applications, including clinical decision-support systems [3] , diagnostic surveillance of medical problems [4] , identification of patient cohorts with specific phenotypes [5] , tracking follow-up recommendations [6] , image retrieval and data-mining [7] , and simplification of report language for patients [8] .",
            "cite_spans": [
                {
                    "start": 88,
                    "end": 91,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 138,
                    "end": 141,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 203,
                    "end": 206,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 244,
                    "end": 247,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 282,
                    "end": 285,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 339,
                    "end": 342,
                    "text": "[8]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Large-scale and real-time use of radiological finding information in these types of secondary use applications requires a detailed semantic representation of the findings that captures the most salient information. Since imaging tests are commonly used for cancer screening and diagnosis, semantic representations for findings associated with lesions and medical problems would be largely applicable to secondary use.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "In this paper, we explored the extraction of comprehensive representations of clinical findings from radiology reports, including the creation of a novel annotation schema, annotation of a new clinical data set, and the development of state-of-the-art clinical finding extraction models. In our annotation schema, we categorized findings in radiology reports as Lesion findings and Medical Problem findings. A Lesion finding was defined as an abnormal spaceoccupying mass that was observable on the images. Lesions included primary tumors, metastases, benign tumors, abscesses, nodules, and other masses. A Medical Problem finding was a pathological process that was not a lesion, for example cirrhosis, air-trapping, atherosclerosis, and effusion. Each finding category was represented through finegrained event-based annotations. We presented a new annotated corpus of 500 computed tomography (CT) reports from the University of Washington (UW). To extract the finding events, we developed a deep learning extraction framework that fine-tuned a single BERT [9] model. We explored different contextualized embeddings through pretraining on different text sources. To assess the generalizability of the event extraction model, we annotated a subset of the MIMC-CXR radiology reports [10] . The extraction model achieved comparable performance on the MIMIC-CXR and UW data sets, despite the differences between the data sets. We extracted the clinical findings from the entire MIMIC-CXR data set and made the extracted findings available to the research community 1 . We also made the annotation guidelines and event extraction framework available 2 . The extraction framework directly processes annotated event data from the BRAT annotation tool [11] and can be readily used for event extraction without any deep learning coding experience.",
            "cite_spans": [
                {
                    "start": 1059,
                    "end": 1062,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1283,
                    "end": 1287,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1746,
                    "end": 1750,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "The development of NLP-based information extraction (IE) models that target important information in clinical text has increased in recent decades [12] . Radiology is a clinical domain where NLP approaches, including IE, have been extensively applied [2] . Radiological finding information can be extracted by using named entity recognition (NER) to identify fine-grained details, such as anatomy, size, characteristics and assertion, and subsequently linking related phenomena using relation extraction (RE) . Several studies employed custom rule-based linguistic patterns to identify clinical finding observations in radiology reports, including appendicitis indication, anatomy and assertion [13] , adrenal observations and modifiers [14] , and osteoporosis fracture categories and modifiers [15] . Due to the heterogeneity of writing styles, ambiguity of abbreviations, and presence of \"hedging\" statements [16] , engineering linguistic and semantic rules to extract information from radiology reports requires substantial effort and clinical expertise. Furthermore, rule-based approaches produce brittle extraction models that do not generalize well. One example is the MedLEE system developed by Columbia University which incorporated comprehensive syntactic and semantic grammars to extract information from chest radiograph reports [17] . The conceptual model comprised 350 semantic grammar rules, 1,720 single-word lexicons, and 1,400 multi-word phrases. Development of the MedLEE semantic grammars required half a person-year [18] , [19] . Sevenster et al. used MedLEE to identify finding observation and body location entities and establish relationships between entities through relations. However, the major drawback was that the recall of overall extraction (entities and relations) was less than 46% due to the lack of comprehensive lexicons and grammatical rules [20] .",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 151,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 251,
                    "end": 254,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 341,
                    "end": 346,
                    "text": "(NER)",
                    "ref_id": null
                },
                {
                    "start": 504,
                    "end": 508,
                    "text": "(RE)",
                    "ref_id": null
                },
                {
                    "start": 695,
                    "end": 699,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 737,
                    "end": 741,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 795,
                    "end": 799,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 911,
                    "end": 915,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1340,
                    "end": 1344,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1536,
                    "end": 1540,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1543,
                    "end": 1547,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1550,
                    "end": 1571,
                    "text": "Sevenster et al. used",
                    "ref_id": null
                },
                {
                    "start": 1879,
                    "end": 1883,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "To overcome the limitations of rule-based systems, more contemporary radiology extraction work used statistical machine learning approaches to extract finding information. There is a body of radiology IE work that utilized discrete modeling approaches. For example, Hassanpour et al. used conditional Markov and conditional random field (CRF) models to extract anatomy, observations, modifiers, uncertainty entities from a corpus of 150 reports [21] . Yim et al.",
            "cite_spans": [
                {
                    "start": 445,
                    "end": 449,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "employed maximum entropy models to extract relations between tumor references and attributes from radiology reports of hepatocellular carcinoma patients [22] . One challenge with statistical machine learning approaches is that manually engineered features are often tailored to solve a specific problem and are not easily adaptable to other domains.",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 157,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Recent radiology extraction studies utilize neural networks, which offer improved modeling capacity, abstraction, and transfer learning than discrete modeling approaches. A commonly applied neural approach is the sequence-based recurrent neural network (RNN) model, which encodes sequences using an internal memory mechanism. The Bidirectional Long Short-term Memory (BiLSTM) network is a popular RNN variant, which captures long-range sequential dependencies in the forward and backward directions. Cornegruta et al. extracted 4 different entities (body location, clinical finding, descriptor and medical device) with an annotated corpus of 2,000 radiology reports using BiLSTM [23] . Steinkamp et al. extracted clinical finding observations and their relations to modifier entities, such as location, size and change over time using another RNN variant, the Gated Recurrent Unit [24] .",
            "cite_spans": [
                {
                    "start": 679,
                    "end": 683,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 881,
                    "end": 885,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Most state-of-the-art NLP classification work, including IE within the radiology domain, utilized pre-trained transformer models with over hundreds of millions of model parameters. The popular BERT [9] model offers several benefits over RNN variants, including the combination of self-supervised pre-training and sub-token representation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "BERT learns word relationships through a masked language modeling task and learns sentence dependency by predicting whether two sentences are adjacent. This pre-training process allows the model to develop deep representation of words in context through layers of multi-head self-attention. BERT intrinsically attends to certain types of syntactic relations [25] , and the dependency information can be leveraged to increase relation extraction performance [26] , [27] . Provided that the model is sufficiently pre-trained on unlabeled data in the target domain, the expressive contextual representations of BERT can be transferred to specific prediction tasks, including IE, and achieve state-of-the-art performance. Sugimoto et al. extracted 7 different clinical entities from a corpus of 540 Japanese CT radiology reports by fine-tuning a pre-trained Japanese BERT model [28] . Other studies extracted breast imaging entities and relations from Chinese radiology reports [29] , [30] . Datta et al. employed a similar BERT finetuning approach to extract relations for clinical finding with spatial indication, such as \"within\" or \"near\" [31] .",
            "cite_spans": [
                {
                    "start": 358,
                    "end": 362,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 457,
                    "end": 461,
                    "text": "[26]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 464,
                    "end": 468,
                    "text": "[27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 874,
                    "end": 878,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 974,
                    "end": 978,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 981,
                    "end": 985,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1139,
                    "end": 1143,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "We identified several gaps in prior work that limit the creation of comprehensive semantic representations of findings in radiology reports, including: (1) the limited scope of the annotation and extraction schemas, (2) the limited scope of diseases and anatomy explored, and (3) the lack of demonstrated generalizability. Findings in radiology reports can be relatively complex, and several attributes are often needed to fully capture all the finding information present (e.g., assertion, anatomy, size, and other characteristics) for meaningful secondary use. Many prior studies only focused on entity extraction, without identifying the relations between entities in order to fully represent the findings [14] , [15] , [21] , [23] , [28] . To address this gap, we introduced an event-based annotation schema that captured a majority of the finding information. Several studies focused on specific diseases and/or anatomical regions [13] , [22] , [29] [30] [31] .",
            "cite_spans": [
                {
                    "start": 709,
                    "end": 713,
                    "text": "[14]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 716,
                    "end": 720,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 723,
                    "end": 727,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 730,
                    "end": 734,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 737,
                    "end": 741,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 936,
                    "end": 940,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 943,
                    "end": 947,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 950,
                    "end": 954,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 955,
                    "end": 959,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 960,
                    "end": 964,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "While this focus may improve performance for the target diseases and/or anatomy, it reduces the generalizability of the annotated data sets and extraction models. To address this gap, we created the first general-purpose gold standard annotated with event-based schema on Lesion and Medical Problem findings without disease or anatomy constraints.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "The gold standard contained randomly sampled 500 CT reports. In comparison to the reports in other imaging modalities, such as chest X-ray reports, CT reports covered a wide range of anatomy, medical problems, lesion types, lesion characteristics, and assertions. We trained and evaluated the event extraction framework on this gold standard of CT reports. No other previous studies evaluated the generalizability of extraction models across imaging modalities or institutions. To address this gap, we evaluated the extraction performance on an external validation set we created from chest X-ray reports from the publicly available MIMC-CXR data set.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "We used an existing clinical dataset of 706,908 computed tomography (CT) reports from the UW clinical repository from 2008-2018. We randomly sampled 500 CT reports from this dataset and annotated as our gold standard corpus.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset and Annotation Schema"
        },
        {
            "text": "Retrospective review of this dataset was approved by the UW institutional review board, and the dataset was deidentified to preserve the privacy of the patients and ensure HIPAA compliance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset and Annotation Schema"
        },
        {
            "text": "Our annotation schema is summarized in Table 1 . We used an event-based representation to capture the details of two clinical finding types: Lesion and Medical Problem. Each event was characterized with a trigger and a set of connected arguments. The trigger was a required key phrase identifying the finding event, while the arguments provided fine-grained details about the event. The argument entities were linked to the corresponding triggers through argument roles, forming a detailed and nuanced semantic representation of the clinical findings. We defined two types of arguments: span-only and span-with-value. The annotation of span-only arguments included the selection of the relevant phrase, assignment of an argument type label, and connection to the trigger, similar to most event annotation work. The annotation of span-with-value arguments included the selection of the relevant phrase, assignment of an argument type label with an additional categorical label that captures the clinical meaning of the selected phrase, as well as connection to the trigger. The categorical labels normalized the contents of the annotated phrase, allowing the extracted information to more easily be incorporated into secondary use applications. For example, in the sentence \"No traumatic abnormality in the abdomen or pelvis\", annotating the text span \"no\" as Medical-Assertion would also include the assignment of the categorical label absent. Because the presence of a lesion or medical problem could be implied rather than explicit, present was the default categorical label for Assertion, unless the report clearly indicated that the possible or absent labels were applicable.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 39,
                    "end": 46,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Dataset and Annotation Schema"
        },
        {
            "text": "Lesion Description (Trigger) span-only -\"mass\", \"lesion\", \"nodule\" Anatomy span-only -\"left lower lobe\" Assertion span-with-value present (default), absent, possible \"no\", \"possible\" Characteristics span-only -\"hypodense\", \"septal\" Count span-only -\"2\", \"numerous\", \"multiple\" Size span-only -\"4.1 x 3.1 cm\", \"small\" Size Trend span-with-value new, increasing, decreasing, no-change \"stable\", \"unchanged\"",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Argument Type Categorical labels Span examples Lesion Finding"
        },
        {
            "text": "Medical Problem (Trigger) span-only -\"atherosclerotic calcifications\" Anatomy span-only -\"abdominal aorta\", \"right kidney\" Assertion span-with-value present (default), absent, possible \"no\", \"possible\" Extraction of these findings was treated as a slot filling task by identifying the text spans that corresponded to the arguments (argument entities with roles) of the clinical finding events. Figure 1 presents example annotations for a",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 394,
                    "end": 402,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Medical Problem Finding"
        },
        {
            "text": "Lesion event and a Medical Problem event. For span-only arguments, the slot values would be the identified text spans. For span-with-value arguments, the slot values would be the identified categorical labels, which capture the meaning of the annotated phrases. A finding event might include multiple arguments of the same type. For example, a medical problem could be linked to multiple anatomical locations, or a lesion could be described by multiple characteristics.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medical Problem Finding"
        },
        {
            "text": "\u2022 Problem = traumatic abnormality \u2022 Anatomy = abdomen or pelvis \u2022 Assertion = absent ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Medical Problem"
        },
        {
            "text": "Inter-annotator agreement and model extraction performance was evaluated using the same scoring criteria. The annotated and extracted events include trigger and argument entities that are connected through argument roles. The pairing of triggers and arguments (entities with identified roles) assembles events from the individual entities. The scoring criteria for trigger and argument entities and argument roles are presented below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Scoring criteria for evaluation"
        },
        {
            "text": "Trigger and argument entities scoring considered the span identification and labeling, without considering the roles linking trigger and argument entities. All trigger and argument entities were compared at the token-level (rather than span-level) to allow partial matches, since partially matched text spans could still contain clinically relevant information, e.g. \"mass lesions\" vs \"lesions\".",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trigger and argument entities"
        },
        {
            "text": "Argument role scoring considered three annotated/extracted phenomena: (1) the trigger entity, (2) the argument entity, and (3) the argument role (linking the trigger-argument entity pair). Argument role equivalence required the trigger entity, argument entity, and role label to be equivalent. In argument role scoring, the entity equivalence criteria for triggers, span-only arguments, and span-with-value arguments were based on the semantics of the event representation, by considering the most salient information being captured by the entities [32] .",
            "cite_spans": [
                {
                    "start": 549,
                    "end": 553,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                }
            ],
            "ref_spans": [],
            "section": "Argument roles"
        },
        {
            "text": "Triggers: Events were aligned based on trigger equivalence, and the arguments associated with aligned events (events with equivalent triggers) were compared based on the argument types. Triggers were considered equivalent if the spans overlapped by at least one token. Figure 2 shows an example of two Medical Problem annotations. Although the word \"displaced\" is not part of the trigger in Annotation #2, their overlapping text spans and connections to the Medical-Anatomy argument entities indicates that both argument entities belong to the same event and can be scored accordingly.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 269,
                    "end": 277,
                    "text": "Figure 2",
                    "ref_id": null
                }
            ],
            "section": "Argument roles"
        },
        {
            "text": "Annotation #1 Annotation #2 ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Argument roles"
        },
        {
            "text": "The annotation was performed by one medical student and one graduate student using the BRAT rapid annotation tool [11] . Annotation guidelines were provided describing the details of each clinical finding event. In the initial iterations, the annotators were given the same samples to annotate independently. After each iteration, the annotators met with the domain expert radiologist to discuss and resolve the disagreements. The annotation guidelines were updated accordingly. At each iteration, we calculated inter-annotator agreement using pair-wise F1 score [33] , Table 2 . As can be observed, the number of annotated Medical Problem events was more than three times higher than the number of Lesion events. In general, each argument type corresponded to a single argument role type (one-to-one mapping between argument types and roles). One exception is Lesion-Size, which could be connected to a trigger through a Lesion-Size (Past) or Lesion-Size (Present) argument role. Table 3 . Gold standard corpus statistics.",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 118,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 563,
                    "end": 567,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [
                {
                    "start": 570,
                    "end": 577,
                    "text": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 981,
                    "end": 988,
                    "text": "Table 3",
                    "ref_id": null
                }
            ],
            "section": "Gold standard corpus annotation"
        },
        {
            "text": "The finding events were extracted in two separate steps: (1) the trigger and argument entities were extracted and (2) the argument roles were identified by connecting extracted trigger and argument entities through relations. The pairing of the trigger and argument entities through the argument roles assembles events from the individual entity extractions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Event extraction"
        },
        {
            "text": "Our event extraction pipeline operated on sentences, which were treated as independent samples.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Event extraction"
        },
        {
            "text": "The extraction of trigger and argument entities was defined as a NER task. For the span-with-value argument entities, the categorical labels were appended to in the entity labels, for example, Medical-Assertion (absent). Predicting the labels of the argument entities would therefore predict both the argument type and the categorical labels. We evaluated two state-of-the-art neural network architectures: (1) BiLSTM-CRF [34] and (2) BERT NER [9] . BiLSTM-CRF was considered a strong NER baseline by multiple studies [28] , [30] , [31] . We used the open source NeuroNER [35] for the BiLSTM-CRF implementation. Figure 5 presents NeuroNER's BiLSTM-CRF architecture. Each token in the input sentence was represented by the concatenation of a pretrained word embedding and a character-aware word embedding.",
            "cite_spans": [
                {
                    "start": 422,
                    "end": 426,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 444,
                    "end": 447,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 518,
                    "end": 522,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 525,
                    "end": 529,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 532,
                    "end": 536,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 572,
                    "end": 576,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [
                {
                    "start": 612,
                    "end": 620,
                    "text": "Figure 5",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Trigger and argument entity extraction"
        },
        {
            "text": "The character-aware word embedding was generated by a BiLSTM operating on the individual characters associated with each token. The character-aware word embedding enabled the model to learn the morphological structure in each word and to encode out-of-vocabulary tokens. The sequence of word embeddings was then encoded using a second BiLSTM layer to create a contextualized representation of the sentence. The label of each word was predicted by a CRF output layer which took into account the conditional dependencies across the neighboring labels. To create input labels for the NER model from our annotated corpus, we used the Begin, Inside, Outside (BIO) tagging schema, based on whether the token was at the beginning, inside or outside of a label. For instance, consider the sentence \"Probable malignant pancreatic mass with no evidence of vascular encasement\". The labels would be classified as illustrated in The BERT NER model was implemented by adding a single linear layer to the BERT output hidden states and finetuning a pre-trained BERT model, as described by Devlin et al [9] . Because BERT utilized WordPiece tokenization [36] , rare words would be segmented into multiple sub-tokens. These sub-tokens, prefixed by \"##\" if not the first sub-token, allowed the segments of the words to be represented in a deterministic fashion. Rather than using a universal token like [UNK], the sub-token representation provided richer contextual embeddings for the model to generalize. During the BIO labeling, the sub-tokens starting with \"##\" were assigned a special label #. In addition, the BERT input included the special tokens [CLS] and [SEP] at the beginning and end of a sentence respectively, to signify the sentence boundaries. Figure 6 illustrates how the labels of an input sentence were classified by BERT NER. ",
            "cite_spans": [
                {
                    "start": 1087,
                    "end": 1090,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1138,
                    "end": 1142,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                }
            ],
            "ref_spans": [
                {
                    "start": 1741,
                    "end": 1749,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Trigger and argument entity extraction"
        },
        {
            "text": "Once the trigger and argument entities were extracted, the argument roles were identified by predicting the links between trigger and argument entities. Identifying the roles of the argument entities filled the slots of the clinical finding events, similar to Figure 1 . Each event included a trigger that anchored the event, with zero or more argument connections. Each argument role was represented by a unidirectional relation where the head was the trigger entity and the tail was an argument entity. We predicted the argument roles, by decomposing each event into a set of relations, predicting the relations, and then assembling events from the predicted relations.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 260,
                    "end": 268,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Argument role extraction"
        },
        {
            "text": "Relations were extracted using BERT by adding a linear layer to the pooled output state (encoded in the [CLS] token) and fine-tuning the model. Figure 7 presents the BERT relation extraction (RE) model with an example input sentence. were alternated randomly, minimizing the cross-entropy loss for the applicable target (NER or RE), and thereby effectively allowing the model to learn from the two different tasks.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 152,
                    "text": "Figure 7",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "Argument role extraction"
        },
        {
            "text": "We performed 5-fold cross validation (CV) for all experiments using the same data split ratio (80% for training, 10%",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Argument role extraction"
        },
        {
            "text": "for validation, 10% for testing). The validation set was used for applying early stopping in order to avoid overfitting the training data [38] . The training was stopped when the validation results no longer showed improvement.",
            "cite_spans": [
                {
                    "start": 138,
                    "end": 142,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Argument role extraction"
        },
        {
            "text": "For the entity extraction baseline (BiLSTM-CRFrad), we used the word2vec embeddings pre-trained on a radiology report dataset from our previous work [37] . This dataset contained over 3 million reports covering a wide range of imaging modalities and were collected from four institutions including the University of Washington Medical Center, Northwest Hospital and Medical Center, the Seattle Cancer Care Alliance, and Harborview Medical Center. In terms of the model hyperparameters, the embedding dimension and the hidden state dimension of the character and sequence LSTM layers were 25 and 100. We used the Adam Optimizer with a learning rate of 0.005, as suggested by NeuroNER.",
            "cite_spans": [
                {
                    "start": 149,
                    "end": 153,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                }
            ],
            "ref_spans": [],
            "section": "Argument role extraction"
        },
        {
            "text": "We experimented with three different pre-trained BERT models (BERTbase, BERTclinical and BERTrad). BERTbase was pre-trained on Wikipedia and BookCorpus, and made available by Google [9] . BERTclinical was pre-trained on 2 million clinical notes, including over 500,000 radiology reports, from the MIMIC-III database [39] , [40] . BERTrad was pretrained on over 3 million UW radiology reports and was initialized from the BERTclinical. We pre-trained BERTrad for To better assess the general performance of the models with different subsamples, we repeated the cross validation 10 times. For each run, the cross validation data splits were created with a different random seed [38] . We reported the average precision, recall and F1 scores across these 50 different runs and included the 95% confidence intervals.",
            "cite_spans": [
                {
                    "start": 182,
                    "end": 185,
                    "text": "[9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 316,
                    "end": 320,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 323,
                    "end": 327,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                },
                {
                    "start": 676,
                    "end": 680,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                }
            ],
            "ref_spans": [],
            "section": "Argument role extraction"
        },
        {
            "text": "All of the trigger and argument entities were extracted first before their relations were identified. Trigger and argument entity extraction performance was evaluated at the token-level, as described in Section 2.2.1. The results are shown in Table 4 . All of the BERT implementations outperformed BiLSTM-CRFrad. The BERT model with radiology-specific pretraining, BERTrad, generally performed better than the other variants, BERTbase and BERTclinical, achieving the highest overall average F1 of 85.5%. In Lesion-Count prediction, BERTclinical is slightly higher than BERTrad. In",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 243,
                    "end": 250,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "Trigger and argument entity extraction results"
        },
        {
            "text": "Lesion-Size-Trend prediction, the decreasing label had relatively low extraction performance due to the small sample size. For the Assertion extraction, the absent label was easier to predict since most of the annotated text spans comprised a single word \"no\", which constituted 70% of the Medical-Assertion and 84% of the Lesion-Assertion entities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Trigger and argument entity extraction results"
        },
        {
            "text": "We conducted statistical significance tests using the overall F1 to access whether the difference in model results were due to randomness or sampling variability. In cross validation, the training sets overlap between different folds. As a result, the classification performance from each fold is not completely independent, and can lead to misleading statistical results when applying standard paired t-tests [41] . Hence, we applied the corrected resampled t-test, as suggested by Nadeau and Bengio [42] , to better estimate the sample variance. The test results showed that the overall performance of BERTrad was better than the other architectures with significance (p-value < 5e-6).",
            "cite_spans": [
                {
                    "start": 410,
                    "end": 414,
                    "text": "[41]",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 501,
                    "end": 505,
                    "text": "[42]",
                    "ref_id": "BIBREF41"
                }
            ],
            "ref_spans": [],
            "section": "Trigger and argument entity extraction results"
        },
        {
            "text": "In this section, we present the end-to-end argument role extraction results. Specifically, we predicted the argument roles using the extracted triggers and argument entities rather than the gold standard entities. We conducted the same statistical tests on the event argument extraction results using the overall performance scores presented in Table 6 . BERTrad achieved the best overall performance with significance (p-values < 1.6e-4).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 345,
                    "end": 352,
                    "text": "Table 6",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Argument role extraction results"
        },
        {
            "text": "We used the chest X-ray reports in the MIMC-CXR database, to explore the generalizability of the event extraction study is associated with a single radiology report [10] . The dataset was made publicly accessible to support independent research, such as predicting pulmonary edema severity [43] , predicting COVID-19 pneumonia severity [44] , and evaluating FDA approved AI devices [45] .",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 169,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 290,
                    "end": 294,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 336,
                    "end": 340,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 382,
                    "end": 386,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                }
            ],
            "ref_spans": [],
            "section": "Extracting findings from MIMIC-CXR radiology reports"
        },
        {
            "text": "To evaluate the generalizability of our extraction model, we manually annotated 50 randomly selected chest X-ray reports from the MIMC-CXR database using the same finding event annotation schema. This validation set included 257 Medical Problem finding events (141 argument entities and 313 roles) and 7 Lesion finding events (9 argument entities, 15 roles). The overall F1 scores on this validation set were 95.6% for triggers, 79.1% for span-only arguments and 89.7% for span-with-value arguments, evaluated using the same argument role scoring criteria in Section 2.2.2.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extracting findings from MIMIC-CXR radiology reports"
        },
        {
            "text": "The extraction performance was comparable to our repeated 5-fold cross validation performance, despite the fact that the MIMC-CXR reports were from a different institution and based on a different imaging modality. The MIMC-CXR radiology reports were generally shorter than the reports in our training corpus. The statistics of word count per report had a mean of 87, and a median of 79, in comparison to the mean and median of 327 and 288 in our corpus. We found that the event extraction model was able to identify clinical concepts that were unseen in our training corpus. For instance, the words \"plasmacytoma\" and \"fibroadenomas\" were correctly identified as lesions and \"acute respiratory distress syndrome\" was correctly identified as medical problem, even though these lesion and medical problem mentions did not appear in any radiology reports in the training corpus. This could be attributed to the pre-training of BERTrad with 3 million UW radiology reports covering a wide range of modalities.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extracting findings from MIMIC-CXR radiology reports"
        },
        {
            "text": "We extracted lesion and medical problem findings from all 227,835 chest X-ray reports in the MIMIC-CXR dataset with our event extraction framework. A total of 1,420,604 medical problem findings and 31,706 lesion findings were extracted using the fine-tuned BERTrad model. To contribute to the core aim of the MIMIC-CXR project and facilitate future research studies in medical imaging, we are releasing the finding extraction results for all 227,835 radiology reports. The extracted data are in BRAT's standoff format and follow the same subject IDs, study IDs and folder structure, such that they can be readily used to augment the existing images and reports 3 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Extracting findings from MIMIC-CXR radiology reports"
        },
        {
            "text": "We presented a new schema for representing lesion and medical problem findings in radiology reports. In trigger and argument entity extraction, the BERT-based NER models outperformed the BiLSTM-CRF baseline. In both the entity extraction and argument role prediction tasks, the BERT model with the most domain-specific pre-training, BERTrad, achieved the best performance. Pre-training BERTrad on 3 million UW radiology reports allowed the model to learn better contextual representations and transfer the knowledge of clinical concepts that are absent in the training corpus.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "BERTrad achieved an end-to-end performance of 92.9% F1 for triggers, 75.0% F1 for span-only arguments, and 84.8%",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "F1 for span-with-value arguments.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Among the finding entities, Medical-Problem and Medical-Anatomy had relatively long text spans. Over 25% of Medical-Problem spans and 35% of Medical-Anatomy spans contained at least 5 words. We found that some entities with lengthy spans were extracted into multiple separate entities, particularly before and after a conjunctive word.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "About 4% of all Medical-Problem entities and 7% of all Medical-Anatomy entities were split into multiple entities by the entity extraction models. Figure 8 presents an example of each case. In our annotation schema, the same entity could be assigned multiple labels. For example, the same anatomy span could possibly be annotated as both Lesion-Anatomy and Medical-Anatomy. Our NER models could only assign a single label to each token, so a text span cannot be extracted as multiple argument entities. Approximately 1% of all entities in our annotated corpus had multiple labels, so this limitation does not fundamentally impact extraction performance. One way to circumvent this single-label limitation is by having a single entity for both findings.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 147,
                    "end": 155,
                    "text": "Figure 8",
                    "ref_id": "FIGREF11"
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Although a single anatomy entity no longer carries any clinical finding connotation, its association with the finding events can still be identified by the RE model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Our extraction framework employed multi-task learning to optimize the parameters of a single BERT model. We did not explore other fine-tuning approaches, such as using graph structures to jointly model the span relations in the different tasks [46] or using entity aware markers to encode input sentences in a relation extraction model, which was shown to outperform joint modeling architectures [47] . Our BERTrad model was pre-trained using the common transfer learning paradigm by initializing its weight from another BERT model in relevant domain. This approach is particularly advantageous when the target data is scarce. However, a recent study showed that pre-training the language model from scratch in a domain with abundant unlabeled text could derive better in-domain vocabulary and result in substantial performance improvement [48] . Since our UW data set contained more than 3 million radiology reports, this pre-training approach could potentially improve the contextual representation of the BERTrad model and possibly lead to better event extraction performance.",
            "cite_spans": [
                {
                    "start": 244,
                    "end": 248,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 396,
                    "end": 400,
                    "text": "[47]",
                    "ref_id": "BIBREF46"
                },
                {
                    "start": 840,
                    "end": 844,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "In this paper, we presented a new schema for extracting lesion and medical problem findings from radiology reports.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The event representation of each clinical finding comprised a trigger and different arguments, capturing the finegrained semantic information of the finding. A total of 2,344 lesion findings and 8,065 medical problem findings were annotated in 500 CT radiology reports. For argument entity extraction, we evaluated two state-of-the-art neural architectures using BiLSTM-CRF and BERT. The BERTrad model pre-trained on 3 million radiology reports achieved an overall average F1 score of 85.5%, based on token-level evaluation. We then extracted the clinical finding events by predicting the argument roles for the extracted entities. The overall average F1 scores for end-to-end event extraction were 92.9% for triggers, 75.0% for span-only arguments and 84.8% for span-with-value arguments. To demonstrate the generalizability of the BERTrad model, we extracted the clinical findings (1,420,604 medical problem findings and 31,706 lesion findings) from all the radiology reports in the MIMIC-CXR database. Based on the evaluation with a manually labeled validation set of 50 chest X-ray reports, the overall average F1 scores for the extraction were 95.6% for triggers, 79.1% for span-only arguments and 89.7% for span-with-value arguments. The extraction performance was comparable to the repeated 5-fold cross validation performance with the UW corpus. We are releasing both our deep learning event extraction framework as well as the MIMIC-CXR extracted clinical findings to the research community. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Common Data Elements in Radiology",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Rubin",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "E"
                    ],
                    "last": "Kahn",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Radiology",
            "volume": "283",
            "issn": "3",
            "pages": "837--844",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2016161553"
                ]
            }
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Natural Language Processing in Radiology: A Systematic Review",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Pons",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [
                        "M M"
                    ],
                    "last": "Braun",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "G M"
                    ],
                    "last": "Hunink",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Kors",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Radiology",
            "volume": "279",
            "issn": "2",
            "pages": "329--343",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.16142770"
                ]
            }
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "What can natural language processing do for clinical decision support?",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Demner-Fushman",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "W"
                    ],
                    "last": "Chapman",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "J"
                    ],
                    "last": "Mcdonald",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Journal of Biomedical Informatics",
            "volume": "42",
            "issn": "5",
            "pages": "760--772",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2009.08.007"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Use of computerized surveillance to detect nosocomial pneumonia in neonatal intensive care unit patients",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Haas",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "A"
                    ],
                    "last": "Mendon\u00e7a",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Ross",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Larson",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "American Journal of Infection Control",
            "volume": "33",
            "issn": "8",
            "pages": "439--443",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ajic.2005.06.008"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Automated Identification of Patients With Pulmonary Nodules in an Integrated Health System Using Administrative Health Plan Data, Radiology Reports, and Natural Language Processing",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "N"
                    ],
                    "last": "Danforth",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "I"
                    ],
                    "last": "Early",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ngan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Kosco",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "K"
                    ],
                    "last": "Gould",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Journal of Thoracic Oncology",
            "volume": "7",
            "issn": "8",
            "pages": "1257--1262",
            "other_ids": {
                "DOI": [
                    "10.1097/JTO.0b013e31825bd9f5"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Automated Tracking of Follow-Up Imaging Recommendations",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Mabotuwana",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "American Journal of Roentgenology",
            "volume": "212",
            "issn": "6",
            "pages": "1287--1294",
            "other_ids": {
                "DOI": [
                    "10.2214/AJR.18.20586"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Intelligent image retrieval based on radiology reports",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gerstmair",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Daumke",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simon",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Langer",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kotter",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Eur Radiol",
            "volume": "22",
            "issn": "12",
            "pages": "2750--2758",
            "other_ids": {
                "DOI": [
                    "10.1007/s00330-012-2608-x"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Text Simplification Using Consumer Health Vocabulary to Generate Patient-Centered Radiology Reporting: Translation and Evaluation",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Qenam",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "Y"
                    ],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Carroll",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Hogarth",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J Med Internet Res",
            "volume": "19",
            "issn": "12",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.2196/jmir.8536"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Devlin",
                    "suffix": ""
                },
                {
                    "first": "M.-W",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Toutanova",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
            "volume": "1",
            "issn": "",
            "pages": "4171--4186",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/N19-1423"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "E W"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Sci Data",
            "volume": "6",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1038/s41597-019-0322-0"
                ]
            }
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "brat: a Web-based Tool for NLP-Assisted Text Annotation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Stenetorp",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Pyysalo",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Topi\u0107",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ohta",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ananiadou",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tsujii",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics",
            "volume": "",
            "issn": "",
            "pages": "102--107",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Clinical information extraction applications: A literature review",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Biomedical Informatics",
            "volume": "77",
            "issn": "",
            "pages": "34--49",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2017.11.011"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Extracting Actionable Findings of Appendicitis from Radiology Reports Using Natural Language Processing",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Rink",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "AMIA Jt Summits Transl Sci Proc",
            "volume": "2013",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Development of Automated Detection of Radiology Reports Citing Adrenal Findings",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Zopf",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Langer",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "W"
                    ],
                    "last": "Boonn",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "M"
                    ],
                    "last": "Zafar",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "J Digit Imaging",
            "volume": "25",
            "issn": "1",
            "pages": "43--49",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-011-9425-7"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Natural language processing of radiology reports for identification of skeletal site-specific fractures",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mehrabi",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sohn",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Atkinson",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Amin",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "BMC Med Inform Decis Mak",
            "volume": "19",
            "issn": "3",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/s12911-019-0780-5"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Language of the radiology report: primer for residents and wayward radiologists",
            "authors": [
                {
                    "first": "F",
                    "middle": [
                        "M"
                    ],
                    "last": "Hall",
                    "suffix": ""
                }
            ],
            "year": 2000,
            "venue": "AJR Am J Roentgenol",
            "volume": "175",
            "issn": "5",
            "pages": "1239--1242",
            "other_ids": {
                "DOI": [
                    "10.2214/ajr.175.5.1751239"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Architectural requirements for a multipurpose natural language processor in the clinical environment",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Forman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Starren",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Proc Annu Symp Comput Appl Med Care",
            "volume": "",
            "issn": "",
            "pages": "347--351",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "A conceptual model for clinical radiology reports",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Cimino",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "Proc Annu Symp Comput Appl Med Care",
            "volume": "",
            "issn": "",
            "pages": "829--833",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "A general natural-language text processor for clinical radiology",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "O"
                    ],
                    "last": "Alderson",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "H"
                    ],
                    "last": "Austin",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "J"
                    ],
                    "last": "Cimino",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 1994,
            "venue": "J Am Med Inform Assoc",
            "volume": "1",
            "issn": "2",
            "pages": "161--174",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Automatically Correlating Clinical Findings and Body Locations in Radiology Reports Using MedLEE",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sevenster",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Van Ommering",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Qian",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "J Digit Imaging",
            "volume": "25",
            "issn": "2",
            "pages": "240--249",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-011-9411-0"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Information extraction from multi-institutional radiology reports",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Hassanpour",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "P"
                    ],
                    "last": "Langlotz",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Artificial Intelligence in Medicine",
            "volume": "66",
            "issn": "",
            "pages": "29--39",
            "other_ids": {
                "DOI": [
                    "10.1016/j.artmed.2015.09.007"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Tumor information extraction in radiology reports for hepatocellular carcinoma patients",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Yim",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Denman",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "W"
                    ],
                    "last": "Kwan",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yetisgen",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "AMIA Jt Summits Transl Sci Proc",
            "volume": "2016",
            "issn": "",
            "pages": "455--464",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Modelling Radiological Language with Bidirectional Long Short-Term Memory Networks",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Cornegruta",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Bakewell",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Withey",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Montana",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis",
            "volume": "",
            "issn": "",
            "pages": "17--27",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/W16-6103"
                ]
            }
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Toward Complete Structured Information Extraction from Radiology Reports Using Machine Learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Steinkamp",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chambers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Lalevic",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "M"
                    ],
                    "last": "Zafar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "S"
                    ],
                    "last": "Cook",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J Digit Imaging",
            "volume": "32",
            "issn": "4",
            "pages": "554--564",
            "other_ids": {
                "DOI": [
                    "10.1007/s10278-019-00234-y"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "What Does BERT Look at? An Analysis of BERT's Attention",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Clark",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Khandelwal",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Levy",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "D"
                    ],
                    "last": "Manning",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
            "volume": "",
            "issn": "",
            "pages": "276--286",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/W19-4828"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "A Dependency-Based Neural Network for Relation Classification",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wei",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ji",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing",
            "volume": "2",
            "issn": "",
            "pages": "285--290",
            "other_ids": {
                "DOI": [
                    "10.3115/v1/P15-2047"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Mou",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
            "volume": "",
            "issn": "",
            "pages": "1785--1794",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/D15-1206"
                ]
            }
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Extracting clinical terms from radiology reports with deep learning",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Sugimoto",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Journal of Biomedical Informatics",
            "volume": "116",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2021.103729"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Extraction of BI-RADS findings from breast ultrasound reports in Chinese using deep learning approaches",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Miao",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "International Journal of Medical Informatics",
            "volume": "119",
            "issn": "",
            "pages": "17--21",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijmedinf.2018.08.009"
                ]
            }
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Extracting comprehensive clinical information for breast cancer using deep learning methods",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Int J Med Inform",
            "volume": "132",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ijmedinf.2019.103985"
                ]
            }
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Understanding spatial language in radiology: Representation framework, annotation, and spatial relation extraction from chest X-ray reports using deep learning",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Datta",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Si",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Rodriguez",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Shooshan",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Demner-Fushman",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of Biomedical Informatics",
            "volume": "108",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2020.103473"
                ]
            }
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Annotating social determinants of health using active learning, and characterizing determinants using neural event extraction",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Lybarger",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ostendorf",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yetisgen",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "J Biomed Inform",
            "volume": "113",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2020.103631"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "Agreement, the F-Measure, and Reliability in Information Retrieval",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hripcsak",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Rothschild",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "J Am Med Inform Assoc",
            "volume": "12",
            "issn": "3",
            "pages": "296--298",
            "other_ids": {
                "DOI": [
                    "10.1197/jamia.M1733"
                ]
            }
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Neural Architectures for Named Entity Recognition",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lample",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Ballesteros",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Subramanian",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Kawakami",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Dyer",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
            "volume": "",
            "issn": "",
            "pages": "260--270",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/N16-1030"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "NeuroNER: an easy-to-use program for named-entity recognition based on neural networks",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Dernoncourt",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Szolovits",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
            "volume": "",
            "issn": "",
            "pages": "97--102",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/D17-2017"
                ]
            }
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1609.08144"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "Extraction and Analysis of Clinically Important Follow-up Recommendations in a Large Radiology Dataset",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Lau",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "H"
                    ],
                    "last": "Payne",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Uzuner",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yetisgen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "AMIA Jt Summits Transl Sci Proc",
            "volume": "2020",
            "issn": "",
            "pages": "335--344",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "Automatic early stopping using cross validation: quantifying the criteria",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Prechelt",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Neural Networks",
            "volume": "11",
            "issn": "4",
            "pages": "761--767",
            "other_ids": {
                "DOI": [
                    "10.1016/S0893-6080(98)00010-0"
                ]
            }
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "Publicly Available Clinical BERT Embeddings",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Alsentzer",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2nd Clinical Natural Language Processing Workshop",
            "volume": "",
            "issn": "",
            "pages": "72--78",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/W19-1909"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "MIMIC-III, a freely accessible critical care database",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "E W"
                    ],
                    "last": "Johnson",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Scientific Data",
            "volume": "3",
            "issn": "1",
            "pages": "1--9",
            "other_ids": {
                "DOI": [
                    "10.1038/sdata.2016.35"
                ]
            }
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms",
            "authors": [
                {
                    "first": "T",
                    "middle": [
                        "G"
                    ],
                    "last": "Dietterich",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Neural Computation",
            "volume": "10",
            "issn": "7",
            "pages": "1895--1923",
            "other_ids": {
                "DOI": [
                    "10.1162/089976698300017197"
                ]
            }
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "Inference for the Generalization Error",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Nadeau",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Machine Learning",
            "volume": "52",
            "issn": "",
            "pages": "239--281",
            "other_ids": {
                "DOI": [
                    "10.1023/A:1024068626366"
                ]
            }
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Joint Modeling of Chest Radiographs and Radiology Reports for Pulmonary Edema Assessment",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Chauhan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Medical Image Computing and Computer Assisted Intervention -MICCAI 2020",
            "volume": "",
            "issn": "",
            "pages": "529--539",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-030-59713-9_51"
                ]
            }
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "Predicting COVID-19 Pneumonia Severity on Chest X-ray With Deep Learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Cohen",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Cureus",
            "volume": "12",
            "issn": "7",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.7759/cureus.9448"
                ]
            }
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Wu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Daneshjou",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ouyang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "E"
                    ],
                    "last": "Ho",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zou",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Nat Med",
            "volume": "27",
            "issn": "4",
            "pages": "582--584",
            "other_ids": {
                "DOI": [
                    "10.1038/s41591-021-01312-x"
                ]
            }
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wadden",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [],
                    "last": "Wennberg",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Luan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Hajishirzi",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
            "volume": "",
            "issn": "",
            "pages": "5784--5789",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/D19-1585"
                ]
            }
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "A Frustratingly Easy Approach for Entity and Relation Extraction",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhong",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
            "volume": "",
            "issn": "",
            "pages": "50--61",
            "other_ids": {
                "DOI": [
                    "10.18653/v1/2021.naacl-main.5"
                ]
            }
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/3458754"
                ],
                "arXiv": [
                    "arXiv:2007.15779"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Example annotations for Lesion and Medical Problem events.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Two Medical Problem Finding event annotations with equivalent triggers.Span-only arguments: When evaluating argument role performance, span-only argument entity equivalence was assessed at the token-level rather than span-level, because partial matches can capture clinically relevant information. The example inFigure 3, includes the same sentence with two sets of annotations for a Lesion event with multiple Lesion-Anatomy arguments. The second Lesion-Anatomy entities in the annotation do not match exactly. The discrepancy between the Lesion-Anatomy annotations (\"extending\" in Annotation #1) includes some clinical information; however, a majority of the clinically relevant information is captured by both spans (\"posteriorly to the nasopharynx\"). The token-level equivalence criteria for span-only argument entities was intended to reward Two Lesion Finding event annotations with partially matched span-only arguments.Span-with-value arguments:The categorical labels of span-with-value argument normalized the contents of the annotated phrase, allowing the extracted information to more easily be incorporated into secondary use applications. When evaluating argument role performance, the span-with-value argument entity equivalence was assessed based on the categorical labels only, without considering the spans. InFigure 4, although the Lesion-Size-Trend argument entity in Annotation #2 does not include the words \"and number\", both Lesion-Size-Trend annotations have the same categorical label and slot value (increasing). Hence both annotations are considered equivalent. Two Lesion Finding event annotations with the same value for Lesion-Size-Trend.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "by holding one set of annotated samples as gold standard and calculating the F1 of the other annotated samples. After four iterations, the final inter-annotator agreement over 30 CT reports was 93.0% F1 for triggers, 83.7% F1 for span-only arguments, and 86.9% F1 for span-with-value arguments, based on the argument role scoring in Section 2.2.2. The medical student single-annotated the remaining 470 CT reports. The final corpus contained 2,344 Lesion events (6,337 arguments entities and 6,617 argument roles) and 8,065 Medical Problem events (5,783 argument entities and 7,406 argument roles). The argument entity counts represented the number of annotated spans, and the argument role counts indicated the number of trigger-argument pairings. Since an argument entity could be linked to multiple triggers, the argument role counts could be greater than the argument entity counts. The distribution of the annotated argument entities and roles is shown in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 5.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Architecture of the NeuroNER BiLSTM-CRF model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Architecture of the BERT NER model.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "unique input sentence was created for each candidate trigger-argument relation. The trigger and argument entity locations were marked with two pairs of special tokens, namely ([unused0], [unused1]) and ([unused2], [unused3]), which provided positional information about the entities and the direction of the relation (disambiguate head and tail). These special tokens were part of the BERT vocabulary designed for introducing new domain specific samples for fine tuning purposes. Consider the aforementioned example where the word \"Probable\" is the Lesion-Assertion of the Lesion trigger \"mass\". The trigger would be marked as \"[unused0] mass [unused1]\" and the Lesion-Assertion would be marked as \"[unused2] Probable [unused3]\". In addition, we introduced a new relation called \"No_relation\" for negative training instances indicating the absence of relations between some argument entities and triggers.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Architecture of the BERT RE model. A single BERT model was fine-tuned for both the NER and RE tasks. In each training epoch, the NER and RE batches",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "150,000 steps with a batch size of 32, maximum sequence length of 128, and a learning rate of 2e-5. In our experiments, both entities and relations were extracted by fine-tuning the same BERT model. We used the same set of hyperparameters in all the extraction experiments, based on the recommended values suggested by Devlin et al., with a learning rate of 3e-5, a drop-out rate of 0.1. Early stopping was also employed using the validation set.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": ".2 82.1 83.1 (\u00b10.37) 86.7 80.9 83.7 (\u00b10.36) 87.7 80.6 84.0 (\u00b10.28) 88.8 82.4 85.5 (\u00b10.28)Table 4. Entity extraction results (average precision, recall and F1 in %), based on 10 runs of 5-fold cross validation. The numbers in brackets are 95% confidence intervals of the averages. The best F1 values are in bold.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "model that was trained on CT reports. The MIMIC-CXR database consists of 337,110 images in 227,835 radiographic studies performed at the emergency department of the Beth Israel Deaconess Medical Center from 2011-2016. Each",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Examples of long text spans being extracted into multiple entities.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "This publication was supported by NIH/NCI (1R01CA248422-01A1), NIH/NLM Biomedical and Health Informatics Training Program (5T15LM007442-19), NIH/NCATS (UL1 TR002319). Research and results reported in this publication was facilitated by the generous contribution of computational resources from the University of Washington Department of Radiology.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Annotation schema of Lesion finding and Medical Problem finding.",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Overall gold standard corpus statistics are presented inTable 3. On average, there were 16 Medical Problem events and 5 Lesion events annotated per report. Some CT reports in the gold standard were very dense and contained over 100 Medical Problem events.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "shows the extraction results based on the scoring criteria described in Section 2.2.2. In general, the in-domain contextualized representations helped the BERTrad model achieved higher performance (except Lesion-Count).",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The performance of BERTbase was comparable to BERTclinical. While BERTclinical performed slightly better than BERTbase on triggers and span-only arguments, BERTbase performed slightly better on span-with-value arguments.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}