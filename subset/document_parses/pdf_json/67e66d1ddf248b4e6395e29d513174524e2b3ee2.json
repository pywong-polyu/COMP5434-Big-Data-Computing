{
    "paper_id": "67e66d1ddf248b4e6395e29d513174524e2b3ee2",
    "metadata": {
        "title": "A Digital Feature Recognition Technology Used in Ballet Training Action Correction",
        "authors": [
            {
                "first": "Jia",
                "middle": [],
                "last": "Sun",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Guangxi University of Arts",
                    "location": {
                        "postCode": "530000",
                        "settlement": "Nanning",
                        "country": "China"
                    }
                },
                "email": "20080014@gxau.edu.cn"
            }
        ]
    },
    "abstract": [
        {
            "text": "In order to improve the effect of ballet training, this paper combines digital technology to improve the motion recognition process, analyzes the imaging process, analyzes the system process combined with the human node model, and combines digital feature recognition technology to construct a ballet training motion correction system. Moreover, this paper inputs the ballet training action recognition results into the system and compares the standard actions to judge the rationality of the actions and builds a ballet training action correction system based on digital feature recognition. In addition, this paper designs experiments to conduct ballet training movements in the system effect evaluation. e experimental research verifies that the digital feature recognition technology proposed in this paper can play an important role in ballet movement recognition and has a good action correction effect.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Ballet is a charming and refreshing art. Its elegance and beauty can be regarded as the essence of human civilization and progress, and it is praised as \"the crown jewel of dance art\" [1] . Its graceful dance, light jumping, and continuous toe rotation often bring people into a dreamlike artistic realm. Ballet originated in Italy during the European Renaissance, flourished in France, and flourished in Russia, and finally moved from Russia to the world. After hundreds of years of development, ballet has formed its own complete training system. In particular, it is unique in the scientific training methods of the correct sense of the feet, posture, various parts of the body, and the consciousness of movement performance [2] . e ballet training system is to improve the performer's physical ability and performance awareness through a series of complete programmatic body movement combination training. Moreover, it enables the dancers to freely and colorfully express the performers' rich thoughts and passions in various situations, thereby creating a brandnew artistic image [3] . e romantic ballet showed the body aesthetics so vividly that the criterion for judging this beauty has continued to this day. e basic skill training of Lei can be summarized as the four principles of opening, stretching, upright, and standing, which are basically consistent with the requirements of the competition rules for the body technical movement specifications of the artistic performances. Basic ballet training has a positive effect on the aesthetics and standardization of Latin dance. erefore, the basic training of ballet is very important for the study and training of Latin dance. At present, there are still many problems that need to be improved in actual teaching: firstly, there is no ballet training material suitable for special and unified sports dance; secondly, the teaching hours are generally too short to meet the special requirements; finally, the goal of ballet training is pertinent not strong, ignoring the training needs of each item. Only by further studying the value and role of basic ballet training in Latin dance teaching, strengthening the thinking of the degree of integration of basic dance and professional dance, and improving the awareness of basic dance services for special dances, can the teaching effect be better improved.",
            "cite_spans": [
                {
                    "start": 184,
                    "end": 187,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 728,
                    "end": 731,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 1085,
                    "end": 1088,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Ballet dynamic technology is to improve the dancers' technical movements and physical abilities through a series of complete and standardized body movements, so as to better show the dance style and dance performance ability, so that the dancers can be in a variety of music rhythms. is kind of emotions can show graceful dance with ease, convey the most accurate emotional expression to the audience, show the most exquisite technical movements, and have the characteristics of science and standardization. Ballet dynamic techniques cover jumping, squatting, turning, and other techniques. In foreign countries, many modern dancers have been trained in ballet since they were young, so they have solid ballet dynamic skills, making the basic dance skills much better than ordinary people, and the performance of modern dance competitions is also very good.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "is article combines digital feature recognition technology to carry out ballet training movement correction analysis and combines the actual ballet movement to correct the actual needs for research and proposes a corresponding intelligent training correction system to improve the effect of ballet training.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Literature [4] introduced the importance of ballet in the dance classroom and then analyzed the problems of unreasonable curriculum setting, single teaching method, and insufficient teachers in the reform of ballet classroom teaching. In response to these problems, corresponding solutions are put forward to help the ballet classroom to be better developed and play its role. Literature [5] pointed out that ballet is a must-have course for dance practitioners. It can not only affect and improve the beauty of people, but also make people have beauty of posture and temperament. It is precisely because of a scientific and standardized system such as ballet that the flowers of dance art can bloom more brilliantly. Literature [6] mentioned that the technical level of modern ballet can be divided into dynamic technology and static technology. Similarly, sports dance also includes dynamic movements and static movements. Dynamic movements require agility and coordination, which not only involves complex steps, but also requires physical sensations and delicate and changeable techniques. Literature [7] believed that the basic ballet training course is an indispensable course for dance majors, and it is also a major course in the ballet teaching system. e most prominent feature is that it not only trains various positions of the body, but also plays a comprehensive training role in the coordination of the entire body. Gao Yiyan said that dance is the art of the body, and the courses to exercise the dancers' bodies are very important. e reason why basic ballet training can be regarded as one of the compulsory basic courses for all dance majors is that basic ballet training is the longest and most scientific basic training course in history. e purpose of the basic ballet training course is to train students' muscles, skills, abilities, etc., to help students lay a foundation for future performances [8] .",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 14,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 388,
                    "end": 391,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 729,
                    "end": 732,
                    "text": "[6]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1105,
                    "end": 1108,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1918,
                    "end": 1921,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Literature [9] pointed out that there are several problems in the development process of dance movement in the emerging stage, such as the decline of dance movement athletes' physical fitness, low technical level, unnew arrangement, and poor completion, and proposed development strategies to improve dance movement items. First of all, establish a scientific and complete training plan, and insist on scientific training for a long time. Secondly, strengthen the coach's own quality and coaching ability, continue to promote and popularize dance movement training, and expand the number of reserve talents to provide talents for the national team. Literature [10] made a preliminary popularization of the origin and development form of dance movements to other scholars who did not understand the development of dance movements and let people gradually understand the development history and essential characteristics of dance movements. e article mentioned that both now and in the future, only the combination of sports and art can continuously create new results. In particular, modern people pursue a healthy lifestyle and the beauty of sports. erefore, it is necessary to strengthen the popularization of people to shape a healthy lifestyle through sports. Literature [11] proposes that only coaches should follow the latest trends in the development of dance movement items and, on the premise of accurately understanding and grasping the scoring rules, propose and implement corresponding training for the common problems of dance movement athletes at this stage and the athletes' physical conditions. Only plans and countermeasures can adapt to the rules of international dance movement competitions and promote the development of dance movement projects in the direction of art and competition that is difficult and beautiful. Literature [12] refers to the limitation of sports events on the road to the emergence of institutional development, forcing sports events to be unable to continue their development.",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 14,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 660,
                    "end": 664,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1274,
                    "end": 1278,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1848,
                    "end": 1852,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Literature [13] writes that dance moves are still a young athletic event, so there is a lot of room for improvement. e complete set of dance moves is not only a superimposition of difficulty, but also a perfect match with the equipment. erefore, the individual characteristics of the project should be fully considered during training, combined with the athlete's physical ability, and appropriate auxiliary method training should be strengthened, including basic quality training such as flexibility, strength, speed, endurance, agility, etc. It also includes the characteristics of different equipment for training to integrate and complement each other. Literature [14] writes that coaches emphasize physical fitness while neglecting equipment skills in training. Poor proficiency directly affects the complete quality of the entire set. If the proficiency training in equipment movements, continuity, and coordinated movements is not strengthened, it will be restricted. For the progress of the dance movement project, [15] pointed out that it has begun to pay attention to the research of athlete selection, movement arrangement, physical training, etc. and strictly train outstanding athletes. Literature [16] writes that it is important to scientifically and rationally arrange the training plans for each stage of the small, medium, and large cycles, intersperse competitions, assessments, relaxation, and other links in the quality training, and combine the large and small cycles, so that the cycle training can achieve excellent results. Literature [17] emphasizes the balanced development of various difficult movements, attaches importance to difficult movements and balance movements, strictly regulates movement standards, strengthens the time of equipment training, participates in more international competitions, accumulates experience, and makes use of the good model of competition-driven training.",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 15,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 668,
                    "end": 672,
                    "text": "[14]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1023,
                    "end": 1027,
                    "text": "[15]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 1211,
                    "end": 1215,
                    "text": "[16]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1560,
                    "end": 1564,
                    "text": "[17]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Related Work"
        },
        {
            "text": "Multiview dense matching uses homography to perform dual-view stereo matching between multiple cameras. e homography relationship can be expressed as follows: a point in a certain image plane can determine the position of its corresponding point in the second image plane through the homography induced by a certain plane.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "As shown in Figure 1 , a point x 1 in the image plane of the camera C 1 can be used to determine the position of the matching point x 2 in the image plane of the camera C 2 through the homography H induced by the \u03c0 plane. e calculation method of the homography matrix H is as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 20,
                    "text": "Figure 1",
                    "ref_id": null
                }
            ],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "We assume that the projection matrices of camera C 1 and camera C 2 are P 1 and P 2 , respectively. First, we backproject the plane point x, and the back-projection ray intersects the plane \u03c0 at the three-dimensional point X, so there is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "en, we map the three-dimensional point X projection to the plane point x 2 and denote it as x 2 \ufffd P 2 X. At this time, the homography correspondence between the plane points x 1 and x 2 can be obtained as [18] ",
            "cite_spans": [
                {
                    "start": 205,
                    "end": 209,
                    "text": "[18]",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "We assume that the projection matrices of camera C 1 and camera C 2 are P 1 \ufffd K 1 [I | 0] and P 2 \ufffd K 2 [R | t], respectively, and the \u03c0 plane can be expressed as \u03c0 \ufffd (n T , 1) T (n is a certain unit vector). Any three-dimensional point on the projection ray of the plane point x1 can be expressed as x \ufffd (x 1 , \u03b7) T , where \u03b7 is the parameterized coefficient of the point X on the projection ray. Since the three-dimensional point X is on the plane \u03c0 at the same time, there is \u03c0 T X \ufffd 0, which is transformed into X \ufffd (x 1 , \u2212n T x 1 ) T . erefore, formula (1) can be further expressed as [19] ",
            "cite_spans": [
                {
                    "start": 591,
                    "end": 595,
                    "text": "[19]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "It is composed of the internal parameter matrix of the camera, the relative external parameters between the cameras, and the plane parameters. e schematic diagram of the spatial plane scanning algorithm is shown in Figure 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 215,
                    "end": 223,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In Figure 2 , we assume that there are a multicamera image I i (i \ufffd 1, . . . , n) and a series of parallel virtual planes Z j (j \ufffd 1, . . . , m) scanned along the Z axis in space. In the algorithm, each virtual plane is divided into cells of a certain size, and the cell size determines the accuracy of the threedimensional points in the reconstruction result. e principle of the spatial plane scanning algorithm is that the algorithm back-projects the image feature point x i , and the back-projected rays intersect the corresponding cell of each virtual plane. e algorithm performs back-projection operation on all image feature points and records the number of times that all cells are intersected. e algorithm counts the total number of intersections of each cell, and the cell with the number of intersections greater than the preset threshold is regarded as the three-dimensional point X corresponding to the multiview matching. At the same time, the image point x i (i \ufffd 1, . . . , n) corresponding to the threedimensional point transmission projection is the matching point of the multiview image. e image point x i (x, y) T and the three-dimensional point X \ufffd (X, Y, Z, 1) T in space are both representations of homogeneous coordinates. e process of projecting the point X in space onto a certain camera image plane I i is [20] x i \ufffd K r 1 r 2 r 3 t X.",
            "cite_spans": [
                {
                    "start": 1332,
                    "end": 1336,
                    "text": "[20]",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 3,
                    "end": 11,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "(3)",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "K in the equation is the camera's internal parameter matrix. Crossover R \ufffd r 1 r 2 r 3 and t are the external parameters of the camera. Since the three-dimensional point X in space lies on the plane Z f , (3) can be replaced by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In this way, the projective transformation is transformed into a homography transformation of two planes, and the homography matrix H j is [21] ",
            "cite_spans": [
                {
                    "start": 139,
                    "end": 143,
                    "text": "[21]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In order to calculate the intersection position of the back-projection ray of the image point and all virtual planes more effectively, we propose to precalculate the intersection (X 1 , Y 1 , Z 1 ) T of the back-projection ray of the image point and a certain virtual plane Z 1 . After that, we directly perform a homography transformation on (X 1 , Y 1 , Z 1 ) T to solve the intersection point (X j , Y j , Z j ) between the back-projected ray and other virtual planes, instead of retransforming the source image point. e calculation expression is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "We assume a pixel p and its surrounding neighborhood pixel square N(p); the intensity of the pixel is expressed as I(p). Nonparametric local transformation is to compare the intensity value I(p \u2032 ) of pixel p \u2032 (p \u2032 \u2208 N(p)) in the neighborhood square matrix with I(p) and define the sign as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "On this basis, the Rank transformation is expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "It refers to the number of pixels in the neighborhood square matrix whose pixel intensity value is less than the center pixel intensity value. When calculating region matching, the LI norm relationship is used for minimization, and the center pixel corresponding to the region with the smallest number after comparison is selected as the matching pixel. It directly performs hierarchical similarity comparison of color images and adopts a multiwindow comparison method to improve the matching accuracy in the case of discontinuous parallax.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Different from the Rank transform, the idea of the Census transform is to compare the intensity value difference between the pixels in the neighborhood square matrix and the center pixel and express the comparison result as a binary bit string in order. e mathematical expression of this transformation is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the formula, the symbol \u2297 represents the concatenation of each value \u03be(p \u2032 , p). e schematic diagram of the Census transformation is shown in Figure 3 , where the pixels in the red dashed frame in the figure are the neighborhood pixel square matrix N(p). Because the Census transform not only uses nonparametric binary characters to represent the attributes of the pixels, but also incorporates the order of the neighboring pixel attributes into the constraints, it is more robust than the Rank transform in the face of changes in external lighting conditions.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 145,
                    "end": 153,
                    "text": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "After the Census transformation of the multiview image to be matched, the Hamming distance between the pixels to be matched is calculated to achieve multiview stereo matching. e Hamming distance refers to the number of different bits between two bit strings. It is very intuitive to express the degree of similarity between pixels. e method of using Hamming distance as the matching criterion can be expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the formula, Cost(p d) represents the matching cost of the pixel p to be matched at the disparity d, and C 1 and C 2 are the bit strings of the two viewpoint images after the Census transformation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the case of discontinuous parallax, usually a point-bypoint matching combined with global optimization is used for processing to reduce the erroneous matching caused by noise and obtain more accurate matching results. e global optimization in this method adds a smoothing term as an additional constraint condition on the basis of the matching cost, so as to punish the change of the neighborhood parallax, which can be expressed mathematically as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "When the neighborhood disparity change |D p \u2212 D p\u2032 | is greater than or equal to one pixel, a constant penalty coefficient p is added to preserve the discontinuity of the disparity. e stereo matching problem combined with the global method becomes the problem of minimizing the global energy function E(D) and solving the parallax D. However, (11) is a two-dimensional global energy function, and it is a complicated process to minimize it. Although the idea of dynamic programming can be used to efficiently minimize one-dimensional image rows one by one, it is still difficult to achieve optimal association between rows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Different from the energy function of global matching, the energy function of semiglobal matching uses two smoothing coefficients p1 and p2 of different sizes to penalize different degrees of parallax changes, which is mathematically expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e p1 in formula (12) penalizes a small range of parallax (for example, the parallax is one pixel) and can adaptively preserve the inclined surface or curved surface, while p2, which penalizes large parallax, can preserve the discontinuous area. e most important thing is that the semiglobal matching adopts a new matching cost accumulation method, which equally accumulates the one-dimensional matching cost of all directions of the pixels, and uses the minimum cost sum of all directions as the final cumulative matching cost. e minimum cost of a path in a certain direction can be expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the formula, C(p,d) represents the point-by-point matching cost, r represents the directional path, p\u2212r is the pixel before the pixel in the r direction, and d represents the parallax. e final cumulative matching cost is expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e actual application process usually accumulates the minimum cost of 8 or 16 directional paths, as shown in Figure 4 . e paths in the eight directions are row accumulation, column accumulation, and diagonal accumulation. In addition to the rows, columns, and diagonals of the 16-direction paths, the accumulation method of the remaining 8 directions is to first perform row or column accumulation, then perform diagonal accumulation, and perform alternately. Finally, the cumulative matching cost energy function Cost agg (p, d) is minimized, and the matching disparity value d corresponding to each pixel is obtained, and the matching is completed.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 108,
                    "end": 116,
                    "text": "Figure 4",
                    "ref_id": "FIGREF3"
                }
            ],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the field of computer vision, applications such as image denoising, stereo image dense matching, and depth generation all have erroneous estimates due to external noise. For this reason, outliers are usually eliminated. e principle of outlier removal can be understood from the perspective of probability models:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "g(x) is a series of noisy measurement values; u(x) \u2208 R M\u00d7N is the solution of the required model. According to Bayesian inference, the probability of obtaining the model solution u(x) optimized from the measurement value b is expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In formula (15) , p(g | u) is called the data generation model, and p(u) is called the prior model. e denominator p(g) is a constant when the measured value is known, so p(u | g) is proportional to p(g | u)p(u) and can be expressed as p(g | u) \u221d p(g | u)p(u). erefore, the target solution u can be solved by maximizing the posterior probability p(u | g):",
            "cite_spans": [
                {
                    "start": 11,
                    "end": 15,
                    "text": "(15)",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Most practical engineering applications will use global optimization methods to eliminate outliers. e global optimization method sets E(u) \ufffd \u2212ln p(u | g) to convert the probability maximization problem to the energy minimization problem. ere are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Furthermore, global optimization usually replaces the probability model with a general energy model, which consists of data items containing model solutions and regular items with smoothing effect, expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e data item E(u) \ufffd \u03a9 \u03c8 D (es(u | x), g(x))dx + \u03c4 \u03a9 \u03c8 D (\u2207u(x))dx in equation (19) is proportional to \u2212ln p(u), and the regular term R(u) is proportional to D(u | g). e data item consists of the error function e induced by the model solution u(x) and the measured value g(x) and the positive penalty function \u03c8 D , expressed as Computational Intelligence and Neuroscience",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e regular term is composed of the smooth function of the model solution u(x) and the positive penalty function v, expressed as R(u) \ufffd x\u2208\u03a9 \u03c8 R (s(u(x))). (20) e value of the regular term is small, which plays a role in preserving certain characteristics of the target solution. In the continuous domain, the smoothing of the model solution",
            "cite_spans": [
                {
                    "start": 153,
                    "end": 157,
                    "text": "(20)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Finally, a variational global optimization energy model can be defined to solve the problem of removing outliers. e energy model is mathematically expressed as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e solution method of formula (21) is to use the Euler-Lagrangian equation zE(u)/zu \ufffd 0 which minimizes the energy functional to find the minimum value of the model solution u(x). In particular, when both the data item and the regular item are convex, the model solution obtained by zE(u)/zu \ufffd 0 is the minimum value.",
            "cite_spans": [
                {
                    "start": 29,
                    "end": 33,
                    "text": "(21)",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "When a convex function is not differentiable at a certain point, the problem of nondifferentiation is often solved by solving its corresponding convex conjugate. e specific method is as follows: by the Legendre-Fenchel transformation, the convex conjugate of the original function f(x) can be written as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Among them, y is a dual variable, and the symbol <. . .> means calculating the inner product of the original variable x and the dual variable y, and the transformed function is differentiable in the entire domain y. erefore, the problem that the original Ll norm is not differentiable at x \ufffd 0 can be solved by convex coballoons. e convex conjugation of Ll cost |x| 1 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the formula, \u03b4(y) is the indicator function, and when \u2016y\u2016 1 \u2264 1, \u03b4(y) \ufffd 0. At the same time, the dual form of the original LI norm can be written as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "Similarly, the convex conjugate combined with the quadratic cost x 2 is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e dual forms of the original quadratic norm and the original Huber norm are",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "We assume that the expression of a common saddle point problem is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "In the formula, x and Y are two-dimensional real vector spaces, and L is a continuous linear operation on X \u27f6 Y. e symbol F * represents the convex conjugation of the function F. e saddle point problem can be regarded as the original problem:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "or the original dual description of the corresponding dual problem:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "For the optimization of this kind of saddle point problem, an iterative optimization method for solving the Computational Intelligence and Neuroscience original variable x and the dual variable y is given. First, we obtain partial derivatives of formula (27) to obtain the presolved subformulas of x and y:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "x \ufffd (I + \u2207G) \u22121 (x \u2212 Ly), y \ufffd (I + \u2207F) \u22121 (y + Lx).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Digital Feature Recognition Technology"
        },
        {
            "text": "e symbol \u2207 in the formula is the gradient operator. After that, the original variable and the dual variable are updated iteratively through the gradient descent/rise method. Taking the ROF denoising model as an example, the expression of the original energy model is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "It is composed of a regular term composed of L1 norm and a data term composed of quadratic norm, where u is the target solution, and f is the input image with noise. When \u2016\u2207u\u2016 1 in formula (31) is replaced with the form of formula (24), the original dual form of the ROF denoising model can be obtained:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "In the formula, p is a dual variable. e convex set R in formula (32) is defined as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Among them, \u2016p\u2016 \u221e \ufffd max i,j |p i,j | represents the discrete maximum norm. By comparing formula (32) with formula (16) , it is not difficult to see that the original dual form of the ROF denoising model is a saddle point problem.",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 118,
                    "text": "(16)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "First, for the original dual form of the ROF denoising model (29), the partial derivative of the dual variable p is calculated, and the presolvent formula of the dual variable is obtained:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "en, we find the gradient of the dual variable u n by fixing the original variable j at the time:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Since F * (p) \ufffd \u03b4 p (p) is an indicator function of a convex set, when solving p n+1 , formula (35) needs to be projected onto the unit sphere 1 (x) \ufffd x/ max(1, \u2016x\u2016), so the final iterative update equation for dual variables is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Similarly, by calculating the partial derivative of u in formula (32), the presolvent formula of the original variable u is obtained:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "In the formula, \u2329p, \u2207u\u232a \ufffd \u2329u, \u2212\u2207 \u00b7 p\u232a. By fixing the obtained p n+1 and performing gradient descent on the original variable, the iterative update equation of the original variable u can be further obtained:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Finally, when the algorithm meets the preset iteration termination condition, the global optimal solution of the original variable u can be obtained.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Taking the optimization problem of the ROF denoising model as an example, the update of the dual variables (formulas (31) and (32)) mainly includes the point-by-point gradient operation of the original variable and the elementwise projection operation of the variable. We assume that the solution of the energy function is two-dimensional. In the discrete case, the original variable can be expressed as ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "e gradient operation of the original variable can be defined as Computational Intelligence and Neuroscience \u2207u \u225c z zx 0 \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 0 z zx \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 z zx z zx 0 \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 z zx \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 z zx",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "Moreover, the partial derivatives z/zx and z/zy in each dimension can be realized by forward difference.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "\u23a7 \u23a8 \u23a9 (30)"
        },
        {
            "text": "is article combines digital feature recognition technology to construct a ballet training movement correction system. e technical imaging principle is shown in Figure 5 . When the laser transmitter does not emit a laser beam to the target, the laser speckle is formed by the scattering of the medium, and the laser speckle is projected on the target. In this process, laser speckle is a random process, and probability statistics are used to find the movement law and intensity distribution of the speckle. e process of the whole ballet training movement recognition method is shown in Figure 6 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 160,
                    "end": 168,
                    "text": "Figure 5",
                    "ref_id": null
                },
                {
                    "start": 586,
                    "end": 594,
                    "text": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Correction of Ballet Training Movements Based on Digital Feature Recognition Technology"
        },
        {
            "text": "e correction system in this paper mainly inputs the ballet training action recognition result into the system to compare with the standard action and judge the rationality of its action. erefore, the process of the ballet movement system proposed in this paper is shown in Figure 7 below. e system built in this paper can recognize the pictures and videos of ballet training and can also perform real-time action recognition and correction for ballet training. Figure 8 shows the effect of the system's ballet dance training action correction.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 273,
                    "end": 281,
                    "text": "Figure 7",
                    "ref_id": null
                },
                {
                    "start": 461,
                    "end": 469,
                    "text": "Figure 8",
                    "ref_id": null
                }
            ],
            "section": "Correction of Ballet Training Movements Based on Digital Feature Recognition Technology"
        },
        {
            "text": "On the basis of the above analysis, the model proposed in this paper is verified. First, the digital feature recognition technology proposed in this paper is evaluated, and the statistical test results are shown in Table 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 215,
                    "end": 222,
                    "text": "Table 1",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Correction of Ballet Training Movements Based on Digital Feature Recognition Technology"
        },
        {
            "text": "On this basis, the correction effect of ballet training is analyzed, and the statistical test results are shown in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 115,
                    "end": 122,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Correction of Ballet Training Movements Based on Digital Feature Recognition Technology"
        },
        {
            "text": "In general, the experimental research results verify that the digital feature recognition technology proposed in this paper can play an important role in ballet movement recognition and has a good motion correction effect. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Correction of Ballet Training Movements Based on Digital Feature Recognition Technology"
        },
        {
            "text": "Most of the students have not received systematic ballet dynamic technical movement training before entering the school, resulting in relatively weak students' basic skills and basic skills and relatively poor acceptance of learning new movements and new techniques. Ballet's dynamic technology has undergone constant casting and tempering by countless ancestors and constant innovations, and a very scientific and standardized training system has been formed. Moreover, it has accumulated a wealth of \"clinical\" experience in terms of training content and training methods. On this basis, this paper combines digital feature recognition technology to carry out ballet training movement correction analysis and combines the actual needs of actual ballet movement correction to conduct research and proposes a corresponding intelligent training correction system to improve the effect of ballet training. e experimental research results verify that the digital feature recognition technology proposed in this paper can play an important role in ballet movement recognition and has a good motion correction effect.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "e labeled dataset used to support the findings of this study is available from the corresponding author upon request.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data Availability"
        },
        {
            "text": "e author declares no competing interests. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflicts of Interest"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Portable 3D human pose estimation for human-human interaction using a chestmounted fisheye camera",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Aso",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "H"
                    ],
                    "last": "Hwang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Koike",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Proceedings of the Augmented Humans Conference 2021",
            "volume": "",
            "issn": "",
            "pages": "116--120",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Algorithm based on one monocular video delivers highly valid and reliable gait parameters",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Azhand",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rabe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "M\u00fcller",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sattler",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Heimann-Steinert",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Scientific Reports",
            "volume": "11",
            "issn": "1",
            "pages": "1--10",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Pose estimate based yoga instructor",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bakshi",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sheikh",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ansari",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Naik",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "International Journal of Recent Advances in Multidisciplinary Topics",
            "volume": "2",
            "issn": "2",
            "pages": "70--73",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A review of the evolution of vision-based motion analysis and the integration of advanced computer vision methods towards developing a markerless system",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Colyer",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Evans",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "P"
                    ],
                    "last": "Cosker",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "I T"
                    ],
                    "last": "Salo",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sports medicine -open",
            "volume": "4",
            "issn": "1",
            "pages": "24--39",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "DTCoach: your digital twin coach on the edge during COVID-19 and beyond",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "G"
                    ],
                    "last": "D\u00edaz",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Laamarti",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "El"
                    ],
                    "last": "Saddik",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Instrumentation and Measurement Magazine",
            "volume": "24",
            "issn": "6",
            "pages": "22--28",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Multiple human 3d pose estimation from multiview images",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ershadi-Nasab",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Noury",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Kasaei",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Sanaei",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Multi-person hierarchical 3d pose estimation in natural videos",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "N"
                    ],
                    "last": "Hwang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
            "volume": "30",
            "issn": "",
            "pages": "4245--4257",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Multipath affinage stacked-hourglass networks for human pose estimation",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hua",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Frontiers of Computer Science",
            "volume": "14",
            "issn": "4",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Judging the normativity of PAF based on TFN and NAN",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Bao",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Jiacheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of Shanghai Jiaotong University",
            "volume": "25",
            "issn": "5",
            "pages": "569--577",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Human pose estimation in video via structured space learning and halfway temporal evaluation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hua",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
            "volume": "29",
            "issn": "",
            "pages": "2029--2038",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Action recognition using deep convolutional neural networks and compressed spatio-temporal pose encodings",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Mcnally",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Wong",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Mcphee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Computational Vision and Imaging Systems",
            "volume": "4",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "VNect",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mehta",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sridhar",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Sotnychenko",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "ACM Transactions on Graphics",
            "volume": "36",
            "issn": "4",
            "pages": "1--14",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Realtime multi-person 2D pose estimation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nasr",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ayman",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ebrahim",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Osama",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Mosaad",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mounir",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "International Journal of Advanced Networking and Applications",
            "volume": "11",
            "issn": "6",
            "pages": "4501--4508",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Hierarchical contextual refinement networks for human pose estimation",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Feng",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xing",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IEEE Transactions on Image Processing",
            "volume": "28",
            "issn": "2",
            "pages": "924--936",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "A multi-stage convolution machine with scaling and dilation for human pose estimation",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Nie",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Yoon",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Park",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "KSII Transactions on Internet and Information Systems (TIIS)",
            "volume": "13",
            "issn": "6",
            "pages": "3182--3198",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Deep probabilistic human pose estimation",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Petrov",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Shakhuro",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Konushin",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "IET Computer Vision",
            "volume": "12",
            "issn": "5",
            "pages": "578--585",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Metrabs: metric-scale truncation-robust heatmaps for absolute 3d human pose estimation",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "S\u00e1r\u00e1ndi",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Linder",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "O"
                    ],
                    "last": "Arras",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Leibe",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Transactions on Biometrics, Behavior, and Identity Science",
            "volume": "3",
            "issn": "1",
            "pages": "16--30",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Body part extraction and pose estimation method in rowing videos",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Sz}",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Tam\u00e1s",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Journal of Computing and Information Technology",
            "volume": "26",
            "issn": "1",
            "pages": "29--43",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "An evaluation of pose estimation in video of traditional martial arts presentation",
            "authors": [
                {
                    "first": "N",
                    "middle": [
                        "T"
                    ],
                    "last": "\u00c0nh",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "T"
                    ],
                    "last": "C\u00f4ng",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Journal of Research and Development on Information and Communication Technology",
            "volume": "2019",
            "issn": "",
            "pages": "114--126",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "[Papers] keep your eye on the ball: detection of kicking motions in multi-view 4K soccer videos",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Tasaka",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "ITE Transactions on Media Technology and Applications",
            "volume": "8",
            "issn": "2",
            "pages": "81--88",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "fast and accurate whole-body pose estimation in the wild and its applications",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Tasaka",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Yamaguchi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "ITE Transactions on Media Technology and Applications",
            "volume": "9",
            "issn": "1",
            "pages": "63--70",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Figure 1: e homography induced by plane in dual-viewpoint matching.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Schematic diagram of the principle of Collins planar scanning algorithm.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Census nonparametric local transformation.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": ": e cumulative path of semiglobal matching costs: (a) 8-direction path; (b) 16-direction path.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "u \u2208 R M\u00d7N , where M and N, respectively, represent the size in each dimension. All the elements in u (i \ufffd x + My) are written in the form of a column vector, namely, u \ufffd u m,n M\u00d7N \ufffd u 1,1 u 1,2 . . . u 1,n u 2,1 u 2,2 . . . u 2,n . . . . . . . . . . . . u m,1 u m,2 . . . u m,n",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "e overall process of ballet movement recognition method.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "e process of ballet movement recognition system. : e effect diagram of ballet dance training movement correction. (a) Original ballet training image. (b) Background elimination. (c) Feature recognition.",
            "latex": null,
            "type": "figure"
        },
        "TABREF3": {
            "text": "Digital feature recognition results of the system.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Corrective effect of ballet training movement of the system.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "is study was sponsored by Guangxi University of Arts.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        }
    ]
}