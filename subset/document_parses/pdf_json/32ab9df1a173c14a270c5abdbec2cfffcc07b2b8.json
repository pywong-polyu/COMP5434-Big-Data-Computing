{
    "paper_id": "32ab9df1a173c14a270c5abdbec2cfffcc07b2b8",
    "metadata": {
        "title": "A demystifying convolutional neural networks using Grad-CAM for prediction of coronavirus disease (COVID-19) on X-ray images",
        "authors": [
            {
                "first": "C",
                "middle": [
                    "V"
                ],
                "last": "Aravinda",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "NITTE",
                    "location": {
                        "region": "KARKALA, KARNATAKA",
                        "country": "INDIA"
                    }
                },
                "email": ""
            },
            {
                "first": "Meng",
                "middle": [],
                "last": "Lin",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "SHIGA",
                    "location": {
                        "country": "JAPAN"
                    }
                },
                "email": ""
            },
            {
                "first": "K",
                "middle": [
                    "R"
                ],
                "last": "Udaya",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Kumar",
                "middle": [],
                "last": "Reddy",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "NITTE",
                    "location": {
                        "region": "KARKALA, KARNATAKA",
                        "country": "INDIA"
                    }
                },
                "email": ""
            },
            {
                "first": "G",
                "middle": [
                    "Amar"
                ],
                "last": "Prabhu",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "KOMATSU KAIHATSU COMPANY",
                    "location": {}
                },
                "email": ""
            }
        ]
    },
    "abstract": [],
    "body_text": [
        {
            "text": "patients noninfected by SARS-CoV-2, 2482 CT scans in total. Authors were able to identify if a person is infected by SARS-CoV-2 through the analysis of his/her CT scans and they claim good results. Sara Haseli, Nastaran Khalili [17] reported chest CT imaging results of patients with laboratory-confirmed COVID-19 pneumonia. Inters of segmental distribution, most commonly, involvement was seen in the posterior segment of the left lower lobe. Moreover, certain segments and lobes were more frequently involved based on age and sex of patients.",
            "cite_spans": [
                {
                    "start": 228,
                    "end": 232,
                    "text": "[17]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Shuai Wang et al. [18] collected CT images of pathogen-confirmed COVID-19 cases along with those previously diagnosed with typical viral pneumonia. They modified the inception transfer-learning model to establish the algorithm, followed by internal and external validation and claims of 85% of results.",
            "cite_spans": [
                {
                    "start": 18,
                    "end": 22,
                    "text": "[18]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Ali Narin, Ceren Kaya [19] from there study proposed three different CNN-based models (ResNet50, InceptionV3, and InceptionResNetV2) have been proposed for the detection of coronavirus pneumoniaeinfected patient using chest X-ray radiographs. Considering the performance results obtained is seen that the pretrained ResNet50 model provides the highest classification performance.",
            "cite_spans": [
                {
                    "start": 22,
                    "end": 26,
                    "text": "[19]",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "This study aimed to establish an early screening model to distinguish COVID-19 and healthy cases with X-ray images using Grad-CAM and CNN models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Objective of the work"
        },
        {
            "text": "(1) Whether this technology can be used to early screen COVID-19 patients from normal patients and what is the indicative precision. (2) In this case study, the overall accuracy of this models was obtained at the end of 15th epoch was 98% along with a training accuracy of 96% for two groups COVID-19 and healthy cases. (3) It is fully programmed and conceivably it will be a hopeful supplementary diagnostic method for clinical doctors. ",
            "cite_spans": [
                {
                    "start": 133,
                    "end": 136,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Vital opinions"
        },
        {
            "text": "The dataset we took was a combination of chest X-ray dataset from two different sources.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset introduction"
        },
        {
            "text": "1. Dr. Joseph Paul Cohen opened a publicly available chest X-ray dataset which contained chest X-ray images and some CT scan images which contained X-ray images of COVID and other similar diseases. 2. COVID-19 chest X-ray data from Kaggle: This dataset contained chest X-ray image data of pneumonia and normal condition of chest X-ray images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset introduction"
        },
        {
            "text": "The standard COVID-19 tests are called polymerase chain reaction tests which look for the existence of antibodies of a given infection. Pathogenic laboratory testing is the diagnostic gold standard, but it is time-consuming with significant false-negative results. Moreover, large scale implementation of the COVID-19 tests which are extremely expensive cannot be afforded by many of the developing and underdeveloped countries, in this regard, we decided to use the deep learning and computer vision approach to diagnose corona virus based off of X-ray images as X-ray is one of the readily available diagnostic solution as compared to CT scan.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset description"
        },
        {
            "text": "(a) At the outset, the first process was concentrated mostly on COVID-19 chest X-ray images and normal chest X-ray images to build our deep learning classification model. (b) Later the second data sources were combined by taking COVID-19 chest X-ray images from first source and normal chest X-ray images from second source, finally obtained 441 X-ray images in total of which 81 were randomly selected and used for validation and 350 images were used for training purpose. (c) The dataset was carefully screened to have only relevant chest X-ray images, discarding images of other type or the images which lacked resolution to get the final dataset ( Fig. 23.4 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 652,
                    "end": 661,
                    "text": "Fig. 23.4",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Data working model explanation"
        },
        {
            "text": "Many nondestructive sections which were inappropriate to this training were cloistered using the \"three-dimensional segmentation model,\" \"fibrotic structure of pulmonary,\" and \"classification spots\" are identified incorrectly. Thus, an additional category was added as extraneous besides COVID-19. The model prospect of COVID-19 cases was prolonged thrice to stabilize the number of extraneous, so as to limit the stimulus of the irregular distribution of different image types on the present dataset. At the same time, data extension mechanisms, such as \"random clipping,\" \"left-right,\" \"up-down flipping,\" and \"mirroring operation,\" were performed on samples to increase the number of training samples and prevent data overfitting.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Data augmentation"
        },
        {
            "text": "The main motivation was to build a classification model which could predict and detect the occurrence of COVID-19 virus in the given X-ray sample of the patient as input to the developed model. To achieve this goal, three different experimentation approaches were carried out as shown below.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Implementation workflow"
        },
        {
            "text": "1. Training the model with some state-of-the-art models and finding out classification accuracy. dataset. The model of covid 19 patients and normal person architecture is as shown in the Fig. 23 .13. However, this gives us an insight into how the CNN trains over the small dataset. These results clearly infer an overfitting trend from the graphs. The overfitting trend remains though we have added image data augmentation to increase the size our dataset. We can then infer from the data such that when construction or finetuning our own model, which becomes necessary to add regularization or dropout layers so as to prevent overfitting of the training data ( Fig. 23.13 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 187,
                    "end": 194,
                    "text": "Fig. 23",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 662,
                    "end": 672,
                    "text": "Fig. 23.13",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Implementation workflow"
        },
        {
            "text": "This is the subbranch of machine learning, and because of its accomplishment in the field of medical image processing, it is used in recent years. Deep learning models have been used successfully in many areas such as classification and segmentation of medical data. Analysis of image and signal data obtained with medical imaging techniques such as magnetic resonance imaging, CT, and X-ray with the help of deep learning models. This model provided the convince results in the field of detection and diagnosis in the field of \"diabetes\", \"skin and breast cancer\" [20e22].",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Deep transfer learning with layer fine turning and VGG 16"
        },
        {
            "text": "Deep learning (DL) models often need a lot of data, but for the analysis of medical data, the main disadvantage is the dataset till today many researchers are facing the issue. The main advantage of using this TL is that it allows the training of data with fewer datasets and requires less calculation costs. This TL method, which is widely used in ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Deep transfer learning with layer fine turning and VGG 16"
        },
        {
            "text": "Python programming language was used to train the proposed deep TL models. All experiments were performed on a Google Collaboratory with Ubuntu 16.04 operating system using Tesla K80 GPU graphics card. CNN model VGG 16 was used for TL which was initialized with pretrained ImageNet weights and optimized using the Adam optimizer. The batch size, learning rate, and number of epochs were determined experimentally and early stopping was implemented over the training process. The dataset used was randomly split into two independent datasets with 80% and 20% for training and testing, respectively. The model was finetuned in their final layers after the convolutional layers as shown in The validation accuracy obtained was around 65% which was very low and comparatively same to the previous section, considering this is a 2-class problem. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental setup for training the model carried out"
        },
        {
            "text": "To obtain an improved accuracy, a new CNN architecture model was developed for training the model. Considering the small dataset, it was proceeded to build a small architecture for CNN classification which is as shown in Table 23 .3.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 221,
                    "end": 229,
                    "text": "Table 23",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Training with a convolutional neural network architecture"
        },
        {
            "text": "The model was compiled with Adam optimizer along with binary cross-entropy as a loss function. Image data augmentation such as zoom, shear, normalization, and horizontal flip was used to negate the effects of using a small dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training with a convolutional neural network architecture"
        },
        {
            "text": "The highest validation accuracy obtained at the end of 15th epoch was 98% along with a training accuracy of 96%.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training with a convolutional neural network architecture"
        },
        {
            "text": "The plots for Training Accuracy versus Validation Accuracy and Training Loss versus Validation Loss are as shown in Figs. 23.14 and 23.15, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Training with a convolutional neural network architecture"
        },
        {
            "text": "During the experiment process to analyze the performance metrics, the following five criteria were used. TP, FP, TN, and FN which constitute the symbol of \"True-Positive/Negative,\" \"False-Positive/Negative,\" respectively. Precise set of data and model, in which \"True-Positive\" is the proportion of positive patient case that are properly considered as COVID-19 by the model; \"False Positive\" is the part of negative normal patient that are mislabeled as positive case, \"True-Negative\" is the part of negative normal patient that are properly considered as normal, and \"False-Negative\" is the part of positive patient that is misbranded as negative normal patient by the model. The Table 23 .4 shows the results of normal and covid-19 patients precision model, and the confusion matrix as shown in the (Fig. 23.16 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 682,
                    "end": 690,
                    "text": "Table 23",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 802,
                    "end": 813,
                    "text": "(Fig. 23.16",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Performance metrics"
        },
        {
            "text": "The architecture of Gradient-weighted Class Activation Mapping (Grad-CAM) which is as shown in Fig. 23 .17 uses the gradients of any target perception in a classification of network flowing into the final convolutional layer to produce a coarse localization map emphasizing the important regions in the image for predicting the concept. This model is applicable to a wide variety of CNN model-families: \"Fully connected layer,\" \"Structured output,\" and \"Multimodal inputs.\" Grad-CAM uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Using Grad-CAM, we can visually validate where our network is looking, verifying that it is indeed looking at the correct patterns in the image and activating around those patterns [4, 26] .",
            "cite_spans": [
                {
                    "start": 862,
                    "end": 865,
                    "text": "[4,",
                    "ref_id": null
                },
                {
                    "start": 866,
                    "end": 869,
                    "text": "26]",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [
                {
                    "start": 95,
                    "end": 102,
                    "text": "Fig. 23",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Gradient-based activation model"
        },
        {
            "text": "However, Class Activation Model (CAM) is a good technique to interpret the working of CNN and build the conviction in the applications developed, but still they undergo from some limitations. Some of the drawbacks of CAM is that it needs feature maps to directly precede the SoftMax layers, so it is applicable to a kind of CNN architectures that perform global average pooling over convolutional maps immediately before prediction. In our experimentation, we used Grad-CAM to find out which part of the chest X-ray was the most significant in diagnosing whether the patient has COVID-19 infection or not infected.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gradient-based activation model"
        },
        {
            "text": "Steps followed in Grad-CAM",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gradient-based activation model"
        },
        {
            "text": "(1) The model is first run on forward pass with the input image on our own architecture.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gradient-based activation model"
        },
        {
            "text": "(2) The input image is preprocessed so that it is compatible with the model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Gradient-based activation model"
        },
        {
            "text": "(3) Then the model is used to make prediction on the image, and the top prediction is decoded. (4) Then, we find the gradients of the target class score with respect to the feature maps of the last convolutional layer. Intuitively it tells us how important each channel is with regard to the target class. (5) The gradients thus obtained are then global average pooled to obtain the neuron important weights corresponding to the target class (6) After that, we multiply each activation map with corresponding pooled gradients which acts as weights determining how important each channel is with regard to the target class. We then take the mean of all the activation maps along the channels, and the result obtained is the final class discriminative saliency map. In Fig. 23 .17, the darker regions are significant in finding weather an X-ray sample has COVID-19 or not as shown by our neural network architecture. The image above shows the similarities between the region of interest marked by Grad-CAM trained from our custom CNN to the region marked as area of interest for COVID-19 obtained from the dataset. The image was part of a test set where the particular image was used to highlight Region of Interest by Grad-CAM. We can clearly see that the region marked is almost close or is exactly near the region of interest in Grad-CAM which to some extent shows that the custom-built CNN is classifying based on actual area of interest rather than some noise or discrepancies in the training or test images. It is important to note that the image obtained for test was from the open source dataset and not other information about the image is known to us (Figs. 23.18e23.20 ).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 767,
                    "end": 774,
                    "text": "Fig. 23",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1659,
                    "end": 1677,
                    "text": "(Figs. 23.18e23.20",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Gradient-based activation model"
        },
        {
            "text": "Prediction and isolation of COVID-19 cases was one of the major and required steps in taking immediate action over controlling the spread of the COVID-19 disease. Throat swab test was one of the methods for detecting the presence of COVID-19. The drawback of this test was a time-consuming test, and equipment were much needed which were not readily available with the everyday hospital. In this regard, we decided to use the concepts of image processing and DL to find the presence of COVID-19 infection in a person. The datasets collection phase involved collecting various X-ray images of COVID-19 and normal patients, in which various images were collected from opensource datasets. The experimentation phase was carried out on the X-ray images, and these were trained with the state-of-the-art deep learning model to an optimal model which could diagnose a given image as COVID-19 or normal. But regrettably, all the models were abortive in achieving accuracy. The reason for less accuracy was mainly because of few reasons which were notified such as huge datasets were used in training all the models which was used were from the image-net competition which includes large datasets of visually different images, and we had a small datasets of visually similar images.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results discussion"
        },
        {
            "text": "In the second step, we strive with using the per-trained weights and the concept of TL to see if we could obtain a higher accuracy. Though the result was the model with a higher accuracy when compared to the one without TL, the accuracy was still not high enough to be considered a good classifying model. Considering the similarities between the previous two steps, it was concluded that the reason behind this was a large number of convolution layers and a small dataset.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results discussion"
        },
        {
            "text": "In the third step, we have developed our own model considering the previous experiments. At the preliminary stage, we developed a small model with a few convolution layers and a few dense layers with normalization and dropouts to prevent the model from under fitting or over fitting. This model was found to be pretty good model when it was compared to the previous two models and achieved a good result with the experiment outcome. Subsequent plan was used to find which part of the X-ray images were responsible for COVID-19, hence to visualize this, a algorithmic technique Grad-CAM was used to generate heat maps from the final convolution layers. The observation made on the test set was a very close similarity to the images marked by professionals ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results discussion"
        },
        {
            "text": "Initial prediction of COVID-19 patients is essential to prevent the spread of the pandemic disease to other people. In this study, we proposed a Grad-CAM approach using chest X-ray images obtained from COVID-19 patients and normal to predict COVID-19 patients automatically. Performance results show that the pretrained model yielded the highest accuracy of 98%. The highest validation accuracy obtained is 98% along with a training accuracy of 96%. It is believed that this may help doctors to take appropriate decisions in clinical practice. To detect and predict the COVID-19 at an early stage, this experiment might give an insight on how Grad-CAM can be used. Further work and rigorous clinical trials need to be conducted by medical professionals before the effectiveness of the model can be proven practically.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The future work of the research involves using the model to classify phenomena, COVID-19, and other illnesses to normal images and to create a classifying model for these diseases using only X-ray images. on this research including clinical tests with a large amount of data, and it is important that the work done should be reviewed and approved by medical professionals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Future work"
        },
        {
            "text": "Aravinda, Meng Lin, and K R Udaya Kumar Reddy were involved in the study conception and acquisition of dataset. Aravinda and Amar Prabhu were involved in the experiments and analyzed the results. All the four authors wrote the manuscript and revised the script critically and reviewed the manuscript.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Author contributions statement"
        },
        {
            "text": "Correspondence and requests for materials should be addressed to Aravinda C.V and Meng Lin.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Additional information"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Automatic organ segmentation for CT scans based on super-pixel and convolutional neural networks",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "J. Digit. Imag",
            "volume": "31",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Deep bilateral learning for real-time image enhancement",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Gharbi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "T"
                    ],
                    "last": "Barron",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "ACM Trans. Graph",
            "volume": "36",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Prediction of criticality in patients with severe Covid-19 infection using three clinical features: a machine learning-based prognostic model with clinical data in Wuhan",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yan",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "T"
                    ],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Tang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Jing",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jin",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Xiao",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Jiao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Cao",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Yuan",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.02.27.20028027"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Deep 445 learning-based image conversion of CT reconstruction kernels improves radiomics reproducibility for pulmonary nodules or masses",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Choe",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "H"
                    ],
                    "last": "Do",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "G"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "M"
                    ],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Radiology",
            "volume": "447",
            "issn": "2",
            "pages": "365--373",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "449 identifying medical diagnoses and treatable diseases by image-based deep learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "S"
                    ],
                    "last": "Kermany",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Goldbaum",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "C S"
                    ],
                    "last": "Valentim",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "L"
                    ],
                    "last": "Baxter",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Cell",
            "volume": "172",
            "issn": "5",
            "pages": "1122--1131",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Correlation of chest ct and rt-pcr testing in coronavirus disease",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "China: a report of 1014cases",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Imaging profile of the covid-19 infection: radiologic findings and literature review",
            "authors": [
                {
                    "first": "M.-Y",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiol. Cardiothorac",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Chest imaging appearance of covid-19 infection",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Kong",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "P"
                    ],
                    "last": "Agarwal",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiol. Cardiothorac",
            "volume": "2",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Levy-Bruhl, I. Team, First cases of coronavirus disease 2019 (COVID-19) in France: surveillance, investigations and control measures",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Stoecklin",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Rolland",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Silue",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mailles",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Campese",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Simondon",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mechain",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Meurice",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Bassi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Yamani",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Behillil",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ismael",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Nguyen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Malvy",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "X"
                    ],
                    "last": "Lescure",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Georges",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Lazarus",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Taba\u00ef",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Stempfelet",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Enouf",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Coignard",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Euro Surveill",
            "volume": "25",
            "issn": "6",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Large scale distributed computer vision as a cloud service",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "S"
                    ],
                    "last": "Mathialagan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Goyal",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Chavali",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Banik",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mohapatra",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Osman",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "B"
                    ],
                    "last": "Cloudcv",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Mobile Cloud Visual Media Computing",
            "volume": "",
            "issn": "",
            "pages": "265--290",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Network dissection: quantifying interpretability of deep visual representations",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Bau",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zhou",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khosla",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Oliva",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Torralba",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Selftaught object localization with deep networks",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Bazzani",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bergamo",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Anguelov",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Torresani",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Representation learning: a review and new perspectives",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bengio",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Courville",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Vincent",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "IEEE Trans. Pattern Anal. Machine Intell",
            "volume": "35",
            "issn": "8",
            "pages": "1798--1828",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "SARS-CoV-2 CT-Scan Dataset: A Large Dataset of Realpatients CT Scans for SARS-CoV-2 Identification, The copyright holder for this preprint this version posted May 12, 2020. medRxiv preprint",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Soares",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Angelov",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Biaso",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "H"
                    ],
                    "last": "Froes",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "K"
                    ],
                    "last": "Abe",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.24.20078584"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Lobar Distribution of COVID-19 Pneumonia based on chest computed tomography findings; a retrospective study Archiv. Acad",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Haseli",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Khalili",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Bakhshayeshkaram",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sanei-Taheri",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Moharramzad",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Emergency Med",
            "volume": "8",
            "issn": "1",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.22037/aaem.v8i1.665"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "COVID-19 Versus Non-COVID-19 Pneumonia\uff1a A Retrospective Cohort Study Paper in collection COVID-19 SARS-CoV-2 preprints from medRxiv and bioRxiv",
            "authors": [
                {
                    "first": "X.-J",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "B.-X",
                    "middle": [],
                    "last": "Shuai",
                    "suffix": ""
                },
                {
                    "first": "Z.-W",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.28.20082784"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images and Deep Convolutional Neural Networks, Image and Video Processing",
            "authors": [
                {
                    "first": "Ali",
                    "middle": [
                        "N"
                    ],
                    "last": "",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Kaya",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Pamuk",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Computer Vision and Pattern Recognition (cs",
            "authors": [],
            "year": null,
            "venue": "CV",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Automated detection of diabetic subject using pre-trained 2D-CNN models with frequency spectrum images extracted from heart rate signals",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Ay",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "B"
                    ],
                    "last": "Baloglu",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Aydin",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Comput. Biol. Med",
            "volume": "113",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Brain tumor detection using fusion of hand crafted and deep learning features",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Saba",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Mohamed",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "El-Affendi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Amin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Sharif",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Cognit. Syst. Res",
            "volume": "59",
            "issn": "",
            "pages": "221--230",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "The skin cancer classification using deep convolutional neural network",
            "authors": [
                {
                    "first": "U",
                    "middle": [
                        "O"
                    ],
                    "last": "Dorj",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "K"
                    ],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "Y"
                    ],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Multimed. Tool. Appl",
            "volume": "77",
            "issn": "8",
            "pages": "9909--9924",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "A comparative study of deep learning architectures on melanoma detection",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "H"
                    ],
                    "last": "Kassani",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [
                        "H"
                    ],
                    "last": "Kassani",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Tissue Cell",
            "volume": "58",
            "issn": "",
            "pages": "76--83",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Detecting and classifying lesions in mammograms with deep learning",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ribli",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Horv\u00e1th",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Unger",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Pollner",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Csabai",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sci. Rep",
            "volume": "8",
            "issn": "1",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Automated invasive ductal carcinoma detection based using deep transfer learning with whole-slide images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Celik",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Talo",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Yildirim",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Karabatak",
                    "suffix": ""
                },
                {
                    "first": "U",
                    "middle": [
                        "R"
                    ],
                    "last": "Acharya",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Pattern Recogn. Lett",
            "volume": "133",
            "issn": "",
            "pages": "232--239",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Analyzing the behavior of visual question answering models",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Agrawal",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Batra",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Parikh",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Flow of process carried out schematic representation.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Training the model with VGG 16 transfer learning (TL) with the ImageNet weights and finetuning final layers to find the classification accuracy. 3. Building CNN architecture to find out the accuracy of the model (Figs. 23.5e23.12).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Precision \u00bc TP = \u00f0TP \u00fe FP\u00de (23.4) F1 \u00c0 Score \u00bc 2x\u00f0\u00f0Precision \u00c3 Recall\u00de = \u00f0Precision \u00fe Recall\u00de\u00de (23.5)",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "14 Validation accuracy versus training accuracy.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "15 Validation loss versus training loss.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "17 A complete architecture toward Gradient-weighted Class Activation Mapping.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Then we apply ReLU on the resulting heatmap to only keep the features that have a positive influence on the output map. (8) We then divide each intensity value of the heatmap with the maximum intensity value to normalize the heatmap such that all values fall between 0 and 1. The obtained results of Grad-CAM Steps are as shown in Figs. 23.18e23.20 respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "18 COVID-19 gradient class activation map.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "19 COVID-19 gradient class activation map description.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "20 Gradient class activation map for samples with no COVID-19.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "obtained from the datasets) and the region shown by our model. Though the result was good in our experiment, all the results are based on a small open-sourced dataset which were made available for research purposes. The experiments results is as shown in the Figs. 23.21e23.24 respectively.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "21 Homepage for testing case X-ray image of random sample1.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF12": {
            "text": "22 Result of the tool detected normal.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF13": {
            "text": "23 Homepage for testing case X-ray image of random sample2.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "24 Result of the tool detected positive.",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Training with state-of-the-art models.FIGURE 23.13 Representation of pretrained models for the prediction of COVID-19 patients and normal.the field of DL, the information gainer by the pretrained model on a large dataset is transferred to the model to be trained [23e25].",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 23.2. The full VGG 16 architecture used for experiment is given in Table 23.2.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "2 Transfer learning with layer fine turning and VGG 16.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "The structure of an architecture.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "The precision model is as given below.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This work was supported by JSPS KAKENHI Grant Number 18K18337.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments"
        },
        {
            "text": " 9 . Summary of work carried out so far 1 . In our problem, X-ray images were used for experiment. These images were taken from open source data sets. 2. This experiment is an end-to-end system, hence it does have not have any feature extraction and selection. 3. We used our own CNN model to carry out the experiment to achieve the better results along with Grad-CAM technique. 4. Since it is a new research topic, the data is limited to less samples, apart from this, good achievement results were obtained. 5. The main problem in this experiment is less amount of COVID-19 samples used for training and testing process (Figs. 23.21e23.24).",
            "cite_spans": [
                {
                    "start": 1,
                    "end": 2,
                    "text": "9",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 40,
                    "end": 41,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "annex"
        },
        {
            "text": "The effort was made to predict the COVID-19 using new technologies for the societal benefits. The COVID-19 X-ray experiment was conducted on a small open-source dataset which was available for research purpose. In this paper, deep learning technologies were used to detect and predict the presence of COVID-19 on the chest X-ray images along with Gradient Class Activation Map (Grad-CAM) can be potentially used to identify the infected region on a chest X-ray. The further work needs to be carried out",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Note"
        }
    ]
}