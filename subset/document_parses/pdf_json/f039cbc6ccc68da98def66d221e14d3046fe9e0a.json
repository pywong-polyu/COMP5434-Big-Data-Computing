{
    "paper_id": "f039cbc6ccc68da98def66d221e14d3046fe9e0a",
    "metadata": {
        "title": "DenseNet Convolutional Neural Networks Application for Predicting COVID-19 Using CT Image",
        "authors": [
            {
                "first": "Najmul",
                "middle": [],
                "last": "Hasan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Yukun",
                "middle": [],
                "last": "Bao",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Ashadullah",
                "middle": [],
                "last": "Shawon",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "Yanmei"
                ],
                "last": "Huang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Recently, the destructive impact of Coronavirus 2019, commonly known as COVID-19, has affected public health and human lives. This catastrophic effect disrupted human experience by introducing an exponentially more damaging unpredictable health crisis since the Second World War (Kursumovic et al. in Anaesthesia 75: 989-992, 2020). Strong communicable characteristics of COVID-19 within human communities make the world's crisis a severe pandemic. Due to the unavailable vaccine of COVID-19 to control rather than cure, early and accurate detection of the virus can be a promising technique for tracking and preventing the infection from spreading (e.g., by isolating the patients). This situation indicates improving the auxiliary COVID-19 detection technique. Computed tomography (CT) imaging is a widely used technique for pneumonia because of its expected availability. The artificial intelligence-aided images analysis might be a promising alternative for identifying COVID-19. This paper presents a promising technique of predicting COVID-19 patients from the CT image using convolutional neural networks (CNN). The novel approach is based on the most recent modified CNN architecture (DenseNet-121) to predict COVID-19. The results outperformed 92% accuracy, with a 95% recall showing acceptable performance for the prediction of COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "A dramatic outbreak of the novel Coronavirus disease 2019 (COVID- 19) has already been recognized as a global alarming public healthcare distraction. COVID-19 was first identified in late 2019 in Wuhan, China [2, 3] , and unexpectedly spread to more than 200 countries; thus, the World Health Organization (WHO) announced a pandemic crisis immediately [4] . Due to strong communicable properties among human-to-human in close contact [5] , healthcare professionals and policymakers have failed to control this dramatic pandemic outbreak, which resulted in rapidly killing people. 1 As secondary infections occur because of close personal interactions in populations, it is crucial to identify and isolate the infected person as soon as possible and implement social lockdown. Thus, early detection of the COVID-19 incidents is a paramount option to take proactive steps to minimize risks and spread of infections, plan of clinical treatment and arrange timely care support. That may play a vital role in better public healthcare management. This will have a direct effect on saving the planet from the virus.",
            "cite_spans": [
                {
                    "start": 66,
                    "end": 69,
                    "text": "19)",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 209,
                    "end": 212,
                    "text": "[2,",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 213,
                    "end": 215,
                    "text": "3]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 352,
                    "end": 355,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 434,
                    "end": 437,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 580,
                    "end": 581,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Due to specific drugs and vaccines' unavailability, there is a crucial need to identify the infected person for taking steps to immediate isolation. Because of the widely used laboratory diagnosis method worldwide, the real-time polymerase chain reaction (RT-PCR) analysis (as a vital diagnosis approach clinically) is generally adopted for the detection of COVID-19 virus in clinical practice, following the national recommendation for disease and treatment of pneumonia caused by the 2019-nCoV, started from China. However, a defective rate of RT-PCR test results [6, 7] might be contributing to any limitations leading to the sample collection process and transportation, which involve a time-consuming procedure [8, 9] . This procedure might not recognize the patients with critical conditions (i.e., patients with intensive care unit (ICU)). Another drawback of the RT-PCT testing system is that the time required for conventional PCR tests to diagnose disease is longer [10] . An infected person may be a carrier to spread the virus to other healthy, ordinary people or healthcare professionals as this virus holds strong transmittable nature. However, developing countries suffer from limited scientific resources and a lack of health technologists or professionals [11] . While there are few resources to fight against a pandemic, the promising alternative of the COVID-19 test protocol reflects a situational demand. Computed tomography (CT) imaging is a standard tool for diagnosing pneumonia that provides more accurate decision-making than a laboratory-based detection method called RT-PCR [12] . In this context, the CT image classification can be a promising alternative methodology for predicting COVID-19 [7] , especially for patients with critical conditions. Literature reveals that the performance of RT-PCR shows a lower sensitivity rate compared to the sensitivity of CT [13] .",
            "cite_spans": [
                {
                    "start": 566,
                    "end": 569,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 570,
                    "end": 572,
                    "text": "7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 716,
                    "end": 719,
                    "text": "[8,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 720,
                    "end": 722,
                    "text": "9]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 976,
                    "end": 980,
                    "text": "[10]",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 1273,
                    "end": 1277,
                    "text": "[11]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1602,
                    "end": 1606,
                    "text": "[12]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 1721,
                    "end": 1724,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1892,
                    "end": 1896,
                    "text": "[13]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This research mainly aims to bring reliable measures to identify patients with COVID-19 from the CT image using CNN. The CNN demonstrated excellent results in several computer vision tasks [14, 15] . CNN recently became a dominant in-depth learning approach for medical image classification due to its self-learning ability [16] . For the detection of COVID-19, numerous CNN-based strategies were proposed [17] [18] [19] [20] [21] [22] . Unlike other image datasets [23] , relatively few training samples of the medical images dataset are used. To achieve ground-breaking efficiency on these datasets, CNNs have been amplified with several techniques like data augmentation. We applied a comparatively new approach, CNN, in which the learning technique is designed with an association of densely connected convolutional networks (DenseNet) [24] to identify patients with COVID-19. The main motivation behind the use of DenseNet-121 is, it mitigates the problem of vanishing gradient, improves feature reuse, and decreases parameter usage, which is useful for training deep learning models [25] . Furthermore, DenseNet-121 has proven effective in diagnosing diseases based on medical imaging [26, 27] . The concept of driving DenseNet would be to link each layer to every other layer behind it to improve the architecture flow. This approach helps CNN to settle based on all layers instead of one final layer. DenseNet is more sophisticated and can capture image information on a larger scale compared to traditional image processing methods [15] .",
            "cite_spans": [
                {
                    "start": 189,
                    "end": 193,
                    "text": "[14,",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 194,
                    "end": 197,
                    "text": "15]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 324,
                    "end": 328,
                    "text": "[16]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 406,
                    "end": 410,
                    "text": "[17]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 416,
                    "end": 420,
                    "text": "[19]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 421,
                    "end": 425,
                    "text": "[20]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 426,
                    "end": 430,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 431,
                    "end": 435,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 466,
                    "end": 470,
                    "text": "[23]",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 840,
                    "end": 844,
                    "text": "[24]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1089,
                    "end": 1093,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1191,
                    "end": 1195,
                    "text": "[26,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 1196,
                    "end": 1199,
                    "text": "27]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1541,
                    "end": 1545,
                    "text": "[15]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This study contributes to current literature in some aspects, which are summarized:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "\u2022 First, we applied a newly adopted DenseNet-121 CNN technique with a data augmentation technique to classify and identify COVID-19 patients. While RT-PCR test results might be contributing to any limitations for the critical patients, the CT image classification technique might be a promising alternative for the detection of COVID-19 as this technique has an exceptionally high sensitivity in diagnosing the disease [2] . \u2022 Second, we conducted an extensive application of experimental analyses and reported the performance of DenseNet-121 CNN on multiple indices, including sensitivity, specificity, and AUC. \u2022 Third, this study resolved a literature gap using more extensive medical image classification data, while previous literature has used comparatively smaller datasets. \u2022 Fourth, as noted by the researchers, the novelty of this study is that DenseNet-121 CNN is an effective pretrained model compared to other models. \u2022 Finally, using real-time COVID-19 CT image data, the applied technique outperforms for prediction of COVID-19. Practically, this approach assists healthcare professionals in fast diagnoses and effective treatment decisions for the patient in an emergency.",
            "cite_spans": [
                {
                    "start": 419,
                    "end": 422,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The remaining part of the paper is structured accordingly. \"Related Works\" includes related works on several deep learning techniques for classifying images and the DenseNet in brief. The data set used in this paper and the descriptions of the method are outlined in \"Methods\". \"ResultsandDiscussion\" contains the results and discussions of experiments. Finally, in \"Conclusion\", the conclusion, strangeness, limitations, and scope of further research have been discussed.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "With the rapid development of artificial intelligence, different image classification techniques in medical informatics have been proposed for various diversified demands. The machine learning (ML) technique has recently been considered a prominent tool for predicting and diagnosing numerous diseases [28] . However, their accuracy and adequate performance criteria are yet to need improvement. AlexNet, VGG, GoogLeNet, and ResNet architecture, for example, are more performing in the classification of medical images. However, these networks face the difficulty of convergence, overfitting, and vanishing gradient problems [29] . Therefore, based on DenseNet, CNN offers accurate medical image classification options to enable features [30] . One of the drawbacks of Gao, Zhang [28] study is that it cannot be used for binary class classification. Additionally, whereas the other baselines must accommodate a larger number of factors, Multipath-DenseNet is capable of more accurate predictions with fewer parameters [29] .",
            "cite_spans": [
                {
                    "start": 302,
                    "end": 306,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 625,
                    "end": 629,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 738,
                    "end": 742,
                    "text": "[30]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 780,
                    "end": 784,
                    "text": "[28]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 1018,
                    "end": 1022,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Recently, radiology images have been widely used for the identification of COVID-19 cases using standard ML techniques. For example, Pereira, Bertolini [31] applied the hierarchical image classification using a chest X-ray for COVID-19 prediction. Ozturk, Talo [22] proposed a deep neural network for automatic detection of COVID-19 cases. While the model is entirely automated from beginning to end, eliminating the requirement for human feature extraction, this study has its limits in the quantity of COVID-19 X-ray images is used. In addition, Khan, Shah [18] performed a multi-level classification using a chest X-ray using an Xception architecture-based convolutional neural network in achieving an overall 89.6% accuracy with 93% precision. The model has been trained and evaluated on a limited dataset of several hundred images obtained via the acquisition of chest X-ray images. To mitigate the drawback, additional training data need to be considered. Thus, it may be possible to enhance the performance even more.",
            "cite_spans": [
                {
                    "start": 152,
                    "end": 156,
                    "text": "[31]",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 261,
                    "end": 265,
                    "text": "[22]",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 559,
                    "end": 563,
                    "text": "[18]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Several strategies of deep learning were suggested for better identification of COVID-19. Panwar, Gupta [32] proposed a deep learning-based nCOVnet technique for analyzing X-ray images, which achieved 88.10% of overall accuracy. Wang, Deng [33] implemented a supervised deep learning framework using a 3D CT image. Wang, Liu [25] applied a noise-robust framework on CT image for automatics segmentation of COVID-19. Soares, Angelov [34] used an eXplainable Deep Learning approach using a CT image. Ucar and Korkmaz [35] employed Bayesian optimization additive fine-tuning for SqueezeNet that performs better COVID-19 detection. DenseNet has used previous studies to obtain higher accuracy of other domains like industrial image classification with superior accuracy. DenseNet is considered a more problem-sensitive network architecture and a multi-level innovative fine-tuning process that creates several specific networks.",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 108,
                    "text": "[32]",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 240,
                    "end": 244,
                    "text": "[33]",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 325,
                    "end": 329,
                    "text": "[25]",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 432,
                    "end": 436,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 515,
                    "end": 519,
                    "text": "[35]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Nevertheless, it would be recognized that deep learning methods also have certain limits in COVID-19 identification. Numerous countries have adopted RT-PCR test methods to detect and, if positive, isolate the patients, instead of CT image examination especially for critical patients, to restrict the transmission of COVID-19 and safeguard the public. Additionally, while much of the relevant research was completed during the early stages of COVID-19, there was a lack of COVID-19 images available for study. For instance, investigations have demonstrated that the range of images contained in the COVID-19 collection is between 127 and 453 in studies [17, 19, 20, 22, [36] [37] [38] [39] . Finally, due to the limited supply of testing kits and the rising number of daily infection cases, one of the major motivations behind applying the Deep Learning model (i.e., DenseNet-121) for COVID-19 diagnosis would help radiologists and healthcare professionals in recognizing instances of COVID-19 using CT images.",
            "cite_spans": [
                {
                    "start": 653,
                    "end": 657,
                    "text": "[17,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 658,
                    "end": 661,
                    "text": "19,",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 662,
                    "end": 665,
                    "text": "20,",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 666,
                    "end": 669,
                    "text": "22,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 670,
                    "end": 674,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 675,
                    "end": 679,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 680,
                    "end": 684,
                    "text": "[38]",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 685,
                    "end": 689,
                    "text": "[39]",
                    "ref_id": "BIBREF38"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "Furthermore, a scholarly work reports that the majority of the approaches employed before were applied with the pre-trained models, except for the output layer. As data augmentation is a crucial component of the training process for deep learning models, and we use this to our advantage and employ it as an additional measure. Moreover, the DenseNet study obtained good precision for CT images, but the accuracy of X-ray images was poor [40] . Another feature of DenseNet is that it has a smaller set of parameters to be optimized than the other deep learning models. Thus, DenseNet is less complicated. To acquire greater accuracy, we applied a DenseNet model with an extra layer of 121 perceptrons.",
            "cite_spans": [
                {
                    "start": 438,
                    "end": 442,
                    "text": "[40]",
                    "ref_id": "BIBREF39"
                }
            ],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "The above discussion reveals that the DenseNet-based CNN technique might be an alternative diagnostic tool for significant identification of COVID-19 patients identification using CT images. The CNN model may achieve significant promising results, but the further use of new architectures can improve outcomes. Prior research suffers from the disadvantage of using only a small number of training data points. In comparison, this work applies a large set of training samples. Therefore, a CNN model's advanced application with extensive training data for COVID-19 classification is the study's primary motivation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related Works"
        },
        {
            "text": "DenseNet is modern architecture of CNN for visual object recognition that has acquired state-of-the-art with fewer parameters. With some principal modifications, DenseNet is very similar to ResNet. DenseNet, along with its concatenated (.) attributes, combines the previous layer output with a future layer, while ResNet uses an additive attribute (+) to merges the previous layer with the future layers. The DenseNet Architecture aims to fix this problem by densely connecting all layers. Among the different DenseNet (DenseNet-121, DenseNet-160, DenseNet-201), this study employed DenseNet-121 [5 + (6 + 12 + 24 + 16) \u00d7 2) = 12 1] architecture. Details of the DenseNet-121 is following: 5-convolution and pooling layers, 3-transition layers (6,12,24), 1-Classification layer (16) and 2-denseblock (1 \u00d7 1 and 3 \u00d7 3 conv).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DenseNet"
        },
        {
            "text": "Generally, traditional CNNs calculate the output layers (lth) using a non-linear transformation H l (.) to the output of the previous layer X l\u22121 DenseNets do not really sum up the layer output functionality maps with the inputs but concatenate them. DenseNet offers an easy communication model for improving information flow between layers: the lth layer receives inputs from the features of all previous levels: The equation is then again transformed into:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DenseNet"
        },
        {
            "text": "where [X 0 , X 1 , X 2 ,\u2026, X l \u2212 1 ,] is a single tensor formed by the concatenation of the output maps of previous layers. Out of the functions, H l (.) represents a non-linear transformation function. This function consists of three major operations, batch normalization (BN), activation (ReLU) and pooling and convolution (CONV). DenseNet architecture is presented in Fig. 1 . However, the growth rate k helps to generalize the lth layer in following manner: k [l] = (k [0] + k(l \u2212 1)). Where k [0] is known as the number of channels.",
            "cite_spans": [
                {
                    "start": 498,
                    "end": 501,
                    "text": "[0]",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 371,
                    "end": 377,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "DenseNet"
        },
        {
            "text": "(1) X l = H l (X l\u22121 ).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DenseNet"
        },
        {
            "text": "(2) X l = H l (X 0 , X 1 , X 2 , \u2026 , X l\u22121 ) ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "DenseNet"
        },
        {
            "text": "Data augmentation is a method that enables practitioners to significantly improve the variety of data for training models without actually collecting new data. The technique of increasing the number of training samples by transforming the images without losing semantic information is referred to as data augmentation, and it enables the image data to be free of bias. To prevent bias in the image data due to the similarity of the underlying image, basic modifications such as horizontal flipping, color space augmentations, and random cropping are frequently employed for model training [41, 42] . Additionally, data augmentation enables the model to learn a more diverse collection of features, which increases the dataset's size and assists in preventing the model from becoming overfitted [43] . As recommended by Singh, Bansal [43] , and Silva, Luz [44] , horizontal flip, rotation, and scaling were considered for data augmentation in this study. Also, there is a call for data augmentation to improve image classification accuracy [45] . To increase training benefits and decrease network regularization image augmentation has been used in this study. We adopted a widely employed data augmentation technique, which is also used in [29] . Images were in different pixels on each side and then randomly cropped to the 64 \u00d7 64 original image size, where the random rotation range was 360 0 . Images were mixed in horizontally and vertically mirrored. Horizontal, vertical, and zoom ranges were set to 0.2, which means that the range between height and weight is 0.8-1.2 (80-120%).",
            "cite_spans": [
                {
                    "start": 589,
                    "end": 593,
                    "text": "[41,",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 594,
                    "end": 597,
                    "text": "42]",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 794,
                    "end": 798,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 833,
                    "end": 837,
                    "text": "[43]",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 855,
                    "end": 859,
                    "text": "[44]",
                    "ref_id": "BIBREF43"
                },
                {
                    "start": 1039,
                    "end": 1043,
                    "text": "[45]",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 1240,
                    "end": 1244,
                    "text": "[29]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Augmentation"
        },
        {
            "text": "To identify the COVID-19 using DenseNet-121 architecture-based CNN, a real patient image dataset 2 from a hospital from Sao Paulo, Brazil, was used in this study. Soares, Angelov [34] made this dataset publicly available to encourage further research development to stimulate knowledge further. There are 2482 CT images in total, while 1252 CT images were COVID-19 positive, and 1230 CT images were non-infected by COVID-19 but presented other pulmonary diseases. The image classes were labeled into two types: COVID and non-COVID. Figure 2 represents a few instances of CT images for patients infected and noninfected by COVID-19 that compose the dataset.",
            "cite_spans": [
                {
                    "start": 179,
                    "end": 183,
                    "text": "[34]",
                    "ref_id": "BIBREF33"
                }
            ],
            "ref_spans": [
                {
                    "start": 532,
                    "end": 540,
                    "text": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Data"
        },
        {
            "text": "The objective of the image pre-processing stage is to smother unwanted twists present in the picture, resize and normalize the image for further processing. There is numerous image pre-processing technique found in the previous literature based on the requirement of model building. Among them, image resizing, image normalization, and covert level to categorical are generally used techniques. In this study, images were resized to ensuring the same size and the same pixel using the \"Pillow 2.7+ + \" 3 python package. This study considers 64 \u00d7 64 pixel values for images. Besides, image normalization is how we adjust the pixel intensity to make the picture increasingly natural. Typically, most of the image pixels integrate values between 0 and 255. But, due to network architecture, it is better to perform all values between 0 and 1, which will be a good fit for the model building. This technique reduces the computational complexity during training the model. However, using Eq. (3), images were normalized where X min and X max refer to the minimum and maximum pixel values.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Pre-processing"
        },
        {
            "text": "The proposed COVID-19 classification model was implemented using Python 3.7 software 4 with related packages. Intel(R) Core(TM) i5-8250U CPU @ 1.60 GHz processor with 16 GB primary memory with 4-GB NVIDIA GeForce 940MX Graphics and 64-bit windows operating systems was used. COVID-19 patients' identification aims to determine if a patient is COVID-19 infected or not. Before model building, data were split into three parts: training (70%), validation (10%), and testing (20%). The model history is presented in Table 1 , which was trained with 50 epochs. The DenseNet-121 code of COVID-19 detection is available at https:// github. com/ shawo n100/ Covid-19-Disea se-Diagn osis. The applied mechanism for predicting COVID-19 is proposed in Fig. 3 . The outcomes of samples of each category correctly and incorrectly classified can be summarized as a confusion matrix, shown in Table 2 . We can determine the accuracy based on the confusion matrix (Eq. 4). The classification model's performance was calculated using four performance measurements: precision, recall, F1-measure, and G-Mean. Accuracy is the percentage of all instances that are correctly predicted. Nonetheless, accuracy cannot differentiate between the numbers of correctly classified samples of each class, particularly for the positive class in classification problems. A very reliable classifier may have misclassified the positive classes as negative. Occasionally, accuracy is, therefore, not enough to evaluate model performance in classification problems.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 513,
                    "end": 520,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                },
                {
                    "start": 742,
                    "end": 748,
                    "text": "Fig. 3",
                    "ref_id": null
                },
                {
                    "start": 879,
                    "end": 886,
                    "text": "Table 2",
                    "ref_id": "TABREF1"
                }
            ],
            "section": "Experimental Setup, Applied Mechanism, and Performance Measurement"
        },
        {
            "text": "(4) Accuracy = TP + TN TP + TN + FP + FN . Moreover, we implemented two metrics: F-measure, and G-mean, along with accuracy, which is widely used for classification problems, are as follows.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup, Applied Mechanism, and Performance Measurement"
        },
        {
            "text": "F-measure is the weighted average of precision and recall. The percentage of correct predictions for the positive class and recall reflects how much a classifier can recognize positive examples. G-Mean aims to evaluate the two-class recall balance. The G-Mean value will be lower if the model is highly biased towards one class since this approach has become widely used in the classification problem. Thus, we used F-measure and G-Mean to assess the model's performance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experimental Setup, Applied Mechanism, and Performance Measurement"
        },
        {
            "text": "The DenseNet-121-based CNN model was trained to classify the CT images for 50 epochs. Each pre-trained model was trained on grayscale images. The model accuracy and loss graph of DenseNet CNN are shown in Fig. 4a and in b.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 205,
                    "end": 212,
                    "text": "Fig. 4a",
                    "ref_id": null
                }
            ],
            "section": "Results and Discussion"
        },
        {
            "text": "The performance of DenseNet-121 was evaluated for grayscale test images. Table 3 shows the overall accuracy of the test data. From Fig. 5 , it is identified that the DenseNet-121 model misclassified only 23 COVID-19 images out of 1252 images and only 15 non-COVID-19 images out of 1230 images. The precision, recall, f1-score, and G-Mean values of DenseNet-121 using the grayscale test dataset are presented in Table 3 for detailed performance analysis. However, Fig. 6a and b represents the example of image prediction for both the COVID-19 and non-COVID-19 perspectives.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 73,
                    "end": 80,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 126,
                    "end": 137,
                    "text": "From Fig. 5",
                    "ref_id": null
                },
                {
                    "start": 411,
                    "end": 418,
                    "text": "Table 3",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 463,
                    "end": 476,
                    "text": "Fig. 6a and b",
                    "ref_id": null
                }
            ],
            "section": "Results and Discussion"
        },
        {
            "text": "There are a few critical studies that used the COVID-19 image classification. Some of the studies used X-ray images, and some used CT images with different accuracy rates (Fig. 6 ). False position (FS) True negative (TN) The overwhelming majority of existing approaches used a small dataset, while a relatively large dataset was used for the applied DenseNet-121 model. There have been several images and strategies for validation by the different state-of-the-art approaches. The used sample size and validation approach used by the different authors is indicated in Table 4 . Table 4 illustrates that a significant number of models were trained and tested iterations and found to classify COVID-19 incidents successfully. For multi-class classification, some models obtained up to 95%+ accuracy [21, 46] , although they are more complicated and computationally costly. Because of the variation in data sets, a fair comparison of performance assessment results and validation methods is not feasible. Nevertheless, it is worth mentioning that the applied technique proved its effectiveness in such a relatively large dataset of 2482 COVID-19 and nonCovid-19 images. The other approaches use slightly fewer COVID-19 images. The method by Ouchicha, Ammor [21] and Narayan Das, Kumar [46] achieved 97.2% and 97.4% overall testing accuracy in an unbalanced dataset where only 219 and 127 COVID-19 images were used for model building. Simultaneously, Pathak, Shukla [36] and Shaban, Rabie [37] used CT images and achieved 93% accuracy applying a small COVID-19 images dataset. Some other studies [18-20, 22, 38, 39, 47] introduced different approaches for early detection of COVID-19 using X-ray and CT images indicating a lower than or around 90% accuracy rate. In this study, a DenseNet-121 architecture-based CNN was used to efficiently detect COVID-19 using a total number of 2482 images (1252 COVID-19 and 1230 non-COVID-19) to develop our model. The DenseNet-121 has yielded 92% total accuracy with 95% sensitivity (recall), 84% precision, 89% F1-score and 89% G-Mean. Compared to other studies in literature, DenseNet-121-based CNN obtained superior results. This study used data augmentation to obtain better outcomes than those previously completed studies, which used the same dataset. For example, GoogLeNet provides 80.56% accuracy [48] . Another strengthens of applying DenseNet-121 is, it can identify COVID-19 instances with an accuracy of 92% and low computational cost and more reliable than the conventional RT-PCR testing method.",
            "cite_spans": [
                {
                    "start": 797,
                    "end": 801,
                    "text": "[21,",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 802,
                    "end": 805,
                    "text": "46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1254,
                    "end": 1258,
                    "text": "[21]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1282,
                    "end": 1286,
                    "text": "[46]",
                    "ref_id": "BIBREF45"
                },
                {
                    "start": 1462,
                    "end": 1466,
                    "text": "[36]",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 1485,
                    "end": 1489,
                    "text": "[37]",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 1592,
                    "end": 1615,
                    "text": "[18-20, 22, 38, 39, 47]",
                    "ref_id": null
                },
                {
                    "start": 2340,
                    "end": 2344,
                    "text": "[48]",
                    "ref_id": "BIBREF47"
                }
            ],
            "ref_spans": [
                {
                    "start": 171,
                    "end": 178,
                    "text": "(Fig. 6",
                    "ref_id": null
                },
                {
                    "start": 568,
                    "end": 575,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 578,
                    "end": 585,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Results and Discussion"
        },
        {
            "text": "For the COVID-19 diagnostic test, the applied model could be used with CT images. CT images are better suited for patients in critical conditions due to their readily available and efficient criteria. The model is capable of instantly identifying COVID-19. Therefore, a deep learning model with CT imagery is recommended because it is a more robust training mechanism. Finally, deep learning techniques utilizing CT images are not only capable of classifying and segmenting images, but it may also be utilized as a strategy to help physicians battling the emerging widespread illness by allowing doctors to anticipate the treatment result.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fig. 4 Accuracy and loss curve"
        },
        {
            "text": "Finally, a few main advantages of this study are outlined following:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fig. 4 Accuracy and loss curve"
        },
        {
            "text": "I. CT image classification provides outperform performance for COVID-19 detection rather than other images like X-ray or Chest images. Additionally, the DenseNet-121 model has better classification accuracy than other studies. II. There is no hand-made extraction technique needed for the applied architecture. III. To conclude, our study showed that a deep learning approach could be applied to help doctors and/or healthcare engineers diagnose patients with COVID-19 and recognize lesions from CT images automatically.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fig. 4 Accuracy and loss curve"
        },
        {
            "text": "The automated image classification of CT images by computer-aided systems is of great importance in medical image analysis. Microscopic analysis of CT images is challenging and time-consuming. This study identified COVID-19 patients using CT image classification based on the deep learning technique that demonstrated outperformed accuracy. The overall accuracy is 92%, and recall is 95%. The DenseNet-121 model performs low computational cost with an average of 195.35 s. We applied DenseNet-121 deep learning architecture for image classification. Several classification models were, for example, to validate our claim. Theoretically, the applied methodology contributed to the current emerging COVID-19 literature providing an unrevealed best alternative identification technique using a DenseNet-121 CNN with a relatively large dataset in the training phase of DenseNet-121 model. In addition, no handmade data extraction technique is required for the applied architecture because of the use of the data augmentation strategy. Practically, this method can be applied to the clinical practice for accurate COVID-19 detection. Thus, increasing reliability represented through the proposed computational method for testing could add value to capture a real picture of the infection rate, which strongly correlates to the number of daily infected cases. The applied methodology offered a powerful machine learning-based approach to minimize human professionals' manual judgment errors and provide a quicker way of providing time and resource-saving.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "However, our present investigation still has many shortcomings. First, a further improvement in network architecture and optimization may improve classification accuracy. Second, an unavoidable issue faced by specific areas is the lack of training data during the initial phases of the COVID-19 epidemic. Thus, several hundred images might not be adequate for reliable prediction. Another drawback of this study is not presenting Grad Cam visualizations of the applied DenseNet-121 model that might enhance the readability. Furthermore, DenseNet can be justified for further research development by applying other types of architecture, i.e., DenseNet-161, DenseNet-169, and DenseNet-201. However, other deep learning methods or modified deep learning methods could be implemented and tested for further development and assessment for more accurate identification of COVID-19 patients using CT images. Once again, since new COVID-19 CT image datasets are being published on a timely basis, updated COVID-19 imaging datasets may be examined to enhance the efficacy of the DenseNet-121 technique.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Deaths in healthcare workers due to COVID-19: the need for robust data and analysis",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Kursumovic",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lennane",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Cook",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Anaesthesia",
            "volume": "75",
            "issn": "8",
            "pages": "989--92",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Predictors of coronavirus disease 19 (COVID-19) pneumonitis outcome based on computed tomography (CT) imaging obtained prior to hospitalization: a retrospective study",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mirza-Aghazadeh-Attari",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Emerg Radiol",
            "volume": "27",
            "issn": "6",
            "pages": "653--61",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Coronavirus disease 2019 (COVID-19) pneumonia incidentally detected on coronary CT angiogram: a do-notmiss diagnosis",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Behzad",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Emerg Radiol",
            "volume": "27",
            "issn": "6",
            "pages": "721--727",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "A methodological approach for predicting COVID-19 epidemic using EEMD-ANN hybrid model",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Hasan",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Internet Things",
            "volume": "11",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "COVID-19 infection: origin, transmission, and characteristics of human coronaviruses",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Shereen",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "J Adv Res",
            "volume": "24",
            "issn": "",
            "pages": "91--99",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Positive rate of RT-PCR detection of SARS-CoV-2 infection in 4880 cases from one hospital in",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Clin Chim Acta",
            "volume": "505",
            "issn": "",
            "pages": "172--177",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Auto-diagnosis of COVID-19 using lung CT Images with semi-supervised shallow learning network",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Konar",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "IEEE Access",
            "volume": "9",
            "issn": "",
            "pages": "28716--28744",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Classification of COVID-19 patients from chest CT images using multi-objective differential evolution-based convolutional neural networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Eur J Clin Microbiol Infect Dis",
            "volume": "39",
            "issn": "7",
            "pages": "1379--89",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Correlation of chest CT and RT-PCR testing in Coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "296",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ahuja",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Appl Intell",
            "volume": "51",
            "issn": "1",
            "pages": "571--85",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Charting the challenges behind the testing of COVID-19 in developing countries: Nepal as a case study",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Giri",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "R"
                    ],
                    "last": "Rana",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Biosaf Health",
            "volume": "2",
            "issn": "2",
            "pages": "53--59",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Harmony-search and otsu based system for coronavirus disease (COVID-19) detection using lung CT scan images",
            "authors": [
                {
                    "first": "V",
                    "middle": [],
                    "last": "Rajinikanth",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Dey",
                    "suffix": ""
                },
                {
                    "first": "Anj",
                    "middle": [],
                    "last": "Raj",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "E"
                    ],
                    "last": "Hassanien",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Santosh",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Raja",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:2004.03431"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Sensitivity of Chest CT for COVID-19: Comparison to RT-PCR",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Fang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Radiology",
            "volume": "296",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Imagenet classification with deep convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Krizhevsky",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Sutskever",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "E"
                    ],
                    "last": "Hinton",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Advances in neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "A biological image classification method based on improved CNN",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Qin",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Ecol Inform",
            "volume": "58",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "DenseNet for anatomical brain segmentation",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "D"
                    ],
                    "last": "Gottapu",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "H"
                    ],
                    "last": "Dagli",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proced Comput Sci",
            "volume": "140",
            "issn": "",
            "pages": "179--85",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Computer-aided detection of COVID-19 from X-ray images using multi-CNN and Bayesnet classifier",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Abraham",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Nair",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Biocybern Biomed Eng",
            "volume": "40",
            "issn": "4",
            "pages": "1436--1481",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "CoroNet: a deep neural network for detection and diagnosis of COVID-19 from chest x-ray images",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "I"
                    ],
                    "last": "Khan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Shah",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "M"
                    ],
                    "last": "Bhat",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput Methods Progr Biomed",
            "volume": "196",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Deep learning-based detection for COVID-19 from chest CT using weak label",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "medRxiv",
            "volume": "395",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "A deep learning and grad-CAM based color visualization approach for fast detection of COVID-19 cases using chest X-ray and CT-Scan images",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Panwar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "140",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "CVDNet: a novel deep learning architecture for detection of coronavirus (Covid-19) from chest x-ray images",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Ouchicha",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Ammor",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Meknassi",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "140",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Automated detection of COVID-19 cases using deep neural networks with X-ray images",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ozturk",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput Biol Medi",
            "volume": "121",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Imagenet: a large-scale hierarchical image database",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Deng",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Densely connected convolutional networks",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "ChronoNet: a deep recurrent neural network for abnormal EEG identification",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Roy",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Kiral-Kornek",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Harrer",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Conference on artificial intelligence in medicine in Europe",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Interstitial lung disease classification using improved DenseNet",
            "authors": [
                {
                    "first": "W",
                    "middle": [],
                    "last": "Guo",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Multimed Tools Appl",
            "volume": "78",
            "issn": "21",
            "pages": "30615--30641",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Classification of colorectal cancer histology images using image reconstruction and modified DenseNet",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sarkar",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Hazra",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "International conference on computational intelligence in communications and business analytics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Handling imbalanced medical image data: a deeplearning-based one-class classification approach",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Artif Intell Med",
            "volume": "108",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Multipath-DenseNet: a supervised ensemble architecture of densely connected convolutional networks",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Lodhi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Inf Sci",
            "volume": "482",
            "issn": "",
            "pages": "63--72",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Classification of skin lesions by combining multilevel learnings in a DenseNet architecture",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Carcagn\u00ec",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Image analysis and processing-ICIAP 2019",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "M"
                    ],
                    "last": "Pereira",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Comput Methods Progr Biomed",
            "volume": "194",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Application of deep learning for fast detection of COVID-19 in X-Rays using nCOVnet",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Panwar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Chaos Solitons Fractals",
            "volume": "138",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "A weakly-supervised Framework for COVID-19 classification and lesion localization from chest CT",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "IEEE Trans Med Imaging",
            "volume": "39",
            "issn": "",
            "pages": "2615--2640",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "SARS-CoV-2 CT-scan dataset: a large dataset of real patients CT scans for SARS-CoV-2 identification",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Soares",
                    "suffix": ""
                }
            ],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1101/2020.04.24.20078584"
                ]
            }
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "COVIDiagnosis-Net: deep Bayes-SqueezeNet based diagnosis of the coronavirus disease 2019 (COVID-19) from X-ray images",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Ucar",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Korkmaz",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Med Hypotheses",
            "volume": "140",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF35": {
            "ref_id": "b35",
            "title": "Deep transfer learning based classification model for COVID-19 disease",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Pathak",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.irbm.2020.05.003"
                ]
            }
        },
        "BIBREF36": {
            "ref_id": "b36",
            "title": "A new COVID-19 Patients Detection Strategy (CPDS) based on hybrid feature selection and enhanced KNN classifier. Knowl-Based Systems",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "M"
                    ],
                    "last": "Shaban",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "205",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF37": {
            "ref_id": "b37",
            "title": "A deep learning system to screen novel Coronavirus Disease",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "pneumonia. Engineering",
            "volume": "6",
            "issn": "10",
            "pages": "1122--1129",
            "other_ids": {
                "DOI": [
                    "10.1016/j.eng.2020.04.010"
                ]
            }
        },
        "BIBREF38": {
            "ref_id": "b38",
            "title": "A deep learning algorithm using CT images to screen for Corona virus disease (COVID-19). A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19)",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "Ma",
                    "middle": [
                        "J"
                    ],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Eur Radiol",
            "volume": "31",
            "issn": "",
            "pages": "6096--6104",
            "other_ids": {
                "DOI": [
                    "10.1007/s00330-021-07715-1"
                ]
            }
        },
        "BIBREF39": {
            "ref_id": "b39",
            "title": "Coronavirus disease (COVID-19) detection using X-ray images and enhanced DenseNet",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Albahli",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Ayub",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Shiraz",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Appl Soft Comput",
            "volume": "110",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF40": {
            "ref_id": "b40",
            "title": "A survey on image data augmentation for deep learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shorten",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J Big Data",
            "volume": "6",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF41": {
            "ref_id": "b41",
            "title": "The effectiveness of data augmentation in image classification using deep learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Perez",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Convolutional Neural Netw Vis Recognit",
            "volume": "11",
            "issn": "",
            "pages": "1--8",
            "other_ids": {}
        },
        "BIBREF42": {
            "ref_id": "b42",
            "title": "Transfer learning-based ensemble support vector machine model for automated COVID-19 detection using lung computerized tomography scan data",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Med Biol Eng Comput",
            "volume": "59",
            "issn": "4",
            "pages": "825--864",
            "other_ids": {}
        },
        "BIBREF43": {
            "ref_id": "b43",
            "title": "COVID-19 detection in CT images with deep learning: a voting-based scheme and cross-datasets analysis",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Silva",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Inform Med Unlocked",
            "volume": "20",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF44": {
            "ref_id": "b44",
            "title": "Efficient deep neural networks for classification of COVID-19 based on CT images: Virtualization via software defined radio",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Fouladi",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "Comput Commun",
            "volume": "176",
            "issn": "",
            "pages": "234--282",
            "other_ids": {}
        },
        "BIBREF45": {
            "ref_id": "b45",
            "title": "Automated deep transfer learning-based approach for detection of COVID-19 infection in chest X-rays",
            "authors": [
                {
                    "first": "Narayan",
                    "middle": [],
                    "last": "Das",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1016/j.irbm.2020.07.001"
                ]
            }
        },
        "BIBREF46": {
            "ref_id": "b46",
            "title": "Deep learning enables accurate diagnosis of novel coronavirus (COVID-19) with CT images",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "30653",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1109/TCBB.2021.3065361"
                ]
            }
        },
        "BIBREF47": {
            "ref_id": "b47",
            "title": "Within the lack of chest COVID-19 X-ray dataset: a novel detection model based on GAN and deep transfer learning",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Loey",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Smarandache",
                    "suffix": ""
                },
                {
                    "first": "Nem",
                    "middle": [],
                    "last": "Khalifa",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Symmetry",
            "volume": "12",
            "issn": "4",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "DenseNet architechture (Source:[24])",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Example images of COVID-19 and non-COVID-19",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Confusion Prediction of COVID-19 infected and non-Infected image",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Model summary of CNN",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Confusion matrix for COVID-19 prediction",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Result comparison with previous studies",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Acknowledgements This research received no specific grant from any funding agency in the public, commercial, or non-profit organization.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "acknowledgement"
        },
        {
            "text": "There is no potential conflict of interest declared by all authors.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conflict of interest"
        }
    ]
}