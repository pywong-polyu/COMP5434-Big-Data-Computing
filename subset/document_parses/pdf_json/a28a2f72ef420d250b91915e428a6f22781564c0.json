{"paper_id": "a28a2f72ef420d250b91915e428a6f22781564c0", "metadata": {"title": "Consequences of Higher Order Asymptotics for the MSE of M-estimators on Neighborhoods", "authors": [{"first": "Peter", "middle": [], "last": "Ruckdeschel", "suffix": "", "affiliation": {"laboratory": "", "institution": "University of Kaiserslautern", "location": {"addrLine": "Fraunhofer-Platz 1", "postBox": "P.O.Box 3049", "postCode": "67663, 67653", "settlement": "Kaiserslautern, Kaiserslautern", "country": "Germany, Germany"}}, "email": ""}]}, "abstract": [{"text": "In Ruckdeschel (2010a), we derive an asymptotic expansion of the maximal mean squared error (MSE) of location M-estimators on suitably thinned out, shrinking gross error neighborhoods. In this paper, we compile several consequences of this result: With the same techniques as used for the MSE, we determine higher order expressions for the risk based on over-/undershooting probabilities as in Huber (1968) and Rieder (1980), respectively. For the MSE problem, we tackle the problem of second order robust optimality: In the symmetric case, we find the second order optimal scores again of Hampel form, but to an O(n \u22121/2 )-smaller clipping height c than in first order asymptotics. This smaller c improves MSE only by O(n \u22121 ). For the case of unknown contamination radius we generalize the minimax inefficiency introduced in Rieder et al. (2008) to our second order setup. Among all risk maximizing contaminations we determine a \"most innocent\" one. This way we quantify the \"limits of detectability\"in Huber (1997)'s definition for the purposes of robustness.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "In Theorem 3.1, we take up the over-and undershooting probabilities used as risk in Huber (1968) to determine a finite sample minimax estimator of location. By means of a s-o expansion, we refine the corresponding f-o translation by Rieder (1980) , providing a closer link to finite sample optimality.", "cite_spans": [{"start": 84, "end": 96, "text": "Huber (1968)", "ref_id": "BIBREF4"}, {"start": 233, "end": 246, "text": "Rieder (1980)", "ref_id": null}], "ref_spans": [], "section": ""}, {"text": "The closed form expressions in (1.1), in particular under certain symmetry assumptions, allows us to tackle corresponding (uniform) higher order optimality problems, so that we may check whether Pfanzagl (1979) 's catchword \"First order efficiency implies second order efficiency\" survives when passing to neighborhoods around the ideal model, which-at least under symmetry-indeed (partially) holds.", "cite_spans": [{"start": 195, "end": 210, "text": "Pfanzagl (1979)", "ref_id": "BIBREF7"}], "ref_spans": [], "section": ""}, {"text": "In this setting, we see that Huber-type location M-estimators remain optimal in second order sense, and we even may determine the s-o-o clipping height c 1 = c 1 (r, n) which in fact is slightly lower (O(n \u22121/2 )) than the f-o-o one. So in fact we only retain the optimal class, not the actual optimal estimator from f-o optimality.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "For situations where the radius is (partially) unknown, the concept of a minimax radius has been introduced and determined in Rieder et al. (2008) : A radius r 0 is determined such that the (f-o) maximal inefficiency\u03c1(r ) (as defined in (5.1)) is minimized in r = r 0 . We translate this to the s-o setup; the s-o results in the Gaussian location model show that neither c 1 (r 1 , \u00b7), nor s-o minimax radius r 1 (\u00b7) vary much in n and that for all n, s-o minimax inefficiency is always smaller than the corresponding f-o one.", "cite_spans": [{"start": 126, "end": 146, "text": "Rieder et al. (2008)", "ref_id": "BIBREF9"}], "ref_spans": [], "section": ""}, {"text": "Asymptotics also helps to understand which contaminations are (already) dangerous: We determine the cniper contamination as a most innocent appearing least favorable contamination, which is shown to form a saddlepoint together with the f-o (s-o) optimal M-estimator. It appears to be innocent, as it produces only \"outliers\" which are hardest to detect in some sense specified in this section.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Organization of the paper We start with the setup of one dimensional location and recall the main theorem of Ruckdeschel (2010a) in section 2. This result is generalized to a over-/undershooting probability loss in section 3.", "cite_spans": [{"start": 109, "end": 128, "text": "Ruckdeschel (2010a)", "ref_id": "BIBREF10"}], "ref_spans": [], "section": ""}, {"text": "Consequences of Theorem 2.1 as to higher order robust optimality are discussed in section 4. As a (partial) explanation for the good, respectively excellent behavior of f-o-o, s-o-o and t-o-o procedures as to numerically exact finite maximal MSE, we present an argument based on a functional implicit function theorem in section 4.2. For decisions upon the procedure to take, only relative risk is relevant which is discussed in some detail in subsection 4.3. Section 5 then considers further supplementary results to Theorem 2.1: a s-o variant of the minimax radius and s-o cniper contaminations. The proofs to the theorems and propositions of this paper are collected in section A.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "We consider estimation of parameter \u03b8 in a one-dimensional location model, i.e.", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "for some ideal distribution F with finite Fisher-Information of location I(F), i.e.", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "We also assume that \u039b f is increasing. By translation equivariance, we may restrict ourselves to \u03b8 0 = 0 which will be suppressed in the notation. The set of influence curves (IC's) \u03a8 for the estimation of \u03b8 is defined as Rieder (1994) \u03a8", "cite_spans": [{"start": 222, "end": 235, "text": "Rieder (1994)", "ref_id": null}], "ref_spans": [], "section": "One-dimensional location"}, {"text": "where both expectations are evaluated under F. As class of estimators we consider asymptotically linear estimators (ALE's), i.e. estimators S n = S n (X 1 , . . . , X n ) with the property \u221a n S n = 1 \u221a n n i=1 \u03c8(X i ) + o F n (n 0 ) (2.4)", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "We consider maximal mean squared error (MSE) on shrinking neighborhoods of this ideal model, defined as the set Q n (r) of distributions L real \u03b8 (X 1 , . . . , X n ) = Q n = n i=1", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "[(1 \u2212 r n \u221a n )F + r n \u221a n P di n,i ] (2.5) with r n = min(r, \u221a n), r > 0 the contamination radius and P di n,i \u2208 M 1 (B) arbitrary, uncontrollable contaminating distributions. As usual, we interpret Q n as the distribution of the vector (X i ) i\u2264n with components", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "Suppressing the dependency upon \u03b8 as usual, in Rieder (1994) , the first order expansion of maximal MSE of an ALE is derived as R(S n , r) = r 2 sup |\u03c8| 2 + E id |\u03c8| 2 (2.7)", "cite_spans": [{"start": 47, "end": 60, "text": "Rieder (1994)", "ref_id": null}], "ref_spans": [], "section": "One-dimensional location"}, {"text": "The (first-order) MSE-optimal IC \u03b7 b 0 in a smooth p-dimensional parametric model with L 2 -derivative \u039b by Theorem 5.5.7 (ibid.) has to be of Hampel form", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "In our location context, for Lagrange multipliers z and A such that \u03b7 b 0 = \u03b7 c 0 \u2208 \u03a8 , we get that", "cite_spans": [], "ref_spans": [], "section": "One-dimensional location"}, {"text": "In Ruckdeschel (2010a) we obtain corresponding higher order expansions of the maximal MSE if we thin out the neighborhood system to the setQ n (r; \u03b5 0 ) of conditional distributions", "cite_spans": [{"start": 3, "end": 22, "text": "Ruckdeschel (2010a)", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "where \u03b5 0 = 1/(2 + \u03b4 0 ) is the functional (Huber (1981, (2.39) ,(2.40))) and the finite sample (\u03b5-contamination) breakdown point (Donoho and Huber (1983, section 2. 2)) of the corresponding M-estimator and \u03b4 0 is defined by", "cite_spans": [{"start": 43, "end": 63, "text": "(Huber (1981, (2.39)", "ref_id": null}, {"start": 130, "end": 165, "text": "(Donoho and Huber (1983, section 2.", "ref_id": null}], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "For the result we use the following assumptions and notation: To scores function \u03c8 : R \u2192 R let \u03c8 t (x) := \u03c8(x \u2212 t) and define the following functions L(t) :", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "Lety n and\u0177 n sequences in R such that for some \u03b3 > 1, \u03c8(y n ) = inf \u03c8 + o( 1 n \u03b3 ), \u03c8(\u0177 n ) = sup \u03c8 + o( 1 n \u03b3 ). For H \u2208 M 1 (B n ) and an ordered set of indices I = (1 \u2264 i 1 < . . . < i k \u2264 n) denote H I the marginal of H with respect to I. Consider three sequences c n , d n , and \u03ba n in R, in (0, \u221e), and in {1, . . . , n}, respectively. We say that the sequence (H (n) ) \u2282 M 1 (B n ) is \u03ba n -concentrated left [right] of c n up to o(d n ), if for each sequence of ordered sets I n of cardinality i n \u2264 \u03ba n 1 \u2212 H (n)", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": ". For the theorem we make the following assumptions:", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "For some \u03b4 \u2208 (0, 1], L, V, \u03c1, and \u03ba as defined above allow the expansions", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "(2.14)", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "(Pd) There are some T > 0 and \u03b7 > 0 such that", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "With these preparations, we have the following theorem (Ruckdeschel (2010a, Thm. 3 .5))", "cite_spans": [{"start": 55, "end": 82, "text": "(Ruckdeschel (2010a, Thm. 3", "ref_id": null}], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "Theorem 2.1 In our one-dim. location model assume (bmi) to (C) (a) the maximal MSE of the M-estimator S n to scores-function \u03c8 expands to", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "and we are in the \u2212 [+]-case depending on whether (2.20) or (2.21) below applies.", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "(b) let P di n := n i=1 P di n,i be contaminating measures for (2.5). Then Q n with P di n as contaminating measures generates maximal risk in (2.17) if for k 1 > 1 and k 2 > 2 \u2228 ( 3 2 + 3 2\u03b4 ) with \u03b4 from (Vb) and K 1 (n) = k 1 r \u221a n either (P di n ) is K 1 (n)-concentrated left ofy n \u2212 b k 2 log(n)/n up to o(n \u22121 ) (2.20)", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "or (P di n ) is K 1 (n)-concentrated right of\u0177 n + b k 2 log(n)/n up to o(n \u22121 ) ", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "If sup \u03c8 = \u2212 inf \u03c8 and there is \"=\" in (2.22), (2.20) and (2.21) generate the same risk up to order o(n \u22121 ).", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "Special cases Let Q 0 n be any distribution inQ n attaining maximal risk in Theorem 2.1. Under symmetry or more specifically if", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "we obtain as maximal risk in (2.17) 24) while under r = 0 (with or without (2.23)), we get", "cite_spans": [{"start": 36, "end": 39, "text": "24)", "ref_id": null}], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "respectively, again under (2.23),", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "(2.26)", "cite_spans": [], "ref_spans": [], "section": "Higher Order Expansion"}, {"text": "One easily shows that under similar condition as for Theorem 2.1, we may replace the squared loss function in the MSE by other loss functions growing atmost at a polynomial rate. In this respect, Theorem 2.1 easily extends to uniform convergence of other risks onQ n , e.g. absolute error ( (x) = |x|), L k -error ( (x) = |x| k ) for 1 < k < \u221e, and certain covering probabilities, (x) = I (\u03b1 1 ,\u03b1 2 ) (x) for some \u03b1 1 < \u03b1 2 \u2208 R.", "cite_spans": [], "ref_spans": [], "section": "Other loss functions"}, {"text": "As an illustration, we consider this last type of loss function, more specifically in the form in which it arises in the finite minimax estimation theory as in Huber (1968) and in which it has been extended to an as. . setup by Rieder (1980) : The risk is defined as Fraiman et al. (2001) have taken up a similar setup with conventional confidence intervals to cover bias and variance simultaneously. We work in the setup of Rieder (1980) here and confine ourselves to the higher order terms of order n \u22121/2 , but of course an extension to terms up to order n \u22121 as in Theorem 2.1 is feasible. Due to translation equivariance, it is no restriction to consider the case \u03b8 = 0 only. As in Rieder (1980) , we work with a possibly asymmetric partition of the interval of given length 2a/ \u221a n laid around the estimator: Using the partition", "cite_spans": [{"start": 160, "end": 172, "text": "Huber (1968)", "ref_id": "BIBREF4"}, {"start": 228, "end": 241, "text": "Rieder (1980)", "ref_id": null}, {"start": 267, "end": 288, "text": "Fraiman et al. (2001)", "ref_id": "BIBREF2"}, {"start": 425, "end": 438, "text": "Rieder (1980)", "ref_id": null}, {"start": 687, "end": 700, "text": "Rieder (1980)", "ref_id": null}], "ref_spans": [], "section": "Other loss functions"}, {"text": "we minimize the risk according to Rieder (1980, formulas (2.8 ) and (2.11) in), if wit\u021f b,b, andb from (2.12) and", "cite_spans": [{"start": 34, "end": 61, "text": "Rieder (1980, formulas (2.8", "ref_id": null}], "ref_spans": [], "section": "Other loss functions"}, {"text": "If we now account for terms of order 1 \u221a n we minimize the risk if we use the partition", "cite_spans": [], "ref_spans": [], "section": "Other loss functions"}, {"text": "\u03b4 = \u03b4 n given in the theorem below. To this end, let", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "Then, with \u03a6 and \u03d5 c.d.f. and density of N(0, 1) and using the notation of Theorem 2.1, we have Theorem 3.1 For the location model (2.1) of finite Fisher information (2.2), assume (bmi), (D') and (C'). Then for sample size n, the minimal over-/undershooting probability of an M-estimator S n for scores-function \u03c8 in Q n obtains eventually in n as", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "with Q 0 n; \u2212 resp. Q 0 n; + according to (2.20) resp. (2.21) and", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "and \u03b4 = \u03b4 n according to", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "Remark 3.2 (a) If l 2 =\u1e7d 1 = 0 andb = \u2212b, we obtain the same result as (3.8), if we use the expressions b n := Bias n and v 2 n = Var n for bias and variance from Ruckdeschel (2010a, Prop.6.4), plug them into the as. . risk, which gives \u03a6((rb n \u2212 a)/v n ), and then expand this up to o(n \u22121/2 ).", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "(b) The numerical values obtainable by Theorem 3.1 should be compared to those of Kohl (2005, sections 11.3.3.3 and 11.4.1); admittedly the approach of Theorem 3.1 in this context gives rather poor (too liberal) approximations compared to those in the cited reference (see the R-file Thm31.R available on the web-page to this article); this is plausible though, as Kohl already starts with finitely optimal procedures whereas our approach improves upon asymptotically optimal ones.", "cite_spans": [], "ref_spans": [], "section": "5)"}, {"text": "In this section, we consider the class S 2 of all M-estimators according to (bmi), (D'), and (C') as well as (Pd); correspondingly, we define S 3 with (D), (C) replacing (D'), (C'); we always assume that the class of M-estimators H of ICs of Hampel-type (2.9) forms a subset of S 2 [S 3 ]. In particular we assume f to be log-concave.", "cite_spans": [], "ref_spans": [], "section": "Consequences: Higher Order Optimality and Relative Risk"}, {"text": "Symmetry allows considerable simplifications; for instance, if F is symmetric, i.e. F(B) = F(\u2212B) for all B \u2208 B, in (2.9) always z = 0. But also, much deeper results are possible. Thus for the rest of this subsection, we assume (2.23). Then (2.24) gives the s-o-maximal MSE for any M-estimator in S 2 ; in particular", "cite_spans": [], "ref_spans": [], "section": "Second-order optimality"}, {"text": "Condition (2.23) clearly holds for skew symmetric \u03c8 and symmetric F. For symmetric F, however, for any IC \u03c8, also\u03c8 := \u2212\u03c8(\u2212 \u00b7 ) is an IC and hence so is the skew-symmetrized \u03c8 (s) := 1 2 (\u03c8 +\u03c8), too. But by convexity of the MSE, \u03c8 (s) will be at least as good as \u03c8 as to MSE, hence it is no restriction to only consider skew symmetric ICs, and we fall into the application range of Ruckdeschel and Rieder (2004, Thm. 3 .1), i.e., Theorem 4.1 Assume that maximal as. . risk of an ALE onQ n resp.Q n ( \u00b7 , s 0 ) is representable as G(rb(\u03c8), v 0 (\u03c8)) for some convex real-valued function G(w, s), strictly isotone in both arguments and totally differentiable, bounded away from the minimum for w \u2192 \u221e. Then, on Q n , respectively onQ n , the optimal IC of Hampel-type (2.9) for some clipping height b = Ac determined by", "cite_spans": [{"start": 381, "end": 417, "text": "Ruckdeschel and Rieder (2004, Thm. 3", "ref_id": null}], "ref_spans": [], "section": "Second-order optimality"}, {"text": "In our case, this theorem specializes to ", "cite_spans": [], "ref_spans": [], "section": "Second-order optimality"}, {"text": "That is, (for n large enough) the f-o-o clipping height c 0 always is too optimistic. Assume s-o risk of ICs of Hampel-type (2.9) is smooth enough in c in its minimum c 1 to allow a s-o Taylor expansion, which is an assumption on the remainder o(n \u22121 ) present in (2.17). Then, around c 1 , s-o risk behaves like a parabola. But, as by", "cite_spans": [], "ref_spans": [], "section": "Second-order optimality"}, {"text": "using c 1 instead of c 0 can only improve s-o risk by order O(1/n). This even carries over to risks \"near\" s-o risk:", "cite_spans": [], "ref_spans": [], "section": "Second-order optimality"}, {"text": "The drawback of this proposition is that assumption (4.5) is difficult to check if we have no explicit expression for G n : For given r \u2265 0, let asMSE j=0,1,2 (c)be the f-o, s-o, and t-o maximal MSE of an M-estimator in H, and exMSE(c) the corresponding exact maximal MSE R n ; we would like to apply Proposition 4.3 to F = asMSE 0 , F n = asMSE j=1,2 and G n = exMSE to conclude on the performance of f-o-o, s-oo, t-o-o procedures as to exMSE. As to (4.5), part (ii) is easy to see checking the expressions, giving \u03b2 = 1/2, while for part (i) Theorem 2.1 only says that sup", "cite_spans": [], "ref_spans": [], "section": "Consequences for the exact MSE"}, {"text": ", and probably, under slightly stronger assumptions, O(n \u2212( j+1)/2 ). So presumably-in view of Table 2 ,", "cite_spans": [], "ref_spans": [{"start": 95, "end": 102, "text": "Table 2", "ref_id": "TABREF3"}], "section": "Consequences for the exact MSE"}, {"text": "Remark 4.4 We even conjecture that we may apply an analogue to Proposition 4.3 for functions F, F n , G n : \u03a8 \u2192 R: Let us denote by\u03c8 ( j;n) , the corresponding f-o, s-o, t-o optimal IC and\u03c8 (ex;n) the exactly optimal IC; then, with the usual abuse of notation as to exMSE, we conjecture that 0 \u2264 exMSE(\u03c8 ( j;n) ) \u2212 exMSE(\u03c8 (ex;n) ) = O(n \u2212 j\u22121 ), j = 0, 1, 2 (4.7)", "cite_spans": [], "ref_spans": [], "section": "Consequences for the exact MSE"}, {"text": "An observation in the simulation study was that the relative MSE w.r.t. the MSE of the f-o-o procedure seemed to converge faster than the absolute terms. This is reflected by our formulas as follows:", "cite_spans": [], "ref_spans": [], "section": "Relative risk"}, {"text": "Let asMSE 0 (c) and A ", "cite_spans": [], "ref_spans": [], "section": "Contaminated situation"}, {"text": "So in fact, the observed faster convergence is not reflected by higher order optimality, but as we will see, the difference between relMSE 0 (c, r) and relMSE 1 (c, r) are in fact small. Procedure choice will usually be based on relative risk, so it is interesting to consider the maximal error compared to the s-o approximation one incurs when using the f-o asymptotics instead. In view of subsection 4.1 we will limit ourselves to only considering Hampel-IC's with a clipping height c in the range", "cite_spans": [], "ref_spans": [], "section": "Contaminated situation"}, {"text": "for \u03c1 \u2265 0. This leads us to", "cite_spans": [], "ref_spans": [], "section": "Contaminated situation"}, {"text": "or even maximizing over the radius", "cite_spans": [], "ref_spans": [], "section": "Contaminated situation"}, {"text": "In the Gaussian case, the function r \u2192 \u2206relMSE(r; \u03c1) is plotted for \u03c1 = 0.1 in Figure 1 , and for \u2206(0.1), we get a value of 0.065, which for an actual sample size n has to be divided by \u221a n-an astonishingly good approximation! So down to very moderate sample sizes we can base our decision which clipping height to take to achieve \"nearly\" the optimal MSE onQ n on f-o asymptotics only. A similar consideration is of course possible for the ideal situation.", "cite_spans": [], "ref_spans": [{"start": 79, "end": 87, "text": "Figure 1", "ref_id": "FIGREF1"}], "section": "Contaminated situation"}, {"text": "As an example we take F = N(0, 1) and calculate the terms c 1 , asMSE 1 := asMSE 0 + r \u221a n A 1 (4.13) and relMSE 1 for the radii and sample sizes of the simulation study where for the optimization for c 1 we use the function optimize in R 2.11.0 (compare R Development Core Team (2010)). The results are tabulated in Table 1 . Correspondingly, we also determine the t-o terms c 2 , asMSE 2 := asMSE 1 + A 2 /n (4.14) and in Figure 2 , we plot the graphs of the five functions r \u2192 asMSE 0 (\u03b7 c 0 (r) , r), r \u2192 asMSE 1 (\u03b7 c 0 (r) , r, n), r \u2192 asMSE 2 (\u03b7 c 0 (r) , r, n) r \u2192 asMSE 1 (\u03b7 c 1 (r,n) , r, n), r \u2192 asMSE 2 (\u03b7 c 2 (r,n) , r, n)", "cite_spans": [], "ref_spans": [{"start": 317, "end": 324, "text": "Table 1", "ref_id": "TABREF2"}, {"start": 424, "end": 432, "text": "Figure 2", "ref_id": "FIGREF0"}], "section": "Illustration"}, {"text": "for F = N(0, 1) and for n = 30. In fact, the choice of the clipping height-c 0 (r), c 1 (r, n), c 2 (r, n)-does not entail any visible changes while the absolute value of f-o, s-o, and t-o MSE clearly differ.", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "In the same situation, the three functions r \u2192 c 0 (r), r \u2192 c 1 (r, n), r \u2192 c 2 (r, n) are plotted in Figure 3 ; while there are visible differences between c 0 (r) and c i (r, n), i = 1, 2, c 1 (r, n) and c 2 (r, n) visually coincide. Fraiman et al. (2001) work in a similar setup, i.e. the one-dimensional location problem where the center distribution is F 0 = N(0, \u03c3 2 ) and an M-estimator S n to skew symmetric scores \u03c8 is searched which minimizes the maximal risk on a neighborhood about F 0 . Contrary to our approach, the authors work with convex contamination neighborhoods V = V(F, \u03b5) to a fixed radius \u03b5.", "cite_spans": [{"start": 236, "end": 257, "text": "Fraiman et al. (2001)", "ref_id": "BIBREF2"}], "ref_spans": [{"start": 102, "end": 110, "text": "Figure 3", "ref_id": null}], "section": "Illustration"}, {"text": "There has been some discussion which approach-fixed or shrinking radius-is more appropriate, but for fixed sample size n, of course we may translate the fixed radius \u03b5 into our radius r/ \u221a n and then compare the approximation quality of both approaches. Fraiman et al. (2001) propose to use risks which are constructed by means of a positive function g : R \u00d7 R + \u2192 R + of as. . bias B = B(F, \u03c8) and as. . variance v 2 = V 2 (F, \u03c8).", "cite_spans": [{"start": 254, "end": 275, "text": "Fraiman et al. (2001)", "ref_id": "BIBREF2"}], "ref_spans": [], "section": "Illustration"}, {"text": "Here, B is defined as zero of \u03b2 \u2192 (1 \u2212 \u03b5) \u03c8 \u03b2 dF + \u03b5b, and v 2 :", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "Function g is assumed lower semicontinuous and symmetric in the first argument as well as isotone in each argument. The risk of an M-estimator to IC \u03c8 is taken as the function", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "A MSE-type risk then is given by g(u, v) = u 2 + v. It is not quite MSE, as it employs the as. . terms B and v, so their results may differ from ours. The crucial point is that to solve their optimization problem, the authors have to assume that besides bias, also variance is maximized (for their optimal\u03c8) if we contaminate with a Dirac measure in \u221e. According to this assumption, if we introduce G 0 := (1 \u2212 \u03b5)F 0 + \u03b5 I {\u221e} , we have to find \u03c8 minimizing", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "Differently to the Hampel-type IC's the solutions to this problem are of form", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "but the \"MSE\"-optimal solutions are numerically quite close to corresponding Hampel-ICs \u03c8 H , for which the authors in turn show that always L g (\u03c8 H ) = l g (\u03c8 H ).", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "For an implementation of this optimization see the R-file FYZ.R available on the webpage.", "cite_spans": [], "ref_spans": [], "section": "Illustration"}, {"text": "As a sort of benchmark for our results, we reproduce a comparison to be found in Ruckdeschel and Kohl (2010) -albeit in some more detail than in the cited reference: For a set of values for n and r, we determine the \"MSE\"-optimal\u03c8 and a corresponding Hampel IC\u03c8 H which is then compared to the f-o-o and s-o-o IC derived in this paper. Within the class of Hampel-IC's, numerically, we also determine the t-o-o and the \"exactly\" optimal clipping-c, c 2 and c ex respectively. We compare the resulting IC's as to their clipping-height and the corresponding (numerically exact) value of R n (S n , r), denoted by MSE n ; the latter comparison is done by the terms relMSE ex n (c \u00b7 ), calculated as", "cite_spans": [{"start": 81, "end": 108, "text": "Ruckdeschel and Kohl (2010)", "ref_id": "BIBREF12"}], "ref_spans": [], "section": "A comparison"}, {"text": "The results are displayed in Table 2 . Also compare the function allMSEs in the R-file asMSE.R available on the web-page to this article. For the numerical evaluation of the MSE, we use Algorithms C (more accurate, but slow for larger n) and D (a little inaccurate for small n, but fast) discussed in Ruckdeschel and . For n = \u221e, we evaluate the corresponding f-o as. . MSE for the IC to the corresponding values of c. As a cross-check, the clipping heights c i , i = 0, 1, 2 are also determined for n = 10 8 . In case of c FZY , for all finite n's the error tolerance used in optimize in R was 10 \u22124 , while for n = \u221e it was 10 \u221212 . For c ex and n = 10 8 , an optimization of the (numerically) exact MSE would have been too timeconsuming and has been skipped for this reason. Also, for n = 5, the radius r = 1.0, corresponding to \u03b5 = 0.447, is not admitted for an optimization of (4.16) and thus no result is available in this case.", "cite_spans": [], "ref_spans": [{"start": 29, "end": 36, "text": "Table 2", "ref_id": "TABREF3"}], "section": "A comparison"}, {"text": "In this subsection, we refine the results of Rieder et al. (2008) . In the cited paper, we want to give a guideline to the statistician which procedure to choose if he knows that there is contamination but does not know the radius exactly: To this end, we consider the maximal inefficiency\u03c1(r ) defined as \u03c1 0 (r ) := sup r\u2208(r l ,r u )\u03c1 (r , r),\u03c1(r , r) :=R (\u03b7 c 0 (r ) , r) R(\u03b7 c 0 (r) , r) (5.1) and determine the minimax radius r 0 as minimizer of\u03c1 0 (r ). If one knows at least that the actual radius will lie in an interval [r/\u03b3, r\u03b3] we may determine r \u03b3,r as minimizer of\u03c1 \u03b3 (r , r) = sup s\u2208(r/\u03b3,r\u03b3)\u03c1 (r , s) and denote the corresponding minimax inefficiency by\u03c1 \u03b3 (r). In a second optimizing step we then determine the maximizer r \u03b3 of\u03c1 \u03b3 (r). The unrestricted case is symbolically included by \u03b3 = \u221e. In the Gaussian location case this gives \u03b3 = 0 \u03b3 = 2 \u03b3 = 3 r 0 c 0 (r 0 )\u03c1 0 (r 0 ) r 2 c 0 (r 2 )\u03c1 2 (r 2 ) r 3 c 0 (r 3 )\u03c1 3 (r 3 ) 0.621 0.718 18.07% 0.575 0.769 8.84% 0.549 0.799 4.41%", "cite_spans": [{"start": 45, "end": 65, "text": "Rieder et al. (2008)", "ref_id": "BIBREF9"}], "ref_spans": [], "section": "Minimax radius"}, {"text": "These calculations can easily be translated to the s-o setup setting R 1 (\u03c8, r, n) := r 2 sup |\u03c8| 2 + E \u03c8 2 + r \u221a n A 1 (5.2) so that in this paper we would instead determine r 1 (n) as minimizer of \u03c1 1 (r , r, n), sup r\u2208(r l ,r u ) \u03c1 1 (r , r, n), \u03c1 1 (r , r, n) := R 1 (\u03b7 c 1 (r (n),n) , r, n) R 1 (\u03b7 c 1 (r,n) , r, n) (5.3) respectively \u03c1 1;\u03b3 and instead of\u03c1 \u03b3 . For finite n, however, we have to take into account that r < \u221a n always. Doing so we get Table 3 , showing that there is not much variation in both c 1 (r \u221e , \u00b7), \u03c1 1;\u03b3 (r \u03b3 , \u00b7) for varying n. So if r is completely unknown, it is a good choice to use the M-estimator to Hampel-scores for c \u2248 0.7-you will never have a larger inefficiency than the limiting 18%! Ex post this is one more argument, why the H07-estimate survived in in Sections 7.B.8 and 7.C.4 of the Princeton robustness study (Andrews et al. (1972) ). A table for the corresponding t-o minimax radii is available on the web-page.", "cite_spans": [{"start": 858, "end": 880, "text": "(Andrews et al. (1972)", "ref_id": "BIBREF0"}], "ref_spans": [{"start": 455, "end": 462, "text": "Table 3", "ref_id": "TABREF4"}], "section": "Minimax radius"}, {"text": "In Huber (1997, p. 62) , the author complains \". . . the considerable confusion between the respective roles of diagnostics and robustness. The purpose of robustness is to safeguard against deviations from the assumptions, in particular against those that are near or below the limits of detectability.\" As worked out in Ruckdeschel (2006) , the exact critical rate for these limits may be determined in a statistical way: For some prescribed outlier set OUT, let p 0 and q n = (1 \u2212 r n )p 0 + r n be the probability under the ideal model, and under convex contaminations of radius r n , respectively. Considering the minimax test between these alternatives yields the exact critical rate 1/ \u221a n: under a faster shrinking p 0 cannot be separated from q n at all, while at a slower rate, asymptotically we can separate them without error.", "cite_spans": [{"start": 3, "end": 22, "text": "Huber (1997, p. 62)", "ref_id": null}, {"start": 321, "end": 339, "text": "Ruckdeschel (2006)", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "Innocent-looking risk-maximizing contaminations"}, {"text": "Going one step further, for some given 1/ \u221a n-shrinking neighborhoods of radius r, we would also like to know how \"small\" an outlier may be, while it is still harmful enough to distort the classically optimal procedure in a way that this procedure is beaten by some robust one.", "cite_spans": [], "ref_spans": [], "section": "Innocent-looking risk-maximizing contaminations"}, {"text": "To a fixed radius r, in the preceding sections, we have found/discussed f-o-o and s-oo ICs of Hampel-form with clipping height c j = c j (r[, n]), j = 0, 1. To these ICs we have derived families of contaminations achieving maximal risk onQ n (r). By means of Theorem 2.1(b), these are induced by any contaminating measures P di n under which \u03b7 \u03b8 (X di ) is constantly either b j or \u2212b j for b j = A j c j -up to an event of probability o(n \u22121 ). Out of these risk-maximizing contaminations, let us limit ourselves to those induced by Dirac masses at x:", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "Among these Q n (x), we seek the least \"suspicious\" looking contamination point x in the sense that the region OUT j := [x; \u221e) [or (\u2212\u221e;", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "x)] carries large ideal probability. With this region as outlier set in Ruckdeschel (2006) , values of x (or slightly above in absolute value) occurring more frequently than they should under the ideal situation, are hardest to detect. More precisely, in the general smooth parametric setup (compare Kohl et al. (2010) ), assume that the observations are univariate; let S (b 0 ) n and\u015c n be ALEs to the classical optimal IC\u03b7 = I \u22121 \u039b and the asMSE 0 -optimal IC \u03b7 b 0 , respectively. In this setup we define n , Q n (x)) < asMSE 0 (\u015c n , Q n (x))}", "cite_spans": [{"start": 72, "end": 90, "text": "Ruckdeschel (2006)", "ref_id": "BIBREF10"}, {"start": 300, "end": 318, "text": "Kohl et al. (2010)", "ref_id": "BIBREF6"}], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "x 0,\u2212 := sup{x < 0 asMSE 0 (S (b 0 ) n , Q n (x)) < asMSE 0 (\u015c n , Q n (x))} (5.5) Remark 5.2 (a) The name cniper point is due to H. Rieder; it alludes to the fact that this \"Ianustype\" contamination Q n (x 0 ) pretends to be nice, but to the contrary is in fact pernicious, \"sniping\" off the classically optimal procedure. . .", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "(b) The cniper concept is of course not bound to quadratic loss. In the obvious manor, the concept may be generalized for multivariate observations, if we define any x 0 of minimal absolute as cniper point.", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "(c) To get rid of the dependency upon the radius r, in the examples we will use the minimax radii r \u03b3 (n) defined in the preceding section.", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "Correspondingly, in the setup of this paper and under (2.23), let S n , Q n (x)) < asMSE 1 (\u015c n , Q n (x))}", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "x 1,\u2212 := sup{x < 0 asMSE 1 (S (c 1 ) n , Q n (x)) < asMSE 1 (\u015c n , Q n (x))} n , Q n (x 0 )) is a saddlepoint for the class of all pairs", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "where S n are ALE's to IC's of form (2.8) and Q n \u2208 Q n w.r.t. f-o riskR. Under (2.23), the same holds in the one-dimensional location model for the pair (S (c 1 ) n , Q n (x 1 )) w.r.t. s-o risk inQ(r).", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "Remark 5.5 A sufficient condition for (5.7) is that \u039b(x) = \u2212\u039b(\u2212x): Then for any b > 0, a b = 0 is possible and,", "cite_spans": [], "ref_spans": [], "section": "The Cniper contaminaton"}, {"text": "For numerical evaluations, we consider the Gaussian location model and the Gaussian location and scale model. In both models, x j,+ = \u2212x j,\u2212 , and without loss, we use x j,+ . For the as. . tests between q n = p 0 and q n > p 0 , alluded to in the beginning of this section, we note that", "cite_spans": [], "ref_spans": [], "section": "Error probabilities"}, {"text": "As to the (f-o) as. . minimax test Ruckdeschel (2006, formula (6. 1)) gives as as. . risk", "cite_spans": [{"start": 35, "end": 65, "text": "Ruckdeschel (2006, formula (6.", "ref_id": null}], "ref_spans": [], "section": "Error probabilities"}, {"text": "For s-o asymptotics, we instead use the finite-sample minimax test, i.e. the Neyman-Pearson test with equal Type-I and Type-II error. In our case this is a corresponding randomized binomial test.", "cite_spans": [], "ref_spans": [], "section": "Error probabilities"}, {"text": "In the Gaussian location model, we draw all necessary expressions from Ruckdeschel (2010a, Prop. ) ; in particular, with c 1 = c 1 (n, r \u03b3 ), and A 1 = (2\u03a6(c 1 ) \u2212 1) \u22121 , b 1 = c 1 A 1 , by Theorem 2.1(b), maximizing risk amounts to either X di > c 1 always or X di < \u2212c 1 always. The classically optimal estimator is the arithmetic mean, and one easily calculates E Q n (x) [x 2 n K = k] = 1 n 2 [k 2 x 2 + (n \u2212 k)] (5.11) and integrating out K we get directly", "cite_spans": [{"start": 71, "end": 98, "text": "Ruckdeschel (2010a, Prop. )", "ref_id": null}], "ref_spans": [], "section": "Gaussian location"}, {"text": "Combining this with formulas (2.17) and (4.1), for M 0 := asMSE 0 (S (c 1 ) n ) we get This yields the results as in Table 4 . We include the type-II error 1 \u2212 \u03b2(\u03b1) for the Neyman Pearson test to niveau \u03b1 = 5% and the risk \u03b5 n of the corresponding minimax test; roughly speaking we cannot do better than overlooking one of 10 contaminations at niveau 5% ideal observations to be falsely marked as outliers, and, equally weighting the two error types we cannot do better than with a false classification rate of 7% for each error type.", "cite_spans": [], "ref_spans": [{"start": 117, "end": 124, "text": "Table 4", "ref_id": "TABREF5"}], "section": "Gaussian location"}, {"text": "To give one more example, consider the one-dimensional location-scale model at central distribution N(0, 1). For this model we have not yet established a s-o as. . theory; for f-o asymptotics, however, we may use R-programs from the bundle RobASt, cf. Kohl (2005, Appendix D) , and get r \u221e = 0.579, max Q n \u2208Q n (r \u221e ) asMSE(\u03b7 \u03b8;0 , Q n ) = 3.123 (5.15) while I \u22121 \u03b8 \u039b \u03b8 = (x, 1 2 (x 2 \u2212 1)) \u03c4 . This gives x 0 = 1.844-and hence \u03b5 \u221e = 5.737% and 1 \u2212 \u03b2 \u221e (5%) = 6.557%. Condition (5.7) is proved to hold in subsection A.6.", "cite_spans": [{"start": 252, "end": 275, "text": "Kohl (2005, Appendix D)", "ref_id": null}], "ref_spans": [], "section": "Gaussian location and scale"}, {"text": "\u223c F, i = 1, . . . , n be real-valued random variables, |\u03be i | \u2264 1 Then for \u00b5 = E[\u03be 1 ] and 0 < \u03b5 < 1 \u2212 \u00b5 Hoeffding (1963) , Thm. 1, inequality (2.1).", "cite_spans": [{"start": 105, "end": 121, "text": "Hoeffding (1963)", "ref_id": "BIBREF3"}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "To settle case (II) in the proof of Theorem 3.1, we need the following sharpening of Ruckdeschel (2010b, Lem. A.2) Lemma A.2 Let k 1 (n) = 1 + d n and assume that for some \u03b4 \u2208 (0, 1/4),", "cite_spans": [{"start": 85, "end": 114, "text": "Ruckdeschel (2010b, Lem. A.2)", "ref_id": null}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Then if lim inf n d n > 0 there is some c > 0 such that", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "and, if d n = o(n 0 ), for any 0 < \u03b4 0 \u2264 2\u03b4, it holds that", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Remark A.3 Even if d n is increasing at a faster rate than n 1/2 , assertion (A.3) remains true, as long as lim inf n d n > 0-but this is not needed here.", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Proof Let", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Then K n > 0, as log(x) > 0 for x > 1 and By the second assumption in (A.2), d n = o( \u221a n ), so 0 < d n r/ \u221a n < 1 \u2212 r/ \u221a n eventually in n and Hoeffding's Lemma A.1 is available; applying it to the case of n independent Bin(1, p) variables, we obtain for B n \u223c Bin(n, p n ), p n = r/ \u221a n and \u03b5 = (k 1 (n) \u2212 1)r/ \u221a n (which is smaller than 1 \u2212 p n eventually)", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "If lim inf n d n > 0, by (A.5) lim inf n K n > 0, and for any 0 < c < lim inf n K n , (A.3) follows. If d n = o(n 0 ), we note that", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "which for any \u03b4 > 0 entails Pr(Bin(n, r/ \u221a n ) > k 1 (n)r \u221a n ) = o exp \u2212 rd 2 n \u221a n 2 + \u03b4 Now for d n = o(n 0 ), by the first assumption in (A.2), for 0 < \u03b4 0 < 2\u03b4 eventually in n, (A.4) holds as", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Another consequence of the exponential decay of (A.3)/(A.4) is that we may neglect values of K > k 1 (n)r \u221a n when integrating along K.", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Corollary A.4 Let K \u223c Bin(n, r/ \u221a n ). Then, in the setup of Lemma A.2, for any j \u2208 N,", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "for any 0 < d < \u221a n if lim inf n d n > 0 and any 0 < d \u2264 \u03b4 0 if lim n d n = 0.", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "A.2 Proof of Theorem 3.1", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "In the risk, we have to treat stochastic arguments in \u03a6, \u03d5; this is settled in the following lemma:", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Lemma A.5 Let F : R \u2192 R be twice differentiable with H\u00f6lder-continuous second derivative and G : R \u2192 R be differentiable with H\u00f6lder-continuous derivative. Then there is a sequence k 1 (n) = 1+d n with d n \u2192 0 according to (A.2) and some \u03b7 > 0, such that for all x, \u03b2 \u2208 R and withk = K/ \u221a n,", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "and", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Proof Using the Taylor approximation of log(1 + x), we get for n sufficiently large", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "By (A.4) of Lemma A.2, for some \u03b4 0 and eventually in n we have P(K > k 1 (n)r \u221a n ) \u2264 exp(\u2212rn \u03b4 0 ), and by the same argument we also get that P(K < (2 \u2212 k 1 (n))r \u221a n ) \u2264 exp(\u2212rn \u03b4 0 ). Hence,", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Thus, as F, G are bounded, the contribution of the set {|k \u2212 r| > rd n } decays exponentially, while on the complement we have a uniformly bounded Taylor expansion up to order 2 respectively 1 for the integrands:", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Integrating these expansions out ink, we see that the first contribution to the Taylor series for F is the quadratic term, which is F (x + \u03b2r) \u03b2 2 2 Vark, and the remainder is o(n \u22121/2 ). For G, the first contribution to the error term is the remainder, hence of form const|k \u2212 r| 1+\u03b7 . By the H\u00f6lder inequality this gives a bound const [Vark] 1+\u03b7 2 = O(n \u2212(1+\u03b7)/4 ). For the proof of Theorem 3.1, we use a tableau like the one of Ruckdeschel (2010a, p. 19) , i.e., to derive the result, we partition the integrand according to K < k 1 (n)r \u221a n k 1 (n)r \u221a n \u2264 K < \u03b5 0 n |t| \u2264 k 2 b 2 log(n)/n (I)", "cite_spans": [{"start": 337, "end": 343, "text": "[Vark]", "ref_id": null}, {"start": 431, "end": 457, "text": "Ruckdeschel (2010a, p. 19)", "ref_id": null}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "with k 1 (n) according to (A.2) . This time, no integration w.r.t. t is needed, so case (IV) from Ruckdeschel (2010a) may be canceled, which is why we may dispense of assumption (Pd) and pass to the unrestricted neighborhoods Q n . Cases (II) and (III) may be taken over unchanged from Ruckdeschel (2010a, Proof of Thm. 3.5), so we may confine us to case (I):", "cite_spans": [{"start": 26, "end": 31, "text": "(A.2)", "ref_id": null}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "We use \u03b1 1 , \u03b1 2 from (3.2) and proceed paralleling the proof in Ruckdeschel (2010a) and get from formula (A.18) therein that Pr(S n \u2264 \u2212 \u03b1 1 \u221a n | D k,t ) =G n ( \u2212 \u03b1 1 \u221a n ) + O(n \u22123/2 ). So we have to spell out s n,k ( \u2212\u03b1 1 \u221a n ), which gives", "cite_spans": [{"start": 65, "end": 84, "text": "Ruckdeschel (2010a)", "ref_id": "BIBREF10"}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "and hence-settings = s n,k ( \u2212\u03b1 1 \u221a n ) ands 1 = \u2212(\u03b1 1 + t )/v 0 as in Ruckdeschel (2010a) Pr", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "This term is maximized eventually in n, if \u2212t is maximal or, essentially equivalent, all contaminating mass (up to mass o(n \u22121/2 )) is concentrated left ofy n from Section 2.2, and then t = k b , and after the substitution according tok := k/ \u221a n, k := k/ \u221an , this gives withs k = \u2212(\u03b1 1 +kb)/v 0 Pr(S n \u2264 \u2212 \u03b1 1 \u221a n | D k,t=kb ) = \u03a6(s k ) + \u03d5(s k ) 2 \u221a nv 0 [\u03b1 1k \u2212 l 2 \u03b1 2 1 \u2212 2s k v 0\u1e7d1 \u03b1 1 \u2212 v 0 \u03c1 0 3 (s 2 k \u2212 1) \u2212k 2b ] + o( 1 \u221a n ) (A.14)", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Now, by (3.6), it holds that s 1 = \u2212(\u03b1 1 + rb)/v 0 , so that by an application of Lemma A.5, for Q 0 n; \u2212 any sequence of measures according to (2.20) A.4 Proof of Proposition 4.3", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "We apply Rieder (1994, Theorem 1.4 .7) to the derivatives; this theorem says that for \u03b7 \u2208 C 1 (R) with \u03b7(\u03b8 0 ) = 0, \u03b7 (\u03b8 0 ) 0 for some \u03b8 0 \u2208 R, there exists an open neighborhood V 0 \u2282 C 1 (R) such that for every open, connected neighborhood V \u2282 V 0 of \u03b7 there is a unique, continuous map T : V \u2192 R with", "cite_spans": [{"start": 9, "end": 34, "text": "Rieder (1994, Theorem 1.4", "ref_id": null}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "even more so, T is continuously bounded differentiable on V with derivative at tangent h", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "Hence there is an open neighborhood V 0;F of F such that for each connected open neighborhood V F \u2282 V 0;F , we get a unique, continuously bounded differentiable map T : V F \u2192 R with", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "But by assumption (4.5) from some n on, F n and G n will lie in V 0;F , and setting x n = T (F n ), by (A.21) F n (x n ) = 0, and |x n \u2212 x 0 | = |T (F n ) \u2212 T (F)| \u2264 |F n (x 0 )|/F (x 0 ) = O(n \u2212\u03b2 ) which is (b); again by (4.5),", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "In particular, eventually in n, F n (x n ) > 0 and hence x n is a minimum of F, so (a) is shown. By (4.5), sup x |F \u2212 G n | + |F \u2212 G n | + |F \u2212 G n | = O(n \u2212\u03b2 ), so (c) follows just as (a). For (d) we note", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "To show (e), we introduce d n := y n \u2212 x n and write 0 \u2264 G n (x n ) \u2212 G n (y n ) = G n (y n )d n + G n (y n )d 2 n /2 + o(d 2 n ) = ( f 2 + o(n 0 ))d 2 n /2 + o(d 2 n ) = O(n \u22122\u03b2 ) (A.22)", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "A.6 Proof for (5.7) in the Gaussian location scale model", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "We abbreviate the location and scale parts by indices l and s respectively. By equivariance we may limit ourselves to the case \u03b8 = (0, 1) \u03c4 . Due to symmetry, A = A(b) from (2.8) is diagonal for all b with elements A l and A s and we may write", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "The centering z s (b) after the clipping is necessary, as the scale part is not skew symmetric; in the pure scale case (with known \u03b8 l ), the corresponding centering z s = z s (b) is antitone in b, because \u039b s is monotone in x 2 : It decreases from 0 to [\u03a6 \u22121 (3/4)] 2 \u2212 1 \u22120.545 =:\u017e. In the combined case, we never reach this extremal case due to the additional location part-compare Kohl (2005, Remark 8.2 .1(a)) wherez s =\u0101 sc /\u1fb1 \u2212 1 \u22120.530; in any case, z s > \u22121 always. Hence in particular, for x 0 = 1.844 and b such that .28) and thus in particular,", "cite_spans": [{"start": 385, "end": 407, "text": "Kohl (2005, Remark 8.2", "ref_id": null}, {"start": 528, "end": 532, "text": ".28)", "ref_id": null}], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}, {"text": "s (x 0 )| 2 + A 0;l (b)x 2 0 >\u03b7 s (x 0 ) 2 + I \u22122 l x 2 0 = |\u03b7(x 0 )| 2 (A.29)", "cite_spans": [], "ref_spans": [], "section": "A.1 A Hoeffding Bound"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Robust estimates of location. Survey and advances", "authors": [{"first": "D", "middle": ["F"], "last": "Andrews", "suffix": ""}, {"first": "P", "middle": ["J"], "last": "Bickel", "suffix": ""}, {"first": "F", "middle": ["R"], "last": "Hampel", "suffix": ""}, {"first": "P", "middle": ["J"], "last": "Huber", "suffix": ""}, {"first": "W", "middle": ["H"], "last": "Rogers", "suffix": ""}, {"first": "J", "middle": ["W"], "last": "Tukey", "suffix": ""}], "year": 1972, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "The notion of breakdown point", "authors": [{"first": "D", "middle": ["L"], "last": "Donoho", "suffix": ""}, {"first": "P", "middle": ["J"], "last": "Huber", "suffix": ""}], "year": 1983, "venue": "Festschr. for Erich L. Lehmann", "volume": "", "issn": "", "pages": "157--184", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Optimal robust M-estimates of location", "authors": [{"first": "R", "middle": [], "last": "Fraiman", "suffix": ""}, {"first": "V", "middle": ["J"], "last": "Yohai", "suffix": ""}, {"first": "R", "middle": ["H"], "last": "Zamar", "suffix": ""}], "year": 2001, "venue": "Ann. Stat", "volume": "29", "issn": "1", "pages": "194--223", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Probability inequalities for sums of bounded random variables", "authors": [{"first": "W", "middle": [], "last": "Hoeffding", "suffix": ""}], "year": 1963, "venue": "J. Am. Stat. Assoc", "volume": "58", "issn": "", "pages": "13--30", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Robust confidence limits", "authors": [{"first": "P", "middle": ["J"], "last": "Huber", "suffix": ""}], "year": 1968, "venue": "Robust statistics. Wiley Series in Probability and Mathematical Statistics", "volume": "10", "issn": "", "pages": "269--278", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Numerical contributions to the asymptotic theory of robustness. Dissertation", "authors": [{"first": "M", "middle": [], "last": "Kohl", "suffix": ""}], "year": 2005, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Infinitesimally robust estimation in general smoothly parametrized models. Statistical Methods and Applications", "authors": [{"first": "M", "middle": [], "last": "Kohl", "suffix": ""}, {"first": "P", "middle": [], "last": "Ruckdeschel", "suffix": ""}, {"first": "H", "middle": [], "last": "Rieder", "suffix": ""}], "year": 2010, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"DOI": ["10.1007/s10260-010-0133-0"]}}, "BIBREF7": {"ref_id": "b7", "title": "First order efficiency implies second order efficiency", "authors": [{"first": "J", "middle": [], "last": "Pfanzagl", "suffix": ""}], "year": 1979, "venue": "Contributions to statistics", "volume": "", "issn": "", "pages": "167--196", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Estimates derived from robust tests", "authors": [], "year": 1980, "venue": "R: A language and environment for statistical computing. R Foundation for Statistical Computing", "volume": "8", "issn": "", "pages": "106--115", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "The costs of not knowing the radius. Statistical Methods and Applications", "authors": [{"first": "H", "middle": [], "last": "Rieder", "suffix": ""}, {"first": "M", "middle": [], "last": "Kohl", "suffix": ""}, {"first": "P", "middle": [], "last": "Ruckdeschel", "suffix": ""}], "year": 2008, "venue": "", "volume": "17", "issn": "", "pages": "13--40", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "A motivation For 1/ \u221a n-Shrinking-Neighborhoods?", "authors": [{"first": "P", "middle": [], "last": "Ruckdeschel", "suffix": ""}], "year": 2006, "venue": "Higher Order Asymptotics for the MSE of M-Estimators on Shrinking Neighborhoods", "volume": "63", "issn": "", "pages": "295--307", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Higher Order Asymptotics for the MSE of the Median on Shrinking Neighborhoods. Sumbitted; ArXiV Nr", "authors": [], "year": 2010, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Computation of the Finite Sample Risk of M-Estimators on Neighborhoods", "authors": [{"first": "P", "middle": [], "last": "Ruckdeschel", "suffix": ""}, {"first": "M", "middle": [], "last": "Kohl", "suffix": ""}], "year": 2010, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "Optimal influence curves for general loss functions", "authors": [{"first": "P", "middle": [], "last": "Ruckdeschel", "suffix": ""}, {"first": "H", "middle": [], "last": "Rieder", "suffix": ""}], "year": 2004, "venue": "Stat. Decis", "volume": "22", "issn": "", "pages": "201--223", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Assume a symmetric model (2.1) with increasing \u039b f and (2.2). Under the assumptions of this section, the s-o-o M-estimator in class S 2 has an IC of Hampel-type (2.9) with z = 0 and the s-o-o clipping height c 1 = c 1 (n) is determined by", "latex": null, "type": "figure"}, "FIGREF1": {"text": "The mapping r \u2192 \u2206relMSE(r; \u03c1) for F = N(0, 1) and for \u03c1 = 0.1.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "The mapping r \u2192 asMSE i[,n] (\u03b7 c j (r[,n]) , r[, n]) for i = 0, 1, 2, j = 0, i, n = 30 and F = N(The mapping r \u2192 c j (r[, n]) for j = 0, 1, 2 and n = 30 and F = N(0, 1)4.4 Comparison with the approach byFraiman et al. (2001)", "latex": null, "type": "figure"}, "FIGREF3": {"text": "The f-o cniper point x 0 is defined as x 0,+ if x 0,+ \u2265 \u2212x 0,\u2212 and x 0,\u2212", "latex": null, "type": "figure"}, "FIGREF4": {"text": "The s-o cniper point x 1 is defined as x 1,+ if x 1,+ \u2265 \u2212x 1,\u2212 and x 1,\u2212", "latex": null, "type": "figure"}, "TABREF1": {"text": "1 (c) be the f-o as. . MSE and the corresponding s-o correction term for the Hampel-IC with clipping height c. Then we may write for the f-o [s-o] relative risk relMSE 0 (c, r) [relMSE 1 (c, r, n)] w.r.t. the corresponding risk of the f-o-o procedure", "latex": null, "type": "table"}, "TABREF2": {"text": "", "latex": null, "type": "table"}, "TABREF3": {"text": "Optimal clipping heights and corresponding (numerically) exact MSE", "latex": null, "type": "table", "html": "<html><body><table><tr><td>r </td><td>\u00a0</td><td>n = 5 </td><td>n = 10 </td><td>n = 30 </td><td>n = 50 </td><td>n = 100 </td><td>n = \u221e\n</td></tr><tr><td>c0 </td><td>1.948 </td><td>1.948 </td><td>1.948 </td><td>1.948 </td><td>1.948 </td><td>1.948\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c0) </td><td>8.679% </td><td>4.065% </td><td>1.340% </td><td>0.836% </td><td>0.448% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c1 </td><td>1.394 </td><td>1.484 </td><td>1.611 </td><td>1.663 </td><td>1.724 </td><td>1.948\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c1) </td><td>0.833% </td><td>0.207% </td><td>0.027% </td><td>0.014% </td><td>0.010% </td><td>-\n</td></tr><tr><td>0.1\n</td><td>c2 </td><td>1.309 </td><td>1.428 </td><td>1.585 </td><td>1.644 </td><td>1.713 </td><td>1.948\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c2) </td><td>0.332% </td><td>0.066% </td><td>0.008% </td><td>0.004% </td><td>0.006% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cFZY </td><td>1.368 </td><td>1.370 </td><td>1.610 </td><td>1.668 </td><td>1.756 </td><td>1.939\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (cFZY) </td><td>0.658% </td><td>0.002% </td><td>0.026% </td><td>0.021% </td><td>0.031% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cex </td><td>1.167 </td><td>1.358 </td><td>1.560 </td><td>1.630 </td><td>1.704 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>MSEn(cex) </td><td>1.388 </td><td>1.239 </td><td>1.151 </td><td>1.129 </td><td>1.107 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c0 </td><td>1.339 </td><td>1.339 </td><td>1.339 </td><td>1.339 </td><td>1.339 </td><td>1.339\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c0) </td><td>6.280% </td><td>3.681% </td><td>1.108% </td><td>0.656% </td><td>0.330% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c1 </td><td>0.994 </td><td>1.059 </td><td>1.147 </td><td>1.181 </td><td>1.219 </td><td>1.339\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c1) </td><td>0.933% </td><td>0.415% </td><td>0.055% </td><td>0.023% </td><td>0.009% </td><td>-\n</td></tr><tr><td>0.25\n</td><td>c2 </td><td>0.890 </td><td>0.990 </td><td>1.114 </td><td>1.159 </td><td>1.207 </td><td>1.339\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c2) </td><td>0.241% </td><td>0.104% </td><td>0.009% </td><td>0.002% </td><td>0.003% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cFZY </td><td>0.924 </td><td>1.020 </td><td>1.205 </td><td>1.177 </td><td>1.211 </td><td>1.338\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (cFZY) </td><td>0.417% </td><td>0.215% </td><td>0.233% </td><td>0.018% </td><td>0.002% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cex </td><td>0.783 </td><td>0.921 </td><td>1.092 </td><td>1.140 </td><td>1.205 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>MSEn(cex) </td><td>2.225 </td><td>1.705 </td><td>1.438 </td><td>1.381 </td><td>1.330 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c0 </td><td>0.862 </td><td>0.862 </td><td>0.862 </td><td>0.862 </td><td>0.862 </td><td>0.862\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c0) </td><td>2.930% </td><td>2.655% </td><td>0.792% </td><td>0.446% </td><td>0.218% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c1 </td><td>0.650 </td><td>0.690 </td><td>0.746 </td><td>0.767 </td><td>0.790 </td><td>0.862\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c1) </td><td>0.756% </td><td>0.615% </td><td>0.087% </td><td>0.036% </td><td>0.013% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c2 </td><td>0.547 </td><td>0.620 </td><td>0.712 </td><td>0.744 </td><td>0.777 </td><td>0.862\n</td></tr><tr><td>0.5\n</td><td>relMSEexn (c2) </td><td>0.230% </td><td>0.191% </td><td>0.015% </td><td>0.008% </td><td>0.003% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cFZY </td><td>0.539 </td><td>0.632 </td><td>0.716 </td><td>0.749 </td><td>0.782 </td><td>0.866\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (cFZY) </td><td>0.200% </td><td>0.248% </td><td>0.021% </td><td>0.011% </td><td>0.008% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cex </td><td>0.413 </td><td>0.531 </td><td>0.686 </td><td>0.728 </td><td>0.770 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>MSEn(cex) </td><td>4.632 </td><td>3.039 </td><td>2.162 </td><td>2.008 </td><td>1.879 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c0 </td><td>0.436 </td><td>0.436 </td><td>0.436 </td><td>0.436 </td><td>0.436 </td><td>0.436\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c0) </td><td>2.716% </td><td>3.132% </td><td>0.746% </td><td>0.348% </td><td>0.149% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>c1 </td><td>0.320 </td><td>0.340 </td><td>0.369 </td><td>0.380 </td><td>0.394 </td><td>0.436\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c1) </td><td>1.411% </td><td>1.610% </td><td>0.251% </td><td>0.076% </td><td>0.021% </td><td>-\n</td></tr><tr><td>1.0\n</td><td>c2 </td><td>0.255 </td><td>0.291 </td><td>0.342 </td><td>0.361 </td><td>0.382 </td><td>0.436\n</td></tr><tr><td>\u00a0</td><td>relMSEexn (c2) </td><td>0.876% </td><td>0.999% </td><td>0.123% </td><td>0.027% </td><td>0.006% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cFZY </td><td>- </td><td>0.281 </td><td>0.344 </td><td>0.375 </td><td>0.387 </td><td>0.440\n</td></tr><tr><td>\u00a0</td><td>relMSEexn </td><td>(cFZY) - </td><td>0.892% </td><td>0.132% </td><td>0.063% </td><td>0.012% </td><td>-\n</td></tr><tr><td>\u00a0</td><td>cex </td><td>0.001 </td><td>0.125 </td><td>0.286 </td><td>0.334 </td><td>0.366 </td><td>-\n</td></tr><tr><td>\u00a0</td><td>MSEn(cex) </td><td>12.627 </td><td>8.445 </td><td>4.948 </td><td>4.296 </td><td>3.787 </td><td>-\n</td></tr></table></body></html>"}, "TABREF4": {"text": "Minimax radii for second order asymptotics", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>\u00a0</td><td>n = 5 </td><td>n = 10 </td><td>n = 30 </td><td>n = 50 </td><td>n = 100 </td><td>n = \u221e\n</td></tr><tr><td>\u00a0</td><td>r\u03b3 </td><td>0.390 </td><td>0.449 </td><td>0.514 </td><td>0.536 </td><td>0.559 </td><td>0.621\n</td></tr><tr><td>\u03b3 = 0 </td><td>c1(r\u03b3) </td><td>0.776 </td><td>0.749 </td><td>0.729 </td><td>0.725 </td><td>0.722 </td><td>0.718\n</td></tr><tr><td>\u00a0</td><td>\u03c11;\u03b3(r\u03b3) </td><td>16.27% </td><td>17.08% </td><td>17.71% </td><td>17.85% </td><td>17.96% </td><td>18.07%\n</td></tr><tr><td>\u03b3 = 3 </td><td>r\u03b3 </td><td>0.481 </td><td>0.496 </td><td>0.518 </td><td>0.524 </td><td>0.534 </td><td>0.548\n</td></tr><tr><td>c1(r\u03b3) </td><td>0.670 </td><td>0.694 </td><td>0.724 </td><td>0.739 </td><td>0.750 </td><td>0.800\n</td></tr><tr><td>\u00a0</td><td>\u03c11;\u03b3(r\u03b3) </td><td>6.213% </td><td>6.773% </td><td>7.490% </td><td>7.751% </td><td>8.036% </td><td>8.836%\n</td></tr><tr><td>\u03b3 = 2 </td><td>r\u03b3 </td><td>0.540 </td><td>0.552 </td><td>0.564 </td><td>0.563 </td><td>0.571 </td><td>0.574\n</td></tr><tr><td>c1(r\u03b3) </td><td>0.609 </td><td>0.637 </td><td>0.675 </td><td>0.695 </td><td>0.707 </td><td>0.770\n</td></tr><tr><td>\u00a0</td><td>\u03c11;\u03b3(r\u03b3) </td><td>2.987% </td><td>3.297% </td><td>3.692% </td><td>3.834% </td><td>3.988% </td><td>4.410%\n</td></tr></table></body></html>"}, "TABREF5": {"text": "Minimax contamination at \u03b3 = 0", "latex": null, "type": "table", "html": "<html><body><table><tr><td>n </td><td>5 </td><td>10 </td><td>30 </td><td>50 </td><td>100 </td><td>200 </td><td>300 </td><td>\u221e\n</td></tr><tr><td>r\u03b3(n) </td><td>0.390 </td><td>0.449 </td><td>0.514 </td><td>0.536 </td><td>0.559 </td><td>0.576 </td><td>0.584 </td><td>0.621\n</td></tr><tr><td>c1(r\u03b3, n) </td><td>0.776 </td><td>0.749 </td><td>0.729 </td><td>0.725 </td><td>0.722 </td><td>0.720 </td><td>0.719 </td><td>0.718\n</td></tr><tr><td>x1(n) </td><td>2.931 </td><td>2.470 </td><td>2.101 </td><td>2.004 </td><td>1.914 </td><td>1.853 </td><td>1.826 </td><td>1.714\n</td></tr><tr><td>1 \u2212 \u03b2n(0.05) </td><td>0.364 </td><td>0.272 </td><td>0.215 </td><td>0.183 </td><td>0.162 </td><td>0.133 </td><td>0.132 </td><td>0.101\n</td></tr><tr><td>\u03b5n </td><td>0.277 </td><td>0.178 </td><td>0.129 </td><td>0.115 </td><td>0.097 </td><td>0.089 </td><td>0.086 </td><td>0.072\n</td></tr></table></body></html>"}}, "back_matter": [{"text": " .15) and analogously for Q 0 n;A.3 Proof of Corollary 4.2The assumptions of Theorem 4.1 are clearly fullfilled. Hence we may start with the verification (4.3):and hence, dividing both sides of (4.2) by 2\u00c2v 0 , we get the assertion. The LHS of (4.3) (with or without factor 1 + r 2 +1 r 2 +r \u221a n ) is isotone, the RHS antitone in c. Thus if we insert the factor to correct the f-o-o clipping height c 0 to c 1 (n), the factor increases the LHS without affecting the RHS. This can only be compensated for by a decrease of c 0 to c 1 (n). If h(c) is differentiable in c 0 with derivative h (c 0 ), (4.4) is an application of the applying the implicit function theorem: Let G(s, c) := r 2 c (1 + s) \u2212 h(c). Then G(0, c 0 ) = 0. Hence for s = (r 2 + 1)/(r 2 + r \u221a n ), up to o(n \u22121/2 ),A.5 Proof of Proposition 5.4We show that under the assumptions of this proposition x j indeed defines a \"uniformly bad contamination\" in the sense that for the fixed contamination Q n (x j ) asMSE 0 (S (b 0 ) n , Q n (x 0 )) = min b>0 asMSE 0 (S (b) n , Q n (x 0 )) (A.23) resp. asMSE 1 (S (c 1 ) n , Q n (x 1 )) = min c>0 asMSE 1 (S (c) n , Q n (x 1 )) In case j = 0, as in the setup of Rieder (1994, chap. 5) , we obtain asMSE 0 (S (b) n , Q n (x 0 )) = tr Cov id (\u03b7 b ) + r 2 |\u03b7 b (x 0 )| 2 , asMSE 0 (\u015c n , Q n (x 0 )) = tr I + r 2 |\u03b7(x 0 )| 2 (A.24) Now for given x 0 , either |\u03b7 (b) (x 0 )| < b or |\u03b7 (b) (x 0 )| = b. In the first case, (5.7) applies and hence asMSE 0 (S (b 0 ) n , Q n (x 0 )) \u2265 asMSE 0 (\u015c n , Q n (x 0 )) (A.25)In the latter, Q n (x 0 ) already achieves maximal as. . risk for S (b) n on Q n , and hence by minimaxity of S (b 0 ) n asMSE 0 (S (b) n , Q n (x 0 )) \u2265 asMSE 0 (S (b 0 ) n , Q n (x 0 )) (A.26)For the case j = 1 one argues in an analogue way.", "cite_spans": [{"start": 1, "end": 5, "text": ".15)", "ref_id": null}, {"start": 1170, "end": 1192, "text": "Rieder (1994, chap. 5)", "ref_id": null}, {"start": 1216, "end": 1219, "text": "(b)", "ref_id": null}], "ref_spans": [], "section": "annex"}]}